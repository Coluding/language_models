dataset_config:
  tokenizer_path: "/data/language_models/tokenizers/finlm-wordpiece-tokenizer.json"
  max_sequence_length: 256
  db_name: "/data/finlm_sequences/finlm_chunks.sqlite"
  batch_size: 128
  database_retrieval:
    form_tenk:
      limit: 128
      offset: 0
    form_eightk:
      limit: 128
      offset: 0
    earning_calls:
      limit: 128
      offset: 0
    tr_news: 
      limit: 128
      offset: 0 
model_config:
  embedding_size: 256
  hidden_size: 256
  num_hidden_layers: 12
  num_attention_heads: 4
optimization_config:
  learning_rate: 0.0001
  n_epochs: 1
  lr_scheduler_warm_up_steps: 1000
  mlm_probability: 0.20
  use_gradient_clipping: True