dataset_config:
  tokenizer_path: "/data/language_models/tokenizers/finlm-wordpiece-tokenizer.json"
  max_sequence_length: 256
  db_name: "/data/finlm_sequences/finlm_chunks_2.sqlite"
  batch_size: 128
  database_retrieval:
    form_tenk:
      limit: 1000
      offset: 0
    form_eightk:
      limit: 1000
      offset: 0
    earning_calls:
      limit: 1000
      offset: 0
    tr_news: 
      limit: 1000
      offset: 0 
    esg_reports:
      limit: 100000
      offset: 0
model_config:
  embedding_size: 128
  hidden_size: 256
  num_hidden_layers: 12
  num_attention_heads: 4
  intermediate_size: 1024
  max_position_embeddings: 256
optimization_config:
  learning_rate: 0.0001
  n_epochs: 10
  lr_scheduler_warm_up_steps: 10000
  mlm_probability: 0.15
  use_gradient_clipping: True
  