2024-08-15 18:04:47,016 : INFO : Counting occurences of labels...
2024-08-15 18:05:17,756 : INFO : Occurence of labels for training data: (array([0, 1]), array([12500, 12500]))
2024-08-15 18:05:47,907 : INFO : Occurence of labels for test data: (array([0, 1]), array([12500, 12500]))
[I 2024-08-15 18:05:47,908] A new study created in memory with name: no-name-760e85e4-9c70-4ecd-b6b5-2d8df97cd0d7
2024-08-15 18:05:47,908 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:05:47,908 : INFO : Starting training for split 1
2024-08-15 18:05:48,177 : INFO : Counting occurences of labels...
2024-08-15 18:06:11,167 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-15 18:06:18,848 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 18:06:19,618 : INFO : Starting epoch 1
2024-08-15 18:06:20,492 : INFO : Current training batch loss: 0.6926 in epoch 1
2024-08-15 18:06:31,163 : INFO : Current training batch loss: 0.6767 in epoch 1
2024-08-15 18:06:41,884 : INFO : Current training batch loss: 0.7867 in epoch 1
2024-08-15 18:06:52,655 : INFO : Current training batch loss: 0.5528 in epoch 1
2024-08-15 18:07:03,460 : INFO : Current training batch loss: 0.5633 in epoch 1
2024-08-15 18:07:14,304 : INFO : Current training batch loss: 0.3064 in epoch 1
2024-08-15 18:07:25,156 : INFO : Current training batch loss: 0.3306 in epoch 1
2024-08-15 18:07:35,993 : INFO : Current training batch loss: 0.3628 in epoch 1
2024-08-15 18:07:46,841 : INFO : Current training batch loss: 0.4320 in epoch 1
2024-08-15 18:07:57,690 : INFO : Current training batch loss: 0.1929 in epoch 1
2024-08-15 18:08:08,545 : INFO : Current training batch loss: 0.2690 in epoch 1
2024-08-15 18:08:19,403 : INFO : Current training batch loss: 0.2862 in epoch 1
2024-08-15 18:08:30,261 : INFO : Current training batch loss: 0.1872 in epoch 1
2024-08-15 18:08:41,128 : INFO : Current training batch loss: 0.1884 in epoch 1
2024-08-15 18:08:52,009 : INFO : Current training batch loss: 0.1795 in epoch 1
2024-08-15 18:09:02,878 : INFO : Current training batch loss: 0.1076 in epoch 1
2024-08-15 18:09:13,762 : INFO : Current training batch loss: 0.2452 in epoch 1
2024-08-15 18:09:24,643 : INFO : Current training batch loss: 0.2140 in epoch 1
2024-08-15 18:09:35,517 : INFO : Current training batch loss: 0.1856 in epoch 1
2024-08-15 18:09:46,388 : INFO : Current training batch loss: 0.3942 in epoch 1
2024-08-15 18:09:57,267 : INFO : Current training batch loss: 0.2369 in epoch 1
2024-08-15 18:10:08,140 : INFO : Current training batch loss: 0.2585 in epoch 1
2024-08-15 18:10:19,027 : INFO : Current training batch loss: 0.2199 in epoch 1
2024-08-15 18:10:29,908 : INFO : Current training batch loss: 0.1906 in epoch 1
2024-08-15 18:10:40,794 : INFO : Current training batch loss: 0.2080 in epoch 1
2024-08-15 18:10:51,683 : INFO : Current training batch loss: 0.1630 in epoch 1
2024-08-15 18:11:02,556 : INFO : Current training batch loss: 0.2186 in epoch 1
2024-08-15 18:11:13,428 : INFO : Current training batch loss: 0.3390 in epoch 1
2024-08-15 18:11:24,311 : INFO : Current training batch loss: 0.1377 in epoch 1
2024-08-15 18:11:35,194 : INFO : Current training batch loss: 0.1677 in epoch 1
2024-08-15 18:11:37,615 : INFO : Epoch finished, average loss over training batches: 0.3290
2024-08-15 18:11:37,920 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:11:37,920 : INFO : Training metrics:
2024-08-15 18:11:37,920 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:11:37,931 : INFO : Accuracy: 0.8486
2024-08-15 18:11:37,931 : INFO : Precision: 0.8506
2024-08-15 18:11:37,931 : INFO : Recall: 0.8446
2024-08-15 18:11:37,931 : INFO : F1 score: 0.8476
2024-08-15 18:12:25,676 : INFO : Average loss over validation batches: 0.2245
2024-08-15 18:12:25,677 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:12:25,677 : INFO : Validation metrics:
2024-08-15 18:12:25,677 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:12:25,682 : INFO : Accuracy: 0.9120
2024-08-15 18:12:25,682 : INFO : Precision: 0.9009
2024-08-15 18:12:25,682 : INFO : Recall: 0.9277
2024-08-15 18:12:25,682 : INFO : F1 score: 0.9141
2024-08-15 18:12:25,682 : INFO : Validation metric decreased (inf --> 0.224527).  Saving model ...
2024-08-15 18:12:25,750 : INFO : Starting epoch 2
2024-08-15 18:12:33,929 : INFO : Current training batch loss: 0.2849 in epoch 2
2024-08-15 18:12:44,802 : INFO : Current training batch loss: 0.2301 in epoch 2
2024-08-15 18:12:55,679 : INFO : Current training batch loss: 0.3186 in epoch 2
2024-08-15 18:13:06,569 : INFO : Current training batch loss: 0.1516 in epoch 2
2024-08-15 18:13:17,450 : INFO : Current training batch loss: 0.1119 in epoch 2
2024-08-15 18:13:28,339 : INFO : Current training batch loss: 0.2387 in epoch 2
2024-08-15 18:13:39,222 : INFO : Current training batch loss: 0.0636 in epoch 2
2024-08-15 18:13:50,103 : INFO : Current training batch loss: 0.0881 in epoch 2
2024-08-15 18:14:00,979 : INFO : Current training batch loss: 0.2046 in epoch 2
2024-08-15 18:14:11,860 : INFO : Current training batch loss: 0.0922 in epoch 2
2024-08-15 18:14:22,746 : INFO : Current training batch loss: 0.0603 in epoch 2
2024-08-15 18:14:33,630 : INFO : Current training batch loss: 0.2256 in epoch 2
2024-08-15 18:14:44,511 : INFO : Current training batch loss: 0.0293 in epoch 2
2024-08-15 18:14:55,396 : INFO : Current training batch loss: 0.0334 in epoch 2
2024-08-15 18:15:06,274 : INFO : Current training batch loss: 0.1610 in epoch 2
2024-08-15 18:15:17,149 : INFO : Current training batch loss: 0.2467 in epoch 2
2024-08-15 18:15:28,026 : INFO : Current training batch loss: 0.1018 in epoch 2
2024-08-15 18:15:38,908 : INFO : Current training batch loss: 0.0721 in epoch 2
2024-08-15 18:15:49,794 : INFO : Current training batch loss: 0.1327 in epoch 2
2024-08-15 18:16:00,669 : INFO : Current training batch loss: 0.3940 in epoch 2
2024-08-15 18:16:11,545 : INFO : Current training batch loss: 0.0664 in epoch 2
2024-08-15 18:16:22,434 : INFO : Current training batch loss: 0.2550 in epoch 2
2024-08-15 18:16:33,310 : INFO : Current training batch loss: 0.0437 in epoch 2
2024-08-15 18:16:44,186 : INFO : Current training batch loss: 0.0392 in epoch 2
2024-08-15 18:16:55,070 : INFO : Current training batch loss: 0.1454 in epoch 2
2024-08-15 18:17:05,956 : INFO : Current training batch loss: 0.0566 in epoch 2
2024-08-15 18:17:16,828 : INFO : Current training batch loss: 0.0652 in epoch 2
2024-08-15 18:17:27,704 : INFO : Current training batch loss: 0.0196 in epoch 2
2024-08-15 18:17:38,583 : INFO : Current training batch loss: 0.0238 in epoch 2
2024-08-15 18:17:44,254 : INFO : Epoch finished, average loss over training batches: 0.1438
2024-08-15 18:17:44,256 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:17:44,256 : INFO : Training metrics:
2024-08-15 18:17:44,256 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:17:44,567 : INFO : Accuracy: 0.9466
2024-08-15 18:17:44,567 : INFO : Precision: 0.9451
2024-08-15 18:17:44,567 : INFO : Recall: 0.9478
2024-08-15 18:17:44,567 : INFO : F1 score: 0.9465
2024-08-15 18:18:32,255 : INFO : Average loss over validation batches: 0.2175
2024-08-15 18:18:32,256 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:18:32,256 : INFO : Validation metrics:
2024-08-15 18:18:32,256 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:18:32,261 : INFO : Accuracy: 0.9202
2024-08-15 18:18:32,261 : INFO : Precision: 0.9153
2024-08-15 18:18:32,261 : INFO : Recall: 0.9277
2024-08-15 18:18:32,261 : INFO : F1 score: 0.9215
2024-08-15 18:18:32,261 : INFO : Validation metric decreased (0.224527 --> 0.217466).  Saving model ...
2024-08-15 18:18:32,349 : INFO : Starting epoch 3
2024-08-15 18:18:37,272 : INFO : Current training batch loss: 0.2626 in epoch 3
2024-08-15 18:18:48,135 : INFO : Current training batch loss: 0.2090 in epoch 3
2024-08-15 18:18:59,005 : INFO : Current training batch loss: 0.0478 in epoch 3
2024-08-15 18:19:09,878 : INFO : Current training batch loss: 0.0179 in epoch 3
2024-08-15 18:19:20,758 : INFO : Current training batch loss: 0.1006 in epoch 3
2024-08-15 18:19:31,630 : INFO : Current training batch loss: 0.0133 in epoch 3
2024-08-15 18:19:42,500 : INFO : Current training batch loss: 0.0346 in epoch 3
2024-08-15 18:19:53,373 : INFO : Current training batch loss: 0.0091 in epoch 3
2024-08-15 18:20:04,241 : INFO : Current training batch loss: 0.0163 in epoch 3
2024-08-15 18:20:15,117 : INFO : Current training batch loss: 0.1700 in epoch 3
2024-08-15 18:20:25,988 : INFO : Current training batch loss: 0.0081 in epoch 3
2024-08-15 18:20:36,859 : INFO : Current training batch loss: 0.1333 in epoch 3
2024-08-15 18:20:47,731 : INFO : Current training batch loss: 0.0123 in epoch 3
2024-08-15 18:20:58,609 : INFO : Current training batch loss: 0.1372 in epoch 3
2024-08-15 18:21:09,487 : INFO : Current training batch loss: 0.0052 in epoch 3
2024-08-15 18:21:20,360 : INFO : Current training batch loss: 0.0059 in epoch 3
2024-08-15 18:21:31,241 : INFO : Current training batch loss: 0.2422 in epoch 3
2024-08-15 18:21:42,122 : INFO : Current training batch loss: 0.0084 in epoch 3
2024-08-15 18:21:53,010 : INFO : Current training batch loss: 0.0041 in epoch 3
2024-08-15 18:22:03,888 : INFO : Current training batch loss: 0.1714 in epoch 3
2024-08-15 18:22:14,776 : INFO : Current training batch loss: 0.0154 in epoch 3
2024-08-15 18:22:25,655 : INFO : Current training batch loss: 0.0096 in epoch 3
2024-08-15 18:22:36,537 : INFO : Current training batch loss: 0.0641 in epoch 3
2024-08-15 18:22:47,419 : INFO : Current training batch loss: 0.0047 in epoch 3
2024-08-15 18:22:58,297 : INFO : Current training batch loss: 0.1182 in epoch 3
2024-08-15 18:23:09,175 : INFO : Current training batch loss: 0.0479 in epoch 3
2024-08-15 18:23:20,059 : INFO : Current training batch loss: 0.1103 in epoch 3
2024-08-15 18:23:30,936 : INFO : Current training batch loss: 0.0098 in epoch 3
2024-08-15 18:23:41,820 : INFO : Current training batch loss: 0.2299 in epoch 3
2024-08-15 18:23:50,747 : INFO : Epoch finished, average loss over training batches: 0.0495
2024-08-15 18:23:50,749 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:23:50,749 : INFO : Training metrics:
2024-08-15 18:23:50,749 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:23:51,058 : INFO : Accuracy: 0.9865
2024-08-15 18:23:51,058 : INFO : Precision: 0.9865
2024-08-15 18:23:51,058 : INFO : Recall: 0.9863
2024-08-15 18:23:51,058 : INFO : F1 score: 0.9864
2024-08-15 18:24:38,735 : INFO : Average loss over validation batches: 0.2462
2024-08-15 18:24:38,736 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:24:38,736 : INFO : Validation metrics:
2024-08-15 18:24:38,736 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:24:38,741 : INFO : Accuracy: 0.9213
2024-08-15 18:24:38,741 : INFO : Precision: 0.9242
2024-08-15 18:24:38,741 : INFO : Recall: 0.9195
2024-08-15 18:24:38,741 : INFO : F1 score: 0.9218
2024-08-15 18:24:38,741 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 18:24:38,741 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 18:24:39,337 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 18:25:25,869 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:25:25,869 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 18:25:25,869 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:25:25,874 : INFO : Accuracy: 0.9202
2024-08-15 18:25:25,874 : INFO : Precision: 0.9153
2024-08-15 18:25:25,874 : INFO : Recall: 0.9277
2024-08-15 18:25:25,874 : INFO : F1 score: 0.9215
2024-08-15 18:25:25,874 : INFO : Determined score from best model, ending training.
2024-08-15 18:25:25,876 : INFO : Split 1 is finished, the score is: 0.9215
2024-08-15 18:25:25,876 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:25:25,876 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:25:25,876 : INFO : Starting training for split 2
2024-08-15 18:25:26,163 : INFO : Counting occurences of labels...
2024-08-15 18:25:49,312 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-15 18:25:57,027 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 18:25:57,521 : INFO : Starting epoch 1
2024-08-15 18:25:58,100 : INFO : Current training batch loss: 0.6885 in epoch 1
2024-08-15 18:26:08,899 : INFO : Current training batch loss: 0.6740 in epoch 1
2024-08-15 18:26:19,727 : INFO : Current training batch loss: 0.6640 in epoch 1
2024-08-15 18:26:30,590 : INFO : Current training batch loss: 0.4903 in epoch 1
2024-08-15 18:26:41,467 : INFO : Current training batch loss: 0.4264 in epoch 1
2024-08-15 18:26:52,324 : INFO : Current training batch loss: 0.2475 in epoch 1
2024-08-15 18:27:03,196 : INFO : Current training batch loss: 0.2221 in epoch 1
2024-08-15 18:27:14,059 : INFO : Current training batch loss: 0.2413 in epoch 1
2024-08-15 18:27:24,929 : INFO : Current training batch loss: 0.2050 in epoch 1
2024-08-15 18:27:35,811 : INFO : Current training batch loss: 0.1724 in epoch 1
2024-08-15 18:27:46,694 : INFO : Current training batch loss: 0.3159 in epoch 1
2024-08-15 18:27:57,576 : INFO : Current training batch loss: 0.3568 in epoch 1
2024-08-15 18:28:08,454 : INFO : Current training batch loss: 0.1651 in epoch 1
2024-08-15 18:28:19,336 : INFO : Current training batch loss: 0.2166 in epoch 1
2024-08-15 18:28:30,228 : INFO : Current training batch loss: 0.1833 in epoch 1
2024-08-15 18:28:41,098 : INFO : Current training batch loss: 0.0790 in epoch 1
2024-08-15 18:28:51,979 : INFO : Current training batch loss: 0.2659 in epoch 1
2024-08-15 18:29:02,859 : INFO : Current training batch loss: 0.1534 in epoch 1
2024-08-15 18:29:13,739 : INFO : Current training batch loss: 0.1648 in epoch 1
2024-08-15 18:29:24,620 : INFO : Current training batch loss: 0.2978 in epoch 1
2024-08-15 18:29:35,508 : INFO : Current training batch loss: 0.2635 in epoch 1
2024-08-15 18:29:46,390 : INFO : Current training batch loss: 0.2260 in epoch 1
2024-08-15 18:29:57,281 : INFO : Current training batch loss: 0.1462 in epoch 1
2024-08-15 18:30:08,163 : INFO : Current training batch loss: 0.2412 in epoch 1
2024-08-15 18:30:19,043 : INFO : Current training batch loss: 0.3286 in epoch 1
2024-08-15 18:30:29,931 : INFO : Current training batch loss: 0.1430 in epoch 1
2024-08-15 18:30:40,806 : INFO : Current training batch loss: 0.2146 in epoch 1
2024-08-15 18:30:51,681 : INFO : Current training batch loss: 0.2986 in epoch 1
2024-08-15 18:31:02,574 : INFO : Current training batch loss: 0.0760 in epoch 1
2024-08-15 18:31:13,461 : INFO : Current training batch loss: 0.3187 in epoch 1
2024-08-15 18:31:15,881 : INFO : Epoch finished, average loss over training batches: 0.3349
2024-08-15 18:31:15,882 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:31:15,882 : INFO : Training metrics:
2024-08-15 18:31:15,882 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:31:16,196 : INFO : Accuracy: 0.8437
2024-08-15 18:31:16,196 : INFO : Precision: 0.8400
2024-08-15 18:31:16,196 : INFO : Recall: 0.8510
2024-08-15 18:31:16,196 : INFO : F1 score: 0.8455
2024-08-15 18:32:03,830 : INFO : Average loss over validation batches: 0.2188
2024-08-15 18:32:03,831 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:32:03,831 : INFO : Validation metrics:
2024-08-15 18:32:03,831 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:32:03,836 : INFO : Accuracy: 0.9136
2024-08-15 18:32:03,836 : INFO : Precision: 0.9120
2024-08-15 18:32:03,836 : INFO : Recall: 0.9126
2024-08-15 18:32:03,836 : INFO : F1 score: 0.9123
2024-08-15 18:32:03,836 : INFO : Validation metric decreased (inf --> 0.218753).  Saving model ...
2024-08-15 18:32:03,920 : INFO : Starting epoch 2
2024-08-15 18:32:12,088 : INFO : Current training batch loss: 0.0822 in epoch 2
2024-08-15 18:32:22,971 : INFO : Current training batch loss: 0.2793 in epoch 2
2024-08-15 18:32:33,846 : INFO : Current training batch loss: 0.1199 in epoch 2
2024-08-15 18:32:44,728 : INFO : Current training batch loss: 0.1993 in epoch 2
2024-08-15 18:32:55,608 : INFO : Current training batch loss: 0.3794 in epoch 2
2024-08-15 18:33:06,488 : INFO : Current training batch loss: 0.2230 in epoch 2
2024-08-15 18:33:17,364 : INFO : Current training batch loss: 0.0845 in epoch 2
2024-08-15 18:33:28,234 : INFO : Current training batch loss: 0.2464 in epoch 2
2024-08-15 18:33:39,106 : INFO : Current training batch loss: 0.1556 in epoch 2
2024-08-15 18:33:49,992 : INFO : Current training batch loss: 0.0615 in epoch 2
2024-08-15 18:34:00,869 : INFO : Current training batch loss: 0.2246 in epoch 2
2024-08-15 18:34:11,753 : INFO : Current training batch loss: 0.1346 in epoch 2
2024-08-15 18:34:22,639 : INFO : Current training batch loss: 0.0631 in epoch 2
2024-08-15 18:34:33,524 : INFO : Current training batch loss: 0.0627 in epoch 2
2024-08-15 18:34:44,409 : INFO : Current training batch loss: 0.0793 in epoch 2
2024-08-15 18:34:55,286 : INFO : Current training batch loss: 0.1690 in epoch 2
2024-08-15 18:35:06,171 : INFO : Current training batch loss: 0.1079 in epoch 2
2024-08-15 18:35:17,056 : INFO : Current training batch loss: 0.0625 in epoch 2
2024-08-15 18:35:27,950 : INFO : Current training batch loss: 0.1255 in epoch 2
2024-08-15 18:35:38,835 : INFO : Current training batch loss: 0.3476 in epoch 2
2024-08-15 18:35:49,727 : INFO : Current training batch loss: 0.1696 in epoch 2
2024-08-15 18:36:00,631 : INFO : Current training batch loss: 0.2013 in epoch 2
2024-08-15 18:36:11,518 : INFO : Current training batch loss: 0.0918 in epoch 2
2024-08-15 18:36:22,405 : INFO : Current training batch loss: 0.0399 in epoch 2
2024-08-15 18:36:33,297 : INFO : Current training batch loss: 0.1344 in epoch 2
2024-08-15 18:36:44,189 : INFO : Current training batch loss: 0.0930 in epoch 2
2024-08-15 18:36:55,063 : INFO : Current training batch loss: 0.0447 in epoch 2
2024-08-15 18:37:05,939 : INFO : Current training batch loss: 0.0210 in epoch 2
2024-08-15 18:37:16,850 : INFO : Current training batch loss: 0.0695 in epoch 2
2024-08-15 18:37:22,520 : INFO : Epoch finished, average loss over training batches: 0.1477
2024-08-15 18:37:22,522 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:37:22,522 : INFO : Training metrics:
2024-08-15 18:37:22,522 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:37:22,835 : INFO : Accuracy: 0.9454
2024-08-15 18:37:22,835 : INFO : Precision: 0.9438
2024-08-15 18:37:22,835 : INFO : Recall: 0.9478
2024-08-15 18:37:22,835 : INFO : F1 score: 0.9458
2024-08-15 18:38:10,468 : INFO : Average loss over validation batches: 0.2240
2024-08-15 18:38:10,468 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:38:10,468 : INFO : Validation metrics:
2024-08-15 18:38:10,469 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:38:10,474 : INFO : Accuracy: 0.9237
2024-08-15 18:38:10,474 : INFO : Precision: 0.9422
2024-08-15 18:38:10,474 : INFO : Recall: 0.9003
2024-08-15 18:38:10,474 : INFO : F1 score: 0.9208
2024-08-15 18:38:10,474 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 18:38:10,474 : INFO : Starting epoch 3
2024-08-15 18:38:15,388 : INFO : Current training batch loss: 0.2473 in epoch 3
2024-08-15 18:38:26,262 : INFO : Current training batch loss: 0.0430 in epoch 3
2024-08-15 18:38:37,181 : INFO : Current training batch loss: 0.1538 in epoch 3
2024-08-15 18:38:48,066 : INFO : Current training batch loss: 0.0553 in epoch 3
2024-08-15 18:38:58,940 : INFO : Current training batch loss: 0.0385 in epoch 3
2024-08-15 18:39:09,813 : INFO : Current training batch loss: 0.0121 in epoch 3
2024-08-15 18:39:20,693 : INFO : Current training batch loss: 0.0107 in epoch 3
2024-08-15 18:39:31,571 : INFO : Current training batch loss: 0.0114 in epoch 3
2024-08-15 18:39:42,444 : INFO : Current training batch loss: 0.0179 in epoch 3
2024-08-15 18:39:53,331 : INFO : Current training batch loss: 0.0238 in epoch 3
2024-08-15 18:40:04,213 : INFO : Current training batch loss: 0.0189 in epoch 3
2024-08-15 18:40:15,085 : INFO : Current training batch loss: 0.0205 in epoch 3
2024-08-15 18:40:25,960 : INFO : Current training batch loss: 0.0372 in epoch 3
2024-08-15 18:40:36,836 : INFO : Current training batch loss: 0.0057 in epoch 3
2024-08-15 18:40:47,713 : INFO : Current training batch loss: 0.0132 in epoch 3
2024-08-15 18:40:58,588 : INFO : Current training batch loss: 0.0157 in epoch 3
2024-08-15 18:41:09,472 : INFO : Current training batch loss: 0.0376 in epoch 3
2024-08-15 18:41:20,451 : INFO : Current training batch loss: 0.0142 in epoch 3
2024-08-15 18:41:31,332 : INFO : Current training batch loss: 0.0150 in epoch 3
2024-08-15 18:41:42,208 : INFO : Current training batch loss: 0.1100 in epoch 3
2024-08-15 18:41:53,096 : INFO : Current training batch loss: 0.0209 in epoch 3
2024-08-15 18:42:04,009 : INFO : Current training batch loss: 0.0287 in epoch 3
2024-08-15 18:42:14,887 : INFO : Current training batch loss: 0.0085 in epoch 3
2024-08-15 18:42:25,769 : INFO : Current training batch loss: 0.0248 in epoch 3
2024-08-15 18:42:36,646 : INFO : Current training batch loss: 0.0282 in epoch 3
2024-08-15 18:42:47,521 : INFO : Current training batch loss: 0.0073 in epoch 3
2024-08-15 18:42:58,403 : INFO : Current training batch loss: 0.0426 in epoch 3
2024-08-15 18:43:09,276 : INFO : Current training batch loss: 0.0110 in epoch 3
2024-08-15 18:43:20,156 : INFO : Current training batch loss: 0.1670 in epoch 3
2024-08-15 18:43:29,079 : INFO : Epoch finished, average loss over training batches: 0.0544
2024-08-15 18:43:29,080 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:43:29,080 : INFO : Training metrics:
2024-08-15 18:43:29,080 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:43:29,393 : INFO : Accuracy: 0.9830
2024-08-15 18:43:29,393 : INFO : Precision: 0.9828
2024-08-15 18:43:29,393 : INFO : Recall: 0.9833
2024-08-15 18:43:29,393 : INFO : F1 score: 0.9831
2024-08-15 18:44:17,077 : INFO : Average loss over validation batches: 0.2493
2024-08-15 18:44:17,078 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:44:17,078 : INFO : Validation metrics:
2024-08-15 18:44:17,078 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:44:17,083 : INFO : Accuracy: 0.9227
2024-08-15 18:44:17,083 : INFO : Precision: 0.9176
2024-08-15 18:44:17,083 : INFO : Recall: 0.9263
2024-08-15 18:44:17,083 : INFO : F1 score: 0.9219
2024-08-15 18:44:17,083 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 18:44:17,083 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 18:44:17,585 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 18:45:04,508 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:45:04,508 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 18:45:04,508 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:45:04,514 : INFO : Accuracy: 0.9136
2024-08-15 18:45:04,514 : INFO : Precision: 0.9120
2024-08-15 18:45:04,514 : INFO : Recall: 0.9126
2024-08-15 18:45:04,514 : INFO : F1 score: 0.9123
2024-08-15 18:45:04,514 : INFO : Determined score from best model, ending training.
2024-08-15 18:45:04,518 : INFO : Split 2 is finished, the score is: 0.9123
2024-08-15 18:45:04,518 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:45:04,518 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:45:04,518 : INFO : Starting training for split 3
2024-08-15 18:45:04,792 : INFO : Counting occurences of labels...
2024-08-15 18:45:28,144 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-15 18:45:36,087 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 18:45:36,517 : INFO : Starting epoch 1
2024-08-15 18:45:37,098 : INFO : Current training batch loss: 0.7448 in epoch 1
2024-08-15 18:45:47,942 : INFO : Current training batch loss: 0.6686 in epoch 1
2024-08-15 18:45:58,792 : INFO : Current training batch loss: 0.6678 in epoch 1
2024-08-15 18:46:09,628 : INFO : Current training batch loss: 0.4405 in epoch 1
2024-08-15 18:46:20,479 : INFO : Current training batch loss: 0.3545 in epoch 1
2024-08-15 18:46:31,330 : INFO : Current training batch loss: 0.2427 in epoch 1
2024-08-15 18:46:42,193 : INFO : Current training batch loss: 0.3107 in epoch 1
2024-08-15 18:46:53,045 : INFO : Current training batch loss: 0.4717 in epoch 1
2024-08-15 18:47:03,906 : INFO : Current training batch loss: 0.2188 in epoch 1
2024-08-15 18:47:14,786 : INFO : Current training batch loss: 0.2049 in epoch 1
2024-08-15 18:47:25,663 : INFO : Current training batch loss: 0.2420 in epoch 1
2024-08-15 18:47:36,539 : INFO : Current training batch loss: 0.1911 in epoch 1
2024-08-15 18:47:47,417 : INFO : Current training batch loss: 0.4218 in epoch 1
2024-08-15 18:47:58,304 : INFO : Current training batch loss: 0.2277 in epoch 1
2024-08-15 18:48:09,195 : INFO : Current training batch loss: 0.3955 in epoch 1
2024-08-15 18:48:20,077 : INFO : Current training batch loss: 0.2535 in epoch 1
2024-08-15 18:48:30,995 : INFO : Current training batch loss: 0.4012 in epoch 1
2024-08-15 18:48:41,880 : INFO : Current training batch loss: 0.2626 in epoch 1
2024-08-15 18:48:52,747 : INFO : Current training batch loss: 0.1669 in epoch 1
2024-08-15 18:49:03,621 : INFO : Current training batch loss: 0.2831 in epoch 1
2024-08-15 18:49:14,499 : INFO : Current training batch loss: 0.1339 in epoch 1
2024-08-15 18:49:25,373 : INFO : Current training batch loss: 0.2768 in epoch 1
2024-08-15 18:49:36,259 : INFO : Current training batch loss: 0.3114 in epoch 1
2024-08-15 18:49:47,139 : INFO : Current training batch loss: 0.2088 in epoch 1
2024-08-15 18:49:58,021 : INFO : Current training batch loss: 0.1957 in epoch 1
2024-08-15 18:50:08,907 : INFO : Current training batch loss: 0.1561 in epoch 1
2024-08-15 18:50:19,768 : INFO : Current training batch loss: 0.2702 in epoch 1
2024-08-15 18:50:30,628 : INFO : Current training batch loss: 0.4768 in epoch 1
2024-08-15 18:50:41,512 : INFO : Current training batch loss: 0.1254 in epoch 1
2024-08-15 18:50:52,387 : INFO : Current training batch loss: 0.1778 in epoch 1
2024-08-15 18:50:54,798 : INFO : Epoch finished, average loss over training batches: 0.3244
2024-08-15 18:50:54,799 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:50:54,799 : INFO : Training metrics:
2024-08-15 18:50:54,799 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:50:55,121 : INFO : Accuracy: 0.8536
2024-08-15 18:50:55,121 : INFO : Precision: 0.8526
2024-08-15 18:50:55,121 : INFO : Recall: 0.8561
2024-08-15 18:50:55,121 : INFO : F1 score: 0.8544
2024-08-15 18:51:43,157 : INFO : Average loss over validation batches: 0.2141
2024-08-15 18:51:43,158 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:51:43,158 : INFO : Validation metrics:
2024-08-15 18:51:43,158 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:51:43,163 : INFO : Accuracy: 0.9166
2024-08-15 18:51:43,163 : INFO : Precision: 0.9000
2024-08-15 18:51:43,163 : INFO : Recall: 0.9357
2024-08-15 18:51:43,163 : INFO : F1 score: 0.9175
2024-08-15 18:51:43,163 : INFO : Validation metric decreased (inf --> 0.214087).  Saving model ...
2024-08-15 18:51:43,248 : INFO : Starting epoch 2
2024-08-15 18:51:51,413 : INFO : Current training batch loss: 0.1065 in epoch 2
2024-08-15 18:52:02,284 : INFO : Current training batch loss: 0.2754 in epoch 2
2024-08-15 18:52:13,151 : INFO : Current training batch loss: 0.0931 in epoch 2
2024-08-15 18:52:24,036 : INFO : Current training batch loss: 0.1708 in epoch 2
2024-08-15 18:52:34,921 : INFO : Current training batch loss: 0.1653 in epoch 2
2024-08-15 18:52:45,807 : INFO : Current training batch loss: 0.1783 in epoch 2
2024-08-15 18:52:56,686 : INFO : Current training batch loss: 0.1715 in epoch 2
2024-08-15 18:53:07,559 : INFO : Current training batch loss: 0.1636 in epoch 2
2024-08-15 18:53:18,451 : INFO : Current training batch loss: 0.0942 in epoch 2
2024-08-15 18:53:29,327 : INFO : Current training batch loss: 0.0247 in epoch 2
2024-08-15 18:53:40,218 : INFO : Current training batch loss: 0.1063 in epoch 2
2024-08-15 18:53:51,100 : INFO : Current training batch loss: 0.1215 in epoch 2
2024-08-15 18:54:01,962 : INFO : Current training batch loss: 0.0326 in epoch 2
2024-08-15 18:54:12,842 : INFO : Current training batch loss: 0.1402 in epoch 2
2024-08-15 18:54:23,714 : INFO : Current training batch loss: 0.0874 in epoch 2
2024-08-15 18:54:34,595 : INFO : Current training batch loss: 0.1048 in epoch 2
2024-08-15 18:54:45,471 : INFO : Current training batch loss: 0.1102 in epoch 2
2024-08-15 18:54:56,335 : INFO : Current training batch loss: 0.3067 in epoch 2
2024-08-15 18:55:07,197 : INFO : Current training batch loss: 0.1344 in epoch 2
2024-08-15 18:55:18,064 : INFO : Current training batch loss: 0.2195 in epoch 2
2024-08-15 18:55:28,933 : INFO : Current training batch loss: 0.0686 in epoch 2
2024-08-15 18:55:39,819 : INFO : Current training batch loss: 0.1880 in epoch 2
2024-08-15 18:55:50,680 : INFO : Current training batch loss: 0.0247 in epoch 2
2024-08-15 18:56:01,821 : INFO : Current training batch loss: 0.0371 in epoch 2
2024-08-15 18:56:12,745 : INFO : Current training batch loss: 0.0678 in epoch 2
2024-08-15 18:56:23,654 : INFO : Current training batch loss: 0.0193 in epoch 2
2024-08-15 18:56:34,541 : INFO : Current training batch loss: 0.0201 in epoch 2
2024-08-15 18:56:45,418 : INFO : Current training batch loss: 0.0749 in epoch 2
2024-08-15 18:56:56,295 : INFO : Current training batch loss: 0.0420 in epoch 2
2024-08-15 18:57:01,965 : INFO : Epoch finished, average loss over training batches: 0.1367
2024-08-15 18:57:01,967 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:57:01,967 : INFO : Training metrics:
2024-08-15 18:57:01,967 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:57:02,281 : INFO : Accuracy: 0.9503
2024-08-15 18:57:02,281 : INFO : Precision: 0.9498
2024-08-15 18:57:02,281 : INFO : Recall: 0.9513
2024-08-15 18:57:02,281 : INFO : F1 score: 0.9505
2024-08-15 18:57:50,090 : INFO : Average loss over validation batches: 0.2228
2024-08-15 18:57:50,090 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:57:50,090 : INFO : Validation metrics:
2024-08-15 18:57:50,090 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 18:57:50,096 : INFO : Accuracy: 0.9187
2024-08-15 18:57:50,096 : INFO : Precision: 0.9395
2024-08-15 18:57:50,096 : INFO : Recall: 0.8934
2024-08-15 18:57:50,096 : INFO : F1 score: 0.9159
2024-08-15 18:57:50,096 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 18:57:50,096 : INFO : Starting epoch 3
2024-08-15 18:57:55,013 : INFO : Current training batch loss: 0.2014 in epoch 3
2024-08-15 18:58:05,889 : INFO : Current training batch loss: 0.0887 in epoch 3
2024-08-15 18:58:16,768 : INFO : Current training batch loss: 0.0838 in epoch 3
2024-08-15 18:58:27,648 : INFO : Current training batch loss: 0.0568 in epoch 3
2024-08-15 18:58:38,527 : INFO : Current training batch loss: 0.0953 in epoch 3
2024-08-15 18:58:49,405 : INFO : Current training batch loss: 0.0367 in epoch 3
2024-08-15 18:59:00,289 : INFO : Current training batch loss: 0.0125 in epoch 3
2024-08-15 18:59:11,174 : INFO : Current training batch loss: 0.0225 in epoch 3
2024-08-15 18:59:22,053 : INFO : Current training batch loss: 0.0970 in epoch 3
2024-08-15 18:59:32,944 : INFO : Current training batch loss: 0.0184 in epoch 3
2024-08-15 18:59:43,832 : INFO : Current training batch loss: 0.0065 in epoch 3
2024-08-15 18:59:54,709 : INFO : Current training batch loss: 0.0075 in epoch 3
2024-08-15 19:00:05,584 : INFO : Current training batch loss: 0.0086 in epoch 3
2024-08-15 19:00:16,459 : INFO : Current training batch loss: 0.1900 in epoch 3
2024-08-15 19:00:27,345 : INFO : Current training batch loss: 0.0047 in epoch 3
2024-08-15 19:00:38,224 : INFO : Current training batch loss: 0.0325 in epoch 3
2024-08-15 19:00:49,114 : INFO : Current training batch loss: 0.0190 in epoch 3
2024-08-15 19:00:59,997 : INFO : Current training batch loss: 0.0080 in epoch 3
2024-08-15 19:01:10,880 : INFO : Current training batch loss: 0.0071 in epoch 3
2024-08-15 19:01:21,764 : INFO : Current training batch loss: 0.0495 in epoch 3
2024-08-15 19:01:32,656 : INFO : Current training batch loss: 0.0061 in epoch 3
2024-08-15 19:01:43,543 : INFO : Current training batch loss: 0.0042 in epoch 3
2024-08-15 19:01:54,432 : INFO : Current training batch loss: 0.0124 in epoch 3
2024-08-15 19:02:05,320 : INFO : Current training batch loss: 0.0091 in epoch 3
2024-08-15 19:02:16,206 : INFO : Current training batch loss: 0.0099 in epoch 3
2024-08-15 19:02:27,089 : INFO : Current training batch loss: 0.0057 in epoch 3
2024-08-15 19:02:37,979 : INFO : Current training batch loss: 0.0143 in epoch 3
2024-08-15 19:02:48,858 : INFO : Current training batch loss: 0.0075 in epoch 3
2024-08-15 19:02:59,740 : INFO : Current training batch loss: 0.2205 in epoch 3
2024-08-15 19:03:08,668 : INFO : Epoch finished, average loss over training batches: 0.0504
2024-08-15 19:03:08,670 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:03:08,670 : INFO : Training metrics:
2024-08-15 19:03:08,670 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:03:08,981 : INFO : Accuracy: 0.9850
2024-08-15 19:03:08,981 : INFO : Precision: 0.9855
2024-08-15 19:03:08,981 : INFO : Recall: 0.9846
2024-08-15 19:03:08,981 : INFO : F1 score: 0.9851
2024-08-15 19:03:56,780 : INFO : Average loss over validation batches: 0.2270
2024-08-15 19:03:56,780 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:03:56,781 : INFO : Validation metrics:
2024-08-15 19:03:56,781 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:03:56,786 : INFO : Accuracy: 0.9328
2024-08-15 19:03:56,786 : INFO : Precision: 0.9353
2024-08-15 19:03:56,786 : INFO : Recall: 0.9286
2024-08-15 19:03:56,786 : INFO : F1 score: 0.9319
2024-08-15 19:03:56,786 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 19:03:56,786 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 19:03:57,244 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 19:04:44,188 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:04:44,188 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 19:04:44,188 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:04:44,194 : INFO : Accuracy: 0.9166
2024-08-15 19:04:44,194 : INFO : Precision: 0.9000
2024-08-15 19:04:44,194 : INFO : Recall: 0.9357
2024-08-15 19:04:44,194 : INFO : F1 score: 0.9175
2024-08-15 19:04:44,194 : INFO : Determined score from best model, ending training.
2024-08-15 19:04:44,195 : INFO : Split 3 is finished, the score is: 0.9175
2024-08-15 19:04:44,196 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:04:44,196 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:04:44,196 : INFO : Starting training for split 4
2024-08-15 19:04:44,495 : INFO : Counting occurences of labels...
2024-08-15 19:05:07,577 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-15 19:05:15,313 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 19:05:15,777 : INFO : Starting epoch 1
2024-08-15 19:05:16,360 : INFO : Current training batch loss: 0.6882 in epoch 1
2024-08-15 19:05:27,204 : INFO : Current training batch loss: 0.6978 in epoch 1
2024-08-15 19:05:38,045 : INFO : Current training batch loss: 0.6710 in epoch 1
2024-08-15 19:05:48,904 : INFO : Current training batch loss: 0.5521 in epoch 1
2024-08-15 19:05:59,788 : INFO : Current training batch loss: 0.5866 in epoch 1
2024-08-15 19:06:10,661 : INFO : Current training batch loss: 0.2562 in epoch 1
2024-08-15 19:06:21,532 : INFO : Current training batch loss: 0.3667 in epoch 1
2024-08-15 19:06:32,399 : INFO : Current training batch loss: 0.4080 in epoch 1
2024-08-15 19:06:43,269 : INFO : Current training batch loss: 0.1975 in epoch 1
2024-08-15 19:06:54,159 : INFO : Current training batch loss: 0.1152 in epoch 1
2024-08-15 19:07:05,041 : INFO : Current training batch loss: 0.2869 in epoch 1
2024-08-15 19:07:15,957 : INFO : Current training batch loss: 0.3373 in epoch 1
2024-08-15 19:07:26,844 : INFO : Current training batch loss: 0.3345 in epoch 1
2024-08-15 19:07:37,732 : INFO : Current training batch loss: 0.2394 in epoch 1
2024-08-15 19:07:48,623 : INFO : Current training batch loss: 0.2996 in epoch 1
2024-08-15 19:07:59,499 : INFO : Current training batch loss: 0.2535 in epoch 1
2024-08-15 19:08:10,375 : INFO : Current training batch loss: 0.2392 in epoch 1
2024-08-15 19:08:21,250 : INFO : Current training batch loss: 0.2700 in epoch 1
2024-08-15 19:08:32,108 : INFO : Current training batch loss: 0.2128 in epoch 1
2024-08-15 19:08:42,973 : INFO : Current training batch loss: 0.3402 in epoch 1
2024-08-15 19:08:53,841 : INFO : Current training batch loss: 0.2326 in epoch 1
2024-08-15 19:09:04,703 : INFO : Current training batch loss: 0.3673 in epoch 1
2024-08-15 19:09:15,568 : INFO : Current training batch loss: 0.4330 in epoch 1
2024-08-15 19:09:26,429 : INFO : Current training batch loss: 0.3250 in epoch 1
2024-08-15 19:09:37,302 : INFO : Current training batch loss: 0.1260 in epoch 1
2024-08-15 19:09:48,162 : INFO : Current training batch loss: 0.2456 in epoch 1
2024-08-15 19:09:59,303 : INFO : Current training batch loss: 0.2851 in epoch 1
2024-08-15 19:10:10,195 : INFO : Current training batch loss: 0.3323 in epoch 1
2024-08-15 19:10:21,071 : INFO : Current training batch loss: 0.3253 in epoch 1
2024-08-15 19:10:31,937 : INFO : Current training batch loss: 0.2929 in epoch 1
2024-08-15 19:10:34,359 : INFO : Epoch finished, average loss over training batches: 0.3362
2024-08-15 19:10:34,361 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:10:34,361 : INFO : Training metrics:
2024-08-15 19:10:34,361 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:10:34,673 : INFO : Accuracy: 0.8400
2024-08-15 19:10:34,673 : INFO : Precision: 0.8423
2024-08-15 19:10:34,673 : INFO : Recall: 0.8347
2024-08-15 19:10:34,673 : INFO : F1 score: 0.8385
2024-08-15 19:11:22,313 : INFO : Average loss over validation batches: 0.2647
2024-08-15 19:11:22,314 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:11:22,314 : INFO : Validation metrics:
2024-08-15 19:11:22,314 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:11:22,319 : INFO : Accuracy: 0.8952
2024-08-15 19:11:22,319 : INFO : Precision: 0.9519
2024-08-15 19:11:22,319 : INFO : Recall: 0.8357
2024-08-15 19:11:22,319 : INFO : F1 score: 0.8900
2024-08-15 19:11:22,319 : INFO : Validation metric decreased (inf --> 0.264714).  Saving model ...
2024-08-15 19:11:22,405 : INFO : Starting epoch 2
2024-08-15 19:11:30,573 : INFO : Current training batch loss: 0.0820 in epoch 2
2024-08-15 19:11:41,433 : INFO : Current training batch loss: 0.2897 in epoch 2
2024-08-15 19:11:52,287 : INFO : Current training batch loss: 0.1577 in epoch 2
2024-08-15 19:12:03,149 : INFO : Current training batch loss: 0.1597 in epoch 2
2024-08-15 19:12:14,016 : INFO : Current training batch loss: 0.2891 in epoch 2
2024-08-15 19:12:24,890 : INFO : Current training batch loss: 0.2583 in epoch 2
2024-08-15 19:12:35,759 : INFO : Current training batch loss: 0.1693 in epoch 2
2024-08-15 19:12:46,626 : INFO : Current training batch loss: 0.2358 in epoch 2
2024-08-15 19:12:57,487 : INFO : Current training batch loss: 0.1049 in epoch 2
2024-08-15 19:13:08,359 : INFO : Current training batch loss: 0.1033 in epoch 2
2024-08-15 19:13:19,238 : INFO : Current training batch loss: 0.1125 in epoch 2
2024-08-15 19:13:30,118 : INFO : Current training batch loss: 0.2651 in epoch 2
2024-08-15 19:13:40,994 : INFO : Current training batch loss: 0.0253 in epoch 2
2024-08-15 19:13:51,870 : INFO : Current training batch loss: 0.1182 in epoch 2
2024-08-15 19:14:02,743 : INFO : Current training batch loss: 0.0719 in epoch 2
2024-08-15 19:14:13,628 : INFO : Current training batch loss: 0.0636 in epoch 2
2024-08-15 19:14:24,506 : INFO : Current training batch loss: 0.0826 in epoch 2
2024-08-15 19:14:35,381 : INFO : Current training batch loss: 0.2476 in epoch 2
2024-08-15 19:14:46,259 : INFO : Current training batch loss: 0.1418 in epoch 2
2024-08-15 19:14:57,139 : INFO : Current training batch loss: 0.0351 in epoch 2
2024-08-15 19:15:08,024 : INFO : Current training batch loss: 0.0664 in epoch 2
2024-08-15 19:15:18,900 : INFO : Current training batch loss: 0.0645 in epoch 2
2024-08-15 19:15:29,779 : INFO : Current training batch loss: 0.1287 in epoch 2
2024-08-15 19:15:40,669 : INFO : Current training batch loss: 0.0172 in epoch 2
2024-08-15 19:15:51,538 : INFO : Current training batch loss: 0.0591 in epoch 2
2024-08-15 19:16:02,417 : INFO : Current training batch loss: 0.0977 in epoch 2
2024-08-15 19:16:13,299 : INFO : Current training batch loss: 0.0555 in epoch 2
2024-08-15 19:16:24,180 : INFO : Current training batch loss: 0.0319 in epoch 2
2024-08-15 19:16:35,058 : INFO : Current training batch loss: 0.3007 in epoch 2
2024-08-15 19:16:40,751 : INFO : Epoch finished, average loss over training batches: 0.1427
2024-08-15 19:16:40,752 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:16:40,752 : INFO : Training metrics:
2024-08-15 19:16:40,752 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:16:41,066 : INFO : Accuracy: 0.9476
2024-08-15 19:16:41,066 : INFO : Precision: 0.9458
2024-08-15 19:16:41,066 : INFO : Recall: 0.9491
2024-08-15 19:16:41,066 : INFO : F1 score: 0.9475
2024-08-15 19:17:28,749 : INFO : Average loss over validation batches: 0.2362
2024-08-15 19:17:28,749 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:17:28,749 : INFO : Validation metrics:
2024-08-15 19:17:28,749 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:17:28,754 : INFO : Accuracy: 0.9184
2024-08-15 19:17:28,754 : INFO : Precision: 0.8990
2024-08-15 19:17:28,755 : INFO : Recall: 0.9454
2024-08-15 19:17:28,755 : INFO : F1 score: 0.9216
2024-08-15 19:17:28,755 : INFO : Validation metric decreased (0.264714 --> 0.236170).  Saving model ...
2024-08-15 19:17:28,841 : INFO : Starting epoch 3
2024-08-15 19:17:33,753 : INFO : Current training batch loss: 0.2662 in epoch 3
2024-08-15 19:17:44,613 : INFO : Current training batch loss: 0.0273 in epoch 3
2024-08-15 19:17:55,480 : INFO : Current training batch loss: 0.1778 in epoch 3
2024-08-15 19:18:06,353 : INFO : Current training batch loss: 0.0231 in epoch 3
2024-08-15 19:18:17,226 : INFO : Current training batch loss: 0.0225 in epoch 3
2024-08-15 19:18:28,100 : INFO : Current training batch loss: 0.0227 in epoch 3
2024-08-15 19:18:38,980 : INFO : Current training batch loss: 0.0167 in epoch 3
2024-08-15 19:18:49,863 : INFO : Current training batch loss: 0.0102 in epoch 3
2024-08-15 19:19:00,741 : INFO : Current training batch loss: 0.0295 in epoch 3
2024-08-15 19:19:11,633 : INFO : Current training batch loss: 0.0132 in epoch 3
2024-08-15 19:19:22,514 : INFO : Current training batch loss: 0.0365 in epoch 3
2024-08-15 19:19:33,385 : INFO : Current training batch loss: 0.0562 in epoch 3
2024-08-15 19:19:44,245 : INFO : Current training batch loss: 0.0093 in epoch 3
2024-08-15 19:19:55,115 : INFO : Current training batch loss: 0.2198 in epoch 3
2024-08-15 19:20:05,989 : INFO : Current training batch loss: 0.0125 in epoch 3
2024-08-15 19:20:16,852 : INFO : Current training batch loss: 0.0114 in epoch 3
2024-08-15 19:20:27,731 : INFO : Current training batch loss: 0.0845 in epoch 3
2024-08-15 19:20:38,601 : INFO : Current training batch loss: 0.0111 in epoch 3
2024-08-15 19:20:49,474 : INFO : Current training batch loss: 0.0060 in epoch 3
2024-08-15 19:21:00,344 : INFO : Current training batch loss: 0.0039 in epoch 3
2024-08-15 19:21:11,217 : INFO : Current training batch loss: 0.0297 in epoch 3
2024-08-15 19:21:22,085 : INFO : Current training batch loss: 0.2037 in epoch 3
2024-08-15 19:21:32,954 : INFO : Current training batch loss: 0.0065 in epoch 3
2024-08-15 19:21:43,796 : INFO : Current training batch loss: 0.0150 in epoch 3
2024-08-15 19:21:54,644 : INFO : Current training batch loss: 0.0246 in epoch 3
2024-08-15 19:22:05,499 : INFO : Current training batch loss: 0.0046 in epoch 3
2024-08-15 19:22:16,360 : INFO : Current training batch loss: 0.0031 in epoch 3
2024-08-15 19:22:27,238 : INFO : Current training batch loss: 0.2131 in epoch 3
2024-08-15 19:22:38,097 : INFO : Current training batch loss: 0.1392 in epoch 3
2024-08-15 19:22:47,004 : INFO : Epoch finished, average loss over training batches: 0.0509
2024-08-15 19:22:47,005 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:22:47,005 : INFO : Training metrics:
2024-08-15 19:22:47,005 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:22:47,319 : INFO : Accuracy: 0.9853
2024-08-15 19:22:47,319 : INFO : Precision: 0.9846
2024-08-15 19:22:47,319 : INFO : Recall: 0.9860
2024-08-15 19:22:47,319 : INFO : F1 score: 0.9853
2024-08-15 19:23:34,976 : INFO : Average loss over validation batches: 0.2564
2024-08-15 19:23:34,976 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:23:34,976 : INFO : Validation metrics:
2024-08-15 19:23:34,976 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:23:34,981 : INFO : Accuracy: 0.9224
2024-08-15 19:23:34,981 : INFO : Precision: 0.9181
2024-08-15 19:23:34,981 : INFO : Recall: 0.9300
2024-08-15 19:23:34,981 : INFO : F1 score: 0.9240
2024-08-15 19:23:34,981 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 19:23:34,981 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 19:23:35,468 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 19:24:22,246 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:24:22,246 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 19:24:22,246 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:24:22,251 : INFO : Accuracy: 0.9184
2024-08-15 19:24:22,251 : INFO : Precision: 0.8990
2024-08-15 19:24:22,251 : INFO : Recall: 0.9454
2024-08-15 19:24:22,251 : INFO : F1 score: 0.9216
2024-08-15 19:24:22,251 : INFO : Determined score from best model, ending training.
2024-08-15 19:24:22,253 : INFO : Split 4 is finished, the score is: 0.9216
2024-08-15 19:24:22,253 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-15 19:24:22,259] Trial 0 finished with value: 0.9182181159100227 and parameters: {}. Best is trial 0 with value: 0.9182181159100227.
2024-08-15 19:24:22,260 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:24:22,260 : INFO : Starting training for split 1
2024-08-15 19:24:22,536 : INFO : Counting occurences of labels...
2024-08-15 19:24:45,643 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-15 19:24:53,382 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 19:24:53,801 : INFO : Starting epoch 1
2024-08-15 19:24:54,391 : INFO : Current training batch loss: 0.7067 in epoch 1
2024-08-15 19:25:05,211 : INFO : Current training batch loss: 0.7249 in epoch 1
2024-08-15 19:25:16,050 : INFO : Current training batch loss: 0.6079 in epoch 1
2024-08-15 19:25:26,895 : INFO : Current training batch loss: 0.4530 in epoch 1
2024-08-15 19:25:37,732 : INFO : Current training batch loss: 0.3641 in epoch 1
2024-08-15 19:25:48,575 : INFO : Current training batch loss: 0.3516 in epoch 1
2024-08-15 19:25:59,421 : INFO : Current training batch loss: 0.3131 in epoch 1
2024-08-15 19:26:10,266 : INFO : Current training batch loss: 0.3669 in epoch 1
2024-08-15 19:26:21,120 : INFO : Current training batch loss: 0.4621 in epoch 1
2024-08-15 19:26:31,980 : INFO : Current training batch loss: 0.1697 in epoch 1
2024-08-15 19:26:42,842 : INFO : Current training batch loss: 0.1974 in epoch 1
2024-08-15 19:26:53,701 : INFO : Current training batch loss: 0.4788 in epoch 1
2024-08-15 19:27:04,556 : INFO : Current training batch loss: 0.1324 in epoch 1
2024-08-15 19:27:15,412 : INFO : Current training batch loss: 0.1364 in epoch 1
2024-08-15 19:27:26,315 : INFO : Current training batch loss: 0.2374 in epoch 1
2024-08-15 19:27:37,168 : INFO : Current training batch loss: 0.1190 in epoch 1
2024-08-15 19:27:48,035 : INFO : Current training batch loss: 0.1810 in epoch 1
2024-08-15 19:27:58,894 : INFO : Current training batch loss: 0.2384 in epoch 1
2024-08-15 19:28:09,754 : INFO : Current training batch loss: 0.2872 in epoch 1
2024-08-15 19:28:20,613 : INFO : Current training batch loss: 0.4189 in epoch 1
2024-08-15 19:28:31,476 : INFO : Current training batch loss: 0.2207 in epoch 1
2024-08-15 19:28:42,335 : INFO : Current training batch loss: 0.1931 in epoch 1
2024-08-15 19:28:53,202 : INFO : Current training batch loss: 0.2230 in epoch 1
2024-08-15 19:29:04,060 : INFO : Current training batch loss: 0.1573 in epoch 1
2024-08-15 19:29:14,917 : INFO : Current training batch loss: 0.1566 in epoch 1
2024-08-15 19:29:25,785 : INFO : Current training batch loss: 0.1475 in epoch 1
2024-08-15 19:29:36,639 : INFO : Current training batch loss: 0.2111 in epoch 1
2024-08-15 19:29:47,496 : INFO : Current training batch loss: 0.3741 in epoch 1
2024-08-15 19:29:58,361 : INFO : Current training batch loss: 0.1103 in epoch 1
2024-08-15 19:30:09,525 : INFO : Current training batch loss: 0.1977 in epoch 1
2024-08-15 19:30:11,938 : INFO : Epoch finished, average loss over training batches: 0.3028
2024-08-15 19:30:11,939 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:30:11,939 : INFO : Training metrics:
2024-08-15 19:30:11,939 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:30:12,255 : INFO : Accuracy: 0.8604
2024-08-15 19:30:12,255 : INFO : Precision: 0.8636
2024-08-15 19:30:12,255 : INFO : Recall: 0.8549
2024-08-15 19:30:12,255 : INFO : F1 score: 0.8592
2024-08-15 19:30:59,864 : INFO : Average loss over validation batches: 0.2024
2024-08-15 19:30:59,864 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:30:59,865 : INFO : Validation metrics:
2024-08-15 19:30:59,865 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:30:59,870 : INFO : Accuracy: 0.9203
2024-08-15 19:30:59,870 : INFO : Precision: 0.9114
2024-08-15 19:30:59,870 : INFO : Recall: 0.9328
2024-08-15 19:30:59,870 : INFO : F1 score: 0.9220
2024-08-15 19:30:59,870 : INFO : Validation metric decreased (inf --> 0.202364).  Saving model ...
2024-08-15 19:30:59,956 : INFO : Split 1 is finished, the score is: 0.9220
2024-08-15 19:30:59,957 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:30:59,957 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:30:59,957 : INFO : Starting training for split 2
2024-08-15 19:31:00,264 : INFO : Counting occurences of labels...
2024-08-15 19:31:23,749 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-15 19:31:31,555 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 19:31:31,976 : INFO : Starting epoch 1
2024-08-15 19:31:32,556 : INFO : Current training batch loss: 0.8550 in epoch 1
2024-08-15 19:31:43,390 : INFO : Current training batch loss: 0.6950 in epoch 1
2024-08-15 19:31:54,232 : INFO : Current training batch loss: 0.4749 in epoch 1
2024-08-15 19:32:05,091 : INFO : Current training batch loss: 0.3730 in epoch 1
2024-08-15 19:32:15,947 : INFO : Current training batch loss: 0.4043 in epoch 1
2024-08-15 19:32:26,805 : INFO : Current training batch loss: 0.2100 in epoch 1
2024-08-15 19:32:37,673 : INFO : Current training batch loss: 0.2141 in epoch 1
2024-08-15 19:32:48,531 : INFO : Current training batch loss: 0.2816 in epoch 1
2024-08-15 19:32:59,390 : INFO : Current training batch loss: 0.1906 in epoch 1
2024-08-15 19:33:10,261 : INFO : Current training batch loss: 0.1669 in epoch 1
2024-08-15 19:33:21,127 : INFO : Current training batch loss: 0.1790 in epoch 1
2024-08-15 19:33:31,997 : INFO : Current training batch loss: 0.4374 in epoch 1
2024-08-15 19:33:42,861 : INFO : Current training batch loss: 0.1757 in epoch 1
2024-08-15 19:33:53,724 : INFO : Current training batch loss: 0.1545 in epoch 1
2024-08-15 19:34:04,600 : INFO : Current training batch loss: 0.2063 in epoch 1
2024-08-15 19:34:15,456 : INFO : Current training batch loss: 0.0689 in epoch 1
2024-08-15 19:34:26,329 : INFO : Current training batch loss: 0.2461 in epoch 1
2024-08-15 19:34:37,199 : INFO : Current training batch loss: 0.1386 in epoch 1
2024-08-15 19:34:48,073 : INFO : Current training batch loss: 0.1768 in epoch 1
2024-08-15 19:34:58,946 : INFO : Current training batch loss: 0.3668 in epoch 1
2024-08-15 19:35:09,822 : INFO : Current training batch loss: 0.1871 in epoch 1
2024-08-15 19:35:20,695 : INFO : Current training batch loss: 0.2367 in epoch 1
2024-08-15 19:35:31,580 : INFO : Current training batch loss: 0.1832 in epoch 1
2024-08-15 19:35:42,457 : INFO : Current training batch loss: 0.2329 in epoch 1
2024-08-15 19:35:53,336 : INFO : Current training batch loss: 0.3302 in epoch 1
2024-08-15 19:36:04,221 : INFO : Current training batch loss: 0.0953 in epoch 1
2024-08-15 19:36:15,084 : INFO : Current training batch loss: 0.1986 in epoch 1
2024-08-15 19:36:25,954 : INFO : Current training batch loss: 0.3589 in epoch 1
2024-08-15 19:36:36,843 : INFO : Current training batch loss: 0.1333 in epoch 1
2024-08-15 19:36:47,731 : INFO : Current training batch loss: 0.1527 in epoch 1
2024-08-15 19:36:50,152 : INFO : Epoch finished, average loss over training batches: 0.2922
2024-08-15 19:36:50,153 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:36:50,153 : INFO : Training metrics:
2024-08-15 19:36:50,153 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:36:50,465 : INFO : Accuracy: 0.8705
2024-08-15 19:36:50,465 : INFO : Precision: 0.8723
2024-08-15 19:36:50,465 : INFO : Recall: 0.8696
2024-08-15 19:36:50,465 : INFO : F1 score: 0.8709
2024-08-15 19:37:38,092 : INFO : Average loss over validation batches: 0.1970
2024-08-15 19:37:38,092 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:37:38,092 : INFO : Validation metrics:
2024-08-15 19:37:38,092 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:37:38,098 : INFO : Accuracy: 0.9251
2024-08-15 19:37:38,098 : INFO : Precision: 0.9112
2024-08-15 19:37:38,098 : INFO : Recall: 0.9396
2024-08-15 19:37:38,098 : INFO : F1 score: 0.9251
2024-08-15 19:37:38,098 : INFO : Validation metric decreased (inf --> 0.197038).  Saving model ...
2024-08-15 19:37:38,186 : INFO : Split 2 is finished, the score is: 0.9251
2024-08-15 19:37:38,186 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:37:38,186 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:37:38,186 : INFO : Starting training for split 3
2024-08-15 19:37:38,514 : INFO : Counting occurences of labels...
2024-08-15 19:38:01,661 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-15 19:38:09,522 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 19:38:09,932 : INFO : Starting epoch 1
2024-08-15 19:38:10,512 : INFO : Current training batch loss: 0.7098 in epoch 1
2024-08-15 19:38:21,318 : INFO : Current training batch loss: 0.6873 in epoch 1
2024-08-15 19:38:32,154 : INFO : Current training batch loss: 0.5054 in epoch 1
2024-08-15 19:38:43,015 : INFO : Current training batch loss: 0.4380 in epoch 1
2024-08-15 19:38:53,864 : INFO : Current training batch loss: 0.5013 in epoch 1
2024-08-15 19:39:04,713 : INFO : Current training batch loss: 0.2485 in epoch 1
2024-08-15 19:39:15,578 : INFO : Current training batch loss: 0.1878 in epoch 1
2024-08-15 19:39:26,425 : INFO : Current training batch loss: 0.2705 in epoch 1
2024-08-15 19:39:37,280 : INFO : Current training batch loss: 0.1914 in epoch 1
2024-08-15 19:39:48,150 : INFO : Current training batch loss: 0.1349 in epoch 1
2024-08-15 19:39:59,019 : INFO : Current training batch loss: 0.2470 in epoch 1
2024-08-15 19:40:09,888 : INFO : Current training batch loss: 0.2032 in epoch 1
2024-08-15 19:40:20,760 : INFO : Current training batch loss: 0.3798 in epoch 1
2024-08-15 19:40:31,633 : INFO : Current training batch loss: 0.3076 in epoch 1
2024-08-15 19:40:42,798 : INFO : Current training batch loss: 0.2584 in epoch 1
2024-08-15 19:40:53,672 : INFO : Current training batch loss: 0.1390 in epoch 1
2024-08-15 19:41:04,576 : INFO : Current training batch loss: 0.2321 in epoch 1
2024-08-15 19:41:15,502 : INFO : Current training batch loss: 0.2347 in epoch 1
2024-08-15 19:41:26,360 : INFO : Current training batch loss: 0.1223 in epoch 1
2024-08-15 19:41:37,221 : INFO : Current training batch loss: 0.2462 in epoch 1
2024-08-15 19:41:48,089 : INFO : Current training batch loss: 0.1337 in epoch 1
2024-08-15 19:41:58,952 : INFO : Current training batch loss: 0.1698 in epoch 1
2024-08-15 19:42:09,825 : INFO : Current training batch loss: 0.1991 in epoch 1
2024-08-15 19:42:20,692 : INFO : Current training batch loss: 0.2070 in epoch 1
2024-08-15 19:42:31,551 : INFO : Current training batch loss: 0.2572 in epoch 1
2024-08-15 19:42:42,423 : INFO : Current training batch loss: 0.1453 in epoch 1
2024-08-15 19:42:53,277 : INFO : Current training batch loss: 0.2260 in epoch 1
2024-08-15 19:43:04,135 : INFO : Current training batch loss: 0.4127 in epoch 1
2024-08-15 19:43:15,000 : INFO : Current training batch loss: 0.1071 in epoch 1
2024-08-15 19:43:25,870 : INFO : Current training batch loss: 0.1956 in epoch 1
2024-08-15 19:43:28,287 : INFO : Epoch finished, average loss over training batches: 0.2944
2024-08-15 19:43:28,288 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:43:28,288 : INFO : Training metrics:
2024-08-15 19:43:28,288 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:43:28,620 : INFO : Accuracy: 0.8705
2024-08-15 19:43:28,621 : INFO : Precision: 0.8735
2024-08-15 19:43:28,621 : INFO : Recall: 0.8673
2024-08-15 19:43:28,621 : INFO : F1 score: 0.8704
2024-08-15 19:44:16,570 : INFO : Average loss over validation batches: 0.2081
2024-08-15 19:44:16,570 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:44:16,570 : INFO : Validation metrics:
2024-08-15 19:44:16,570 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:44:16,576 : INFO : Accuracy: 0.9170
2024-08-15 19:44:16,576 : INFO : Precision: 0.8963
2024-08-15 19:44:16,576 : INFO : Recall: 0.9412
2024-08-15 19:44:16,576 : INFO : F1 score: 0.9182
2024-08-15 19:44:16,576 : INFO : Validation metric decreased (inf --> 0.208142).  Saving model ...
2024-08-15 19:44:16,662 : INFO : Split 3 is finished, the score is: 0.9182
2024-08-15 19:44:16,662 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:44:16,662 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:44:16,662 : INFO : Starting training for split 4
2024-08-15 19:44:16,961 : INFO : Counting occurences of labels...
2024-08-15 19:44:40,455 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-15 19:44:48,266 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 19:44:48,706 : INFO : Starting epoch 1
2024-08-15 19:44:49,285 : INFO : Current training batch loss: 0.7019 in epoch 1
2024-08-15 19:45:00,089 : INFO : Current training batch loss: 0.6758 in epoch 1
2024-08-15 19:45:10,894 : INFO : Current training batch loss: 0.5187 in epoch 1
2024-08-15 19:45:21,723 : INFO : Current training batch loss: 0.3276 in epoch 1
2024-08-15 19:45:32,568 : INFO : Current training batch loss: 0.3655 in epoch 1
2024-08-15 19:45:43,422 : INFO : Current training batch loss: 0.3015 in epoch 1
2024-08-15 19:45:54,289 : INFO : Current training batch loss: 0.2083 in epoch 1
2024-08-15 19:46:05,145 : INFO : Current training batch loss: 0.2775 in epoch 1
2024-08-15 19:46:16,010 : INFO : Current training batch loss: 0.1997 in epoch 1
2024-08-15 19:46:26,881 : INFO : Current training batch loss: 0.1396 in epoch 1
2024-08-15 19:46:37,757 : INFO : Current training batch loss: 0.2660 in epoch 1
2024-08-15 19:46:48,669 : INFO : Current training batch loss: 0.2356 in epoch 1
2024-08-15 19:46:59,551 : INFO : Current training batch loss: 0.3828 in epoch 1
2024-08-15 19:47:10,435 : INFO : Current training batch loss: 0.2322 in epoch 1
2024-08-15 19:47:21,328 : INFO : Current training batch loss: 0.2308 in epoch 1
2024-08-15 19:47:32,213 : INFO : Current training batch loss: 0.1363 in epoch 1
2024-08-15 19:47:43,096 : INFO : Current training batch loss: 0.2484 in epoch 1
2024-08-15 19:47:53,979 : INFO : Current training batch loss: 0.2158 in epoch 1
2024-08-15 19:48:04,848 : INFO : Current training batch loss: 0.0902 in epoch 1
2024-08-15 19:48:15,724 : INFO : Current training batch loss: 0.2707 in epoch 1
2024-08-15 19:48:26,607 : INFO : Current training batch loss: 0.2662 in epoch 1
2024-08-15 19:48:37,483 : INFO : Current training batch loss: 0.3231 in epoch 1
2024-08-15 19:48:48,357 : INFO : Current training batch loss: 0.2757 in epoch 1
2024-08-15 19:48:59,228 : INFO : Current training batch loss: 0.1726 in epoch 1
2024-08-15 19:49:10,109 : INFO : Current training batch loss: 0.0974 in epoch 1
2024-08-15 19:49:20,982 : INFO : Current training batch loss: 0.2708 in epoch 1
2024-08-15 19:49:32,146 : INFO : Current training batch loss: 0.3199 in epoch 1
2024-08-15 19:49:43,025 : INFO : Current training batch loss: 0.2380 in epoch 1
2024-08-15 19:49:53,907 : INFO : Current training batch loss: 0.3162 in epoch 1
2024-08-15 19:50:04,777 : INFO : Current training batch loss: 0.3118 in epoch 1
2024-08-15 19:50:07,199 : INFO : Epoch finished, average loss over training batches: 0.2878
2024-08-15 19:50:07,200 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:50:07,200 : INFO : Training metrics:
2024-08-15 19:50:07,200 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:50:07,552 : INFO : Accuracy: 0.8739
2024-08-15 19:50:07,552 : INFO : Precision: 0.8738
2024-08-15 19:50:07,552 : INFO : Recall: 0.8727
2024-08-15 19:50:07,552 : INFO : F1 score: 0.8732
2024-08-15 19:50:55,164 : INFO : Average loss over validation batches: 0.2089
2024-08-15 19:50:55,165 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:50:55,165 : INFO : Validation metrics:
2024-08-15 19:50:55,165 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:50:55,170 : INFO : Accuracy: 0.9216
2024-08-15 19:50:55,170 : INFO : Precision: 0.9268
2024-08-15 19:50:55,170 : INFO : Recall: 0.9180
2024-08-15 19:50:55,170 : INFO : F1 score: 0.9224
2024-08-15 19:50:55,170 : INFO : Validation metric decreased (inf --> 0.208898).  Saving model ...
2024-08-15 19:50:55,258 : INFO : Split 4 is finished, the score is: 0.9224
2024-08-15 19:50:55,258 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-15 19:50:55,264] Trial 1 finished with value: 0.9219339021161369 and parameters: {'n_epochs': 1, 'learning_rate': 0.000160879962509044, 'classifier_dropout': 0.40155359857075223, 'warmup_step_fraction': 0.03871550741350008, 'use_gradient_clipping': False}. Best is trial 1 with value: 0.9219339021161369.
2024-08-15 19:50:55,265 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:50:55,265 : INFO : Starting training for split 1
2024-08-15 19:50:55,567 : INFO : Counting occurences of labels...
2024-08-15 19:51:18,821 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-15 19:51:26,580 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 19:51:27,002 : INFO : Starting epoch 1
2024-08-15 19:51:27,609 : INFO : Current training batch loss: 0.7156 in epoch 1
2024-08-15 19:51:38,422 : INFO : Current training batch loss: 0.6798 in epoch 1
2024-08-15 19:51:49,263 : INFO : Current training batch loss: 0.7142 in epoch 1
2024-08-15 19:52:00,115 : INFO : Current training batch loss: 0.6357 in epoch 1
2024-08-15 19:52:10,970 : INFO : Current training batch loss: 0.4161 in epoch 1
2024-08-15 19:52:21,834 : INFO : Current training batch loss: 0.6127 in epoch 1
2024-08-15 19:52:32,695 : INFO : Current training batch loss: 0.5180 in epoch 1
2024-08-15 19:52:43,889 : INFO : Current training batch loss: 0.4067 in epoch 1
2024-08-15 19:52:54,760 : INFO : Current training batch loss: 0.3667 in epoch 1
2024-08-15 19:53:05,628 : INFO : Current training batch loss: 0.2168 in epoch 1
2024-08-15 19:53:16,472 : INFO : Current training batch loss: 0.1855 in epoch 1
2024-08-15 19:53:27,326 : INFO : Current training batch loss: 0.3116 in epoch 1
2024-08-15 19:53:38,163 : INFO : Current training batch loss: 0.2268 in epoch 1
2024-08-15 19:53:49,004 : INFO : Current training batch loss: 0.2193 in epoch 1
2024-08-15 19:53:59,857 : INFO : Current training batch loss: 0.3494 in epoch 1
2024-08-15 19:54:10,688 : INFO : Current training batch loss: 0.1495 in epoch 1
2024-08-15 19:54:21,537 : INFO : Current training batch loss: 0.2046 in epoch 1
2024-08-15 19:54:32,380 : INFO : Current training batch loss: 0.2216 in epoch 1
2024-08-15 19:54:43,217 : INFO : Current training batch loss: 0.1187 in epoch 1
2024-08-15 19:54:54,060 : INFO : Current training batch loss: 0.3274 in epoch 1
2024-08-15 19:55:04,915 : INFO : Current training batch loss: 0.2528 in epoch 1
2024-08-15 19:55:15,764 : INFO : Current training batch loss: 0.1689 in epoch 1
2024-08-15 19:55:26,636 : INFO : Current training batch loss: 0.1585 in epoch 1
2024-08-15 19:55:37,482 : INFO : Current training batch loss: 0.1686 in epoch 1
2024-08-15 19:55:48,330 : INFO : Current training batch loss: 0.2141 in epoch 1
2024-08-15 19:55:59,187 : INFO : Current training batch loss: 0.1577 in epoch 1
2024-08-15 19:56:10,351 : INFO : Current training batch loss: 0.2435 in epoch 1
2024-08-15 19:56:21,190 : INFO : Current training batch loss: 0.4464 in epoch 1
2024-08-15 19:56:32,042 : INFO : Current training batch loss: 0.0834 in epoch 1
2024-08-15 19:56:42,898 : INFO : Current training batch loss: 0.2456 in epoch 1
2024-08-15 19:56:45,312 : INFO : Epoch finished, average loss over training batches: 0.3365
2024-08-15 19:56:45,313 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:56:45,313 : INFO : Training metrics:
2024-08-15 19:56:45,313 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:56:45,623 : INFO : Accuracy: 0.8452
2024-08-15 19:56:45,624 : INFO : Precision: 0.8399
2024-08-15 19:56:45,624 : INFO : Recall: 0.8519
2024-08-15 19:56:45,624 : INFO : F1 score: 0.8458
2024-08-15 19:57:33,311 : INFO : Average loss over validation batches: 0.2543
2024-08-15 19:57:33,311 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:57:33,311 : INFO : Validation metrics:
2024-08-15 19:57:33,311 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 19:57:33,317 : INFO : Accuracy: 0.9006
2024-08-15 19:57:33,317 : INFO : Precision: 0.9502
2024-08-15 19:57:33,317 : INFO : Recall: 0.8475
2024-08-15 19:57:33,317 : INFO : F1 score: 0.8960
2024-08-15 19:57:33,317 : INFO : Validation metric decreased (inf --> 0.254300).  Saving model ...
2024-08-15 19:57:33,404 : INFO : Starting epoch 2
2024-08-15 19:57:41,574 : INFO : Current training batch loss: 0.1616 in epoch 2
2024-08-15 19:57:52,442 : INFO : Current training batch loss: 0.2809 in epoch 2
2024-08-15 19:58:03,301 : INFO : Current training batch loss: 0.3709 in epoch 2
2024-08-15 19:58:14,147 : INFO : Current training batch loss: 0.1638 in epoch 2
2024-08-15 19:58:24,993 : INFO : Current training batch loss: 0.2872 in epoch 2
2024-08-15 19:58:35,844 : INFO : Current training batch loss: 0.2439 in epoch 2
2024-08-15 19:58:46,691 : INFO : Current training batch loss: 0.0580 in epoch 2
2024-08-15 19:58:57,533 : INFO : Current training batch loss: 0.2343 in epoch 2
2024-08-15 19:59:08,366 : INFO : Current training batch loss: 0.1709 in epoch 2
2024-08-15 19:59:19,210 : INFO : Current training batch loss: 0.1334 in epoch 2
2024-08-15 19:59:30,059 : INFO : Current training batch loss: 0.0895 in epoch 2
2024-08-15 19:59:40,904 : INFO : Current training batch loss: 0.0936 in epoch 2
2024-08-15 19:59:51,750 : INFO : Current training batch loss: 0.0301 in epoch 2
2024-08-15 20:00:02,599 : INFO : Current training batch loss: 0.0236 in epoch 2
2024-08-15 20:00:13,439 : INFO : Current training batch loss: 0.1604 in epoch 2
2024-08-15 20:00:24,280 : INFO : Current training batch loss: 0.2373 in epoch 2
2024-08-15 20:00:35,154 : INFO : Current training batch loss: 0.0909 in epoch 2
2024-08-15 20:00:46,040 : INFO : Current training batch loss: 0.0668 in epoch 2
2024-08-15 20:00:56,919 : INFO : Current training batch loss: 0.0722 in epoch 2
2024-08-15 20:01:07,786 : INFO : Current training batch loss: 0.6042 in epoch 2
2024-08-15 20:01:18,656 : INFO : Current training batch loss: 0.2370 in epoch 2
2024-08-15 20:01:29,547 : INFO : Current training batch loss: 0.2072 in epoch 2
2024-08-15 20:01:40,421 : INFO : Current training batch loss: 0.0991 in epoch 2
2024-08-15 20:01:51,292 : INFO : Current training batch loss: 0.0299 in epoch 2
2024-08-15 20:02:02,172 : INFO : Current training batch loss: 0.1619 in epoch 2
2024-08-15 20:02:13,052 : INFO : Current training batch loss: 0.0062 in epoch 2
2024-08-15 20:02:23,918 : INFO : Current training batch loss: 0.1450 in epoch 2
2024-08-15 20:02:34,778 : INFO : Current training batch loss: 0.0448 in epoch 2
2024-08-15 20:02:45,648 : INFO : Current training batch loss: 0.1154 in epoch 2
2024-08-15 20:02:51,317 : INFO : Epoch finished, average loss over training batches: 0.1646
2024-08-15 20:02:51,319 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:02:51,319 : INFO : Training metrics:
2024-08-15 20:02:51,319 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:02:51,628 : INFO : Accuracy: 0.9399
2024-08-15 20:02:51,628 : INFO : Precision: 0.9398
2024-08-15 20:02:51,628 : INFO : Recall: 0.9398
2024-08-15 20:02:51,628 : INFO : F1 score: 0.9398
2024-08-15 20:03:39,370 : INFO : Average loss over validation batches: 0.2458
2024-08-15 20:03:39,370 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:03:39,371 : INFO : Validation metrics:
2024-08-15 20:03:39,371 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:03:39,375 : INFO : Accuracy: 0.9130
2024-08-15 20:03:39,376 : INFO : Precision: 0.8880
2024-08-15 20:03:39,376 : INFO : Recall: 0.9471
2024-08-15 20:03:39,376 : INFO : F1 score: 0.9166
2024-08-15 20:03:39,376 : INFO : Validation metric decreased (0.254300 --> 0.245800).  Saving model ...
2024-08-15 20:03:39,459 : INFO : Starting epoch 3
2024-08-15 20:03:44,386 : INFO : Current training batch loss: 0.0511 in epoch 3
2024-08-15 20:03:55,257 : INFO : Current training batch loss: 0.1165 in epoch 3
2024-08-15 20:04:06,132 : INFO : Current training batch loss: 0.0190 in epoch 3
2024-08-15 20:04:17,010 : INFO : Current training batch loss: 0.0117 in epoch 3
2024-08-15 20:04:27,890 : INFO : Current training batch loss: 0.2370 in epoch 3
2024-08-15 20:04:38,737 : INFO : Current training batch loss: 0.2173 in epoch 3
2024-08-15 20:04:49,583 : INFO : Current training batch loss: 0.0253 in epoch 3
2024-08-15 20:05:00,438 : INFO : Current training batch loss: 0.0535 in epoch 3
2024-08-15 20:05:11,280 : INFO : Current training batch loss: 0.0099 in epoch 3
2024-08-15 20:05:22,134 : INFO : Current training batch loss: 0.2438 in epoch 3
2024-08-15 20:05:32,979 : INFO : Current training batch loss: 0.0259 in epoch 3
2024-08-15 20:05:43,821 : INFO : Current training batch loss: 0.0118 in epoch 3
2024-08-15 20:05:54,662 : INFO : Current training batch loss: 0.0206 in epoch 3
2024-08-15 20:06:05,514 : INFO : Current training batch loss: 0.0258 in epoch 3
2024-08-15 20:06:16,363 : INFO : Current training batch loss: 0.0295 in epoch 3
2024-08-15 20:06:27,206 : INFO : Current training batch loss: 0.0153 in epoch 3
2024-08-15 20:06:38,062 : INFO : Current training batch loss: 0.4432 in epoch 3
2024-08-15 20:06:48,942 : INFO : Current training batch loss: 0.0156 in epoch 3
2024-08-15 20:06:59,798 : INFO : Current training batch loss: 0.0060 in epoch 3
2024-08-15 20:07:10,649 : INFO : Current training batch loss: 0.0718 in epoch 3
2024-08-15 20:07:21,505 : INFO : Current training batch loss: 0.0203 in epoch 3
2024-08-15 20:07:32,352 : INFO : Current training batch loss: 0.2064 in epoch 3
2024-08-15 20:07:43,200 : INFO : Current training batch loss: 0.0257 in epoch 3
2024-08-15 20:07:54,048 : INFO : Current training batch loss: 0.0146 in epoch 3
2024-08-15 20:08:04,896 : INFO : Current training batch loss: 0.0043 in epoch 3
2024-08-15 20:08:15,743 : INFO : Current training batch loss: 0.0029 in epoch 3
2024-08-15 20:08:26,596 : INFO : Current training batch loss: 0.0039 in epoch 3
2024-08-15 20:08:37,439 : INFO : Current training batch loss: 0.0020 in epoch 3
2024-08-15 20:08:48,278 : INFO : Current training batch loss: 0.3750 in epoch 3
2024-08-15 20:08:57,165 : INFO : Epoch finished, average loss over training batches: 0.0737
2024-08-15 20:08:57,166 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:08:57,166 : INFO : Training metrics:
2024-08-15 20:08:57,166 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:08:57,482 : INFO : Accuracy: 0.9777
2024-08-15 20:08:57,482 : INFO : Precision: 0.9793
2024-08-15 20:08:57,482 : INFO : Recall: 0.9759
2024-08-15 20:08:57,482 : INFO : F1 score: 0.9776
2024-08-15 20:09:45,157 : INFO : Average loss over validation batches: 0.3254
2024-08-15 20:09:45,157 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:09:45,157 : INFO : Validation metrics:
2024-08-15 20:09:45,157 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:09:45,162 : INFO : Accuracy: 0.9158
2024-08-15 20:09:45,163 : INFO : Precision: 0.9374
2024-08-15 20:09:45,163 : INFO : Recall: 0.8929
2024-08-15 20:09:45,163 : INFO : F1 score: 0.9146
2024-08-15 20:09:45,163 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 20:09:45,163 : INFO : Starting epoch 4
2024-08-15 20:09:46,840 : INFO : Current training batch loss: 0.1429 in epoch 4
2024-08-15 20:09:57,703 : INFO : Current training batch loss: 0.0593 in epoch 4
2024-08-15 20:10:08,568 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-15 20:10:19,440 : INFO : Current training batch loss: 0.0151 in epoch 4
2024-08-15 20:10:30,332 : INFO : Current training batch loss: 0.0044 in epoch 4
2024-08-15 20:10:41,227 : INFO : Current training batch loss: 0.0051 in epoch 4
2024-08-15 20:10:52,108 : INFO : Current training batch loss: 0.2023 in epoch 4
2024-08-15 20:11:03,010 : INFO : Current training batch loss: 0.0028 in epoch 4
2024-08-15 20:11:13,890 : INFO : Current training batch loss: 0.0046 in epoch 4
2024-08-15 20:11:24,772 : INFO : Current training batch loss: 0.0020 in epoch 4
2024-08-15 20:11:35,651 : INFO : Current training batch loss: 0.0033 in epoch 4
2024-08-15 20:11:46,533 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-15 20:11:57,416 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-15 20:12:08,302 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 20:12:19,184 : INFO : Current training batch loss: 0.0105 in epoch 4
2024-08-15 20:12:30,072 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 20:12:40,957 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 20:12:51,843 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 20:13:02,736 : INFO : Current training batch loss: 0.0038 in epoch 4
2024-08-15 20:13:13,624 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-15 20:13:24,515 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 20:13:35,395 : INFO : Current training batch loss: 0.0726 in epoch 4
2024-08-15 20:13:46,271 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 20:13:57,146 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 20:14:08,025 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 20:14:18,911 : INFO : Current training batch loss: 0.0018 in epoch 4
2024-08-15 20:14:29,777 : INFO : Current training batch loss: 0.2065 in epoch 4
2024-08-15 20:14:40,653 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-15 20:14:51,528 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 20:15:02,417 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-15 20:15:03,750 : INFO : Epoch finished, average loss over training batches: 0.0211
2024-08-15 20:15:03,752 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:15:03,752 : INFO : Training metrics:
2024-08-15 20:15:03,752 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:15:04,069 : INFO : Accuracy: 0.9949
2024-08-15 20:15:04,069 : INFO : Precision: 0.9947
2024-08-15 20:15:04,069 : INFO : Recall: 0.9951
2024-08-15 20:15:04,069 : INFO : F1 score: 0.9949
2024-08-15 20:15:51,723 : INFO : Average loss over validation batches: 0.3248
2024-08-15 20:15:51,724 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:15:51,724 : INFO : Validation metrics:
2024-08-15 20:15:51,724 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:15:51,729 : INFO : Accuracy: 0.9222
2024-08-15 20:15:51,729 : INFO : Precision: 0.9298
2024-08-15 20:15:51,729 : INFO : Recall: 0.9151
2024-08-15 20:15:51,729 : INFO : F1 score: 0.9224
2024-08-15 20:15:51,729 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 20:15:51,729 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 20:15:52,218 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 20:16:38,849 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:16:38,849 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 20:16:38,850 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:16:38,855 : INFO : Accuracy: 0.9130
2024-08-15 20:16:38,855 : INFO : Precision: 0.8880
2024-08-15 20:16:38,855 : INFO : Recall: 0.9471
2024-08-15 20:16:38,855 : INFO : F1 score: 0.9166
2024-08-15 20:16:38,855 : INFO : Determined score from best model, ending training.
2024-08-15 20:16:38,856 : INFO : Split 1 is finished, the score is: 0.9166
2024-08-15 20:16:38,856 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:16:38,856 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:16:38,856 : INFO : Starting training for split 2
2024-08-15 20:16:39,155 : INFO : Counting occurences of labels...
2024-08-15 20:17:02,811 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-15 20:17:10,661 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 20:17:11,088 : INFO : Starting epoch 1
2024-08-15 20:17:11,669 : INFO : Current training batch loss: 0.7282 in epoch 1
2024-08-15 20:17:22,485 : INFO : Current training batch loss: 0.6701 in epoch 1
2024-08-15 20:17:33,312 : INFO : Current training batch loss: 0.6925 in epoch 1
2024-08-15 20:17:44,157 : INFO : Current training batch loss: 0.5218 in epoch 1
2024-08-15 20:17:55,022 : INFO : Current training batch loss: 0.4502 in epoch 1
2024-08-15 20:18:05,892 : INFO : Current training batch loss: 0.3751 in epoch 1
2024-08-15 20:18:16,759 : INFO : Current training batch loss: 0.2781 in epoch 1
2024-08-15 20:18:27,595 : INFO : Current training batch loss: 0.2114 in epoch 1
2024-08-15 20:18:38,435 : INFO : Current training batch loss: 0.2463 in epoch 1
2024-08-15 20:18:49,287 : INFO : Current training batch loss: 0.1191 in epoch 1
2024-08-15 20:19:00,137 : INFO : Current training batch loss: 0.1891 in epoch 1
2024-08-15 20:19:10,987 : INFO : Current training batch loss: 0.2600 in epoch 1
2024-08-15 20:19:21,826 : INFO : Current training batch loss: 0.2820 in epoch 1
2024-08-15 20:19:32,668 : INFO : Current training batch loss: 0.2060 in epoch 1
2024-08-15 20:19:43,524 : INFO : Current training batch loss: 0.1533 in epoch 1
2024-08-15 20:19:54,361 : INFO : Current training batch loss: 0.1056 in epoch 1
2024-08-15 20:20:05,210 : INFO : Current training batch loss: 0.2593 in epoch 1
2024-08-15 20:20:16,058 : INFO : Current training batch loss: 0.1755 in epoch 1
2024-08-15 20:20:26,905 : INFO : Current training batch loss: 0.1356 in epoch 1
2024-08-15 20:20:37,757 : INFO : Current training batch loss: 0.6115 in epoch 1
2024-08-15 20:20:48,608 : INFO : Current training batch loss: 0.2570 in epoch 1
2024-08-15 20:20:59,453 : INFO : Current training batch loss: 0.2847 in epoch 1
2024-08-15 20:21:10,308 : INFO : Current training batch loss: 0.3136 in epoch 1
2024-08-15 20:21:21,160 : INFO : Current training batch loss: 0.2062 in epoch 1
2024-08-15 20:21:32,013 : INFO : Current training batch loss: 0.1615 in epoch 1
2024-08-15 20:21:42,871 : INFO : Current training batch loss: 0.2402 in epoch 1
2024-08-15 20:21:53,716 : INFO : Current training batch loss: 0.2519 in epoch 1
2024-08-15 20:22:04,559 : INFO : Current training batch loss: 0.3954 in epoch 1
2024-08-15 20:22:15,414 : INFO : Current training batch loss: 0.0936 in epoch 1
2024-08-15 20:22:26,272 : INFO : Current training batch loss: 0.3474 in epoch 1
2024-08-15 20:22:28,691 : INFO : Epoch finished, average loss over training batches: 0.3484
2024-08-15 20:22:28,693 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:22:28,693 : INFO : Training metrics:
2024-08-15 20:22:28,693 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:22:29,001 : INFO : Accuracy: 0.8368
2024-08-15 20:22:29,001 : INFO : Precision: 0.8410
2024-08-15 20:22:29,001 : INFO : Recall: 0.8326
2024-08-15 20:22:29,001 : INFO : F1 score: 0.8368
2024-08-15 20:23:16,647 : INFO : Average loss over validation batches: 0.2105
2024-08-15 20:23:16,648 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:23:16,648 : INFO : Validation metrics:
2024-08-15 20:23:16,648 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:23:16,654 : INFO : Accuracy: 0.9166
2024-08-15 20:23:16,654 : INFO : Precision: 0.9147
2024-08-15 20:23:16,654 : INFO : Recall: 0.9162
2024-08-15 20:23:16,654 : INFO : F1 score: 0.9154
2024-08-15 20:23:16,654 : INFO : Validation metric decreased (inf --> 0.210478).  Saving model ...
2024-08-15 20:23:16,739 : INFO : Starting epoch 2
2024-08-15 20:23:24,907 : INFO : Current training batch loss: 0.1579 in epoch 2
2024-08-15 20:23:35,786 : INFO : Current training batch loss: 0.3539 in epoch 2
2024-08-15 20:23:46,661 : INFO : Current training batch loss: 0.1676 in epoch 2
2024-08-15 20:23:57,527 : INFO : Current training batch loss: 0.2731 in epoch 2
2024-08-15 20:24:08,380 : INFO : Current training batch loss: 0.4823 in epoch 2
2024-08-15 20:24:19,237 : INFO : Current training batch loss: 0.1690 in epoch 2
2024-08-15 20:24:30,086 : INFO : Current training batch loss: 0.1996 in epoch 2
2024-08-15 20:24:40,931 : INFO : Current training batch loss: 0.2423 in epoch 2
2024-08-15 20:24:51,777 : INFO : Current training batch loss: 0.0597 in epoch 2
2024-08-15 20:25:02,627 : INFO : Current training batch loss: 0.0472 in epoch 2
2024-08-15 20:25:13,479 : INFO : Current training batch loss: 0.0493 in epoch 2
2024-08-15 20:25:24,331 : INFO : Current training batch loss: 0.2052 in epoch 2
2024-08-15 20:25:35,183 : INFO : Current training batch loss: 0.1633 in epoch 2
2024-08-15 20:25:46,040 : INFO : Current training batch loss: 0.0544 in epoch 2
2024-08-15 20:25:56,885 : INFO : Current training batch loss: 0.1996 in epoch 2
2024-08-15 20:26:07,734 : INFO : Current training batch loss: 0.4117 in epoch 2
2024-08-15 20:26:18,586 : INFO : Current training batch loss: 0.1812 in epoch 2
2024-08-15 20:26:29,440 : INFO : Current training batch loss: 0.0311 in epoch 2
2024-08-15 20:26:40,297 : INFO : Current training batch loss: 0.1755 in epoch 2
2024-08-15 20:26:51,143 : INFO : Current training batch loss: 0.2472 in epoch 2
2024-08-15 20:27:01,994 : INFO : Current training batch loss: 0.0265 in epoch 2
2024-08-15 20:27:12,856 : INFO : Current training batch loss: 0.2428 in epoch 2
2024-08-15 20:27:23,702 : INFO : Current training batch loss: 0.0475 in epoch 2
2024-08-15 20:27:34,552 : INFO : Current training batch loss: 0.0814 in epoch 2
2024-08-15 20:27:45,409 : INFO : Current training batch loss: 0.1457 in epoch 2
2024-08-15 20:27:56,267 : INFO : Current training batch loss: 0.0321 in epoch 2
2024-08-15 20:28:07,112 : INFO : Current training batch loss: 0.1319 in epoch 2
2024-08-15 20:28:17,963 : INFO : Current training batch loss: 0.0093 in epoch 2
2024-08-15 20:28:28,818 : INFO : Current training batch loss: 0.0509 in epoch 2
2024-08-15 20:28:34,481 : INFO : Epoch finished, average loss over training batches: 0.1664
2024-08-15 20:28:34,482 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:28:34,482 : INFO : Training metrics:
2024-08-15 20:28:34,482 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:28:34,789 : INFO : Accuracy: 0.9393
2024-08-15 20:28:34,789 : INFO : Precision: 0.9382
2024-08-15 20:28:34,789 : INFO : Recall: 0.9412
2024-08-15 20:28:34,789 : INFO : F1 score: 0.9397
2024-08-15 20:29:22,406 : INFO : Average loss over validation batches: 0.2432
2024-08-15 20:29:22,406 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:29:22,406 : INFO : Validation metrics:
2024-08-15 20:29:22,406 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:29:22,412 : INFO : Accuracy: 0.9213
2024-08-15 20:29:22,412 : INFO : Precision: 0.9128
2024-08-15 20:29:22,412 : INFO : Recall: 0.9288
2024-08-15 20:29:22,412 : INFO : F1 score: 0.9208
2024-08-15 20:29:22,412 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 20:29:22,412 : INFO : Starting epoch 3
2024-08-15 20:29:27,328 : INFO : Current training batch loss: 0.1979 in epoch 3
2024-08-15 20:29:38,172 : INFO : Current training batch loss: 0.0859 in epoch 3
2024-08-15 20:29:49,023 : INFO : Current training batch loss: 0.1121 in epoch 3
2024-08-15 20:29:59,870 : INFO : Current training batch loss: 0.1137 in epoch 3
2024-08-15 20:30:10,717 : INFO : Current training batch loss: 0.0107 in epoch 3
2024-08-15 20:30:21,562 : INFO : Current training batch loss: 0.0144 in epoch 3
2024-08-15 20:30:32,415 : INFO : Current training batch loss: 0.0800 in epoch 3
2024-08-15 20:30:43,266 : INFO : Current training batch loss: 0.0031 in epoch 3
2024-08-15 20:30:54,111 : INFO : Current training batch loss: 0.0116 in epoch 3
2024-08-15 20:31:04,968 : INFO : Current training batch loss: 0.0079 in epoch 3
2024-08-15 20:31:15,825 : INFO : Current training batch loss: 0.0030 in epoch 3
2024-08-15 20:31:26,670 : INFO : Current training batch loss: 0.2168 in epoch 3
2024-08-15 20:31:37,517 : INFO : Current training batch loss: 0.0912 in epoch 3
2024-08-15 20:31:48,370 : INFO : Current training batch loss: 0.0161 in epoch 3
2024-08-15 20:31:59,224 : INFO : Current training batch loss: 0.0320 in epoch 3
2024-08-15 20:32:10,076 : INFO : Current training batch loss: 0.1008 in epoch 3
2024-08-15 20:32:20,939 : INFO : Current training batch loss: 0.2407 in epoch 3
2024-08-15 20:32:31,798 : INFO : Current training batch loss: 0.0564 in epoch 3
2024-08-15 20:32:42,665 : INFO : Current training batch loss: 0.0027 in epoch 3
2024-08-15 20:32:53,524 : INFO : Current training batch loss: 0.0689 in epoch 3
2024-08-15 20:33:04,390 : INFO : Current training batch loss: 0.0165 in epoch 3
2024-08-15 20:33:15,245 : INFO : Current training batch loss: 0.0444 in epoch 3
2024-08-15 20:33:26,100 : INFO : Current training batch loss: 0.0087 in epoch 3
2024-08-15 20:33:36,955 : INFO : Current training batch loss: 0.0033 in epoch 3
2024-08-15 20:33:47,809 : INFO : Current training batch loss: 0.0049 in epoch 3
2024-08-15 20:33:58,662 : INFO : Current training batch loss: 0.0019 in epoch 3
2024-08-15 20:34:09,520 : INFO : Current training batch loss: 0.0041 in epoch 3
2024-08-15 20:34:20,369 : INFO : Current training batch loss: 0.0019 in epoch 3
2024-08-15 20:34:31,225 : INFO : Current training batch loss: 0.3509 in epoch 3
2024-08-15 20:34:40,129 : INFO : Epoch finished, average loss over training batches: 0.0775
2024-08-15 20:34:40,131 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:34:40,131 : INFO : Training metrics:
2024-08-15 20:34:40,131 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:34:40,440 : INFO : Accuracy: 0.9754
2024-08-15 20:34:40,440 : INFO : Precision: 0.9774
2024-08-15 20:34:40,440 : INFO : Recall: 0.9735
2024-08-15 20:34:40,440 : INFO : F1 score: 0.9754
2024-08-15 20:35:28,099 : INFO : Average loss over validation batches: 0.2758
2024-08-15 20:35:28,100 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:35:28,100 : INFO : Validation metrics:
2024-08-15 20:35:28,100 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:35:28,106 : INFO : Accuracy: 0.9272
2024-08-15 20:35:28,106 : INFO : Precision: 0.9282
2024-08-15 20:35:28,106 : INFO : Recall: 0.9237
2024-08-15 20:35:28,106 : INFO : F1 score: 0.9259
2024-08-15 20:35:28,106 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 20:35:28,106 : INFO : Starting epoch 4
2024-08-15 20:35:29,771 : INFO : Current training batch loss: 0.0020 in epoch 4
2024-08-15 20:35:40,634 : INFO : Current training batch loss: 0.0170 in epoch 4
2024-08-15 20:35:51,507 : INFO : Current training batch loss: 0.0032 in epoch 4
2024-08-15 20:36:02,379 : INFO : Current training batch loss: 0.0371 in epoch 4
2024-08-15 20:36:13,231 : INFO : Current training batch loss: 0.0039 in epoch 4
2024-08-15 20:36:24,077 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-15 20:36:34,922 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 20:36:45,771 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-15 20:36:56,635 : INFO : Current training batch loss: 0.0031 in epoch 4
2024-08-15 20:37:07,472 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-15 20:37:18,330 : INFO : Current training batch loss: 0.0059 in epoch 4
2024-08-15 20:37:29,177 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 20:37:40,022 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 20:37:50,873 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-15 20:38:01,725 : INFO : Current training batch loss: 0.0028 in epoch 4
2024-08-15 20:38:12,573 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 20:38:23,424 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 20:38:34,273 : INFO : Current training batch loss: 0.2165 in epoch 4
2024-08-15 20:38:45,124 : INFO : Current training batch loss: 0.0046 in epoch 4
2024-08-15 20:38:55,971 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-15 20:39:06,830 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 20:39:17,678 : INFO : Current training batch loss: 0.4890 in epoch 4
2024-08-15 20:39:28,521 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 20:39:39,360 : INFO : Current training batch loss: 0.0089 in epoch 4
2024-08-15 20:39:50,208 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-15 20:40:01,061 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 20:40:11,910 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 20:40:22,764 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-15 20:40:33,616 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 20:40:44,479 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-15 20:40:45,815 : INFO : Epoch finished, average loss over training batches: 0.0239
2024-08-15 20:40:45,817 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:40:45,817 : INFO : Training metrics:
2024-08-15 20:40:45,817 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:40:46,125 : INFO : Accuracy: 0.9940
2024-08-15 20:40:46,125 : INFO : Precision: 0.9935
2024-08-15 20:40:46,125 : INFO : Recall: 0.9945
2024-08-15 20:40:46,125 : INFO : F1 score: 0.9940
2024-08-15 20:41:33,779 : INFO : Average loss over validation batches: 0.3127
2024-08-15 20:41:33,780 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:41:33,780 : INFO : Validation metrics:
2024-08-15 20:41:33,780 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:41:33,785 : INFO : Accuracy: 0.9267
2024-08-15 20:41:33,785 : INFO : Precision: 0.9250
2024-08-15 20:41:33,785 : INFO : Recall: 0.9263
2024-08-15 20:41:33,786 : INFO : F1 score: 0.9256
2024-08-15 20:41:33,786 : INFO : EarlyStopping counter: 3 out of 3
2024-08-15 20:41:33,786 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 20:41:34,285 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 20:42:20,921 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:42:20,922 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 20:42:20,922 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:42:20,927 : INFO : Accuracy: 0.9166
2024-08-15 20:42:20,927 : INFO : Precision: 0.9147
2024-08-15 20:42:20,927 : INFO : Recall: 0.9162
2024-08-15 20:42:20,927 : INFO : F1 score: 0.9154
2024-08-15 20:42:20,927 : INFO : Determined score from best model, ending training.
2024-08-15 20:42:20,929 : INFO : Split 2 is finished, the score is: 0.9154
2024-08-15 20:42:20,929 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:42:20,929 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:42:20,929 : INFO : Starting training for split 3
2024-08-15 20:42:21,221 : INFO : Counting occurences of labels...
2024-08-15 20:42:44,540 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-15 20:42:52,374 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 20:42:52,795 : INFO : Starting epoch 1
2024-08-15 20:42:53,376 : INFO : Current training batch loss: 0.6818 in epoch 1
2024-08-15 20:43:04,207 : INFO : Current training batch loss: 0.6875 in epoch 1
2024-08-15 20:43:15,048 : INFO : Current training batch loss: 0.6798 in epoch 1
2024-08-15 20:43:25,911 : INFO : Current training batch loss: 0.6137 in epoch 1
2024-08-15 20:43:36,785 : INFO : Current training batch loss: 0.4212 in epoch 1
2024-08-15 20:43:47,660 : INFO : Current training batch loss: 0.2119 in epoch 1
2024-08-15 20:43:58,548 : INFO : Current training batch loss: 0.2694 in epoch 1
2024-08-15 20:44:09,422 : INFO : Current training batch loss: 0.2388 in epoch 1
2024-08-15 20:44:20,300 : INFO : Current training batch loss: 0.2352 in epoch 1
2024-08-15 20:44:31,189 : INFO : Current training batch loss: 0.2116 in epoch 1
2024-08-15 20:44:42,080 : INFO : Current training batch loss: 0.3923 in epoch 1
2024-08-15 20:44:52,971 : INFO : Current training batch loss: 0.3583 in epoch 1
2024-08-15 20:45:03,862 : INFO : Current training batch loss: 0.3353 in epoch 1
2024-08-15 20:45:14,755 : INFO : Current training batch loss: 0.1516 in epoch 1
2024-08-15 20:45:25,655 : INFO : Current training batch loss: 0.2664 in epoch 1
2024-08-15 20:45:36,545 : INFO : Current training batch loss: 0.3339 in epoch 1
2024-08-15 20:45:47,437 : INFO : Current training batch loss: 0.2704 in epoch 1
2024-08-15 20:45:58,334 : INFO : Current training batch loss: 0.2252 in epoch 1
2024-08-15 20:46:09,215 : INFO : Current training batch loss: 0.2233 in epoch 1
2024-08-15 20:46:20,103 : INFO : Current training batch loss: 0.3697 in epoch 1
2024-08-15 20:46:30,997 : INFO : Current training batch loss: 0.2500 in epoch 1
2024-08-15 20:46:41,888 : INFO : Current training batch loss: 0.2177 in epoch 1
2024-08-15 20:46:52,790 : INFO : Current training batch loss: 0.4593 in epoch 1
2024-08-15 20:47:03,683 : INFO : Current training batch loss: 0.2191 in epoch 1
2024-08-15 20:47:14,576 : INFO : Current training batch loss: 0.2793 in epoch 1
2024-08-15 20:47:25,470 : INFO : Current training batch loss: 0.1482 in epoch 1
2024-08-15 20:47:36,342 : INFO : Current training batch loss: 0.2585 in epoch 1
2024-08-15 20:47:47,215 : INFO : Current training batch loss: 0.4471 in epoch 1
2024-08-15 20:47:58,104 : INFO : Current training batch loss: 0.0847 in epoch 1
2024-08-15 20:48:08,993 : INFO : Current training batch loss: 0.2973 in epoch 1
2024-08-15 20:48:11,409 : INFO : Epoch finished, average loss over training batches: 0.3506
2024-08-15 20:48:11,410 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:48:11,410 : INFO : Training metrics:
2024-08-15 20:48:11,410 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:48:11,749 : INFO : Accuracy: 0.8383
2024-08-15 20:48:11,749 : INFO : Precision: 0.8427
2024-08-15 20:48:11,749 : INFO : Recall: 0.8333
2024-08-15 20:48:11,749 : INFO : F1 score: 0.8379
2024-08-15 20:48:59,563 : INFO : Average loss over validation batches: 0.2274
2024-08-15 20:48:59,564 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:48:59,564 : INFO : Validation metrics:
2024-08-15 20:48:59,564 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:48:59,569 : INFO : Accuracy: 0.9094
2024-08-15 20:48:59,569 : INFO : Precision: 0.8869
2024-08-15 20:48:59,569 : INFO : Recall: 0.9367
2024-08-15 20:48:59,569 : INFO : F1 score: 0.9111
2024-08-15 20:48:59,569 : INFO : Validation metric decreased (inf --> 0.227401).  Saving model ...
2024-08-15 20:48:59,654 : INFO : Starting epoch 2
2024-08-15 20:49:07,809 : INFO : Current training batch loss: 0.1689 in epoch 2
2024-08-15 20:49:18,676 : INFO : Current training batch loss: 0.2741 in epoch 2
2024-08-15 20:49:29,548 : INFO : Current training batch loss: 0.1243 in epoch 2
2024-08-15 20:49:40,428 : INFO : Current training batch loss: 0.1395 in epoch 2
2024-08-15 20:49:51,313 : INFO : Current training batch loss: 0.3032 in epoch 2
2024-08-15 20:50:02,203 : INFO : Current training batch loss: 0.2354 in epoch 2
2024-08-15 20:50:13,093 : INFO : Current training batch loss: 0.1557 in epoch 2
2024-08-15 20:50:23,972 : INFO : Current training batch loss: 0.2441 in epoch 2
2024-08-15 20:50:34,847 : INFO : Current training batch loss: 0.1250 in epoch 2
2024-08-15 20:50:45,730 : INFO : Current training batch loss: 0.0566 in epoch 2
2024-08-15 20:50:56,622 : INFO : Current training batch loss: 0.1622 in epoch 2
2024-08-15 20:51:07,503 : INFO : Current training batch loss: 0.2921 in epoch 2
2024-08-15 20:51:18,381 : INFO : Current training batch loss: 0.0968 in epoch 2
2024-08-15 20:51:29,267 : INFO : Current training batch loss: 0.0332 in epoch 2
2024-08-15 20:51:40,152 : INFO : Current training batch loss: 0.1765 in epoch 2
2024-08-15 20:51:51,048 : INFO : Current training batch loss: 0.0806 in epoch 2
2024-08-15 20:52:01,933 : INFO : Current training batch loss: 0.0479 in epoch 2
2024-08-15 20:52:12,814 : INFO : Current training batch loss: 0.2104 in epoch 2
2024-08-15 20:52:23,694 : INFO : Current training batch loss: 0.3567 in epoch 2
2024-08-15 20:52:34,577 : INFO : Current training batch loss: 0.1910 in epoch 2
2024-08-15 20:52:45,457 : INFO : Current training batch loss: 0.3748 in epoch 2
2024-08-15 20:52:56,350 : INFO : Current training batch loss: 0.2432 in epoch 2
2024-08-15 20:53:07,229 : INFO : Current training batch loss: 0.0986 in epoch 2
2024-08-15 20:53:18,107 : INFO : Current training batch loss: 0.0338 in epoch 2
2024-08-15 20:53:28,988 : INFO : Current training batch loss: 0.1186 in epoch 2
2024-08-15 20:53:39,869 : INFO : Current training batch loss: 0.0056 in epoch 2
2024-08-15 20:53:50,729 : INFO : Current training batch loss: 0.0328 in epoch 2
2024-08-15 20:54:01,595 : INFO : Current training batch loss: 0.0414 in epoch 2
2024-08-15 20:54:12,469 : INFO : Current training batch loss: 0.1076 in epoch 2
2024-08-15 20:54:18,137 : INFO : Epoch finished, average loss over training batches: 0.1674
2024-08-15 20:54:18,139 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:54:18,139 : INFO : Training metrics:
2024-08-15 20:54:18,139 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:54:18,451 : INFO : Accuracy: 0.9412
2024-08-15 20:54:18,451 : INFO : Precision: 0.9406
2024-08-15 20:54:18,451 : INFO : Recall: 0.9423
2024-08-15 20:54:18,451 : INFO : F1 score: 0.9414
2024-08-15 20:55:06,258 : INFO : Average loss over validation batches: 0.2269
2024-08-15 20:55:06,258 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:55:06,258 : INFO : Validation metrics:
2024-08-15 20:55:06,258 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 20:55:06,264 : INFO : Accuracy: 0.9224
2024-08-15 20:55:06,264 : INFO : Precision: 0.9084
2024-08-15 20:55:06,264 : INFO : Recall: 0.9380
2024-08-15 20:55:06,264 : INFO : F1 score: 0.9229
2024-08-15 20:55:06,264 : INFO : Validation metric decreased (0.227401 --> 0.226879).  Saving model ...
2024-08-15 20:55:06,352 : INFO : Starting epoch 3
2024-08-15 20:55:11,266 : INFO : Current training batch loss: 0.0717 in epoch 3
2024-08-15 20:55:22,127 : INFO : Current training batch loss: 0.0543 in epoch 3
2024-08-15 20:55:32,993 : INFO : Current training batch loss: 0.1952 in epoch 3
2024-08-15 20:55:43,864 : INFO : Current training batch loss: 0.0098 in epoch 3
2024-08-15 20:55:54,733 : INFO : Current training batch loss: 0.1562 in epoch 3
2024-08-15 20:56:05,599 : INFO : Current training batch loss: 0.0657 in epoch 3
2024-08-15 20:56:16,483 : INFO : Current training batch loss: 0.0045 in epoch 3
2024-08-15 20:56:27,371 : INFO : Current training batch loss: 0.0585 in epoch 3
2024-08-15 20:56:38,247 : INFO : Current training batch loss: 0.0076 in epoch 3
2024-08-15 20:56:49,133 : INFO : Current training batch loss: 0.0123 in epoch 3
2024-08-15 20:57:00,016 : INFO : Current training batch loss: 0.0097 in epoch 3
2024-08-15 20:57:10,893 : INFO : Current training batch loss: 0.0103 in epoch 3
2024-08-15 20:57:21,769 : INFO : Current training batch loss: 0.0092 in epoch 3
2024-08-15 20:57:32,655 : INFO : Current training batch loss: 0.1932 in epoch 3
2024-08-15 20:57:43,552 : INFO : Current training batch loss: 0.0361 in epoch 3
2024-08-15 20:57:54,438 : INFO : Current training batch loss: 0.1403 in epoch 3
2024-08-15 20:58:05,330 : INFO : Current training batch loss: 0.0925 in epoch 3
2024-08-15 20:58:16,213 : INFO : Current training batch loss: 0.0638 in epoch 3
2024-08-15 20:58:27,098 : INFO : Current training batch loss: 0.0080 in epoch 3
2024-08-15 20:58:37,984 : INFO : Current training batch loss: 0.0024 in epoch 3
2024-08-15 20:58:48,874 : INFO : Current training batch loss: 0.1468 in epoch 3
2024-08-15 20:58:59,755 : INFO : Current training batch loss: 0.0043 in epoch 3
2024-08-15 20:59:10,639 : INFO : Current training batch loss: 0.0282 in epoch 3
2024-08-15 20:59:21,520 : INFO : Current training batch loss: 0.0114 in epoch 3
2024-08-15 20:59:32,401 : INFO : Current training batch loss: 0.0064 in epoch 3
2024-08-15 20:59:43,279 : INFO : Current training batch loss: 0.0038 in epoch 3
2024-08-15 20:59:54,162 : INFO : Current training batch loss: 0.0023 in epoch 3
2024-08-15 21:00:05,038 : INFO : Current training batch loss: 0.0030 in epoch 3
2024-08-15 21:00:15,916 : INFO : Current training batch loss: 0.3226 in epoch 3
2024-08-15 21:00:24,843 : INFO : Epoch finished, average loss over training batches: 0.0734
2024-08-15 21:00:24,845 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:00:24,845 : INFO : Training metrics:
2024-08-15 21:00:24,845 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:00:25,155 : INFO : Accuracy: 0.9779
2024-08-15 21:00:25,155 : INFO : Precision: 0.9742
2024-08-15 21:00:25,155 : INFO : Recall: 0.9820
2024-08-15 21:00:25,155 : INFO : F1 score: 0.9781
2024-08-15 21:01:13,051 : INFO : Average loss over validation batches: 0.3329
2024-08-15 21:01:13,052 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:01:13,052 : INFO : Validation metrics:
2024-08-15 21:01:13,052 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:01:13,057 : INFO : Accuracy: 0.9136
2024-08-15 21:01:13,058 : INFO : Precision: 0.9551
2024-08-15 21:01:13,058 : INFO : Recall: 0.8663
2024-08-15 21:01:13,058 : INFO : F1 score: 0.9085
2024-08-15 21:01:13,058 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 21:01:13,058 : INFO : Starting epoch 4
2024-08-15 21:01:14,723 : INFO : Current training batch loss: 0.1851 in epoch 4
2024-08-15 21:01:25,591 : INFO : Current training batch loss: 0.2258 in epoch 4
2024-08-15 21:01:36,465 : INFO : Current training batch loss: 0.0023 in epoch 4
2024-08-15 21:01:47,342 : INFO : Current training batch loss: 0.0031 in epoch 4
2024-08-15 21:01:58,218 : INFO : Current training batch loss: 0.0036 in epoch 4
2024-08-15 21:02:09,095 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-15 21:02:19,974 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 21:02:30,854 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 21:02:41,748 : INFO : Current training batch loss: 0.0218 in epoch 4
2024-08-15 21:02:52,626 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 21:03:03,518 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 21:03:14,371 : INFO : Current training batch loss: 0.1277 in epoch 4
2024-08-15 21:03:25,226 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 21:03:36,080 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 21:03:46,924 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 21:03:57,767 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 21:04:08,618 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 21:04:19,469 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 21:04:30,306 : INFO : Current training batch loss: 0.0160 in epoch 4
2024-08-15 21:04:41,148 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 21:04:51,995 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 21:05:02,836 : INFO : Current training batch loss: 0.2122 in epoch 4
2024-08-15 21:05:13,673 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-15 21:05:24,508 : INFO : Current training batch loss: 0.0018 in epoch 4
2024-08-15 21:05:35,345 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-15 21:05:46,224 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 21:05:57,097 : INFO : Current training batch loss: 0.0034 in epoch 4
2024-08-15 21:06:07,979 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 21:06:18,875 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-15 21:06:29,769 : INFO : Current training batch loss: 0.0050 in epoch 4
2024-08-15 21:06:31,111 : INFO : Epoch finished, average loss over training batches: 0.0231
2024-08-15 21:06:31,113 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:06:31,113 : INFO : Training metrics:
2024-08-15 21:06:31,113 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:06:31,423 : INFO : Accuracy: 0.9947
2024-08-15 21:06:31,423 : INFO : Precision: 0.9957
2024-08-15 21:06:31,423 : INFO : Recall: 0.9937
2024-08-15 21:06:31,423 : INFO : F1 score: 0.9947
2024-08-15 21:07:19,290 : INFO : Average loss over validation batches: 0.3163
2024-08-15 21:07:19,291 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:07:19,291 : INFO : Validation metrics:
2024-08-15 21:07:19,291 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:07:19,296 : INFO : Accuracy: 0.9269
2024-08-15 21:07:19,296 : INFO : Precision: 0.9294
2024-08-15 21:07:19,296 : INFO : Recall: 0.9225
2024-08-15 21:07:19,296 : INFO : F1 score: 0.9259
2024-08-15 21:07:19,296 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 21:07:19,296 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 21:07:19,793 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 21:08:06,640 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:08:06,640 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 21:08:06,640 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:08:06,645 : INFO : Accuracy: 0.9224
2024-08-15 21:08:06,645 : INFO : Precision: 0.9084
2024-08-15 21:08:06,645 : INFO : Recall: 0.9380
2024-08-15 21:08:06,645 : INFO : F1 score: 0.9229
2024-08-15 21:08:06,645 : INFO : Determined score from best model, ending training.
2024-08-15 21:08:06,647 : INFO : Split 3 is finished, the score is: 0.9229
2024-08-15 21:08:06,647 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:08:06,652 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:08:06,652 : INFO : Starting training for split 4
2024-08-15 21:08:06,941 : INFO : Counting occurences of labels...
2024-08-15 21:08:30,286 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-15 21:08:37,988 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 21:08:38,442 : INFO : Starting epoch 1
2024-08-15 21:08:39,022 : INFO : Current training batch loss: 0.7050 in epoch 1
2024-08-15 21:08:49,858 : INFO : Current training batch loss: 0.6678 in epoch 1
2024-08-15 21:09:00,692 : INFO : Current training batch loss: 0.6668 in epoch 1
2024-08-15 21:09:11,541 : INFO : Current training batch loss: 0.6019 in epoch 1
2024-08-15 21:09:22,403 : INFO : Current training batch loss: 0.3030 in epoch 1
2024-08-15 21:09:33,267 : INFO : Current training batch loss: 0.2815 in epoch 1
2024-08-15 21:09:44,143 : INFO : Current training batch loss: 0.2085 in epoch 1
2024-08-15 21:09:55,004 : INFO : Current training batch loss: 0.2460 in epoch 1
2024-08-15 21:10:05,878 : INFO : Current training batch loss: 0.2130 in epoch 1
2024-08-15 21:10:16,754 : INFO : Current training batch loss: 0.1685 in epoch 1
2024-08-15 21:10:27,627 : INFO : Current training batch loss: 0.3015 in epoch 1
2024-08-15 21:10:38,505 : INFO : Current training batch loss: 0.2609 in epoch 1
2024-08-15 21:10:49,384 : INFO : Current training batch loss: 0.5388 in epoch 1
2024-08-15 21:11:00,265 : INFO : Current training batch loss: 0.1684 in epoch 1
2024-08-15 21:11:11,150 : INFO : Current training batch loss: 0.2719 in epoch 1
2024-08-15 21:11:22,031 : INFO : Current training batch loss: 0.2128 in epoch 1
2024-08-15 21:11:32,919 : INFO : Current training batch loss: 0.2088 in epoch 1
2024-08-15 21:11:43,812 : INFO : Current training batch loss: 0.1904 in epoch 1
2024-08-15 21:11:54,689 : INFO : Current training batch loss: 0.3700 in epoch 1
2024-08-15 21:12:05,568 : INFO : Current training batch loss: 0.3152 in epoch 1
2024-08-15 21:12:16,450 : INFO : Current training batch loss: 0.4118 in epoch 1
2024-08-15 21:12:27,326 : INFO : Current training batch loss: 0.3097 in epoch 1
2024-08-15 21:12:38,201 : INFO : Current training batch loss: 0.2296 in epoch 1
2024-08-15 21:12:49,073 : INFO : Current training batch loss: 0.5036 in epoch 1
2024-08-15 21:12:59,951 : INFO : Current training batch loss: 0.1701 in epoch 1
2024-08-15 21:13:10,822 : INFO : Current training batch loss: 0.2273 in epoch 1
2024-08-15 21:13:21,700 : INFO : Current training batch loss: 0.3264 in epoch 1
2024-08-15 21:13:32,580 : INFO : Current training batch loss: 0.5348 in epoch 1
2024-08-15 21:13:43,462 : INFO : Current training batch loss: 0.3739 in epoch 1
2024-08-15 21:13:54,331 : INFO : Current training batch loss: 0.2894 in epoch 1
2024-08-15 21:13:56,758 : INFO : Epoch finished, average loss over training batches: 0.3388
2024-08-15 21:13:56,760 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:13:56,760 : INFO : Training metrics:
2024-08-15 21:13:56,760 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:13:57,069 : INFO : Accuracy: 0.8462
2024-08-15 21:13:57,069 : INFO : Precision: 0.8469
2024-08-15 21:13:57,069 : INFO : Recall: 0.8435
2024-08-15 21:13:57,069 : INFO : F1 score: 0.8452
2024-08-15 21:14:44,744 : INFO : Average loss over validation batches: 0.2279
2024-08-15 21:14:44,745 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:14:44,745 : INFO : Validation metrics:
2024-08-15 21:14:44,745 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:14:44,750 : INFO : Accuracy: 0.9115
2024-08-15 21:14:44,750 : INFO : Precision: 0.9264
2024-08-15 21:14:44,750 : INFO : Recall: 0.8969
2024-08-15 21:14:44,750 : INFO : F1 score: 0.9114
2024-08-15 21:14:44,750 : INFO : Validation metric decreased (inf --> 0.227940).  Saving model ...
2024-08-15 21:14:44,834 : INFO : Starting epoch 2
2024-08-15 21:14:52,991 : INFO : Current training batch loss: 0.0532 in epoch 2
2024-08-15 21:15:03,851 : INFO : Current training batch loss: 0.2342 in epoch 2
2024-08-15 21:15:14,717 : INFO : Current training batch loss: 0.1546 in epoch 2
2024-08-15 21:15:25,591 : INFO : Current training batch loss: 0.2058 in epoch 2
2024-08-15 21:15:36,473 : INFO : Current training batch loss: 0.3900 in epoch 2
2024-08-15 21:15:47,355 : INFO : Current training batch loss: 0.1232 in epoch 2
2024-08-15 21:15:58,235 : INFO : Current training batch loss: 0.4047 in epoch 2
2024-08-15 21:16:09,111 : INFO : Current training batch loss: 0.2419 in epoch 2
2024-08-15 21:16:19,986 : INFO : Current training batch loss: 0.3080 in epoch 2
2024-08-15 21:16:30,867 : INFO : Current training batch loss: 0.0987 in epoch 2
2024-08-15 21:16:41,758 : INFO : Current training batch loss: 0.1616 in epoch 2
2024-08-15 21:16:52,642 : INFO : Current training batch loss: 0.1184 in epoch 2
2024-08-15 21:17:03,522 : INFO : Current training batch loss: 0.0323 in epoch 2
2024-08-15 21:17:14,394 : INFO : Current training batch loss: 0.1186 in epoch 2
2024-08-15 21:17:25,261 : INFO : Current training batch loss: 0.1158 in epoch 2
2024-08-15 21:17:36,138 : INFO : Current training batch loss: 0.2010 in epoch 2
2024-08-15 21:17:47,008 : INFO : Current training batch loss: 0.1177 in epoch 2
2024-08-15 21:17:57,873 : INFO : Current training batch loss: 0.1687 in epoch 2
2024-08-15 21:18:08,748 : INFO : Current training batch loss: 0.1072 in epoch 2
2024-08-15 21:18:19,626 : INFO : Current training batch loss: 0.0510 in epoch 2
2024-08-15 21:18:30,512 : INFO : Current training batch loss: 0.0195 in epoch 2
2024-08-15 21:18:41,388 : INFO : Current training batch loss: 0.0577 in epoch 2
2024-08-15 21:18:52,268 : INFO : Current training batch loss: 0.0729 in epoch 2
2024-08-15 21:19:03,154 : INFO : Current training batch loss: 0.0102 in epoch 2
2024-08-15 21:19:14,022 : INFO : Current training batch loss: 0.0159 in epoch 2
2024-08-15 21:19:24,889 : INFO : Current training batch loss: 0.0858 in epoch 2
2024-08-15 21:19:35,761 : INFO : Current training batch loss: 0.1033 in epoch 2
2024-08-15 21:19:46,628 : INFO : Current training batch loss: 0.1372 in epoch 2
2024-08-15 21:19:57,493 : INFO : Current training batch loss: 0.0578 in epoch 2
2024-08-15 21:20:03,174 : INFO : Epoch finished, average loss over training batches: 0.1594
2024-08-15 21:20:03,176 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:20:03,176 : INFO : Training metrics:
2024-08-15 21:20:03,176 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:20:03,531 : INFO : Accuracy: 0.9418
2024-08-15 21:20:03,532 : INFO : Precision: 0.9408
2024-08-15 21:20:03,532 : INFO : Recall: 0.9423
2024-08-15 21:20:03,532 : INFO : F1 score: 0.9416
2024-08-15 21:20:51,179 : INFO : Average loss over validation batches: 0.2739
2024-08-15 21:20:51,180 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:20:51,180 : INFO : Validation metrics:
2024-08-15 21:20:51,180 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:20:51,186 : INFO : Accuracy: 0.9107
2024-08-15 21:20:51,186 : INFO : Precision: 0.9430
2024-08-15 21:20:51,186 : INFO : Recall: 0.8770
2024-08-15 21:20:51,186 : INFO : F1 score: 0.9088
2024-08-15 21:20:51,186 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 21:20:51,186 : INFO : Starting epoch 3
2024-08-15 21:20:56,095 : INFO : Current training batch loss: 0.2084 in epoch 3
2024-08-15 21:21:06,953 : INFO : Current training batch loss: 0.1632 in epoch 3
2024-08-15 21:21:17,814 : INFO : Current training batch loss: 0.1018 in epoch 3
2024-08-15 21:21:28,682 : INFO : Current training batch loss: 0.0227 in epoch 3
2024-08-15 21:21:39,548 : INFO : Current training batch loss: 0.0296 in epoch 3
2024-08-15 21:21:50,413 : INFO : Current training batch loss: 0.0046 in epoch 3
2024-08-15 21:22:01,287 : INFO : Current training batch loss: 0.0974 in epoch 3
2024-08-15 21:22:12,158 : INFO : Current training batch loss: 0.0066 in epoch 3
2024-08-15 21:22:23,028 : INFO : Current training batch loss: 0.0133 in epoch 3
2024-08-15 21:22:33,910 : INFO : Current training batch loss: 0.2031 in epoch 3
2024-08-15 21:22:44,791 : INFO : Current training batch loss: 0.0032 in epoch 3
2024-08-15 21:22:55,665 : INFO : Current training batch loss: 0.0038 in epoch 3
2024-08-15 21:23:06,539 : INFO : Current training batch loss: 0.0072 in epoch 3
2024-08-15 21:23:17,413 : INFO : Current training batch loss: 0.2436 in epoch 3
2024-08-15 21:23:28,296 : INFO : Current training batch loss: 0.0157 in epoch 3
2024-08-15 21:23:39,173 : INFO : Current training batch loss: 0.0095 in epoch 3
2024-08-15 21:23:50,064 : INFO : Current training batch loss: 0.0243 in epoch 3
2024-08-15 21:24:00,949 : INFO : Current training batch loss: 0.0094 in epoch 3
2024-08-15 21:24:11,834 : INFO : Current training batch loss: 0.0037 in epoch 3
2024-08-15 21:24:22,712 : INFO : Current training batch loss: 0.0016 in epoch 3
2024-08-15 21:24:33,597 : INFO : Current training batch loss: 0.0066 in epoch 3
2024-08-15 21:24:44,473 : INFO : Current training batch loss: 0.2065 in epoch 3
2024-08-15 21:24:55,346 : INFO : Current training batch loss: 0.0736 in epoch 3
2024-08-15 21:25:06,208 : INFO : Current training batch loss: 0.0051 in epoch 3
2024-08-15 21:25:17,061 : INFO : Current training batch loss: 0.0022 in epoch 3
2024-08-15 21:25:27,927 : INFO : Current training batch loss: 0.0047 in epoch 3
2024-08-15 21:25:38,797 : INFO : Current training batch loss: 0.0013 in epoch 3
2024-08-15 21:25:49,680 : INFO : Current training batch loss: 0.1270 in epoch 3
2024-08-15 21:26:00,546 : INFO : Current training batch loss: 0.0013 in epoch 3
2024-08-15 21:26:09,459 : INFO : Epoch finished, average loss over training batches: 0.0694
2024-08-15 21:26:09,461 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:26:09,461 : INFO : Training metrics:
2024-08-15 21:26:09,461 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:26:09,771 : INFO : Accuracy: 0.9782
2024-08-15 21:26:09,771 : INFO : Precision: 0.9767
2024-08-15 21:26:09,771 : INFO : Recall: 0.9796
2024-08-15 21:26:09,771 : INFO : F1 score: 0.9782
2024-08-15 21:26:57,382 : INFO : Average loss over validation batches: 0.3171
2024-08-15 21:26:57,383 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:26:57,383 : INFO : Validation metrics:
2024-08-15 21:26:57,383 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:26:57,388 : INFO : Accuracy: 0.9192
2024-08-15 21:26:57,388 : INFO : Precision: 0.9256
2024-08-15 21:26:57,388 : INFO : Recall: 0.9142
2024-08-15 21:26:57,388 : INFO : F1 score: 0.9199
2024-08-15 21:26:57,388 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 21:26:57,388 : INFO : Starting epoch 4
2024-08-15 21:26:59,051 : INFO : Current training batch loss: 0.1566 in epoch 4
2024-08-15 21:27:09,898 : INFO : Current training batch loss: 0.0052 in epoch 4
2024-08-15 21:27:20,748 : INFO : Current training batch loss: 0.0106 in epoch 4
2024-08-15 21:27:31,594 : INFO : Current training batch loss: 0.0021 in epoch 4
2024-08-15 21:27:42,439 : INFO : Current training batch loss: 0.0757 in epoch 4
2024-08-15 21:27:53,287 : INFO : Current training batch loss: 0.0022 in epoch 4
2024-08-15 21:28:04,143 : INFO : Current training batch loss: 0.0018 in epoch 4
2024-08-15 21:28:15,001 : INFO : Current training batch loss: 0.0017 in epoch 4
2024-08-15 21:28:25,878 : INFO : Current training batch loss: 0.0020 in epoch 4
2024-08-15 21:28:36,731 : INFO : Current training batch loss: 0.0020 in epoch 4
2024-08-15 21:28:47,604 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 21:28:58,466 : INFO : Current training batch loss: 0.0212 in epoch 4
2024-08-15 21:29:09,342 : INFO : Current training batch loss: 0.0099 in epoch 4
2024-08-15 21:29:20,210 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 21:29:31,069 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 21:29:41,931 : INFO : Current training batch loss: 0.0031 in epoch 4
2024-08-15 21:29:52,803 : INFO : Current training batch loss: 0.0446 in epoch 4
2024-08-15 21:30:03,665 : INFO : Current training batch loss: 0.0143 in epoch 4
2024-08-15 21:30:14,523 : INFO : Current training batch loss: 0.0025 in epoch 4
2024-08-15 21:30:25,384 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 21:30:36,250 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 21:30:47,113 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 21:30:57,979 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 21:31:08,840 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 21:31:19,698 : INFO : Current training batch loss: 0.0058 in epoch 4
2024-08-15 21:31:30,582 : INFO : Current training batch loss: 0.0028 in epoch 4
2024-08-15 21:31:41,461 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 21:31:52,341 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 21:32:03,209 : INFO : Current training batch loss: 0.0017 in epoch 4
2024-08-15 21:32:14,070 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-15 21:32:15,394 : INFO : Epoch finished, average loss over training batches: 0.0202
2024-08-15 21:32:15,395 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:32:15,395 : INFO : Training metrics:
2024-08-15 21:32:15,395 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:32:15,714 : INFO : Accuracy: 0.9953
2024-08-15 21:32:15,714 : INFO : Precision: 0.9945
2024-08-15 21:32:15,714 : INFO : Recall: 0.9960
2024-08-15 21:32:15,714 : INFO : F1 score: 0.9953
2024-08-15 21:33:03,336 : INFO : Average loss over validation batches: 0.3388
2024-08-15 21:33:03,337 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:33:03,337 : INFO : Validation metrics:
2024-08-15 21:33:03,337 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:33:03,342 : INFO : Accuracy: 0.9214
2024-08-15 21:33:03,342 : INFO : Precision: 0.9251
2024-08-15 21:33:03,342 : INFO : Recall: 0.9196
2024-08-15 21:33:03,342 : INFO : F1 score: 0.9223
2024-08-15 21:33:03,342 : INFO : EarlyStopping counter: 3 out of 3
2024-08-15 21:33:03,342 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 21:33:03,835 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 21:33:50,374 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:33:50,374 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 21:33:50,375 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:33:50,380 : INFO : Accuracy: 0.9115
2024-08-15 21:33:50,380 : INFO : Precision: 0.9264
2024-08-15 21:33:50,380 : INFO : Recall: 0.8969
2024-08-15 21:33:50,380 : INFO : F1 score: 0.9114
2024-08-15 21:33:50,380 : INFO : Determined score from best model, ending training.
2024-08-15 21:33:50,381 : INFO : Split 4 is finished, the score is: 0.9114
2024-08-15 21:33:50,381 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-15 21:33:50,387] Trial 2 finished with value: 0.9165807170165061 and parameters: {'n_epochs': 4, 'learning_rate': 0.00014188233598563558, 'classifier_dropout': 0.12525626395995992, 'warmup_step_fraction': 0.04666768557367567, 'use_gradient_clipping': True}. Best is trial 1 with value: 0.9219339021161369.
2024-08-15 21:33:50,388 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:33:50,388 : INFO : Starting training for split 1
2024-08-15 21:33:50,701 : INFO : Counting occurences of labels...
2024-08-15 21:34:13,935 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-15 21:34:21,780 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 21:34:22,208 : INFO : Starting epoch 1
2024-08-15 21:34:22,797 : INFO : Current training batch loss: 0.7359 in epoch 1
2024-08-15 21:34:33,578 : INFO : Current training batch loss: 0.6796 in epoch 1
2024-08-15 21:34:44,404 : INFO : Current training batch loss: 0.6386 in epoch 1
2024-08-15 21:34:55,231 : INFO : Current training batch loss: 0.5133 in epoch 1
2024-08-15 21:35:06,057 : INFO : Current training batch loss: 0.4341 in epoch 1
2024-08-15 21:35:16,899 : INFO : Current training batch loss: 0.4425 in epoch 1
2024-08-15 21:35:27,744 : INFO : Current training batch loss: 0.4332 in epoch 1
2024-08-15 21:35:38,598 : INFO : Current training batch loss: 0.3505 in epoch 1
2024-08-15 21:35:49,457 : INFO : Current training batch loss: 0.3849 in epoch 1
2024-08-15 21:36:00,321 : INFO : Current training batch loss: 0.1192 in epoch 1
2024-08-15 21:36:11,193 : INFO : Current training batch loss: 0.3607 in epoch 1
2024-08-15 21:36:22,055 : INFO : Current training batch loss: 0.3887 in epoch 1
2024-08-15 21:36:32,909 : INFO : Current training batch loss: 0.1426 in epoch 1
2024-08-15 21:36:43,766 : INFO : Current training batch loss: 0.2192 in epoch 1
2024-08-15 21:36:54,640 : INFO : Current training batch loss: 0.1180 in epoch 1
2024-08-15 21:37:05,502 : INFO : Current training batch loss: 0.1201 in epoch 1
2024-08-15 21:37:16,380 : INFO : Current training batch loss: 0.2081 in epoch 1
2024-08-15 21:37:27,249 : INFO : Current training batch loss: 0.1482 in epoch 1
2024-08-15 21:37:38,120 : INFO : Current training batch loss: 0.1917 in epoch 1
2024-08-15 21:37:48,993 : INFO : Current training batch loss: 0.3990 in epoch 1
2024-08-15 21:37:59,874 : INFO : Current training batch loss: 0.1929 in epoch 1
2024-08-15 21:38:10,749 : INFO : Current training batch loss: 0.3119 in epoch 1
2024-08-15 21:38:21,632 : INFO : Current training batch loss: 0.2569 in epoch 1
2024-08-15 21:38:32,499 : INFO : Current training batch loss: 0.1896 in epoch 1
2024-08-15 21:38:43,366 : INFO : Current training batch loss: 0.2899 in epoch 1
2024-08-15 21:38:54,237 : INFO : Current training batch loss: 0.1258 in epoch 1
2024-08-15 21:39:05,097 : INFO : Current training batch loss: 0.1779 in epoch 1
2024-08-15 21:39:15,954 : INFO : Current training batch loss: 0.3321 in epoch 1
2024-08-15 21:39:26,827 : INFO : Current training batch loss: 0.1768 in epoch 1
2024-08-15 21:39:37,708 : INFO : Current training batch loss: 0.2000 in epoch 1
2024-08-15 21:39:40,129 : INFO : Epoch finished, average loss over training batches: 0.3280
2024-08-15 21:39:40,131 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:39:40,131 : INFO : Training metrics:
2024-08-15 21:39:40,131 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:39:40,440 : INFO : Accuracy: 0.8443
2024-08-15 21:39:40,440 : INFO : Precision: 0.8466
2024-08-15 21:39:40,440 : INFO : Recall: 0.8398
2024-08-15 21:39:40,440 : INFO : F1 score: 0.8432
2024-08-15 21:40:28,034 : INFO : Average loss over validation batches: 0.2283
2024-08-15 21:40:28,035 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:40:28,035 : INFO : Validation metrics:
2024-08-15 21:40:28,035 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:40:28,040 : INFO : Accuracy: 0.9085
2024-08-15 21:40:28,040 : INFO : Precision: 0.8875
2024-08-15 21:40:28,040 : INFO : Recall: 0.9376
2024-08-15 21:40:28,040 : INFO : F1 score: 0.9118
2024-08-15 21:40:28,040 : INFO : Validation metric decreased (inf --> 0.228333).  Saving model ...
2024-08-15 21:40:28,132 : INFO : Split 1 is finished, the score is: 0.9118
2024-08-15 21:40:28,132 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:40:28,133 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:40:28,133 : INFO : Starting training for split 2
2024-08-15 21:40:28,466 : INFO : Counting occurences of labels...
2024-08-15 21:40:51,772 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-15 21:40:59,525 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 21:40:59,962 : INFO : Starting epoch 1
2024-08-15 21:41:00,542 : INFO : Current training batch loss: 0.7073 in epoch 1
2024-08-15 21:41:11,371 : INFO : Current training batch loss: 0.7071 in epoch 1
2024-08-15 21:41:22,206 : INFO : Current training batch loss: 0.5849 in epoch 1
2024-08-15 21:41:33,047 : INFO : Current training batch loss: 0.3687 in epoch 1
2024-08-15 21:41:43,901 : INFO : Current training batch loss: 0.2777 in epoch 1
2024-08-15 21:41:54,752 : INFO : Current training batch loss: 0.1959 in epoch 1
2024-08-15 21:42:05,615 : INFO : Current training batch loss: 0.2241 in epoch 1
2024-08-15 21:42:16,469 : INFO : Current training batch loss: 0.3477 in epoch 1
2024-08-15 21:42:27,328 : INFO : Current training batch loss: 0.2279 in epoch 1
2024-08-15 21:42:38,202 : INFO : Current training batch loss: 0.1648 in epoch 1
2024-08-15 21:42:49,063 : INFO : Current training batch loss: 0.1902 in epoch 1
2024-08-15 21:42:59,930 : INFO : Current training batch loss: 0.3969 in epoch 1
2024-08-15 21:43:10,793 : INFO : Current training batch loss: 0.1809 in epoch 1
2024-08-15 21:43:21,660 : INFO : Current training batch loss: 0.1917 in epoch 1
2024-08-15 21:43:32,543 : INFO : Current training batch loss: 0.2192 in epoch 1
2024-08-15 21:43:43,404 : INFO : Current training batch loss: 0.0886 in epoch 1
2024-08-15 21:43:54,282 : INFO : Current training batch loss: 0.2028 in epoch 1
2024-08-15 21:44:05,154 : INFO : Current training batch loss: 0.1325 in epoch 1
2024-08-15 21:44:16,024 : INFO : Current training batch loss: 0.1379 in epoch 1
2024-08-15 21:44:26,898 : INFO : Current training batch loss: 0.3607 in epoch 1
2024-08-15 21:44:37,774 : INFO : Current training batch loss: 0.1382 in epoch 1
2024-08-15 21:44:48,648 : INFO : Current training batch loss: 0.2874 in epoch 1
2024-08-15 21:44:59,533 : INFO : Current training batch loss: 0.1797 in epoch 1
2024-08-15 21:45:10,412 : INFO : Current training batch loss: 0.2003 in epoch 1
2024-08-15 21:45:21,290 : INFO : Current training batch loss: 0.2605 in epoch 1
2024-08-15 21:45:32,174 : INFO : Current training batch loss: 0.0988 in epoch 1
2024-08-15 21:45:43,047 : INFO : Current training batch loss: 0.2662 in epoch 1
2024-08-15 21:45:53,916 : INFO : Current training batch loss: 0.3281 in epoch 1
2024-08-15 21:46:04,797 : INFO : Current training batch loss: 0.0755 in epoch 1
2024-08-15 21:46:15,681 : INFO : Current training batch loss: 0.2032 in epoch 1
2024-08-15 21:46:18,101 : INFO : Epoch finished, average loss over training batches: 0.3126
2024-08-15 21:46:18,102 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:46:18,102 : INFO : Training metrics:
2024-08-15 21:46:18,102 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:46:18,413 : INFO : Accuracy: 0.8579
2024-08-15 21:46:18,413 : INFO : Precision: 0.8610
2024-08-15 21:46:18,413 : INFO : Recall: 0.8553
2024-08-15 21:46:18,413 : INFO : F1 score: 0.8582
2024-08-15 21:47:06,024 : INFO : Average loss over validation batches: 0.2144
2024-08-15 21:47:06,025 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:47:06,025 : INFO : Validation metrics:
2024-08-15 21:47:06,025 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:47:06,031 : INFO : Accuracy: 0.9186
2024-08-15 21:47:06,031 : INFO : Precision: 0.8993
2024-08-15 21:47:06,031 : INFO : Recall: 0.9399
2024-08-15 21:47:06,031 : INFO : F1 score: 0.9191
2024-08-15 21:47:06,031 : INFO : Validation metric decreased (inf --> 0.214438).  Saving model ...
2024-08-15 21:47:06,124 : INFO : Split 2 is finished, the score is: 0.9191
2024-08-15 21:47:06,124 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:47:06,124 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:47:06,124 : INFO : Starting training for split 3
2024-08-15 21:47:06,454 : INFO : Counting occurences of labels...
2024-08-15 21:47:29,541 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-15 21:47:37,359 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 21:47:37,804 : INFO : Starting epoch 1
2024-08-15 21:47:38,383 : INFO : Current training batch loss: 0.6790 in epoch 1
2024-08-15 21:47:49,183 : INFO : Current training batch loss: 0.6751 in epoch 1
2024-08-15 21:48:00,012 : INFO : Current training batch loss: 0.6049 in epoch 1
2024-08-15 21:48:10,853 : INFO : Current training batch loss: 0.4332 in epoch 1
2024-08-15 21:48:21,692 : INFO : Current training batch loss: 0.4679 in epoch 1
2024-08-15 21:48:32,538 : INFO : Current training batch loss: 0.2251 in epoch 1
2024-08-15 21:48:43,397 : INFO : Current training batch loss: 0.1839 in epoch 1
2024-08-15 21:48:54,248 : INFO : Current training batch loss: 0.2633 in epoch 1
2024-08-15 21:49:05,108 : INFO : Current training batch loss: 0.4828 in epoch 1
2024-08-15 21:49:15,981 : INFO : Current training batch loss: 0.3177 in epoch 1
2024-08-15 21:49:26,849 : INFO : Current training batch loss: 0.2292 in epoch 1
2024-08-15 21:49:37,721 : INFO : Current training batch loss: 0.3374 in epoch 1
2024-08-15 21:49:48,594 : INFO : Current training batch loss: 0.3223 in epoch 1
2024-08-15 21:49:59,464 : INFO : Current training batch loss: 0.2148 in epoch 1
2024-08-15 21:50:10,345 : INFO : Current training batch loss: 0.3424 in epoch 1
2024-08-15 21:50:21,221 : INFO : Current training batch loss: 0.2198 in epoch 1
2024-08-15 21:50:32,099 : INFO : Current training batch loss: 0.3014 in epoch 1
2024-08-15 21:50:42,982 : INFO : Current training batch loss: 0.2714 in epoch 1
2024-08-15 21:50:53,846 : INFO : Current training batch loss: 0.1751 in epoch 1
2024-08-15 21:51:04,716 : INFO : Current training batch loss: 0.2307 in epoch 1
2024-08-15 21:51:15,592 : INFO : Current training batch loss: 0.1664 in epoch 1
2024-08-15 21:51:26,465 : INFO : Current training batch loss: 0.1698 in epoch 1
2024-08-15 21:51:37,347 : INFO : Current training batch loss: 0.2365 in epoch 1
2024-08-15 21:51:48,223 : INFO : Current training batch loss: 0.1340 in epoch 1
2024-08-15 21:51:59,096 : INFO : Current training batch loss: 0.2692 in epoch 1
2024-08-15 21:52:09,973 : INFO : Current training batch loss: 0.2078 in epoch 1
2024-08-15 21:52:20,841 : INFO : Current training batch loss: 0.2870 in epoch 1
2024-08-15 21:52:31,705 : INFO : Current training batch loss: 0.4130 in epoch 1
2024-08-15 21:52:42,584 : INFO : Current training batch loss: 0.1100 in epoch 1
2024-08-15 21:52:53,463 : INFO : Current training batch loss: 0.2166 in epoch 1
2024-08-15 21:52:55,882 : INFO : Epoch finished, average loss over training batches: 0.3184
2024-08-15 21:52:55,883 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:52:55,884 : INFO : Training metrics:
2024-08-15 21:52:55,884 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:52:56,195 : INFO : Accuracy: 0.8565
2024-08-15 21:52:56,195 : INFO : Precision: 0.8564
2024-08-15 21:52:56,195 : INFO : Recall: 0.8578
2024-08-15 21:52:56,195 : INFO : F1 score: 0.8571
2024-08-15 21:53:43,985 : INFO : Average loss over validation batches: 0.2183
2024-08-15 21:53:43,985 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:53:43,985 : INFO : Validation metrics:
2024-08-15 21:53:43,985 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:53:43,990 : INFO : Accuracy: 0.9173
2024-08-15 21:53:43,990 : INFO : Precision: 0.8959
2024-08-15 21:53:43,990 : INFO : Recall: 0.9425
2024-08-15 21:53:43,990 : INFO : F1 score: 0.9186
2024-08-15 21:53:43,990 : INFO : Validation metric decreased (inf --> 0.218310).  Saving model ...
2024-08-15 21:53:44,080 : INFO : Split 3 is finished, the score is: 0.9186
2024-08-15 21:53:44,080 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:53:44,080 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:53:44,080 : INFO : Starting training for split 4
2024-08-15 21:53:44,402 : INFO : Counting occurences of labels...
2024-08-15 21:54:07,871 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-15 21:54:15,667 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 21:54:16,093 : INFO : Starting epoch 1
2024-08-15 21:54:16,673 : INFO : Current training batch loss: 0.7575 in epoch 1
2024-08-15 21:54:27,499 : INFO : Current training batch loss: 0.6809 in epoch 1
2024-08-15 21:54:38,348 : INFO : Current training batch loss: 0.5978 in epoch 1
2024-08-15 21:54:49,194 : INFO : Current training batch loss: 0.2741 in epoch 1
2024-08-15 21:55:00,038 : INFO : Current training batch loss: 0.4354 in epoch 1
2024-08-15 21:55:10,886 : INFO : Current training batch loss: 0.3303 in epoch 1
2024-08-15 21:55:21,743 : INFO : Current training batch loss: 0.2541 in epoch 1
2024-08-15 21:55:32,586 : INFO : Current training batch loss: 0.4359 in epoch 1
2024-08-15 21:55:43,434 : INFO : Current training batch loss: 0.1887 in epoch 1
2024-08-15 21:55:54,296 : INFO : Current training batch loss: 0.1745 in epoch 1
2024-08-15 21:56:05,152 : INFO : Current training batch loss: 0.3211 in epoch 1
2024-08-15 21:56:16,013 : INFO : Current training batch loss: 0.2926 in epoch 1
2024-08-15 21:56:26,876 : INFO : Current training batch loss: 0.2955 in epoch 1
2024-08-15 21:56:37,738 : INFO : Current training batch loss: 0.1894 in epoch 1
2024-08-15 21:56:48,610 : INFO : Current training batch loss: 0.2178 in epoch 1
2024-08-15 21:56:59,477 : INFO : Current training batch loss: 0.1106 in epoch 1
2024-08-15 21:57:10,346 : INFO : Current training batch loss: 0.2515 in epoch 1
2024-08-15 21:57:21,213 : INFO : Current training batch loss: 0.2701 in epoch 1
2024-08-15 21:57:32,064 : INFO : Current training batch loss: 0.1303 in epoch 1
2024-08-15 21:57:42,919 : INFO : Current training batch loss: 0.2835 in epoch 1
2024-08-15 21:57:53,779 : INFO : Current training batch loss: 0.2520 in epoch 1
2024-08-15 21:58:04,632 : INFO : Current training batch loss: 0.3470 in epoch 1
2024-08-15 21:58:15,482 : INFO : Current training batch loss: 0.2228 in epoch 1
2024-08-15 21:58:26,329 : INFO : Current training batch loss: 0.2158 in epoch 1
2024-08-15 21:58:37,182 : INFO : Current training batch loss: 0.1061 in epoch 1
2024-08-15 21:58:48,028 : INFO : Current training batch loss: 0.2109 in epoch 1
2024-08-15 21:58:58,875 : INFO : Current training batch loss: 0.3053 in epoch 1
2024-08-15 21:59:09,728 : INFO : Current training batch loss: 0.3653 in epoch 1
2024-08-15 21:59:20,581 : INFO : Current training batch loss: 0.3060 in epoch 1
2024-08-15 21:59:31,425 : INFO : Current training batch loss: 0.2859 in epoch 1
2024-08-15 21:59:33,840 : INFO : Epoch finished, average loss over training batches: 0.2978
2024-08-15 21:59:33,842 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:59:33,842 : INFO : Training metrics:
2024-08-15 21:59:33,842 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 21:59:34,154 : INFO : Accuracy: 0.8673
2024-08-15 21:59:34,154 : INFO : Precision: 0.8677
2024-08-15 21:59:34,154 : INFO : Recall: 0.8650
2024-08-15 21:59:34,154 : INFO : F1 score: 0.8664
2024-08-15 22:00:21,736 : INFO : Average loss over validation batches: 0.2150
2024-08-15 22:00:21,737 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:00:21,737 : INFO : Validation metrics:
2024-08-15 22:00:21,737 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:00:21,742 : INFO : Accuracy: 0.9168
2024-08-15 22:00:21,742 : INFO : Precision: 0.9191
2024-08-15 22:00:21,742 : INFO : Recall: 0.9167
2024-08-15 22:00:21,742 : INFO : F1 score: 0.9179
2024-08-15 22:00:21,742 : INFO : Validation metric decreased (inf --> 0.215002).  Saving model ...
2024-08-15 22:00:21,830 : INFO : Split 4 is finished, the score is: 0.9179
2024-08-15 22:00:21,831 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-15 22:00:21,837] Trial 3 finished with value: 0.916875979194609 and parameters: {'n_epochs': 1, 'learning_rate': 0.00019856833213797672, 'classifier_dropout': 0.5823927146581523, 'warmup_step_fraction': 0.07532682803601065, 'use_gradient_clipping': False}. Best is trial 1 with value: 0.9219339021161369.
2024-08-15 22:00:21,838 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:00:21,838 : INFO : Starting training for split 1
2024-08-15 22:00:22,175 : INFO : Counting occurences of labels...
2024-08-15 22:00:45,498 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-15 22:00:53,301 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 22:00:53,745 : INFO : Starting epoch 1
2024-08-15 22:00:54,335 : INFO : Current training batch loss: 0.8200 in epoch 1
2024-08-15 22:01:05,129 : INFO : Current training batch loss: 0.7016 in epoch 1
2024-08-15 22:01:15,972 : INFO : Current training batch loss: 0.7137 in epoch 1
2024-08-15 22:01:26,843 : INFO : Current training batch loss: 0.6633 in epoch 1
2024-08-15 22:01:37,708 : INFO : Current training batch loss: 0.6013 in epoch 1
2024-08-15 22:01:48,567 : INFO : Current training batch loss: 0.5649 in epoch 1
2024-08-15 22:01:59,429 : INFO : Current training batch loss: 0.3548 in epoch 1
2024-08-15 22:02:10,297 : INFO : Current training batch loss: 0.3775 in epoch 1
2024-08-15 22:02:21,170 : INFO : Current training batch loss: 0.6559 in epoch 1
2024-08-15 22:02:32,046 : INFO : Current training batch loss: 0.1626 in epoch 1
2024-08-15 22:02:42,927 : INFO : Current training batch loss: 0.2506 in epoch 1
2024-08-15 22:02:53,803 : INFO : Current training batch loss: 0.5097 in epoch 1
2024-08-15 22:03:04,674 : INFO : Current training batch loss: 0.2192 in epoch 1
2024-08-15 22:03:15,547 : INFO : Current training batch loss: 0.1359 in epoch 1
2024-08-15 22:03:26,435 : INFO : Current training batch loss: 0.2365 in epoch 1
2024-08-15 22:03:37,303 : INFO : Current training batch loss: 0.1285 in epoch 1
2024-08-15 22:03:48,189 : INFO : Current training batch loss: 0.2903 in epoch 1
2024-08-15 22:03:59,070 : INFO : Current training batch loss: 0.3307 in epoch 1
2024-08-15 22:04:09,951 : INFO : Current training batch loss: 0.2091 in epoch 1
2024-08-15 22:04:20,836 : INFO : Current training batch loss: 0.3994 in epoch 1
2024-08-15 22:04:31,723 : INFO : Current training batch loss: 0.1354 in epoch 1
2024-08-15 22:04:42,605 : INFO : Current training batch loss: 0.2259 in epoch 1
2024-08-15 22:04:53,497 : INFO : Current training batch loss: 0.2764 in epoch 1
2024-08-15 22:05:04,382 : INFO : Current training batch loss: 0.2171 in epoch 1
2024-08-15 22:05:15,265 : INFO : Current training batch loss: 0.2595 in epoch 1
2024-08-15 22:05:26,156 : INFO : Current training batch loss: 0.2553 in epoch 1
2024-08-15 22:05:37,036 : INFO : Current training batch loss: 0.2115 in epoch 1
2024-08-15 22:05:47,913 : INFO : Current training batch loss: 0.3148 in epoch 1
2024-08-15 22:05:58,804 : INFO : Current training batch loss: 0.1318 in epoch 1
2024-08-15 22:06:09,697 : INFO : Current training batch loss: 0.1874 in epoch 1
2024-08-15 22:06:12,121 : INFO : Epoch finished, average loss over training batches: 0.3660
2024-08-15 22:06:12,122 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:06:12,123 : INFO : Training metrics:
2024-08-15 22:06:12,123 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:06:12,434 : INFO : Accuracy: 0.8290
2024-08-15 22:06:12,434 : INFO : Precision: 0.8319
2024-08-15 22:06:12,434 : INFO : Recall: 0.8232
2024-08-15 22:06:12,434 : INFO : F1 score: 0.8275
2024-08-15 22:07:00,080 : INFO : Average loss over validation batches: 0.2411
2024-08-15 22:07:00,081 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:07:00,081 : INFO : Validation metrics:
2024-08-15 22:07:00,081 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:07:00,086 : INFO : Accuracy: 0.9030
2024-08-15 22:07:00,086 : INFO : Precision: 0.9208
2024-08-15 22:07:00,086 : INFO : Recall: 0.8840
2024-08-15 22:07:00,086 : INFO : F1 score: 0.9020
2024-08-15 22:07:00,086 : INFO : Validation metric decreased (inf --> 0.241090).  Saving model ...
2024-08-15 22:07:00,171 : INFO : Starting epoch 2
2024-08-15 22:07:08,350 : INFO : Current training batch loss: 0.2250 in epoch 2
2024-08-15 22:07:19,228 : INFO : Current training batch loss: 0.3834 in epoch 2
2024-08-15 22:07:30,111 : INFO : Current training batch loss: 0.4160 in epoch 2
2024-08-15 22:07:40,998 : INFO : Current training batch loss: 0.1667 in epoch 2
2024-08-15 22:07:51,881 : INFO : Current training batch loss: 0.3081 in epoch 2
2024-08-15 22:08:02,765 : INFO : Current training batch loss: 0.1961 in epoch 2
2024-08-15 22:08:13,643 : INFO : Current training batch loss: 0.1312 in epoch 2
2024-08-15 22:08:24,516 : INFO : Current training batch loss: 0.1628 in epoch 2
2024-08-15 22:08:35,381 : INFO : Current training batch loss: 0.1080 in epoch 2
2024-08-15 22:08:46,253 : INFO : Current training batch loss: 0.1719 in epoch 2
2024-08-15 22:08:57,130 : INFO : Current training batch loss: 0.1150 in epoch 2
2024-08-15 22:09:08,001 : INFO : Current training batch loss: 0.1574 in epoch 2
2024-08-15 22:09:18,870 : INFO : Current training batch loss: 0.1159 in epoch 2
2024-08-15 22:09:29,739 : INFO : Current training batch loss: 0.0566 in epoch 2
2024-08-15 22:09:40,600 : INFO : Current training batch loss: 0.3417 in epoch 2
2024-08-15 22:09:51,463 : INFO : Current training batch loss: 0.5832 in epoch 2
2024-08-15 22:10:02,335 : INFO : Current training batch loss: 0.1459 in epoch 2
2024-08-15 22:10:13,209 : INFO : Current training batch loss: 0.0689 in epoch 2
2024-08-15 22:10:24,088 : INFO : Current training batch loss: 0.1795 in epoch 2
2024-08-15 22:10:34,956 : INFO : Current training batch loss: 0.1673 in epoch 2
2024-08-15 22:10:45,831 : INFO : Current training batch loss: 0.1335 in epoch 2
2024-08-15 22:10:56,715 : INFO : Current training batch loss: 0.2181 in epoch 2
2024-08-15 22:11:07,584 : INFO : Current training batch loss: 0.0832 in epoch 2
2024-08-15 22:11:18,454 : INFO : Current training batch loss: 0.0669 in epoch 2
2024-08-15 22:11:29,337 : INFO : Current training batch loss: 0.1387 in epoch 2
2024-08-15 22:11:40,218 : INFO : Current training batch loss: 0.0114 in epoch 2
2024-08-15 22:11:51,087 : INFO : Current training batch loss: 0.0810 in epoch 2
2024-08-15 22:12:01,957 : INFO : Current training batch loss: 0.0952 in epoch 2
2024-08-15 22:12:12,827 : INFO : Current training batch loss: 0.0679 in epoch 2
2024-08-15 22:12:18,498 : INFO : Epoch finished, average loss over training batches: 0.2027
2024-08-15 22:12:18,500 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:12:18,500 : INFO : Training metrics:
2024-08-15 22:12:18,500 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:12:18,807 : INFO : Accuracy: 0.9244
2024-08-15 22:12:18,807 : INFO : Precision: 0.9259
2024-08-15 22:12:18,807 : INFO : Recall: 0.9221
2024-08-15 22:12:18,807 : INFO : F1 score: 0.9240
2024-08-15 22:13:06,450 : INFO : Average loss over validation batches: 0.2357
2024-08-15 22:13:06,451 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:13:06,451 : INFO : Validation metrics:
2024-08-15 22:13:06,451 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:13:06,456 : INFO : Accuracy: 0.9112
2024-08-15 22:13:06,456 : INFO : Precision: 0.9037
2024-08-15 22:13:06,456 : INFO : Recall: 0.9223
2024-08-15 22:13:06,456 : INFO : F1 score: 0.9129
2024-08-15 22:13:06,456 : INFO : Validation metric decreased (0.241090 --> 0.235746).  Saving model ...
2024-08-15 22:13:06,541 : INFO : Starting epoch 3
2024-08-15 22:13:11,465 : INFO : Current training batch loss: 0.1631 in epoch 3
2024-08-15 22:13:22,325 : INFO : Current training batch loss: 0.1291 in epoch 3
2024-08-15 22:13:33,189 : INFO : Current training batch loss: 0.2321 in epoch 3
2024-08-15 22:13:44,057 : INFO : Current training batch loss: 0.0150 in epoch 3
2024-08-15 22:13:54,941 : INFO : Current training batch loss: 0.5023 in epoch 3
2024-08-15 22:14:05,812 : INFO : Current training batch loss: 0.0818 in epoch 3
2024-08-15 22:14:16,690 : INFO : Current training batch loss: 0.0579 in epoch 3
2024-08-15 22:14:27,571 : INFO : Current training batch loss: 0.0743 in epoch 3
2024-08-15 22:14:38,447 : INFO : Current training batch loss: 0.0112 in epoch 3
2024-08-15 22:14:49,332 : INFO : Current training batch loss: 0.2410 in epoch 3
2024-08-15 22:15:00,207 : INFO : Current training batch loss: 0.0621 in epoch 3
2024-08-15 22:15:11,081 : INFO : Current training batch loss: 0.2000 in epoch 3
2024-08-15 22:15:21,955 : INFO : Current training batch loss: 0.0383 in epoch 3
2024-08-15 22:15:32,828 : INFO : Current training batch loss: 0.0082 in epoch 3
2024-08-15 22:15:43,701 : INFO : Current training batch loss: 0.0232 in epoch 3
2024-08-15 22:15:54,569 : INFO : Current training batch loss: 0.1148 in epoch 3
2024-08-15 22:16:05,449 : INFO : Current training batch loss: 0.3251 in epoch 3
2024-08-15 22:16:16,325 : INFO : Current training batch loss: 0.0316 in epoch 3
2024-08-15 22:16:27,208 : INFO : Current training batch loss: 0.0152 in epoch 3
2024-08-15 22:16:38,084 : INFO : Current training batch loss: 0.1096 in epoch 3
2024-08-15 22:16:48,966 : INFO : Current training batch loss: 0.0067 in epoch 3
2024-08-15 22:16:59,840 : INFO : Current training batch loss: 0.3200 in epoch 3
2024-08-15 22:17:10,712 : INFO : Current training batch loss: 0.0062 in epoch 3
2024-08-15 22:17:21,590 : INFO : Current training batch loss: 0.0433 in epoch 3
2024-08-15 22:17:32,460 : INFO : Current training batch loss: 0.0289 in epoch 3
2024-08-15 22:17:43,332 : INFO : Current training batch loss: 0.0762 in epoch 3
2024-08-15 22:17:54,210 : INFO : Current training batch loss: 0.0430 in epoch 3
2024-08-15 22:18:05,079 : INFO : Current training batch loss: 0.0023 in epoch 3
2024-08-15 22:18:15,957 : INFO : Current training batch loss: 0.4207 in epoch 3
2024-08-15 22:18:24,882 : INFO : Epoch finished, average loss over training batches: 0.1027
2024-08-15 22:18:24,884 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:18:24,884 : INFO : Training metrics:
2024-08-15 22:18:24,884 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:18:25,191 : INFO : Accuracy: 0.9666
2024-08-15 22:18:25,191 : INFO : Precision: 0.9662
2024-08-15 22:18:25,191 : INFO : Recall: 0.9667
2024-08-15 22:18:25,191 : INFO : F1 score: 0.9665
2024-08-15 22:19:12,847 : INFO : Average loss over validation batches: 0.3123
2024-08-15 22:19:12,847 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:19:12,848 : INFO : Validation metrics:
2024-08-15 22:19:12,848 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:19:12,853 : INFO : Accuracy: 0.9130
2024-08-15 22:19:12,853 : INFO : Precision: 0.9183
2024-08-15 22:19:12,853 : INFO : Recall: 0.9084
2024-08-15 22:19:12,853 : INFO : F1 score: 0.9133
2024-08-15 22:19:12,853 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 22:19:12,853 : INFO : Starting epoch 4
2024-08-15 22:19:14,530 : INFO : Current training batch loss: 0.1539 in epoch 4
2024-08-15 22:19:25,388 : INFO : Current training batch loss: 0.1392 in epoch 4
2024-08-15 22:19:36,251 : INFO : Current training batch loss: 0.1719 in epoch 4
2024-08-15 22:19:47,114 : INFO : Current training batch loss: 0.0293 in epoch 4
2024-08-15 22:19:57,984 : INFO : Current training batch loss: 0.0761 in epoch 4
2024-08-15 22:20:08,866 : INFO : Current training batch loss: 0.1738 in epoch 4
2024-08-15 22:20:19,735 : INFO : Current training batch loss: 0.4156 in epoch 4
2024-08-15 22:20:30,624 : INFO : Current training batch loss: 0.1128 in epoch 4
2024-08-15 22:20:41,494 : INFO : Current training batch loss: 0.0025 in epoch 4
2024-08-15 22:20:52,375 : INFO : Current training batch loss: 0.0031 in epoch 4
2024-08-15 22:21:03,256 : INFO : Current training batch loss: 0.0020 in epoch 4
2024-08-15 22:21:14,125 : INFO : Current training batch loss: 0.0025 in epoch 4
2024-08-15 22:21:25,000 : INFO : Current training batch loss: 0.0022 in epoch 4
2024-08-15 22:21:35,875 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 22:21:46,756 : INFO : Current training batch loss: 0.0442 in epoch 4
2024-08-15 22:21:57,634 : INFO : Current training batch loss: 0.0017 in epoch 4
2024-08-15 22:22:08,513 : INFO : Current training batch loss: 0.0156 in epoch 4
2024-08-15 22:22:19,393 : INFO : Current training batch loss: 0.0090 in epoch 4
2024-08-15 22:22:30,273 : INFO : Current training batch loss: 0.0036 in epoch 4
2024-08-15 22:22:41,150 : INFO : Current training batch loss: 0.0028 in epoch 4
2024-08-15 22:22:52,042 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 22:23:02,928 : INFO : Current training batch loss: 0.4805 in epoch 4
2024-08-15 22:23:13,809 : INFO : Current training batch loss: 0.0160 in epoch 4
2024-08-15 22:23:24,688 : INFO : Current training batch loss: 0.0769 in epoch 4
2024-08-15 22:23:35,557 : INFO : Current training batch loss: 0.0114 in epoch 4
2024-08-15 22:23:46,432 : INFO : Current training batch loss: 0.1497 in epoch 4
2024-08-15 22:23:57,309 : INFO : Current training batch loss: 0.0018 in epoch 4
2024-08-15 22:24:08,196 : INFO : Current training batch loss: 0.0023 in epoch 4
2024-08-15 22:24:19,082 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 22:24:29,972 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 22:24:31,305 : INFO : Epoch finished, average loss over training batches: 0.0451
2024-08-15 22:24:31,306 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:24:31,306 : INFO : Training metrics:
2024-08-15 22:24:31,306 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:24:31,623 : INFO : Accuracy: 0.9879
2024-08-15 22:24:31,623 : INFO : Precision: 0.9878
2024-08-15 22:24:31,623 : INFO : Recall: 0.9880
2024-08-15 22:24:31,623 : INFO : F1 score: 0.9879
2024-08-15 22:25:19,285 : INFO : Average loss over validation batches: 0.3581
2024-08-15 22:25:19,286 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:25:19,286 : INFO : Validation metrics:
2024-08-15 22:25:19,286 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:25:19,291 : INFO : Accuracy: 0.9142
2024-08-15 22:25:19,291 : INFO : Precision: 0.9355
2024-08-15 22:25:19,291 : INFO : Recall: 0.8916
2024-08-15 22:25:19,291 : INFO : F1 score: 0.9130
2024-08-15 22:25:19,291 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 22:25:19,291 : INFO : Starting epoch 5
2024-08-15 22:25:28,550 : INFO : Current training batch loss: 0.0010 in epoch 5
2024-08-15 22:25:39,434 : INFO : Current training batch loss: 0.2234 in epoch 5
2024-08-15 22:25:50,314 : INFO : Current training batch loss: 0.0033 in epoch 5
2024-08-15 22:26:01,200 : INFO : Current training batch loss: 0.0015 in epoch 5
2024-08-15 22:26:12,078 : INFO : Current training batch loss: 0.0015 in epoch 5
2024-08-15 22:26:22,963 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 22:26:33,840 : INFO : Current training batch loss: 0.0013 in epoch 5
2024-08-15 22:26:44,718 : INFO : Current training batch loss: 0.0013 in epoch 5
2024-08-15 22:26:55,600 : INFO : Current training batch loss: 0.2144 in epoch 5
2024-08-15 22:27:06,480 : INFO : Current training batch loss: 0.0011 in epoch 5
2024-08-15 22:27:17,358 : INFO : Current training batch loss: 0.0019 in epoch 5
2024-08-15 22:27:28,240 : INFO : Current training batch loss: 0.0011 in epoch 5
2024-08-15 22:27:39,123 : INFO : Current training batch loss: 0.0011 in epoch 5
2024-08-15 22:27:50,007 : INFO : Current training batch loss: 0.0018 in epoch 5
2024-08-15 22:28:00,882 : INFO : Current training batch loss: 0.0011 in epoch 5
2024-08-15 22:28:11,770 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-15 22:28:22,657 : INFO : Current training batch loss: 0.0009 in epoch 5
2024-08-15 22:28:33,541 : INFO : Current training batch loss: 0.0009 in epoch 5
2024-08-15 22:28:44,411 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 22:28:55,286 : INFO : Current training batch loss: 0.0009 in epoch 5
2024-08-15 22:29:06,154 : INFO : Current training batch loss: 0.0043 in epoch 5
2024-08-15 22:29:17,025 : INFO : Current training batch loss: 0.0009 in epoch 5
2024-08-15 22:29:27,894 : INFO : Current training batch loss: 0.0011 in epoch 5
2024-08-15 22:29:38,764 : INFO : Current training batch loss: 0.0009 in epoch 5
2024-08-15 22:29:49,654 : INFO : Current training batch loss: 0.0009 in epoch 5
2024-08-15 22:30:00,536 : INFO : Current training batch loss: 0.0009 in epoch 5
2024-08-15 22:30:11,414 : INFO : Current training batch loss: 0.0010 in epoch 5
2024-08-15 22:30:22,295 : INFO : Current training batch loss: 0.0010 in epoch 5
2024-08-15 22:30:33,179 : INFO : Current training batch loss: 0.0198 in epoch 5
2024-08-15 22:30:37,772 : INFO : Epoch finished, average loss over training batches: 0.0147
2024-08-15 22:30:37,774 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:30:37,774 : INFO : Training metrics:
2024-08-15 22:30:37,774 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:30:38,081 : INFO : Accuracy: 0.9972
2024-08-15 22:30:38,081 : INFO : Precision: 0.9969
2024-08-15 22:30:38,081 : INFO : Recall: 0.9975
2024-08-15 22:30:38,081 : INFO : F1 score: 0.9972
2024-08-15 22:31:25,757 : INFO : Average loss over validation batches: 0.3756
2024-08-15 22:31:25,758 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:31:25,758 : INFO : Validation metrics:
2024-08-15 22:31:25,758 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:31:25,763 : INFO : Accuracy: 0.9163
2024-08-15 22:31:25,763 : INFO : Precision: 0.9210
2024-08-15 22:31:25,763 : INFO : Recall: 0.9125
2024-08-15 22:31:25,763 : INFO : F1 score: 0.9167
2024-08-15 22:31:25,763 : INFO : EarlyStopping counter: 3 out of 3
2024-08-15 22:31:25,763 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 22:31:26,441 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 22:32:12,794 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:32:12,794 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 22:32:12,794 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:32:12,799 : INFO : Accuracy: 0.9112
2024-08-15 22:32:12,800 : INFO : Precision: 0.9037
2024-08-15 22:32:12,800 : INFO : Recall: 0.9223
2024-08-15 22:32:12,800 : INFO : F1 score: 0.9129
2024-08-15 22:32:12,800 : INFO : Determined score from best model, ending training.
2024-08-15 22:32:12,807 : INFO : Split 1 is finished, the score is: 0.9129
2024-08-15 22:32:12,807 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:32:12,807 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:32:12,807 : INFO : Starting training for split 2
2024-08-15 22:32:13,096 : INFO : Counting occurences of labels...
2024-08-15 22:32:36,352 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-15 22:32:44,073 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 22:32:44,521 : INFO : Starting epoch 1
2024-08-15 22:32:45,101 : INFO : Current training batch loss: 0.7830 in epoch 1
2024-08-15 22:32:55,934 : INFO : Current training batch loss: 0.6637 in epoch 1
2024-08-15 22:33:06,783 : INFO : Current training batch loss: 0.6903 in epoch 1
2024-08-15 22:33:17,632 : INFO : Current training batch loss: 0.6654 in epoch 1
2024-08-15 22:33:28,494 : INFO : Current training batch loss: 0.5650 in epoch 1
2024-08-15 22:33:39,360 : INFO : Current training batch loss: 0.4867 in epoch 1
2024-08-15 22:33:50,235 : INFO : Current training batch loss: 0.2194 in epoch 1
2024-08-15 22:34:01,097 : INFO : Current training batch loss: 0.2823 in epoch 1
2024-08-15 22:34:11,965 : INFO : Current training batch loss: 0.2498 in epoch 1
2024-08-15 22:34:22,845 : INFO : Current training batch loss: 0.2045 in epoch 1
2024-08-15 22:34:33,721 : INFO : Current training batch loss: 0.3861 in epoch 1
2024-08-15 22:34:44,595 : INFO : Current training batch loss: 0.2732 in epoch 1
2024-08-15 22:34:55,467 : INFO : Current training batch loss: 0.1786 in epoch 1
2024-08-15 22:35:06,345 : INFO : Current training batch loss: 0.2152 in epoch 1
2024-08-15 22:35:17,237 : INFO : Current training batch loss: 0.2773 in epoch 1
2024-08-15 22:35:28,110 : INFO : Current training batch loss: 0.0850 in epoch 1
2024-08-15 22:35:38,996 : INFO : Current training batch loss: 0.3144 in epoch 1
2024-08-15 22:35:49,877 : INFO : Current training batch loss: 0.2599 in epoch 1
2024-08-15 22:36:00,754 : INFO : Current training batch loss: 0.2107 in epoch 1
2024-08-15 22:36:11,636 : INFO : Current training batch loss: 0.3814 in epoch 1
2024-08-15 22:36:22,521 : INFO : Current training batch loss: 0.3289 in epoch 1
2024-08-15 22:36:33,400 : INFO : Current training batch loss: 0.2359 in epoch 1
2024-08-15 22:36:44,292 : INFO : Current training batch loss: 0.1816 in epoch 1
2024-08-15 22:36:55,178 : INFO : Current training batch loss: 0.2296 in epoch 1
2024-08-15 22:37:06,063 : INFO : Current training batch loss: 0.2330 in epoch 1
2024-08-15 22:37:16,957 : INFO : Current training batch loss: 0.2037 in epoch 1
2024-08-15 22:37:27,836 : INFO : Current training batch loss: 0.2905 in epoch 1
2024-08-15 22:37:38,714 : INFO : Current training batch loss: 0.5530 in epoch 1
2024-08-15 22:37:49,607 : INFO : Current training batch loss: 0.1525 in epoch 1
2024-08-15 22:38:00,499 : INFO : Current training batch loss: 0.3007 in epoch 1
2024-08-15 22:38:02,921 : INFO : Epoch finished, average loss over training batches: 0.3712
2024-08-15 22:38:02,922 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:38:02,922 : INFO : Training metrics:
2024-08-15 22:38:02,922 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:38:03,234 : INFO : Accuracy: 0.8227
2024-08-15 22:38:03,234 : INFO : Precision: 0.8244
2024-08-15 22:38:03,234 : INFO : Recall: 0.8223
2024-08-15 22:38:03,234 : INFO : F1 score: 0.8234
2024-08-15 22:38:50,872 : INFO : Average loss over validation batches: 0.2383
2024-08-15 22:38:50,872 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:38:50,872 : INFO : Validation metrics:
2024-08-15 22:38:50,872 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:38:50,878 : INFO : Accuracy: 0.9062
2024-08-15 22:38:50,878 : INFO : Precision: 0.8981
2024-08-15 22:38:50,878 : INFO : Recall: 0.9133
2024-08-15 22:38:50,878 : INFO : F1 score: 0.9056
2024-08-15 22:38:50,878 : INFO : Validation metric decreased (inf --> 0.238300).  Saving model ...
2024-08-15 22:38:50,965 : INFO : Starting epoch 2
2024-08-15 22:38:59,129 : INFO : Current training batch loss: 0.1164 in epoch 2
2024-08-15 22:39:10,008 : INFO : Current training batch loss: 0.2724 in epoch 2
2024-08-15 22:39:20,881 : INFO : Current training batch loss: 0.2329 in epoch 2
2024-08-15 22:39:31,765 : INFO : Current training batch loss: 0.2484 in epoch 2
2024-08-15 22:39:42,651 : INFO : Current training batch loss: 0.5609 in epoch 2
2024-08-15 22:39:53,539 : INFO : Current training batch loss: 0.2069 in epoch 2
2024-08-15 22:40:04,424 : INFO : Current training batch loss: 0.2064 in epoch 2
2024-08-15 22:40:15,301 : INFO : Current training batch loss: 0.3379 in epoch 2
2024-08-15 22:40:26,175 : INFO : Current training batch loss: 0.3090 in epoch 2
2024-08-15 22:40:37,059 : INFO : Current training batch loss: 0.1670 in epoch 2
2024-08-15 22:40:47,945 : INFO : Current training batch loss: 0.1497 in epoch 2
2024-08-15 22:40:58,828 : INFO : Current training batch loss: 0.1793 in epoch 2
2024-08-15 22:41:09,710 : INFO : Current training batch loss: 0.0795 in epoch 2
2024-08-15 22:41:20,597 : INFO : Current training batch loss: 0.0852 in epoch 2
2024-08-15 22:41:31,476 : INFO : Current training batch loss: 0.2498 in epoch 2
2024-08-15 22:41:42,353 : INFO : Current training batch loss: 0.2229 in epoch 2
2024-08-15 22:41:53,236 : INFO : Current training batch loss: 0.1298 in epoch 2
2024-08-15 22:42:04,123 : INFO : Current training batch loss: 0.0855 in epoch 2
2024-08-15 22:42:15,015 : INFO : Current training batch loss: 0.1138 in epoch 2
2024-08-15 22:42:25,896 : INFO : Current training batch loss: 0.7983 in epoch 2
2024-08-15 22:42:36,780 : INFO : Current training batch loss: 0.0560 in epoch 2
2024-08-15 22:42:47,675 : INFO : Current training batch loss: 0.1506 in epoch 2
2024-08-15 22:42:58,555 : INFO : Current training batch loss: 0.1628 in epoch 2
2024-08-15 22:43:09,438 : INFO : Current training batch loss: 0.0834 in epoch 2
2024-08-15 22:43:20,329 : INFO : Current training batch loss: 0.1088 in epoch 2
2024-08-15 22:43:31,227 : INFO : Current training batch loss: 0.0751 in epoch 2
2024-08-15 22:43:42,106 : INFO : Current training batch loss: 0.0610 in epoch 2
2024-08-15 22:43:52,990 : INFO : Current training batch loss: 0.0670 in epoch 2
2024-08-15 22:44:03,873 : INFO : Current training batch loss: 0.1090 in epoch 2
2024-08-15 22:44:09,547 : INFO : Epoch finished, average loss over training batches: 0.2149
2024-08-15 22:44:09,548 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:44:09,548 : INFO : Training metrics:
2024-08-15 22:44:09,548 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:44:09,861 : INFO : Accuracy: 0.9193
2024-08-15 22:44:09,861 : INFO : Precision: 0.9180
2024-08-15 22:44:09,861 : INFO : Recall: 0.9218
2024-08-15 22:44:09,861 : INFO : F1 score: 0.9199
2024-08-15 22:44:57,453 : INFO : Average loss over validation batches: 0.2282
2024-08-15 22:44:57,454 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:44:57,454 : INFO : Validation metrics:
2024-08-15 22:44:57,454 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:44:57,459 : INFO : Accuracy: 0.9141
2024-08-15 22:44:57,459 : INFO : Precision: 0.9262
2024-08-15 22:44:57,459 : INFO : Recall: 0.8970
2024-08-15 22:44:57,459 : INFO : F1 score: 0.9114
2024-08-15 22:44:57,459 : INFO : Validation metric decreased (0.238300 --> 0.228233).  Saving model ...
2024-08-15 22:44:57,546 : INFO : Starting epoch 3
2024-08-15 22:45:02,459 : INFO : Current training batch loss: 0.4342 in epoch 3
2024-08-15 22:45:13,321 : INFO : Current training batch loss: 0.0178 in epoch 3
2024-08-15 22:45:24,192 : INFO : Current training batch loss: 0.7650 in epoch 3
2024-08-15 22:45:35,064 : INFO : Current training batch loss: 0.0954 in epoch 3
2024-08-15 22:45:45,929 : INFO : Current training batch loss: 0.0672 in epoch 3
2024-08-15 22:45:56,797 : INFO : Current training batch loss: 0.0966 in epoch 3
2024-08-15 22:46:07,672 : INFO : Current training batch loss: 0.1374 in epoch 3
2024-08-15 22:46:18,544 : INFO : Current training batch loss: 0.0134 in epoch 3
2024-08-15 22:46:29,416 : INFO : Current training batch loss: 0.0359 in epoch 3
2024-08-15 22:46:40,304 : INFO : Current training batch loss: 0.0630 in epoch 3
2024-08-15 22:46:51,185 : INFO : Current training batch loss: 0.0346 in epoch 3
2024-08-15 22:47:02,059 : INFO : Current training batch loss: 0.2047 in epoch 3
2024-08-15 22:47:12,932 : INFO : Current training batch loss: 0.2410 in epoch 3
2024-08-15 22:47:23,805 : INFO : Current training batch loss: 0.0027 in epoch 3
2024-08-15 22:47:34,682 : INFO : Current training batch loss: 0.0130 in epoch 3
2024-08-15 22:47:45,551 : INFO : Current training batch loss: 0.0169 in epoch 3
2024-08-15 22:47:56,434 : INFO : Current training batch loss: 0.4613 in epoch 3
2024-08-15 22:48:07,312 : INFO : Current training batch loss: 0.1303 in epoch 3
2024-08-15 22:48:18,194 : INFO : Current training batch loss: 0.0181 in epoch 3
2024-08-15 22:48:29,073 : INFO : Current training batch loss: 0.7192 in epoch 3
2024-08-15 22:48:39,960 : INFO : Current training batch loss: 0.0084 in epoch 3
2024-08-15 22:48:50,838 : INFO : Current training batch loss: 0.0633 in epoch 3
2024-08-15 22:49:01,717 : INFO : Current training batch loss: 0.0248 in epoch 3
2024-08-15 22:49:12,599 : INFO : Current training batch loss: 0.1507 in epoch 3
2024-08-15 22:49:23,479 : INFO : Current training batch loss: 0.1662 in epoch 3
2024-08-15 22:49:34,356 : INFO : Current training batch loss: 0.0143 in epoch 3
2024-08-15 22:49:45,240 : INFO : Current training batch loss: 0.0589 in epoch 3
2024-08-15 22:49:56,117 : INFO : Current training batch loss: 0.0024 in epoch 3
2024-08-15 22:50:06,996 : INFO : Current training batch loss: 0.5114 in epoch 3
2024-08-15 22:50:15,919 : INFO : Epoch finished, average loss over training batches: 0.1174
2024-08-15 22:50:15,920 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:50:15,920 : INFO : Training metrics:
2024-08-15 22:50:15,920 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:50:16,231 : INFO : Accuracy: 0.9611
2024-08-15 22:50:16,231 : INFO : Precision: 0.9624
2024-08-15 22:50:16,231 : INFO : Recall: 0.9600
2024-08-15 22:50:16,231 : INFO : F1 score: 0.9612
2024-08-15 22:51:03,850 : INFO : Average loss over validation batches: 0.3218
2024-08-15 22:51:03,851 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:51:03,851 : INFO : Validation metrics:
2024-08-15 22:51:03,851 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:51:03,856 : INFO : Accuracy: 0.9088
2024-08-15 22:51:03,857 : INFO : Precision: 0.8882
2024-08-15 22:51:03,857 : INFO : Recall: 0.9321
2024-08-15 22:51:03,857 : INFO : F1 score: 0.9096
2024-08-15 22:51:03,857 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 22:51:03,857 : INFO : Starting epoch 4
2024-08-15 22:51:05,521 : INFO : Current training batch loss: 0.0066 in epoch 4
2024-08-15 22:51:16,381 : INFO : Current training batch loss: 0.0625 in epoch 4
2024-08-15 22:51:27,248 : INFO : Current training batch loss: 0.0050 in epoch 4
2024-08-15 22:51:38,119 : INFO : Current training batch loss: 0.1053 in epoch 4
2024-08-15 22:51:48,988 : INFO : Current training batch loss: 0.0414 in epoch 4
2024-08-15 22:51:59,860 : INFO : Current training batch loss: 0.0070 in epoch 4
2024-08-15 22:52:10,737 : INFO : Current training batch loss: 0.0189 in epoch 4
2024-08-15 22:52:21,616 : INFO : Current training batch loss: 0.0416 in epoch 4
2024-08-15 22:52:32,515 : INFO : Current training batch loss: 0.0410 in epoch 4
2024-08-15 22:52:43,392 : INFO : Current training batch loss: 0.0070 in epoch 4
2024-08-15 22:52:54,287 : INFO : Current training batch loss: 0.2042 in epoch 4
2024-08-15 22:53:05,166 : INFO : Current training batch loss: 0.0133 in epoch 4
2024-08-15 22:53:16,050 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-15 22:53:26,933 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 22:53:37,816 : INFO : Current training batch loss: 0.0143 in epoch 4
2024-08-15 22:53:48,691 : INFO : Current training batch loss: 0.0052 in epoch 4
2024-08-15 22:53:59,564 : INFO : Current training batch loss: 0.0038 in epoch 4
2024-08-15 22:54:10,437 : INFO : Current training batch loss: 0.1087 in epoch 4
2024-08-15 22:54:21,319 : INFO : Current training batch loss: 0.0023 in epoch 4
2024-08-15 22:54:32,199 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-15 22:54:43,090 : INFO : Current training batch loss: 0.0100 in epoch 4
2024-08-15 22:54:53,967 : INFO : Current training batch loss: 0.4929 in epoch 4
2024-08-15 22:55:04,842 : INFO : Current training batch loss: 0.0035 in epoch 4
2024-08-15 22:55:15,712 : INFO : Current training batch loss: 0.0036 in epoch 4
2024-08-15 22:55:26,589 : INFO : Current training batch loss: 0.1443 in epoch 4
2024-08-15 22:55:37,475 : INFO : Current training batch loss: 0.0022 in epoch 4
2024-08-15 22:55:48,355 : INFO : Current training batch loss: 0.0017 in epoch 4
2024-08-15 22:55:59,240 : INFO : Current training batch loss: 0.0057 in epoch 4
2024-08-15 22:56:10,123 : INFO : Current training batch loss: 0.0019 in epoch 4
2024-08-15 22:56:21,016 : INFO : Current training batch loss: 0.0019 in epoch 4
2024-08-15 22:56:22,355 : INFO : Epoch finished, average loss over training batches: 0.0484
2024-08-15 22:56:22,356 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:56:22,356 : INFO : Training metrics:
2024-08-15 22:56:22,356 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:56:22,667 : INFO : Accuracy: 0.9874
2024-08-15 22:56:22,667 : INFO : Precision: 0.9879
2024-08-15 22:56:22,667 : INFO : Recall: 0.9871
2024-08-15 22:56:22,667 : INFO : F1 score: 0.9875
2024-08-15 22:57:10,272 : INFO : Average loss over validation batches: 0.3393
2024-08-15 22:57:10,272 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:57:10,272 : INFO : Validation metrics:
2024-08-15 22:57:10,272 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 22:57:10,278 : INFO : Accuracy: 0.9186
2024-08-15 22:57:10,278 : INFO : Precision: 0.9082
2024-08-15 22:57:10,278 : INFO : Recall: 0.9285
2024-08-15 22:57:10,278 : INFO : F1 score: 0.9182
2024-08-15 22:57:10,278 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 22:57:10,278 : INFO : Starting epoch 5
2024-08-15 22:57:19,526 : INFO : Current training batch loss: 0.0193 in epoch 5
2024-08-15 22:57:30,407 : INFO : Current training batch loss: 0.0021 in epoch 5
2024-08-15 22:57:41,290 : INFO : Current training batch loss: 0.0018 in epoch 5
2024-08-15 22:57:52,171 : INFO : Current training batch loss: 0.0074 in epoch 5
2024-08-15 22:58:03,054 : INFO : Current training batch loss: 0.0172 in epoch 5
2024-08-15 22:58:13,939 : INFO : Current training batch loss: 0.0076 in epoch 5
2024-08-15 22:58:24,807 : INFO : Current training batch loss: 0.0016 in epoch 5
2024-08-15 22:58:35,687 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 22:58:46,566 : INFO : Current training batch loss: 0.0013 in epoch 5
2024-08-15 22:58:57,453 : INFO : Current training batch loss: 0.0014 in epoch 5
2024-08-15 22:59:08,335 : INFO : Current training batch loss: 0.0014 in epoch 5
2024-08-15 22:59:19,215 : INFO : Current training batch loss: 0.0025 in epoch 5
2024-08-15 22:59:30,099 : INFO : Current training batch loss: 0.0029 in epoch 5
2024-08-15 22:59:40,989 : INFO : Current training batch loss: 0.0016 in epoch 5
2024-08-15 22:59:51,867 : INFO : Current training batch loss: 0.0010 in epoch 5
2024-08-15 23:00:02,752 : INFO : Current training batch loss: 0.0013 in epoch 5
2024-08-15 23:00:13,645 : INFO : Current training batch loss: 0.0011 in epoch 5
2024-08-15 23:00:24,534 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 23:00:35,411 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 23:00:46,295 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 23:00:57,172 : INFO : Current training batch loss: 0.0075 in epoch 5
2024-08-15 23:01:08,054 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 23:01:18,933 : INFO : Current training batch loss: 0.0014 in epoch 5
2024-08-15 23:01:29,816 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 23:01:40,704 : INFO : Current training batch loss: 0.0014 in epoch 5
2024-08-15 23:01:51,585 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-15 23:02:02,469 : INFO : Current training batch loss: 0.0013 in epoch 5
2024-08-15 23:02:13,350 : INFO : Current training batch loss: 0.0013 in epoch 5
2024-08-15 23:02:24,234 : INFO : Current training batch loss: 0.0028 in epoch 5
2024-08-15 23:02:28,825 : INFO : Epoch finished, average loss over training batches: 0.0180
2024-08-15 23:02:28,826 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:02:28,826 : INFO : Training metrics:
2024-08-15 23:02:28,826 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:02:29,137 : INFO : Accuracy: 0.9961
2024-08-15 23:02:29,137 : INFO : Precision: 0.9967
2024-08-15 23:02:29,137 : INFO : Recall: 0.9955
2024-08-15 23:02:29,137 : INFO : F1 score: 0.9961
2024-08-15 23:03:16,790 : INFO : Average loss over validation batches: 0.3394
2024-08-15 23:03:16,791 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:03:16,791 : INFO : Validation metrics:
2024-08-15 23:03:16,791 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:03:16,796 : INFO : Accuracy: 0.9216
2024-08-15 23:03:16,796 : INFO : Precision: 0.9237
2024-08-15 23:03:16,796 : INFO : Recall: 0.9165
2024-08-15 23:03:16,796 : INFO : F1 score: 0.9201
2024-08-15 23:03:16,796 : INFO : EarlyStopping counter: 3 out of 3
2024-08-15 23:03:16,796 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 23:03:17,310 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 23:04:03,631 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:04:03,631 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 23:04:03,631 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:04:03,637 : INFO : Accuracy: 0.9141
2024-08-15 23:04:03,637 : INFO : Precision: 0.9262
2024-08-15 23:04:03,637 : INFO : Recall: 0.8970
2024-08-15 23:04:03,637 : INFO : F1 score: 0.9114
2024-08-15 23:04:03,637 : INFO : Determined score from best model, ending training.
2024-08-15 23:04:03,639 : INFO : Split 2 is finished, the score is: 0.9114
2024-08-15 23:04:03,639 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:04:03,639 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:04:03,639 : INFO : Starting training for split 3
2024-08-15 23:04:03,913 : INFO : Counting occurences of labels...
2024-08-15 23:04:27,030 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-15 23:04:34,833 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 23:04:35,261 : INFO : Starting epoch 1
2024-08-15 23:04:35,842 : INFO : Current training batch loss: 0.7265 in epoch 1
2024-08-15 23:04:46,684 : INFO : Current training batch loss: 0.6730 in epoch 1
2024-08-15 23:04:57,534 : INFO : Current training batch loss: 0.6816 in epoch 1
2024-08-15 23:05:08,382 : INFO : Current training batch loss: 0.5811 in epoch 1
2024-08-15 23:05:19,242 : INFO : Current training batch loss: 0.3996 in epoch 1
2024-08-15 23:05:30,108 : INFO : Current training batch loss: 0.3438 in epoch 1
2024-08-15 23:05:40,985 : INFO : Current training batch loss: 0.3266 in epoch 1
2024-08-15 23:05:51,849 : INFO : Current training batch loss: 0.3109 in epoch 1
2024-08-15 23:06:02,717 : INFO : Current training batch loss: 0.2019 in epoch 1
2024-08-15 23:06:13,600 : INFO : Current training batch loss: 0.1687 in epoch 1
2024-08-15 23:06:24,477 : INFO : Current training batch loss: 0.4295 in epoch 1
2024-08-15 23:06:35,357 : INFO : Current training batch loss: 0.3777 in epoch 1
2024-08-15 23:06:46,238 : INFO : Current training batch loss: 0.4018 in epoch 1
2024-08-15 23:06:57,122 : INFO : Current training batch loss: 0.3693 in epoch 1
2024-08-15 23:07:08,014 : INFO : Current training batch loss: 0.3484 in epoch 1
2024-08-15 23:07:18,897 : INFO : Current training batch loss: 0.1439 in epoch 1
2024-08-15 23:07:29,780 : INFO : Current training batch loss: 0.3259 in epoch 1
2024-08-15 23:07:40,664 : INFO : Current training batch loss: 0.2786 in epoch 1
2024-08-15 23:07:51,531 : INFO : Current training batch loss: 0.1672 in epoch 1
2024-08-15 23:08:02,409 : INFO : Current training batch loss: 0.3718 in epoch 1
2024-08-15 23:08:13,292 : INFO : Current training batch loss: 0.2674 in epoch 1
2024-08-15 23:08:24,170 : INFO : Current training batch loss: 0.3297 in epoch 1
2024-08-15 23:08:35,061 : INFO : Current training batch loss: 0.1690 in epoch 1
2024-08-15 23:08:45,947 : INFO : Current training batch loss: 0.1978 in epoch 1
2024-08-15 23:08:56,829 : INFO : Current training batch loss: 0.1827 in epoch 1
2024-08-15 23:09:07,719 : INFO : Current training batch loss: 0.2680 in epoch 1
2024-08-15 23:09:18,595 : INFO : Current training batch loss: 0.2659 in epoch 1
2024-08-15 23:09:29,469 : INFO : Current training batch loss: 0.4638 in epoch 1
2024-08-15 23:09:40,357 : INFO : Current training batch loss: 0.1567 in epoch 1
2024-08-15 23:09:51,245 : INFO : Current training batch loss: 0.4154 in epoch 1
2024-08-15 23:09:53,667 : INFO : Epoch finished, average loss over training batches: 0.3776
2024-08-15 23:09:53,668 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:09:53,668 : INFO : Training metrics:
2024-08-15 23:09:53,668 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:09:54,000 : INFO : Accuracy: 0.8258
2024-08-15 23:09:54,000 : INFO : Precision: 0.8219
2024-08-15 23:09:54,000 : INFO : Recall: 0.8332
2024-08-15 23:09:54,000 : INFO : F1 score: 0.8275
2024-08-15 23:10:41,885 : INFO : Average loss over validation batches: 0.2321
2024-08-15 23:10:41,886 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:10:41,886 : INFO : Validation metrics:
2024-08-15 23:10:41,886 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:10:41,891 : INFO : Accuracy: 0.9096
2024-08-15 23:10:41,891 : INFO : Precision: 0.9234
2024-08-15 23:10:41,891 : INFO : Recall: 0.8915
2024-08-15 23:10:41,891 : INFO : F1 score: 0.9071
2024-08-15 23:10:41,891 : INFO : Validation metric decreased (inf --> 0.232084).  Saving model ...
2024-08-15 23:10:41,977 : INFO : Starting epoch 2
2024-08-15 23:10:50,133 : INFO : Current training batch loss: 0.1396 in epoch 2
2024-08-15 23:11:00,996 : INFO : Current training batch loss: 0.3685 in epoch 2
2024-08-15 23:11:11,857 : INFO : Current training batch loss: 0.0933 in epoch 2
2024-08-15 23:11:22,728 : INFO : Current training batch loss: 0.2881 in epoch 2
2024-08-15 23:11:33,602 : INFO : Current training batch loss: 0.4040 in epoch 2
2024-08-15 23:11:44,481 : INFO : Current training batch loss: 0.2426 in epoch 2
2024-08-15 23:11:55,356 : INFO : Current training batch loss: 0.1770 in epoch 2
2024-08-15 23:12:06,228 : INFO : Current training batch loss: 0.3370 in epoch 2
2024-08-15 23:12:17,099 : INFO : Current training batch loss: 0.3560 in epoch 2
2024-08-15 23:12:27,980 : INFO : Current training batch loss: 0.2439 in epoch 2
2024-08-15 23:12:38,873 : INFO : Current training batch loss: 0.1486 in epoch 2
2024-08-15 23:12:49,758 : INFO : Current training batch loss: 0.2358 in epoch 2
2024-08-15 23:13:00,636 : INFO : Current training batch loss: 0.0646 in epoch 2
2024-08-15 23:13:11,513 : INFO : Current training batch loss: 0.0942 in epoch 2
2024-08-15 23:13:22,386 : INFO : Current training batch loss: 0.1771 in epoch 2
2024-08-15 23:13:33,272 : INFO : Current training batch loss: 0.1125 in epoch 2
2024-08-15 23:13:44,145 : INFO : Current training batch loss: 0.3164 in epoch 2
2024-08-15 23:13:55,020 : INFO : Current training batch loss: 0.2961 in epoch 2
2024-08-15 23:14:05,898 : INFO : Current training batch loss: 0.1795 in epoch 2
2024-08-15 23:14:16,782 : INFO : Current training batch loss: 0.2430 in epoch 2
2024-08-15 23:14:27,661 : INFO : Current training batch loss: 0.1407 in epoch 2
2024-08-15 23:14:38,550 : INFO : Current training batch loss: 0.2887 in epoch 2
2024-08-15 23:14:49,427 : INFO : Current training batch loss: 0.0671 in epoch 2
2024-08-15 23:15:00,305 : INFO : Current training batch loss: 0.0596 in epoch 2
2024-08-15 23:15:11,193 : INFO : Current training batch loss: 0.1742 in epoch 2
2024-08-15 23:15:22,081 : INFO : Current training batch loss: 0.0370 in epoch 2
2024-08-15 23:15:32,953 : INFO : Current training batch loss: 0.0142 in epoch 2
2024-08-15 23:15:43,829 : INFO : Current training batch loss: 0.1623 in epoch 2
2024-08-15 23:15:54,709 : INFO : Current training batch loss: 0.1208 in epoch 2
2024-08-15 23:16:00,380 : INFO : Epoch finished, average loss over training batches: 0.2051
2024-08-15 23:16:00,381 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:16:00,381 : INFO : Training metrics:
2024-08-15 23:16:00,382 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:16:00,695 : INFO : Accuracy: 0.9239
2024-08-15 23:16:00,695 : INFO : Precision: 0.9210
2024-08-15 23:16:00,695 : INFO : Recall: 0.9278
2024-08-15 23:16:00,695 : INFO : F1 score: 0.9244
2024-08-15 23:16:48,533 : INFO : Average loss over validation batches: 0.2632
2024-08-15 23:16:48,534 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:16:48,534 : INFO : Validation metrics:
2024-08-15 23:16:48,534 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:16:48,539 : INFO : Accuracy: 0.9083
2024-08-15 23:16:48,539 : INFO : Precision: 0.8740
2024-08-15 23:16:48,539 : INFO : Recall: 0.9522
2024-08-15 23:16:48,539 : INFO : F1 score: 0.9114
2024-08-15 23:16:48,539 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 23:16:48,539 : INFO : Starting epoch 3
2024-08-15 23:16:53,450 : INFO : Current training batch loss: 0.3254 in epoch 3
2024-08-15 23:17:04,312 : INFO : Current training batch loss: 0.0460 in epoch 3
2024-08-15 23:17:15,179 : INFO : Current training batch loss: 0.2864 in epoch 3
2024-08-15 23:17:26,048 : INFO : Current training batch loss: 0.2511 in epoch 3
2024-08-15 23:17:36,916 : INFO : Current training batch loss: 0.0605 in epoch 3
2024-08-15 23:17:47,782 : INFO : Current training batch loss: 0.3441 in epoch 3
2024-08-15 23:17:58,657 : INFO : Current training batch loss: 0.0131 in epoch 3
2024-08-15 23:18:09,531 : INFO : Current training batch loss: 0.0264 in epoch 3
2024-08-15 23:18:20,402 : INFO : Current training batch loss: 0.0435 in epoch 3
2024-08-15 23:18:31,287 : INFO : Current training batch loss: 0.1675 in epoch 3
2024-08-15 23:18:42,170 : INFO : Current training batch loss: 0.1149 in epoch 3
2024-08-15 23:18:53,044 : INFO : Current training batch loss: 0.0625 in epoch 3
2024-08-15 23:19:03,921 : INFO : Current training batch loss: 0.0628 in epoch 3
2024-08-15 23:19:14,798 : INFO : Current training batch loss: 0.3019 in epoch 3
2024-08-15 23:19:25,684 : INFO : Current training batch loss: 0.0094 in epoch 3
2024-08-15 23:19:36,564 : INFO : Current training batch loss: 0.2725 in epoch 3
2024-08-15 23:19:47,454 : INFO : Current training batch loss: 0.1466 in epoch 3
2024-08-15 23:19:58,333 : INFO : Current training batch loss: 0.0202 in epoch 3
2024-08-15 23:20:09,215 : INFO : Current training batch loss: 0.1765 in epoch 3
2024-08-15 23:20:20,095 : INFO : Current training batch loss: 0.0031 in epoch 3
2024-08-15 23:20:30,985 : INFO : Current training batch loss: 0.0630 in epoch 3
2024-08-15 23:20:41,869 : INFO : Current training batch loss: 0.0550 in epoch 3
2024-08-15 23:20:52,751 : INFO : Current training batch loss: 0.0083 in epoch 3
2024-08-15 23:21:03,635 : INFO : Current training batch loss: 0.1961 in epoch 3
2024-08-15 23:21:14,516 : INFO : Current training batch loss: 0.0942 in epoch 3
2024-08-15 23:21:25,396 : INFO : Current training batch loss: 0.0781 in epoch 3
2024-08-15 23:21:36,281 : INFO : Current training batch loss: 0.0124 in epoch 3
2024-08-15 23:21:47,158 : INFO : Current training batch loss: 0.0033 in epoch 3
2024-08-15 23:21:58,041 : INFO : Current training batch loss: 0.5627 in epoch 3
2024-08-15 23:22:06,968 : INFO : Epoch finished, average loss over training batches: 0.1045
2024-08-15 23:22:06,970 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:22:06,970 : INFO : Training metrics:
2024-08-15 23:22:06,970 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:22:07,281 : INFO : Accuracy: 0.9648
2024-08-15 23:22:07,281 : INFO : Precision: 0.9647
2024-08-15 23:22:07,281 : INFO : Recall: 0.9651
2024-08-15 23:22:07,281 : INFO : F1 score: 0.9649
2024-08-15 23:22:55,142 : INFO : Average loss over validation batches: 0.2784
2024-08-15 23:22:55,142 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:22:55,142 : INFO : Validation metrics:
2024-08-15 23:22:55,142 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:22:55,148 : INFO : Accuracy: 0.9213
2024-08-15 23:22:55,148 : INFO : Precision: 0.9176
2024-08-15 23:22:55,148 : INFO : Recall: 0.9241
2024-08-15 23:22:55,148 : INFO : F1 score: 0.9208
2024-08-15 23:22:55,148 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 23:22:55,148 : INFO : Starting epoch 4
2024-08-15 23:22:56,814 : INFO : Current training batch loss: 0.0376 in epoch 4
2024-08-15 23:23:07,675 : INFO : Current training batch loss: 0.2554 in epoch 4
2024-08-15 23:23:18,541 : INFO : Current training batch loss: 0.0059 in epoch 4
2024-08-15 23:23:29,413 : INFO : Current training batch loss: 0.0947 in epoch 4
2024-08-15 23:23:40,285 : INFO : Current training batch loss: 0.0040 in epoch 4
2024-08-15 23:23:51,162 : INFO : Current training batch loss: 0.0051 in epoch 4
2024-08-15 23:24:02,044 : INFO : Current training batch loss: 0.1344 in epoch 4
2024-08-15 23:24:12,926 : INFO : Current training batch loss: 0.0036 in epoch 4
2024-08-15 23:24:23,831 : INFO : Current training batch loss: 0.0345 in epoch 4
2024-08-15 23:24:34,713 : INFO : Current training batch loss: 0.0198 in epoch 4
2024-08-15 23:24:45,612 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-15 23:24:56,505 : INFO : Current training batch loss: 0.0019 in epoch 4
2024-08-15 23:25:07,402 : INFO : Current training batch loss: 0.0022 in epoch 4
2024-08-15 23:25:18,294 : INFO : Current training batch loss: 0.0163 in epoch 4
2024-08-15 23:25:29,181 : INFO : Current training batch loss: 0.0017 in epoch 4
2024-08-15 23:25:40,068 : INFO : Current training batch loss: 0.0540 in epoch 4
2024-08-15 23:25:50,967 : INFO : Current training batch loss: 0.0072 in epoch 4
2024-08-15 23:26:01,859 : INFO : Current training batch loss: 0.0028 in epoch 4
2024-08-15 23:26:12,743 : INFO : Current training batch loss: 0.0073 in epoch 4
2024-08-15 23:26:23,632 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-15 23:26:34,525 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 23:26:45,412 : INFO : Current training batch loss: 0.3865 in epoch 4
2024-08-15 23:26:56,300 : INFO : Current training batch loss: 0.0030 in epoch 4
2024-08-15 23:27:07,178 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-15 23:27:18,063 : INFO : Current training batch loss: 0.0527 in epoch 4
2024-08-15 23:27:28,959 : INFO : Current training batch loss: 0.0178 in epoch 4
2024-08-15 23:27:39,847 : INFO : Current training batch loss: 0.2156 in epoch 4
2024-08-15 23:27:50,743 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-15 23:28:01,637 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 23:28:12,541 : INFO : Current training batch loss: 0.0014 in epoch 4
2024-08-15 23:28:13,884 : INFO : Epoch finished, average loss over training batches: 0.0428
2024-08-15 23:28:13,886 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:28:13,886 : INFO : Training metrics:
2024-08-15 23:28:13,886 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:28:14,196 : INFO : Accuracy: 0.9877
2024-08-15 23:28:14,196 : INFO : Precision: 0.9876
2024-08-15 23:28:14,196 : INFO : Recall: 0.9879
2024-08-15 23:28:14,196 : INFO : F1 score: 0.9877
2024-08-15 23:29:02,024 : INFO : Average loss over validation batches: 0.3151
2024-08-15 23:29:02,025 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:29:02,025 : INFO : Validation metrics:
2024-08-15 23:29:02,025 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:29:02,030 : INFO : Accuracy: 0.9283
2024-08-15 23:29:02,030 : INFO : Precision: 0.9358
2024-08-15 23:29:02,030 : INFO : Recall: 0.9183
2024-08-15 23:29:02,030 : INFO : F1 score: 0.9270
2024-08-15 23:29:02,030 : INFO : EarlyStopping counter: 3 out of 3
2024-08-15 23:29:02,030 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 23:29:02,543 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 23:29:49,337 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:29:49,337 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 23:29:49,337 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:29:49,343 : INFO : Accuracy: 0.9096
2024-08-15 23:29:49,343 : INFO : Precision: 0.9234
2024-08-15 23:29:49,343 : INFO : Recall: 0.8915
2024-08-15 23:29:49,343 : INFO : F1 score: 0.9071
2024-08-15 23:29:49,343 : INFO : Determined score from best model, ending training.
2024-08-15 23:29:49,345 : INFO : Split 3 is finished, the score is: 0.9071
2024-08-15 23:29:49,345 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:29:49,345 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:29:49,345 : INFO : Starting training for split 4
2024-08-15 23:29:49,649 : INFO : Counting occurences of labels...
2024-08-15 23:30:12,934 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-15 23:30:20,650 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 23:30:21,083 : INFO : Starting epoch 1
2024-08-15 23:30:21,664 : INFO : Current training batch loss: 0.6847 in epoch 1
2024-08-15 23:30:32,505 : INFO : Current training batch loss: 0.6731 in epoch 1
2024-08-15 23:30:43,356 : INFO : Current training batch loss: 0.6712 in epoch 1
2024-08-15 23:30:54,210 : INFO : Current training batch loss: 0.5903 in epoch 1
2024-08-15 23:31:05,075 : INFO : Current training batch loss: 0.4289 in epoch 1
2024-08-15 23:31:15,946 : INFO : Current training batch loss: 0.2684 in epoch 1
2024-08-15 23:31:26,829 : INFO : Current training batch loss: 0.2802 in epoch 1
2024-08-15 23:31:37,694 : INFO : Current training batch loss: 0.3185 in epoch 1
2024-08-15 23:31:48,568 : INFO : Current training batch loss: 0.2997 in epoch 1
2024-08-15 23:31:59,450 : INFO : Current training batch loss: 0.2423 in epoch 1
2024-08-15 23:32:10,332 : INFO : Current training batch loss: 0.3511 in epoch 1
2024-08-15 23:32:21,219 : INFO : Current training batch loss: 0.3177 in epoch 1
2024-08-15 23:32:32,110 : INFO : Current training batch loss: 0.4478 in epoch 1
2024-08-15 23:32:43,001 : INFO : Current training batch loss: 0.1654 in epoch 1
2024-08-15 23:32:53,898 : INFO : Current training batch loss: 0.5586 in epoch 1
2024-08-15 23:33:04,790 : INFO : Current training batch loss: 0.3290 in epoch 1
2024-08-15 23:33:15,680 : INFO : Current training batch loss: 0.2560 in epoch 1
2024-08-15 23:33:26,571 : INFO : Current training batch loss: 0.3022 in epoch 1
2024-08-15 23:33:37,448 : INFO : Current training batch loss: 0.1219 in epoch 1
2024-08-15 23:33:48,334 : INFO : Current training batch loss: 0.2027 in epoch 1
2024-08-15 23:33:59,223 : INFO : Current training batch loss: 0.4029 in epoch 1
2024-08-15 23:34:10,108 : INFO : Current training batch loss: 0.5993 in epoch 1
2024-08-15 23:34:20,989 : INFO : Current training batch loss: 0.2284 in epoch 1
2024-08-15 23:34:31,865 : INFO : Current training batch loss: 0.3052 in epoch 1
2024-08-15 23:34:42,748 : INFO : Current training batch loss: 0.2049 in epoch 1
2024-08-15 23:34:53,616 : INFO : Current training batch loss: 0.2448 in epoch 1
2024-08-15 23:35:04,489 : INFO : Current training batch loss: 0.2011 in epoch 1
2024-08-15 23:35:15,365 : INFO : Current training batch loss: 0.7669 in epoch 1
2024-08-15 23:35:26,244 : INFO : Current training batch loss: 0.3073 in epoch 1
2024-08-15 23:35:37,110 : INFO : Current training batch loss: 0.2876 in epoch 1
2024-08-15 23:35:39,531 : INFO : Epoch finished, average loss over training batches: 0.3594
2024-08-15 23:35:39,533 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:35:39,533 : INFO : Training metrics:
2024-08-15 23:35:39,533 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:35:39,883 : INFO : Accuracy: 0.8349
2024-08-15 23:35:39,883 : INFO : Precision: 0.8354
2024-08-15 23:35:39,883 : INFO : Recall: 0.8320
2024-08-15 23:35:39,883 : INFO : F1 score: 0.8337
2024-08-15 23:36:27,533 : INFO : Average loss over validation batches: 0.2433
2024-08-15 23:36:27,533 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:36:27,534 : INFO : Validation metrics:
2024-08-15 23:36:27,534 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:36:27,539 : INFO : Accuracy: 0.9050
2024-08-15 23:36:27,539 : INFO : Precision: 0.8920
2024-08-15 23:36:27,539 : INFO : Recall: 0.9246
2024-08-15 23:36:27,539 : INFO : F1 score: 0.9080
2024-08-15 23:36:27,539 : INFO : Validation metric decreased (inf --> 0.243292).  Saving model ...
2024-08-15 23:36:27,625 : INFO : Starting epoch 2
2024-08-15 23:36:35,788 : INFO : Current training batch loss: 0.1224 in epoch 2
2024-08-15 23:36:46,654 : INFO : Current training batch loss: 0.2635 in epoch 2
2024-08-15 23:36:57,520 : INFO : Current training batch loss: 0.1609 in epoch 2
2024-08-15 23:37:08,400 : INFO : Current training batch loss: 0.3445 in epoch 2
2024-08-15 23:37:19,285 : INFO : Current training batch loss: 0.3116 in epoch 2
2024-08-15 23:37:30,172 : INFO : Current training batch loss: 0.3080 in epoch 2
2024-08-15 23:37:41,056 : INFO : Current training batch loss: 0.2165 in epoch 2
2024-08-15 23:37:51,934 : INFO : Current training batch loss: 0.4974 in epoch 2
2024-08-15 23:38:02,814 : INFO : Current training batch loss: 0.1916 in epoch 2
2024-08-15 23:38:13,699 : INFO : Current training batch loss: 0.1385 in epoch 2
2024-08-15 23:38:24,593 : INFO : Current training batch loss: 0.1363 in epoch 2
2024-08-15 23:38:35,482 : INFO : Current training batch loss: 0.3014 in epoch 2
2024-08-15 23:38:46,369 : INFO : Current training batch loss: 0.1081 in epoch 2
2024-08-15 23:38:57,254 : INFO : Current training batch loss: 0.1227 in epoch 2
2024-08-15 23:39:08,137 : INFO : Current training batch loss: 0.1489 in epoch 2
2024-08-15 23:39:19,031 : INFO : Current training batch loss: 0.1089 in epoch 2
2024-08-15 23:39:29,916 : INFO : Current training batch loss: 0.0896 in epoch 2
2024-08-15 23:39:40,796 : INFO : Current training batch loss: 0.1936 in epoch 2
2024-08-15 23:39:51,682 : INFO : Current training batch loss: 0.3285 in epoch 2
2024-08-15 23:40:02,568 : INFO : Current training batch loss: 0.1483 in epoch 2
2024-08-15 23:40:13,460 : INFO : Current training batch loss: 0.0856 in epoch 2
2024-08-15 23:40:24,344 : INFO : Current training batch loss: 0.0323 in epoch 2
2024-08-15 23:40:35,232 : INFO : Current training batch loss: 0.2045 in epoch 2
2024-08-15 23:40:46,130 : INFO : Current training batch loss: 0.0938 in epoch 2
2024-08-15 23:40:57,010 : INFO : Current training batch loss: 0.2130 in epoch 2
2024-08-15 23:41:07,895 : INFO : Current training batch loss: 0.0640 in epoch 2
2024-08-15 23:41:18,785 : INFO : Current training batch loss: 0.0685 in epoch 2
2024-08-15 23:41:29,670 : INFO : Current training batch loss: 0.3261 in epoch 2
2024-08-15 23:41:40,552 : INFO : Current training batch loss: 0.2890 in epoch 2
2024-08-15 23:41:46,251 : INFO : Epoch finished, average loss over training batches: 0.1881
2024-08-15 23:41:46,253 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:41:46,253 : INFO : Training metrics:
2024-08-15 23:41:46,253 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:41:46,563 : INFO : Accuracy: 0.9297
2024-08-15 23:41:46,563 : INFO : Precision: 0.9268
2024-08-15 23:41:46,563 : INFO : Recall: 0.9323
2024-08-15 23:41:46,563 : INFO : F1 score: 0.9295
2024-08-15 23:42:34,317 : INFO : Average loss over validation batches: 0.2870
2024-08-15 23:42:34,317 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:42:34,317 : INFO : Validation metrics:
2024-08-15 23:42:34,317 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:42:34,322 : INFO : Accuracy: 0.9037
2024-08-15 23:42:34,322 : INFO : Precision: 0.9362
2024-08-15 23:42:34,322 : INFO : Recall: 0.8694
2024-08-15 23:42:34,322 : INFO : F1 score: 0.9016
2024-08-15 23:42:34,322 : INFO : EarlyStopping counter: 1 out of 3
2024-08-15 23:42:34,322 : INFO : Starting epoch 3
2024-08-15 23:42:39,242 : INFO : Current training batch loss: 0.1846 in epoch 3
2024-08-15 23:42:50,129 : INFO : Current training batch loss: 0.1030 in epoch 3
2024-08-15 23:43:01,020 : INFO : Current training batch loss: 0.0471 in epoch 3
2024-08-15 23:43:11,910 : INFO : Current training batch loss: 0.0331 in epoch 3
2024-08-15 23:43:22,795 : INFO : Current training batch loss: 0.0487 in epoch 3
2024-08-15 23:43:33,679 : INFO : Current training batch loss: 0.2611 in epoch 3
2024-08-15 23:43:44,572 : INFO : Current training batch loss: 0.0320 in epoch 3
2024-08-15 23:43:55,462 : INFO : Current training batch loss: 0.0337 in epoch 3
2024-08-15 23:44:06,350 : INFO : Current training batch loss: 0.0212 in epoch 3
2024-08-15 23:44:17,251 : INFO : Current training batch loss: 0.0858 in epoch 3
2024-08-15 23:44:28,150 : INFO : Current training batch loss: 0.1755 in epoch 3
2024-08-15 23:44:39,039 : INFO : Current training batch loss: 0.0596 in epoch 3
2024-08-15 23:44:49,927 : INFO : Current training batch loss: 0.0842 in epoch 3
2024-08-15 23:45:00,812 : INFO : Current training batch loss: 0.2089 in epoch 3
2024-08-15 23:45:11,708 : INFO : Current training batch loss: 0.1154 in epoch 3
2024-08-15 23:45:22,599 : INFO : Current training batch loss: 0.0126 in epoch 3
2024-08-15 23:45:33,499 : INFO : Current training batch loss: 0.0239 in epoch 3
2024-08-15 23:45:44,394 : INFO : Current training batch loss: 0.0240 in epoch 3
2024-08-15 23:45:55,287 : INFO : Current training batch loss: 0.0643 in epoch 3
2024-08-15 23:46:06,176 : INFO : Current training batch loss: 0.1153 in epoch 3
2024-08-15 23:46:17,071 : INFO : Current training batch loss: 0.1226 in epoch 3
2024-08-15 23:46:27,960 : INFO : Current training batch loss: 0.2158 in epoch 3
2024-08-15 23:46:38,852 : INFO : Current training batch loss: 0.0043 in epoch 3
2024-08-15 23:46:49,734 : INFO : Current training batch loss: 0.1062 in epoch 3
2024-08-15 23:47:00,615 : INFO : Current training batch loss: 0.0559 in epoch 3
2024-08-15 23:47:11,502 : INFO : Current training batch loss: 0.0093 in epoch 3
2024-08-15 23:47:22,396 : INFO : Current training batch loss: 0.0019 in epoch 3
2024-08-15 23:47:33,304 : INFO : Current training batch loss: 0.2180 in epoch 3
2024-08-15 23:47:44,193 : INFO : Current training batch loss: 0.0106 in epoch 3
2024-08-15 23:47:53,126 : INFO : Epoch finished, average loss over training batches: 0.1001
2024-08-15 23:47:53,128 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:47:53,128 : INFO : Training metrics:
2024-08-15 23:47:53,128 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:47:53,441 : INFO : Accuracy: 0.9665
2024-08-15 23:47:53,441 : INFO : Precision: 0.9665
2024-08-15 23:47:53,441 : INFO : Recall: 0.9661
2024-08-15 23:47:53,441 : INFO : F1 score: 0.9663
2024-08-15 23:48:41,148 : INFO : Average loss over validation batches: 0.4296
2024-08-15 23:48:41,148 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:48:41,148 : INFO : Validation metrics:
2024-08-15 23:48:41,148 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:48:41,153 : INFO : Accuracy: 0.8859
2024-08-15 23:48:41,153 : INFO : Precision: 0.8329
2024-08-15 23:48:41,153 : INFO : Recall: 0.9697
2024-08-15 23:48:41,153 : INFO : F1 score: 0.8961
2024-08-15 23:48:41,153 : INFO : EarlyStopping counter: 2 out of 3
2024-08-15 23:48:41,153 : INFO : Starting epoch 4
2024-08-15 23:48:42,820 : INFO : Current training batch loss: 0.2862 in epoch 4
2024-08-15 23:48:53,697 : INFO : Current training batch loss: 0.0625 in epoch 4
2024-08-15 23:49:04,581 : INFO : Current training batch loss: 0.0615 in epoch 4
2024-08-15 23:49:15,467 : INFO : Current training batch loss: 0.0084 in epoch 4
2024-08-15 23:49:26,351 : INFO : Current training batch loss: 0.1127 in epoch 4
2024-08-15 23:49:37,242 : INFO : Current training batch loss: 0.1168 in epoch 4
2024-08-15 23:49:48,132 : INFO : Current training batch loss: 0.0029 in epoch 4
2024-08-15 23:49:59,017 : INFO : Current training batch loss: 0.0020 in epoch 4
2024-08-15 23:50:09,919 : INFO : Current training batch loss: 0.0018 in epoch 4
2024-08-15 23:50:20,800 : INFO : Current training batch loss: 0.0034 in epoch 4
2024-08-15 23:50:31,693 : INFO : Current training batch loss: 0.0018 in epoch 4
2024-08-15 23:50:42,579 : INFO : Current training batch loss: 0.1011 in epoch 4
2024-08-15 23:50:53,467 : INFO : Current training batch loss: 0.0023 in epoch 4
2024-08-15 23:51:04,353 : INFO : Current training batch loss: 0.0306 in epoch 4
2024-08-15 23:51:15,236 : INFO : Current training batch loss: 0.0022 in epoch 4
2024-08-15 23:51:26,116 : INFO : Current training batch loss: 0.0027 in epoch 4
2024-08-15 23:51:37,006 : INFO : Current training batch loss: 0.0300 in epoch 4
2024-08-15 23:51:47,890 : INFO : Current training batch loss: 0.0066 in epoch 4
2024-08-15 23:51:58,772 : INFO : Current training batch loss: 0.0042 in epoch 4
2024-08-15 23:52:09,659 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-15 23:52:20,545 : INFO : Current training batch loss: 0.0023 in epoch 4
2024-08-15 23:52:31,428 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-15 23:52:42,314 : INFO : Current training batch loss: 0.0178 in epoch 4
2024-08-15 23:52:53,191 : INFO : Current training batch loss: 0.0025 in epoch 4
2024-08-15 23:53:04,069 : INFO : Current training batch loss: 0.1443 in epoch 4
2024-08-15 23:53:14,961 : INFO : Current training batch loss: 0.0055 in epoch 4
2024-08-15 23:53:25,847 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-15 23:53:36,738 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 23:53:47,626 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-15 23:53:58,506 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-15 23:53:59,839 : INFO : Epoch finished, average loss over training batches: 0.0416
2024-08-15 23:53:59,841 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:53:59,841 : INFO : Training metrics:
2024-08-15 23:53:59,841 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:54:00,154 : INFO : Accuracy: 0.9869
2024-08-15 23:54:00,155 : INFO : Precision: 0.9879
2024-08-15 23:54:00,155 : INFO : Recall: 0.9859
2024-08-15 23:54:00,155 : INFO : F1 score: 0.9869
2024-08-15 23:54:47,828 : INFO : Average loss over validation batches: 0.4097
2024-08-15 23:54:47,829 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:54:47,829 : INFO : Validation metrics:
2024-08-15 23:54:47,829 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:54:47,834 : INFO : Accuracy: 0.9080
2024-08-15 23:54:47,834 : INFO : Precision: 0.9482
2024-08-15 23:54:47,834 : INFO : Recall: 0.8660
2024-08-15 23:54:47,834 : INFO : F1 score: 0.9052
2024-08-15 23:54:47,834 : INFO : EarlyStopping counter: 3 out of 3
2024-08-15 23:54:47,834 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 23:54:48,339 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-15 23:55:34,978 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:55:34,978 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-15 23:55:34,978 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:55:34,983 : INFO : Accuracy: 0.9050
2024-08-15 23:55:34,983 : INFO : Precision: 0.8920
2024-08-15 23:55:34,983 : INFO : Recall: 0.9246
2024-08-15 23:55:34,983 : INFO : F1 score: 0.9080
2024-08-15 23:55:34,983 : INFO : Determined score from best model, ending training.
2024-08-15 23:55:34,985 : INFO : Split 4 is finished, the score is: 0.9080
2024-08-15 23:55:34,985 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-15 23:55:34,991] Trial 4 finished with value: 0.909870618862357 and parameters: {'n_epochs': 5, 'learning_rate': 0.00018829267199797257, 'classifier_dropout': 0.713036681542136, 'warmup_step_fraction': 0.07867531597207844, 'use_gradient_clipping': True}. Best is trial 1 with value: 0.9219339021161369.
2024-08-15 23:55:34,992 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-15 23:55:34,992 : INFO : Starting training for split 1
2024-08-15 23:55:35,462 : INFO : Counting occurences of labels...
2024-08-15 23:55:58,835 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-15 23:56:06,656 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-15 23:56:07,094 : INFO : Starting epoch 1
2024-08-15 23:56:07,685 : INFO : Current training batch loss: 0.7298 in epoch 1
2024-08-15 23:56:18,509 : INFO : Current training batch loss: 0.7312 in epoch 1
2024-08-15 23:56:29,349 : INFO : Current training batch loss: 0.7860 in epoch 1
2024-08-15 23:56:40,188 : INFO : Current training batch loss: 0.6853 in epoch 1
2024-08-15 23:56:51,031 : INFO : Current training batch loss: 0.6312 in epoch 1
2024-08-15 23:57:01,885 : INFO : Current training batch loss: 0.3903 in epoch 1
2024-08-15 23:57:12,737 : INFO : Current training batch loss: 0.3197 in epoch 1
2024-08-15 23:57:23,594 : INFO : Current training batch loss: 0.2816 in epoch 1
2024-08-15 23:57:34,452 : INFO : Current training batch loss: 0.6992 in epoch 1
2024-08-15 23:57:45,313 : INFO : Current training batch loss: 0.2153 in epoch 1
2024-08-15 23:57:56,178 : INFO : Current training batch loss: 0.3071 in epoch 1
2024-08-15 23:58:07,039 : INFO : Current training batch loss: 0.3740 in epoch 1
2024-08-15 23:58:17,894 : INFO : Current training batch loss: 0.2030 in epoch 1
2024-08-15 23:58:28,751 : INFO : Current training batch loss: 0.1968 in epoch 1
2024-08-15 23:58:39,623 : INFO : Current training batch loss: 0.2199 in epoch 1
2024-08-15 23:58:50,473 : INFO : Current training batch loss: 0.3189 in epoch 1
2024-08-15 23:59:01,338 : INFO : Current training batch loss: 0.2743 in epoch 1
2024-08-15 23:59:12,199 : INFO : Current training batch loss: 0.1483 in epoch 1
2024-08-15 23:59:23,056 : INFO : Current training batch loss: 0.0895 in epoch 1
2024-08-15 23:59:33,917 : INFO : Current training batch loss: 0.3790 in epoch 1
2024-08-15 23:59:44,784 : INFO : Current training batch loss: 0.3166 in epoch 1
2024-08-15 23:59:55,647 : INFO : Current training batch loss: 0.3531 in epoch 1
2024-08-16 00:00:06,519 : INFO : Current training batch loss: 0.1906 in epoch 1
2024-08-16 00:00:17,386 : INFO : Current training batch loss: 0.2425 in epoch 1
2024-08-16 00:00:28,252 : INFO : Current training batch loss: 0.2130 in epoch 1
2024-08-16 00:00:39,125 : INFO : Current training batch loss: 0.3896 in epoch 1
2024-08-16 00:00:49,985 : INFO : Current training batch loss: 0.1689 in epoch 1
2024-08-16 00:01:00,849 : INFO : Current training batch loss: 0.3719 in epoch 1
2024-08-16 00:01:11,727 : INFO : Current training batch loss: 0.0713 in epoch 1
2024-08-16 00:01:22,610 : INFO : Current training batch loss: 0.3246 in epoch 1
2024-08-16 00:01:25,031 : INFO : Epoch finished, average loss over training batches: 0.3682
2024-08-16 00:01:25,033 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:01:25,033 : INFO : Training metrics:
2024-08-16 00:01:25,033 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:01:25,344 : INFO : Accuracy: 0.8244
2024-08-16 00:01:25,344 : INFO : Precision: 0.8308
2024-08-16 00:01:25,344 : INFO : Recall: 0.8133
2024-08-16 00:01:25,344 : INFO : F1 score: 0.8219
2024-08-16 00:02:12,958 : INFO : Average loss over validation batches: 0.2659
2024-08-16 00:02:12,958 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:02:12,958 : INFO : Validation metrics:
2024-08-16 00:02:12,958 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:02:12,963 : INFO : Accuracy: 0.8920
2024-08-16 00:02:12,963 : INFO : Precision: 0.8481
2024-08-16 00:02:12,963 : INFO : Recall: 0.9575
2024-08-16 00:02:12,963 : INFO : F1 score: 0.8995
2024-08-16 00:02:12,963 : INFO : Validation metric decreased (inf --> 0.265892).  Saving model ...
2024-08-16 00:02:13,055 : INFO : Starting epoch 2
2024-08-16 00:02:21,215 : INFO : Current training batch loss: 0.2544 in epoch 2
2024-08-16 00:02:32,071 : INFO : Current training batch loss: 0.2778 in epoch 2
2024-08-16 00:02:42,929 : INFO : Current training batch loss: 0.4123 in epoch 2
2024-08-16 00:02:53,790 : INFO : Current training batch loss: 0.3447 in epoch 2
2024-08-16 00:03:04,650 : INFO : Current training batch loss: 0.1958 in epoch 2
2024-08-16 00:03:15,519 : INFO : Current training batch loss: 0.1827 in epoch 2
2024-08-16 00:03:26,384 : INFO : Current training batch loss: 0.0237 in epoch 2
2024-08-16 00:03:37,247 : INFO : Current training batch loss: 0.1425 in epoch 2
2024-08-16 00:03:48,107 : INFO : Current training batch loss: 0.0517 in epoch 2
2024-08-16 00:03:58,971 : INFO : Current training batch loss: 0.2829 in epoch 2
2024-08-16 00:04:09,844 : INFO : Current training batch loss: 0.0630 in epoch 2
2024-08-16 00:04:20,715 : INFO : Current training batch loss: 0.2385 in epoch 2
2024-08-16 00:04:31,586 : INFO : Current training batch loss: 0.1036 in epoch 2
2024-08-16 00:04:42,458 : INFO : Current training batch loss: 0.0363 in epoch 2
2024-08-16 00:04:53,325 : INFO : Current training batch loss: 0.3404 in epoch 2
2024-08-16 00:05:04,187 : INFO : Current training batch loss: 0.3140 in epoch 2
2024-08-16 00:05:15,055 : INFO : Current training batch loss: 0.0336 in epoch 2
2024-08-16 00:05:25,924 : INFO : Current training batch loss: 0.0157 in epoch 2
2024-08-16 00:05:36,796 : INFO : Current training batch loss: 0.1207 in epoch 2
2024-08-16 00:05:47,658 : INFO : Current training batch loss: 0.2617 in epoch 2
2024-08-16 00:05:58,523 : INFO : Current training batch loss: 0.0481 in epoch 2
2024-08-16 00:06:09,401 : INFO : Current training batch loss: 0.2307 in epoch 2
2024-08-16 00:06:20,272 : INFO : Current training batch loss: 0.1793 in epoch 2
2024-08-16 00:06:31,150 : INFO : Current training batch loss: 0.0660 in epoch 2
2024-08-16 00:06:42,034 : INFO : Current training batch loss: 0.1066 in epoch 2
2024-08-16 00:06:52,916 : INFO : Current training batch loss: 0.0906 in epoch 2
2024-08-16 00:07:03,779 : INFO : Current training batch loss: 0.0173 in epoch 2
2024-08-16 00:07:14,643 : INFO : Current training batch loss: 0.0205 in epoch 2
2024-08-16 00:07:25,515 : INFO : Current training batch loss: 0.0390 in epoch 2
2024-08-16 00:07:31,182 : INFO : Epoch finished, average loss over training batches: 0.1634
2024-08-16 00:07:31,183 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:07:31,183 : INFO : Training metrics:
2024-08-16 00:07:31,183 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:07:31,493 : INFO : Accuracy: 0.9421
2024-08-16 00:07:31,493 : INFO : Precision: 0.9418
2024-08-16 00:07:31,493 : INFO : Recall: 0.9420
2024-08-16 00:07:31,493 : INFO : F1 score: 0.9419
2024-08-16 00:08:19,114 : INFO : Average loss over validation batches: 0.2325
2024-08-16 00:08:19,115 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:08:19,115 : INFO : Validation metrics:
2024-08-16 00:08:19,115 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:08:19,120 : INFO : Accuracy: 0.9178
2024-08-16 00:08:19,120 : INFO : Precision: 0.9228
2024-08-16 00:08:19,120 : INFO : Recall: 0.9135
2024-08-16 00:08:19,120 : INFO : F1 score: 0.9181
2024-08-16 00:08:19,120 : INFO : Validation metric decreased (0.265892 --> 0.232450).  Saving model ...
2024-08-16 00:08:19,205 : INFO : Split 1 is finished, the score is: 0.9181
2024-08-16 00:08:19,205 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:08:19,205 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:08:19,205 : INFO : Starting training for split 2
2024-08-16 00:08:19,523 : INFO : Counting occurences of labels...
2024-08-16 00:08:42,789 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-16 00:08:50,509 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 00:08:50,956 : INFO : Starting epoch 1
2024-08-16 00:08:51,537 : INFO : Current training batch loss: 0.7184 in epoch 1
2024-08-16 00:09:02,375 : INFO : Current training batch loss: 0.7001 in epoch 1
2024-08-16 00:09:13,202 : INFO : Current training batch loss: 0.5300 in epoch 1
2024-08-16 00:09:24,048 : INFO : Current training batch loss: 0.2509 in epoch 1
2024-08-16 00:09:34,900 : INFO : Current training batch loss: 0.3320 in epoch 1
2024-08-16 00:09:45,759 : INFO : Current training batch loss: 0.4693 in epoch 1
2024-08-16 00:09:56,634 : INFO : Current training batch loss: 0.2976 in epoch 1
2024-08-16 00:10:07,496 : INFO : Current training batch loss: 0.3380 in epoch 1
2024-08-16 00:10:18,359 : INFO : Current training batch loss: 0.1683 in epoch 1
2024-08-16 00:10:29,231 : INFO : Current training batch loss: 0.1058 in epoch 1
2024-08-16 00:10:40,100 : INFO : Current training batch loss: 0.4751 in epoch 1
2024-08-16 00:10:50,970 : INFO : Current training batch loss: 0.3367 in epoch 1
2024-08-16 00:11:01,833 : INFO : Current training batch loss: 0.2157 in epoch 1
2024-08-16 00:11:12,703 : INFO : Current training batch loss: 0.1723 in epoch 1
2024-08-16 00:11:23,580 : INFO : Current training batch loss: 0.1436 in epoch 1
2024-08-16 00:11:34,436 : INFO : Current training batch loss: 0.0602 in epoch 1
2024-08-16 00:11:45,308 : INFO : Current training batch loss: 0.2363 in epoch 1
2024-08-16 00:11:56,177 : INFO : Current training batch loss: 0.2290 in epoch 1
2024-08-16 00:12:07,042 : INFO : Current training batch loss: 0.1039 in epoch 1
2024-08-16 00:12:17,910 : INFO : Current training batch loss: 0.4055 in epoch 1
2024-08-16 00:12:28,783 : INFO : Current training batch loss: 0.2926 in epoch 1
2024-08-16 00:12:39,651 : INFO : Current training batch loss: 0.2393 in epoch 1
2024-08-16 00:12:50,530 : INFO : Current training batch loss: 0.1880 in epoch 1
2024-08-16 00:13:01,404 : INFO : Current training batch loss: 0.2900 in epoch 1
2024-08-16 00:13:12,276 : INFO : Current training batch loss: 0.1564 in epoch 1
2024-08-16 00:13:23,155 : INFO : Current training batch loss: 0.1177 in epoch 1
2024-08-16 00:13:34,021 : INFO : Current training batch loss: 0.3080 in epoch 1
2024-08-16 00:13:44,883 : INFO : Current training batch loss: 0.4274 in epoch 1
2024-08-16 00:13:55,759 : INFO : Current training batch loss: 0.1285 in epoch 1
2024-08-16 00:14:06,636 : INFO : Current training batch loss: 0.2092 in epoch 1
2024-08-16 00:14:09,056 : INFO : Epoch finished, average loss over training batches: 0.3285
2024-08-16 00:14:09,057 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:14:09,057 : INFO : Training metrics:
2024-08-16 00:14:09,057 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:14:09,368 : INFO : Accuracy: 0.8551
2024-08-16 00:14:09,368 : INFO : Precision: 0.8561
2024-08-16 00:14:09,368 : INFO : Recall: 0.8554
2024-08-16 00:14:09,368 : INFO : F1 score: 0.8558
2024-08-16 00:14:56,953 : INFO : Average loss over validation batches: 0.2206
2024-08-16 00:14:56,954 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:14:56,954 : INFO : Validation metrics:
2024-08-16 00:14:56,954 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:14:56,959 : INFO : Accuracy: 0.9154
2024-08-16 00:14:56,959 : INFO : Precision: 0.8892
2024-08-16 00:14:56,959 : INFO : Recall: 0.9461
2024-08-16 00:14:56,959 : INFO : F1 score: 0.9167
2024-08-16 00:14:56,959 : INFO : Validation metric decreased (inf --> 0.220578).  Saving model ...
2024-08-16 00:14:57,052 : INFO : Starting epoch 2
2024-08-16 00:15:05,205 : INFO : Current training batch loss: 0.1363 in epoch 2
2024-08-16 00:15:16,062 : INFO : Current training batch loss: 0.1987 in epoch 2
2024-08-16 00:15:26,912 : INFO : Current training batch loss: 0.0677 in epoch 2
2024-08-16 00:15:37,770 : INFO : Current training batch loss: 0.2123 in epoch 2
2024-08-16 00:15:48,629 : INFO : Current training batch loss: 0.3898 in epoch 2
2024-08-16 00:15:59,489 : INFO : Current training batch loss: 0.0836 in epoch 2
2024-08-16 00:16:10,345 : INFO : Current training batch loss: 0.0913 in epoch 2
2024-08-16 00:16:21,195 : INFO : Current training batch loss: 0.2302 in epoch 2
2024-08-16 00:16:32,044 : INFO : Current training batch loss: 0.1787 in epoch 2
2024-08-16 00:16:42,901 : INFO : Current training batch loss: 0.0745 in epoch 2
2024-08-16 00:16:53,763 : INFO : Current training batch loss: 0.0379 in epoch 2
2024-08-16 00:17:04,624 : INFO : Current training batch loss: 0.0367 in epoch 2
2024-08-16 00:17:15,481 : INFO : Current training batch loss: 0.0721 in epoch 2
2024-08-16 00:17:26,342 : INFO : Current training batch loss: 0.0511 in epoch 2
2024-08-16 00:17:37,195 : INFO : Current training batch loss: 0.1252 in epoch 2
2024-08-16 00:17:48,047 : INFO : Current training batch loss: 0.1563 in epoch 2
2024-08-16 00:17:58,907 : INFO : Current training batch loss: 0.0301 in epoch 2
2024-08-16 00:18:09,767 : INFO : Current training batch loss: 0.0152 in epoch 2
2024-08-16 00:18:20,633 : INFO : Current training batch loss: 0.1530 in epoch 2
2024-08-16 00:18:31,486 : INFO : Current training batch loss: 0.3527 in epoch 2
2024-08-16 00:18:42,344 : INFO : Current training batch loss: 0.0400 in epoch 2
2024-08-16 00:18:53,212 : INFO : Current training batch loss: 0.2955 in epoch 2
2024-08-16 00:19:04,068 : INFO : Current training batch loss: 0.1846 in epoch 2
2024-08-16 00:19:14,925 : INFO : Current training batch loss: 0.0184 in epoch 2
2024-08-16 00:19:25,792 : INFO : Current training batch loss: 0.0400 in epoch 2
2024-08-16 00:19:36,660 : INFO : Current training batch loss: 0.0055 in epoch 2
2024-08-16 00:19:47,512 : INFO : Current training batch loss: 0.0138 in epoch 2
2024-08-16 00:19:58,372 : INFO : Current training batch loss: 0.0196 in epoch 2
2024-08-16 00:20:09,234 : INFO : Current training batch loss: 0.0102 in epoch 2
2024-08-16 00:20:14,895 : INFO : Epoch finished, average loss over training batches: 0.1450
2024-08-16 00:20:14,897 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:20:14,897 : INFO : Training metrics:
2024-08-16 00:20:14,897 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:20:15,207 : INFO : Accuracy: 0.9483
2024-08-16 00:20:15,207 : INFO : Precision: 0.9484
2024-08-16 00:20:15,207 : INFO : Recall: 0.9487
2024-08-16 00:20:15,207 : INFO : F1 score: 0.9486
2024-08-16 00:21:02,770 : INFO : Average loss over validation batches: 0.2171
2024-08-16 00:21:02,771 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:21:02,771 : INFO : Validation metrics:
2024-08-16 00:21:02,771 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:21:02,776 : INFO : Accuracy: 0.9267
2024-08-16 00:21:02,776 : INFO : Precision: 0.9253
2024-08-16 00:21:02,776 : INFO : Recall: 0.9259
2024-08-16 00:21:02,776 : INFO : F1 score: 0.9256
2024-08-16 00:21:02,776 : INFO : Validation metric decreased (0.220578 --> 0.217119).  Saving model ...
2024-08-16 00:21:02,862 : INFO : Split 2 is finished, the score is: 0.9256
2024-08-16 00:21:02,862 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:21:02,863 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:21:02,863 : INFO : Starting training for split 3
2024-08-16 00:21:03,163 : INFO : Counting occurences of labels...
2024-08-16 00:21:26,124 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-16 00:21:33,888 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 00:21:34,325 : INFO : Starting epoch 1
2024-08-16 00:21:34,904 : INFO : Current training batch loss: 0.7332 in epoch 1
2024-08-16 00:21:45,701 : INFO : Current training batch loss: 0.7217 in epoch 1
2024-08-16 00:21:56,519 : INFO : Current training batch loss: 0.4549 in epoch 1
2024-08-16 00:22:07,352 : INFO : Current training batch loss: 0.3111 in epoch 1
2024-08-16 00:22:18,181 : INFO : Current training batch loss: 0.2768 in epoch 1
2024-08-16 00:22:29,019 : INFO : Current training batch loss: 0.6481 in epoch 1
2024-08-16 00:22:39,867 : INFO : Current training batch loss: 0.2131 in epoch 1
2024-08-16 00:22:50,707 : INFO : Current training batch loss: 0.3034 in epoch 1
2024-08-16 00:23:01,550 : INFO : Current training batch loss: 0.2217 in epoch 1
2024-08-16 00:23:12,408 : INFO : Current training batch loss: 0.1687 in epoch 1
2024-08-16 00:23:23,268 : INFO : Current training batch loss: 0.2601 in epoch 1
2024-08-16 00:23:34,130 : INFO : Current training batch loss: 0.2878 in epoch 1
2024-08-16 00:23:44,992 : INFO : Current training batch loss: 0.4078 in epoch 1
2024-08-16 00:23:55,855 : INFO : Current training batch loss: 0.1088 in epoch 1
2024-08-16 00:24:06,724 : INFO : Current training batch loss: 0.4570 in epoch 1
2024-08-16 00:24:17,585 : INFO : Current training batch loss: 0.1385 in epoch 1
2024-08-16 00:24:28,445 : INFO : Current training batch loss: 0.1945 in epoch 1
2024-08-16 00:24:39,307 : INFO : Current training batch loss: 0.3122 in epoch 1
2024-08-16 00:24:50,155 : INFO : Current training batch loss: 0.4022 in epoch 1
2024-08-16 00:25:01,009 : INFO : Current training batch loss: 0.3394 in epoch 1
2024-08-16 00:25:11,871 : INFO : Current training batch loss: 0.1849 in epoch 1
2024-08-16 00:25:22,730 : INFO : Current training batch loss: 0.2198 in epoch 1
2024-08-16 00:25:33,600 : INFO : Current training batch loss: 0.2039 in epoch 1
2024-08-16 00:25:44,466 : INFO : Current training batch loss: 0.1237 in epoch 1
2024-08-16 00:25:55,328 : INFO : Current training batch loss: 0.2438 in epoch 1
2024-08-16 00:26:06,200 : INFO : Current training batch loss: 0.1941 in epoch 1
2024-08-16 00:26:17,059 : INFO : Current training batch loss: 0.2721 in epoch 1
2024-08-16 00:26:27,918 : INFO : Current training batch loss: 0.3708 in epoch 1
2024-08-16 00:26:38,788 : INFO : Current training batch loss: 0.0902 in epoch 1
2024-08-16 00:26:49,660 : INFO : Current training batch loss: 0.2950 in epoch 1
2024-08-16 00:26:52,079 : INFO : Epoch finished, average loss over training batches: 0.3123
2024-08-16 00:26:52,080 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:26:52,080 : INFO : Training metrics:
2024-08-16 00:26:52,080 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:26:52,393 : INFO : Accuracy: 0.8652
2024-08-16 00:26:52,393 : INFO : Precision: 0.8685
2024-08-16 00:26:52,393 : INFO : Recall: 0.8617
2024-08-16 00:26:52,393 : INFO : F1 score: 0.8651
2024-08-16 00:27:40,221 : INFO : Average loss over validation batches: 0.2207
2024-08-16 00:27:40,222 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:27:40,222 : INFO : Validation metrics:
2024-08-16 00:27:40,222 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:27:40,227 : INFO : Accuracy: 0.9144
2024-08-16 00:27:40,227 : INFO : Precision: 0.8891
2024-08-16 00:27:40,227 : INFO : Recall: 0.9451
2024-08-16 00:27:40,227 : INFO : F1 score: 0.9162
2024-08-16 00:27:40,227 : INFO : Validation metric decreased (inf --> 0.220677).  Saving model ...
2024-08-16 00:27:40,312 : INFO : Starting epoch 2
2024-08-16 00:27:48,464 : INFO : Current training batch loss: 0.1219 in epoch 2
2024-08-16 00:27:59,320 : INFO : Current training batch loss: 0.2461 in epoch 2
2024-08-16 00:28:10,171 : INFO : Current training batch loss: 0.0587 in epoch 2
2024-08-16 00:28:21,033 : INFO : Current training batch loss: 0.1298 in epoch 2
2024-08-16 00:28:31,898 : INFO : Current training batch loss: 0.3028 in epoch 2
2024-08-16 00:28:42,765 : INFO : Current training batch loss: 0.1878 in epoch 2
2024-08-16 00:28:53,630 : INFO : Current training batch loss: 0.1485 in epoch 2
2024-08-16 00:29:04,491 : INFO : Current training batch loss: 0.2452 in epoch 2
2024-08-16 00:29:15,348 : INFO : Current training batch loss: 0.1830 in epoch 2
2024-08-16 00:29:26,212 : INFO : Current training batch loss: 0.1196 in epoch 2
2024-08-16 00:29:37,083 : INFO : Current training batch loss: 0.2079 in epoch 2
2024-08-16 00:29:47,947 : INFO : Current training batch loss: 0.0931 in epoch 2
2024-08-16 00:29:58,808 : INFO : Current training batch loss: 0.0328 in epoch 2
2024-08-16 00:30:09,668 : INFO : Current training batch loss: 0.1644 in epoch 2
2024-08-16 00:30:20,526 : INFO : Current training batch loss: 0.1053 in epoch 2
2024-08-16 00:30:31,398 : INFO : Current training batch loss: 0.0122 in epoch 2
2024-08-16 00:30:42,260 : INFO : Current training batch loss: 0.0820 in epoch 2
2024-08-16 00:30:53,117 : INFO : Current training batch loss: 0.4480 in epoch 2
2024-08-16 00:31:03,979 : INFO : Current training batch loss: 0.0389 in epoch 2
2024-08-16 00:31:14,846 : INFO : Current training batch loss: 0.1998 in epoch 2
2024-08-16 00:31:25,709 : INFO : Current training batch loss: 0.0223 in epoch 2
2024-08-16 00:31:36,583 : INFO : Current training batch loss: 0.1767 in epoch 2
2024-08-16 00:31:47,441 : INFO : Current training batch loss: 0.0211 in epoch 2
2024-08-16 00:31:58,299 : INFO : Current training batch loss: 0.0125 in epoch 2
2024-08-16 00:32:09,168 : INFO : Current training batch loss: 0.0215 in epoch 2
2024-08-16 00:32:20,041 : INFO : Current training batch loss: 0.0053 in epoch 2
2024-08-16 00:32:30,901 : INFO : Current training batch loss: 0.0331 in epoch 2
2024-08-16 00:32:41,768 : INFO : Current training batch loss: 0.0178 in epoch 2
2024-08-16 00:32:52,634 : INFO : Current training batch loss: 0.0378 in epoch 2
2024-08-16 00:32:58,298 : INFO : Epoch finished, average loss over training batches: 0.1323
2024-08-16 00:32:58,300 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:32:58,300 : INFO : Training metrics:
2024-08-16 00:32:58,300 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:32:58,613 : INFO : Accuracy: 0.9530
2024-08-16 00:32:58,613 : INFO : Precision: 0.9520
2024-08-16 00:32:58,613 : INFO : Recall: 0.9544
2024-08-16 00:32:58,613 : INFO : F1 score: 0.9532
2024-08-16 00:33:46,420 : INFO : Average loss over validation batches: 0.2160
2024-08-16 00:33:46,420 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:33:46,420 : INFO : Validation metrics:
2024-08-16 00:33:46,420 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:33:46,426 : INFO : Accuracy: 0.9293
2024-08-16 00:33:46,426 : INFO : Precision: 0.9337
2024-08-16 00:33:46,426 : INFO : Recall: 0.9228
2024-08-16 00:33:46,426 : INFO : F1 score: 0.9282
2024-08-16 00:33:46,426 : INFO : Validation metric decreased (0.220677 --> 0.215985).  Saving model ...
2024-08-16 00:33:46,517 : INFO : Split 3 is finished, the score is: 0.9282
2024-08-16 00:33:46,517 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:33:46,517 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:33:46,517 : INFO : Starting training for split 4
2024-08-16 00:33:46,895 : INFO : Counting occurences of labels...
2024-08-16 00:34:10,342 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-16 00:34:18,079 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 00:34:18,535 : INFO : Starting epoch 1
2024-08-16 00:34:19,115 : INFO : Current training batch loss: 0.6613 in epoch 1
2024-08-16 00:34:29,921 : INFO : Current training batch loss: 0.6607 in epoch 1
2024-08-16 00:34:40,754 : INFO : Current training batch loss: 0.4920 in epoch 1
2024-08-16 00:34:51,595 : INFO : Current training batch loss: 0.4022 in epoch 1
2024-08-16 00:35:02,436 : INFO : Current training batch loss: 0.3807 in epoch 1
2024-08-16 00:35:13,292 : INFO : Current training batch loss: 0.2793 in epoch 1
2024-08-16 00:35:24,162 : INFO : Current training batch loss: 0.2063 in epoch 1
2024-08-16 00:35:35,020 : INFO : Current training batch loss: 0.3180 in epoch 1
2024-08-16 00:35:45,885 : INFO : Current training batch loss: 0.3180 in epoch 1
2024-08-16 00:35:56,762 : INFO : Current training batch loss: 0.1338 in epoch 1
2024-08-16 00:36:07,634 : INFO : Current training batch loss: 0.2237 in epoch 1
2024-08-16 00:36:18,509 : INFO : Current training batch loss: 0.2131 in epoch 1
2024-08-16 00:36:29,385 : INFO : Current training batch loss: 0.5133 in epoch 1
2024-08-16 00:36:40,260 : INFO : Current training batch loss: 0.1840 in epoch 1
2024-08-16 00:36:51,143 : INFO : Current training batch loss: 0.2346 in epoch 1
2024-08-16 00:37:02,018 : INFO : Current training batch loss: 0.1777 in epoch 1
2024-08-16 00:37:12,892 : INFO : Current training batch loss: 0.3915 in epoch 1
2024-08-16 00:37:23,771 : INFO : Current training batch loss: 0.1975 in epoch 1
2024-08-16 00:37:34,633 : INFO : Current training batch loss: 0.0838 in epoch 1
2024-08-16 00:37:45,504 : INFO : Current training batch loss: 0.3617 in epoch 1
2024-08-16 00:37:56,381 : INFO : Current training batch loss: 0.2316 in epoch 1
2024-08-16 00:38:07,254 : INFO : Current training batch loss: 0.3610 in epoch 1
2024-08-16 00:38:18,129 : INFO : Current training batch loss: 0.3062 in epoch 1
2024-08-16 00:38:28,999 : INFO : Current training batch loss: 0.2592 in epoch 1
2024-08-16 00:38:39,877 : INFO : Current training batch loss: 0.1129 in epoch 1
2024-08-16 00:38:50,747 : INFO : Current training batch loss: 0.2631 in epoch 1
2024-08-16 00:39:01,620 : INFO : Current training batch loss: 0.3753 in epoch 1
2024-08-16 00:39:12,496 : INFO : Current training batch loss: 0.4496 in epoch 1
2024-08-16 00:39:23,374 : INFO : Current training batch loss: 0.4627 in epoch 1
2024-08-16 00:39:34,243 : INFO : Current training batch loss: 0.3557 in epoch 1
2024-08-16 00:39:36,665 : INFO : Epoch finished, average loss over training batches: 0.3106
2024-08-16 00:39:36,666 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:39:36,666 : INFO : Training metrics:
2024-08-16 00:39:36,666 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:39:36,980 : INFO : Accuracy: 0.8629
2024-08-16 00:39:36,980 : INFO : Precision: 0.8644
2024-08-16 00:39:36,980 : INFO : Recall: 0.8593
2024-08-16 00:39:36,980 : INFO : F1 score: 0.8618
2024-08-16 00:40:24,539 : INFO : Average loss over validation batches: 0.2700
2024-08-16 00:40:24,539 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:40:24,539 : INFO : Validation metrics:
2024-08-16 00:40:24,539 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:40:24,544 : INFO : Accuracy: 0.8891
2024-08-16 00:40:24,544 : INFO : Precision: 0.9463
2024-08-16 00:40:24,544 : INFO : Recall: 0.8284
2024-08-16 00:40:24,544 : INFO : F1 score: 0.8835
2024-08-16 00:40:24,544 : INFO : Validation metric decreased (inf --> 0.269950).  Saving model ...
2024-08-16 00:40:24,630 : INFO : Starting epoch 2
2024-08-16 00:40:32,782 : INFO : Current training batch loss: 0.1289 in epoch 2
2024-08-16 00:40:43,637 : INFO : Current training batch loss: 0.1941 in epoch 2
2024-08-16 00:40:54,496 : INFO : Current training batch loss: 0.1248 in epoch 2
2024-08-16 00:41:05,367 : INFO : Current training batch loss: 0.2723 in epoch 2
2024-08-16 00:41:16,237 : INFO : Current training batch loss: 0.2021 in epoch 2
2024-08-16 00:41:27,111 : INFO : Current training batch loss: 0.2202 in epoch 2
2024-08-16 00:41:37,983 : INFO : Current training batch loss: 0.1323 in epoch 2
2024-08-16 00:41:48,856 : INFO : Current training batch loss: 0.1333 in epoch 2
2024-08-16 00:41:59,725 : INFO : Current training batch loss: 0.2157 in epoch 2
2024-08-16 00:42:10,600 : INFO : Current training batch loss: 0.0271 in epoch 2
2024-08-16 00:42:21,487 : INFO : Current training batch loss: 0.1112 in epoch 2
2024-08-16 00:42:32,365 : INFO : Current training batch loss: 0.2681 in epoch 2
2024-08-16 00:42:43,239 : INFO : Current training batch loss: 0.0433 in epoch 2
2024-08-16 00:42:54,111 : INFO : Current training batch loss: 0.0337 in epoch 2
2024-08-16 00:43:04,978 : INFO : Current training batch loss: 0.0892 in epoch 2
2024-08-16 00:43:15,859 : INFO : Current training batch loss: 0.0255 in epoch 2
2024-08-16 00:43:26,728 : INFO : Current training batch loss: 0.0799 in epoch 2
2024-08-16 00:43:37,596 : INFO : Current training batch loss: 0.2742 in epoch 2
2024-08-16 00:43:48,469 : INFO : Current training batch loss: 0.0827 in epoch 2
2024-08-16 00:43:59,345 : INFO : Current training batch loss: 0.0077 in epoch 2
2024-08-16 00:44:10,224 : INFO : Current training batch loss: 0.0418 in epoch 2
2024-08-16 00:44:21,092 : INFO : Current training batch loss: 0.0390 in epoch 2
2024-08-16 00:44:31,964 : INFO : Current training batch loss: 0.0096 in epoch 2
2024-08-16 00:44:42,843 : INFO : Current training batch loss: 0.0053 in epoch 2
2024-08-16 00:44:53,705 : INFO : Current training batch loss: 0.1042 in epoch 2
2024-08-16 00:45:04,569 : INFO : Current training batch loss: 0.0455 in epoch 2
2024-08-16 00:45:15,441 : INFO : Current training batch loss: 0.0908 in epoch 2
2024-08-16 00:45:26,313 : INFO : Current training batch loss: 0.1640 in epoch 2
2024-08-16 00:45:37,181 : INFO : Current training batch loss: 0.0718 in epoch 2
2024-08-16 00:45:42,868 : INFO : Epoch finished, average loss over training batches: 0.1283
2024-08-16 00:45:42,870 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:45:42,870 : INFO : Training metrics:
2024-08-16 00:45:42,870 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:45:43,183 : INFO : Accuracy: 0.9525
2024-08-16 00:45:43,183 : INFO : Precision: 0.9525
2024-08-16 00:45:43,183 : INFO : Recall: 0.9521
2024-08-16 00:45:43,183 : INFO : F1 score: 0.9523
2024-08-16 00:46:30,778 : INFO : Average loss over validation batches: 0.2529
2024-08-16 00:46:30,779 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:46:30,779 : INFO : Validation metrics:
2024-08-16 00:46:30,779 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:46:30,784 : INFO : Accuracy: 0.9240
2024-08-16 00:46:30,784 : INFO : Precision: 0.9288
2024-08-16 00:46:30,784 : INFO : Recall: 0.9208
2024-08-16 00:46:30,784 : INFO : F1 score: 0.9248
2024-08-16 00:46:30,784 : INFO : Validation metric decreased (0.269950 --> 0.252946).  Saving model ...
2024-08-16 00:46:30,871 : INFO : Split 4 is finished, the score is: 0.9248
2024-08-16 00:46:30,871 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-16 00:46:30,877] Trial 5 finished with value: 0.9241835973410469 and parameters: {'n_epochs': 2, 'learning_rate': 0.00019475065456539222, 'classifier_dropout': 0.5604450862639451, 'warmup_step_fraction': 0.013707085280030971, 'use_gradient_clipping': True}. Best is trial 5 with value: 0.9241835973410469.
2024-08-16 00:46:30,878 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:46:30,878 : INFO : Starting training for split 1
2024-08-16 00:46:31,194 : INFO : Counting occurences of labels...
2024-08-16 00:46:54,573 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-16 00:47:02,367 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 00:47:02,823 : INFO : Starting epoch 1
2024-08-16 00:47:03,412 : INFO : Current training batch loss: 0.6865 in epoch 1
2024-08-16 00:47:14,204 : INFO : Current training batch loss: 0.6894 in epoch 1
2024-08-16 00:47:25,040 : INFO : Current training batch loss: 0.6518 in epoch 1
2024-08-16 00:47:35,909 : INFO : Current training batch loss: 0.2542 in epoch 1
2024-08-16 00:47:46,768 : INFO : Current training batch loss: 0.3458 in epoch 1
2024-08-16 00:47:57,630 : INFO : Current training batch loss: 0.3564 in epoch 1
2024-08-16 00:48:08,494 : INFO : Current training batch loss: 0.3072 in epoch 1
2024-08-16 00:48:19,365 : INFO : Current training batch loss: 0.3912 in epoch 1
2024-08-16 00:48:30,238 : INFO : Current training batch loss: 0.5380 in epoch 1
2024-08-16 00:48:41,110 : INFO : Current training batch loss: 0.1845 in epoch 1
2024-08-16 00:48:51,991 : INFO : Current training batch loss: 0.2215 in epoch 1
2024-08-16 00:49:02,867 : INFO : Current training batch loss: 0.3819 in epoch 1
2024-08-16 00:49:13,742 : INFO : Current training batch loss: 0.1720 in epoch 1
2024-08-16 00:49:24,621 : INFO : Current training batch loss: 0.1495 in epoch 1
2024-08-16 00:49:35,512 : INFO : Current training batch loss: 0.2957 in epoch 1
2024-08-16 00:49:46,383 : INFO : Current training batch loss: 0.0676 in epoch 1
2024-08-16 00:49:57,268 : INFO : Current training batch loss: 0.3179 in epoch 1
2024-08-16 00:50:08,148 : INFO : Current training batch loss: 0.1526 in epoch 1
2024-08-16 00:50:19,029 : INFO : Current training batch loss: 0.2217 in epoch 1
2024-08-16 00:50:29,914 : INFO : Current training batch loss: 0.3687 in epoch 1
2024-08-16 00:50:40,801 : INFO : Current training batch loss: 0.1265 in epoch 1
2024-08-16 00:50:51,678 : INFO : Current training batch loss: 0.1541 in epoch 1
2024-08-16 00:51:02,566 : INFO : Current training batch loss: 0.1777 in epoch 1
2024-08-16 00:51:13,445 : INFO : Current training batch loss: 0.2616 in epoch 1
2024-08-16 00:51:24,320 : INFO : Current training batch loss: 0.2626 in epoch 1
2024-08-16 00:51:35,200 : INFO : Current training batch loss: 0.1080 in epoch 1
2024-08-16 00:51:46,068 : INFO : Current training batch loss: 0.1954 in epoch 1
2024-08-16 00:51:56,934 : INFO : Current training batch loss: 0.4058 in epoch 1
2024-08-16 00:52:07,813 : INFO : Current training batch loss: 0.1590 in epoch 1
2024-08-16 00:52:18,690 : INFO : Current training batch loss: 0.1348 in epoch 1
2024-08-16 00:52:21,109 : INFO : Epoch finished, average loss over training batches: 0.3032
2024-08-16 00:52:21,111 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:52:21,111 : INFO : Training metrics:
2024-08-16 00:52:21,111 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:52:21,422 : INFO : Accuracy: 0.8671
2024-08-16 00:52:21,422 : INFO : Precision: 0.8706
2024-08-16 00:52:21,422 : INFO : Recall: 0.8614
2024-08-16 00:52:21,422 : INFO : F1 score: 0.8660
2024-08-16 00:53:09,090 : INFO : Average loss over validation batches: 0.2111
2024-08-16 00:53:09,091 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:53:09,091 : INFO : Validation metrics:
2024-08-16 00:53:09,091 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:53:09,096 : INFO : Accuracy: 0.9163
2024-08-16 00:53:09,096 : INFO : Precision: 0.8995
2024-08-16 00:53:09,096 : INFO : Recall: 0.9391
2024-08-16 00:53:09,096 : INFO : F1 score: 0.9189
2024-08-16 00:53:09,096 : INFO : Validation metric decreased (inf --> 0.211121).  Saving model ...
2024-08-16 00:53:09,184 : INFO : Split 1 is finished, the score is: 0.9189
2024-08-16 00:53:09,184 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:53:09,184 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:53:09,184 : INFO : Starting training for split 2
2024-08-16 00:53:09,522 : INFO : Counting occurences of labels...
2024-08-16 00:53:32,768 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-16 00:53:40,503 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 00:53:40,949 : INFO : Starting epoch 1
2024-08-16 00:53:41,529 : INFO : Current training batch loss: 0.7275 in epoch 1
2024-08-16 00:53:52,342 : INFO : Current training batch loss: 0.6838 in epoch 1
2024-08-16 00:54:03,180 : INFO : Current training batch loss: 0.5425 in epoch 1
2024-08-16 00:54:14,051 : INFO : Current training batch loss: 0.5105 in epoch 1
2024-08-16 00:54:24,905 : INFO : Current training batch loss: 0.5540 in epoch 1
2024-08-16 00:54:35,764 : INFO : Current training batch loss: 0.2746 in epoch 1
2024-08-16 00:54:46,637 : INFO : Current training batch loss: 0.2182 in epoch 1
2024-08-16 00:54:57,500 : INFO : Current training batch loss: 0.2452 in epoch 1
2024-08-16 00:55:08,369 : INFO : Current training batch loss: 0.2201 in epoch 1
2024-08-16 00:55:19,250 : INFO : Current training batch loss: 0.3265 in epoch 1
2024-08-16 00:55:30,125 : INFO : Current training batch loss: 0.1265 in epoch 1
2024-08-16 00:55:41,000 : INFO : Current training batch loss: 0.4750 in epoch 1
2024-08-16 00:55:51,873 : INFO : Current training batch loss: 0.1347 in epoch 1
2024-08-16 00:56:02,750 : INFO : Current training batch loss: 0.1618 in epoch 1
2024-08-16 00:56:13,638 : INFO : Current training batch loss: 0.1584 in epoch 1
2024-08-16 00:56:24,508 : INFO : Current training batch loss: 0.1123 in epoch 1
2024-08-16 00:56:35,391 : INFO : Current training batch loss: 0.2777 in epoch 1
2024-08-16 00:56:46,275 : INFO : Current training batch loss: 0.2334 in epoch 1
2024-08-16 00:56:57,155 : INFO : Current training batch loss: 0.1651 in epoch 1
2024-08-16 00:57:08,038 : INFO : Current training batch loss: 0.3887 in epoch 1
2024-08-16 00:57:18,924 : INFO : Current training batch loss: 0.1419 in epoch 1
2024-08-16 00:57:29,803 : INFO : Current training batch loss: 0.1952 in epoch 1
2024-08-16 00:57:40,693 : INFO : Current training batch loss: 0.2237 in epoch 1
2024-08-16 00:57:51,580 : INFO : Current training batch loss: 0.1116 in epoch 1
2024-08-16 00:58:02,464 : INFO : Current training batch loss: 0.2657 in epoch 1
2024-08-16 00:58:13,354 : INFO : Current training batch loss: 0.1541 in epoch 1
2024-08-16 00:58:24,232 : INFO : Current training batch loss: 0.2210 in epoch 1
2024-08-16 00:58:35,109 : INFO : Current training batch loss: 0.3837 in epoch 1
2024-08-16 00:58:46,003 : INFO : Current training batch loss: 0.0868 in epoch 1
2024-08-16 00:58:56,896 : INFO : Current training batch loss: 0.1877 in epoch 1
2024-08-16 00:58:59,318 : INFO : Epoch finished, average loss over training batches: 0.3037
2024-08-16 00:58:59,320 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:58:59,320 : INFO : Training metrics:
2024-08-16 00:58:59,320 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:58:59,631 : INFO : Accuracy: 0.8655
2024-08-16 00:58:59,631 : INFO : Precision: 0.8627
2024-08-16 00:58:59,631 : INFO : Recall: 0.8709
2024-08-16 00:58:59,631 : INFO : F1 score: 0.8668
2024-08-16 00:59:47,221 : INFO : Average loss over validation batches: 0.2138
2024-08-16 00:59:47,222 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:59:47,222 : INFO : Validation metrics:
2024-08-16 00:59:47,222 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:59:47,227 : INFO : Accuracy: 0.9154
2024-08-16 00:59:47,227 : INFO : Precision: 0.8928
2024-08-16 00:59:47,227 : INFO : Recall: 0.9412
2024-08-16 00:59:47,227 : INFO : F1 score: 0.9163
2024-08-16 00:59:47,227 : INFO : Validation metric decreased (inf --> 0.213823).  Saving model ...
2024-08-16 00:59:47,320 : INFO : Split 2 is finished, the score is: 0.9163
2024-08-16 00:59:47,321 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:59:47,321 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 00:59:47,321 : INFO : Starting training for split 3
2024-08-16 00:59:47,656 : INFO : Counting occurences of labels...
2024-08-16 01:00:10,693 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-16 01:00:18,537 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 01:00:19,034 : INFO : Starting epoch 1
2024-08-16 01:00:19,615 : INFO : Current training batch loss: 0.7240 in epoch 1
2024-08-16 01:00:30,453 : INFO : Current training batch loss: 0.6720 in epoch 1
2024-08-16 01:00:41,300 : INFO : Current training batch loss: 0.6215 in epoch 1
2024-08-16 01:00:52,147 : INFO : Current training batch loss: 0.2970 in epoch 1
2024-08-16 01:01:03,006 : INFO : Current training batch loss: 0.2782 in epoch 1
2024-08-16 01:01:13,867 : INFO : Current training batch loss: 0.5738 in epoch 1
2024-08-16 01:01:24,739 : INFO : Current training batch loss: 0.3255 in epoch 1
2024-08-16 01:01:35,597 : INFO : Current training batch loss: 0.3176 in epoch 1
2024-08-16 01:01:46,461 : INFO : Current training batch loss: 0.2632 in epoch 1
2024-08-16 01:01:57,339 : INFO : Current training batch loss: 0.1460 in epoch 1
2024-08-16 01:02:08,214 : INFO : Current training batch loss: 0.2399 in epoch 1
2024-08-16 01:02:19,093 : INFO : Current training batch loss: 0.2858 in epoch 1
2024-08-16 01:02:29,971 : INFO : Current training batch loss: 0.3065 in epoch 1
2024-08-16 01:02:40,848 : INFO : Current training batch loss: 0.1622 in epoch 1
2024-08-16 01:02:51,735 : INFO : Current training batch loss: 0.2730 in epoch 1
2024-08-16 01:03:02,612 : INFO : Current training batch loss: 0.2127 in epoch 1
2024-08-16 01:03:13,490 : INFO : Current training batch loss: 0.2487 in epoch 1
2024-08-16 01:03:24,368 : INFO : Current training batch loss: 0.2544 in epoch 1
2024-08-16 01:03:35,233 : INFO : Current training batch loss: 0.1573 in epoch 1
2024-08-16 01:03:46,103 : INFO : Current training batch loss: 0.2345 in epoch 1
2024-08-16 01:03:56,983 : INFO : Current training batch loss: 0.1378 in epoch 1
2024-08-16 01:04:07,859 : INFO : Current training batch loss: 0.1779 in epoch 1
2024-08-16 01:04:18,745 : INFO : Current training batch loss: 0.1727 in epoch 1
2024-08-16 01:04:29,626 : INFO : Current training batch loss: 0.1697 in epoch 1
2024-08-16 01:04:40,506 : INFO : Current training batch loss: 0.2404 in epoch 1
2024-08-16 01:04:51,392 : INFO : Current training batch loss: 0.1443 in epoch 1
2024-08-16 01:05:02,263 : INFO : Current training batch loss: 0.2340 in epoch 1
2024-08-16 01:05:13,137 : INFO : Current training batch loss: 0.3684 in epoch 1
2024-08-16 01:05:24,022 : INFO : Current training batch loss: 0.1530 in epoch 1
2024-08-16 01:05:34,911 : INFO : Current training batch loss: 0.1777 in epoch 1
2024-08-16 01:05:37,332 : INFO : Epoch finished, average loss over training batches: 0.3152
2024-08-16 01:05:37,333 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:05:37,333 : INFO : Training metrics:
2024-08-16 01:05:37,333 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:05:37,647 : INFO : Accuracy: 0.8552
2024-08-16 01:05:37,647 : INFO : Precision: 0.8595
2024-08-16 01:05:37,647 : INFO : Recall: 0.8503
2024-08-16 01:05:37,647 : INFO : F1 score: 0.8549
2024-08-16 01:06:25,439 : INFO : Average loss over validation batches: 0.2136
2024-08-16 01:06:25,440 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:06:25,440 : INFO : Validation metrics:
2024-08-16 01:06:25,440 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:06:25,445 : INFO : Accuracy: 0.9157
2024-08-16 01:06:25,445 : INFO : Precision: 0.8973
2024-08-16 01:06:25,445 : INFO : Recall: 0.9370
2024-08-16 01:06:25,445 : INFO : F1 score: 0.9167
2024-08-16 01:06:25,445 : INFO : Validation metric decreased (inf --> 0.213636).  Saving model ...
2024-08-16 01:06:25,533 : INFO : Split 3 is finished, the score is: 0.9167
2024-08-16 01:06:25,533 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:06:25,533 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:06:25,533 : INFO : Starting training for split 4
2024-08-16 01:06:26,037 : INFO : Counting occurences of labels...
2024-08-16 01:06:49,444 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-16 01:06:57,160 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 01:06:57,569 : INFO : Starting epoch 1
2024-08-16 01:06:58,148 : INFO : Current training batch loss: 0.7099 in epoch 1
2024-08-16 01:07:08,952 : INFO : Current training batch loss: 0.6726 in epoch 1
2024-08-16 01:07:19,785 : INFO : Current training batch loss: 0.5424 in epoch 1
2024-08-16 01:07:30,650 : INFO : Current training batch loss: 0.2428 in epoch 1
2024-08-16 01:07:41,516 : INFO : Current training batch loss: 0.4019 in epoch 1
2024-08-16 01:07:52,376 : INFO : Current training batch loss: 0.3990 in epoch 1
2024-08-16 01:08:03,248 : INFO : Current training batch loss: 0.2272 in epoch 1
2024-08-16 01:08:14,109 : INFO : Current training batch loss: 0.2468 in epoch 1
2024-08-16 01:08:24,975 : INFO : Current training batch loss: 0.1349 in epoch 1
2024-08-16 01:08:35,857 : INFO : Current training batch loss: 0.3027 in epoch 1
2024-08-16 01:08:46,737 : INFO : Current training batch loss: 0.2579 in epoch 1
2024-08-16 01:08:57,619 : INFO : Current training batch loss: 0.2405 in epoch 1
2024-08-16 01:09:08,500 : INFO : Current training batch loss: 0.6302 in epoch 1
2024-08-16 01:09:19,381 : INFO : Current training batch loss: 0.1681 in epoch 1
2024-08-16 01:09:30,270 : INFO : Current training batch loss: 0.3055 in epoch 1
2024-08-16 01:09:41,150 : INFO : Current training batch loss: 0.2293 in epoch 1
2024-08-16 01:09:52,031 : INFO : Current training batch loss: 0.2446 in epoch 1
2024-08-16 01:10:02,913 : INFO : Current training batch loss: 0.3050 in epoch 1
2024-08-16 01:10:13,778 : INFO : Current training batch loss: 0.0911 in epoch 1
2024-08-16 01:10:24,655 : INFO : Current training batch loss: 0.2445 in epoch 1
2024-08-16 01:10:35,537 : INFO : Current training batch loss: 0.4317 in epoch 1
2024-08-16 01:10:46,414 : INFO : Current training batch loss: 0.2664 in epoch 1
2024-08-16 01:10:57,289 : INFO : Current training batch loss: 0.2704 in epoch 1
2024-08-16 01:11:08,163 : INFO : Current training batch loss: 0.2232 in epoch 1
2024-08-16 01:11:19,046 : INFO : Current training batch loss: 0.0978 in epoch 1
2024-08-16 01:11:29,922 : INFO : Current training batch loss: 0.2661 in epoch 1
2024-08-16 01:11:40,803 : INFO : Current training batch loss: 0.3434 in epoch 1
2024-08-16 01:11:51,688 : INFO : Current training batch loss: 0.2187 in epoch 1
2024-08-16 01:12:02,578 : INFO : Current training batch loss: 0.3546 in epoch 1
2024-08-16 01:12:13,456 : INFO : Current training batch loss: 0.3066 in epoch 1
2024-08-16 01:12:15,879 : INFO : Epoch finished, average loss over training batches: 0.2948
2024-08-16 01:12:15,881 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:12:15,881 : INFO : Training metrics:
2024-08-16 01:12:15,881 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:12:16,232 : INFO : Accuracy: 0.8684
2024-08-16 01:12:16,232 : INFO : Precision: 0.8713
2024-08-16 01:12:16,232 : INFO : Recall: 0.8629
2024-08-16 01:12:16,232 : INFO : F1 score: 0.8671
2024-08-16 01:13:03,828 : INFO : Average loss over validation batches: 0.2130
2024-08-16 01:13:03,829 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:13:03,829 : INFO : Validation metrics:
2024-08-16 01:13:03,829 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:13:03,834 : INFO : Accuracy: 0.9194
2024-08-16 01:13:03,834 : INFO : Precision: 0.9303
2024-08-16 01:13:03,834 : INFO : Recall: 0.9092
2024-08-16 01:13:03,834 : INFO : F1 score: 0.9196
2024-08-16 01:13:03,834 : INFO : Validation metric decreased (inf --> 0.212959).  Saving model ...
2024-08-16 01:13:03,921 : INFO : Split 4 is finished, the score is: 0.9196
2024-08-16 01:13:03,921 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-16 01:13:03,930] Trial 6 finished with value: 0.9178972657889674 and parameters: {'n_epochs': 1, 'learning_rate': 0.0001526224317322648, 'classifier_dropout': 0.436599574762666, 'warmup_step_fraction': 0.07510658044058426, 'use_gradient_clipping': True}. Best is trial 5 with value: 0.9241835973410469.
2024-08-16 01:13:03,931 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:13:03,931 : INFO : Starting training for split 1
2024-08-16 01:13:04,247 : INFO : Counting occurences of labels...
2024-08-16 01:13:27,446 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-16 01:13:35,253 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 01:13:35,678 : INFO : Starting epoch 1
2024-08-16 01:13:36,269 : INFO : Current training batch loss: 0.7596 in epoch 1
2024-08-16 01:13:47,108 : INFO : Current training batch loss: 0.6688 in epoch 1
2024-08-16 01:13:57,974 : INFO : Current training batch loss: 0.7400 in epoch 1
2024-08-16 01:14:08,838 : INFO : Current training batch loss: 0.6295 in epoch 1
2024-08-16 01:14:19,703 : INFO : Current training batch loss: 0.4993 in epoch 1
2024-08-16 01:14:30,579 : INFO : Current training batch loss: 0.3185 in epoch 1
2024-08-16 01:14:41,450 : INFO : Current training batch loss: 0.2927 in epoch 1
2024-08-16 01:14:52,325 : INFO : Current training batch loss: 0.3017 in epoch 1
2024-08-16 01:15:03,203 : INFO : Current training batch loss: 0.3310 in epoch 1
2024-08-16 01:15:14,080 : INFO : Current training batch loss: 0.1810 in epoch 1
2024-08-16 01:15:24,964 : INFO : Current training batch loss: 0.2134 in epoch 1
2024-08-16 01:15:35,842 : INFO : Current training batch loss: 0.3377 in epoch 1
2024-08-16 01:15:46,714 : INFO : Current training batch loss: 0.1444 in epoch 1
2024-08-16 01:15:57,588 : INFO : Current training batch loss: 0.1203 in epoch 1
2024-08-16 01:16:08,474 : INFO : Current training batch loss: 0.2197 in epoch 1
2024-08-16 01:16:19,341 : INFO : Current training batch loss: 0.0828 in epoch 1
2024-08-16 01:16:30,224 : INFO : Current training batch loss: 0.1715 in epoch 1
2024-08-16 01:16:41,100 : INFO : Current training batch loss: 0.1273 in epoch 1
2024-08-16 01:16:51,974 : INFO : Current training batch loss: 0.1844 in epoch 1
2024-08-16 01:17:02,851 : INFO : Current training batch loss: 0.3502 in epoch 1
2024-08-16 01:17:13,734 : INFO : Current training batch loss: 0.1380 in epoch 1
2024-08-16 01:17:24,610 : INFO : Current training batch loss: 0.3732 in epoch 1
2024-08-16 01:17:35,497 : INFO : Current training batch loss: 0.2143 in epoch 1
2024-08-16 01:17:46,379 : INFO : Current training batch loss: 0.1972 in epoch 1
2024-08-16 01:17:57,263 : INFO : Current training batch loss: 0.3102 in epoch 1
2024-08-16 01:18:08,150 : INFO : Current training batch loss: 0.1111 in epoch 1
2024-08-16 01:18:19,026 : INFO : Current training batch loss: 0.1843 in epoch 1
2024-08-16 01:18:29,905 : INFO : Current training batch loss: 0.3421 in epoch 1
2024-08-16 01:18:40,799 : INFO : Current training batch loss: 0.1540 in epoch 1
2024-08-16 01:18:51,693 : INFO : Current training batch loss: 0.1945 in epoch 1
2024-08-16 01:18:54,117 : INFO : Epoch finished, average loss over training batches: 0.3087
2024-08-16 01:18:54,118 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:18:54,118 : INFO : Training metrics:
2024-08-16 01:18:54,118 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:18:54,427 : INFO : Accuracy: 0.8547
2024-08-16 01:18:54,427 : INFO : Precision: 0.8607
2024-08-16 01:18:54,427 : INFO : Recall: 0.8453
2024-08-16 01:18:54,427 : INFO : F1 score: 0.8529
2024-08-16 01:19:42,092 : INFO : Average loss over validation batches: 0.2055
2024-08-16 01:19:42,093 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:19:42,093 : INFO : Validation metrics:
2024-08-16 01:19:42,093 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:19:42,098 : INFO : Accuracy: 0.9203
2024-08-16 01:19:42,098 : INFO : Precision: 0.9137
2024-08-16 01:19:42,098 : INFO : Recall: 0.9300
2024-08-16 01:19:42,098 : INFO : F1 score: 0.9218
2024-08-16 01:19:42,098 : INFO : Validation metric decreased (inf --> 0.205480).  Saving model ...
2024-08-16 01:19:42,185 : INFO : Split 1 is finished, the score is: 0.9218
2024-08-16 01:19:42,185 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:19:42,185 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:19:42,185 : INFO : Starting training for split 2
2024-08-16 01:19:42,507 : INFO : Counting occurences of labels...
2024-08-16 01:20:05,779 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-16 01:20:13,470 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 01:20:13,903 : INFO : Starting epoch 1
2024-08-16 01:20:14,483 : INFO : Current training batch loss: 0.7417 in epoch 1
2024-08-16 01:20:25,287 : INFO : Current training batch loss: 0.7085 in epoch 1
2024-08-16 01:20:36,119 : INFO : Current training batch loss: 0.5727 in epoch 1
2024-08-16 01:20:46,977 : INFO : Current training batch loss: 0.3793 in epoch 1
2024-08-16 01:20:57,841 : INFO : Current training batch loss: 0.4354 in epoch 1
2024-08-16 01:21:08,693 : INFO : Current training batch loss: 0.2180 in epoch 1
2024-08-16 01:21:19,558 : INFO : Current training batch loss: 0.2314 in epoch 1
2024-08-16 01:21:30,411 : INFO : Current training batch loss: 0.3316 in epoch 1
2024-08-16 01:21:41,269 : INFO : Current training batch loss: 0.1496 in epoch 1
2024-08-16 01:21:52,139 : INFO : Current training batch loss: 0.1624 in epoch 1
2024-08-16 01:22:03,008 : INFO : Current training batch loss: 0.1759 in epoch 1
2024-08-16 01:22:13,877 : INFO : Current training batch loss: 0.3548 in epoch 1
2024-08-16 01:22:24,740 : INFO : Current training batch loss: 0.2359 in epoch 1
2024-08-16 01:22:35,607 : INFO : Current training batch loss: 0.1807 in epoch 1
2024-08-16 01:22:46,490 : INFO : Current training batch loss: 0.1905 in epoch 1
2024-08-16 01:22:57,353 : INFO : Current training batch loss: 0.1172 in epoch 1
2024-08-16 01:23:08,230 : INFO : Current training batch loss: 0.2299 in epoch 1
2024-08-16 01:23:19,105 : INFO : Current training batch loss: 0.1490 in epoch 1
2024-08-16 01:23:29,977 : INFO : Current training batch loss: 0.1545 in epoch 1
2024-08-16 01:23:40,848 : INFO : Current training batch loss: 0.3942 in epoch 1
2024-08-16 01:23:51,726 : INFO : Current training batch loss: 0.1397 in epoch 1
2024-08-16 01:24:02,598 : INFO : Current training batch loss: 0.2900 in epoch 1
2024-08-16 01:24:13,478 : INFO : Current training batch loss: 0.1699 in epoch 1
2024-08-16 01:24:24,354 : INFO : Current training batch loss: 0.2411 in epoch 1
2024-08-16 01:24:35,231 : INFO : Current training batch loss: 0.3220 in epoch 1
2024-08-16 01:24:46,116 : INFO : Current training batch loss: 0.1308 in epoch 1
2024-08-16 01:24:56,990 : INFO : Current training batch loss: 0.2094 in epoch 1
2024-08-16 01:25:07,864 : INFO : Current training batch loss: 0.3624 in epoch 1
2024-08-16 01:25:18,751 : INFO : Current training batch loss: 0.1106 in epoch 1
2024-08-16 01:25:29,620 : INFO : Current training batch loss: 0.2091 in epoch 1
2024-08-16 01:25:32,039 : INFO : Epoch finished, average loss over training batches: 0.2971
2024-08-16 01:25:32,040 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:25:32,040 : INFO : Training metrics:
2024-08-16 01:25:32,040 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:25:32,354 : INFO : Accuracy: 0.8666
2024-08-16 01:25:32,354 : INFO : Precision: 0.8661
2024-08-16 01:25:32,354 : INFO : Recall: 0.8688
2024-08-16 01:25:32,354 : INFO : F1 score: 0.8674
2024-08-16 01:26:19,907 : INFO : Average loss over validation batches: 0.2049
2024-08-16 01:26:19,908 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:26:19,908 : INFO : Validation metrics:
2024-08-16 01:26:19,908 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:26:19,913 : INFO : Accuracy: 0.9221
2024-08-16 01:26:19,913 : INFO : Precision: 0.9078
2024-08-16 01:26:19,913 : INFO : Recall: 0.9370
2024-08-16 01:26:19,913 : INFO : F1 score: 0.9221
2024-08-16 01:26:19,913 : INFO : Validation metric decreased (inf --> 0.204852).  Saving model ...
2024-08-16 01:26:20,007 : INFO : Split 2 is finished, the score is: 0.9221
2024-08-16 01:26:20,007 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:26:20,007 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:26:20,007 : INFO : Starting training for split 3
2024-08-16 01:26:20,333 : INFO : Counting occurences of labels...
2024-08-16 01:26:43,348 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-16 01:26:51,134 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 01:26:51,556 : INFO : Starting epoch 1
2024-08-16 01:26:52,136 : INFO : Current training batch loss: 0.7211 in epoch 1
2024-08-16 01:27:02,977 : INFO : Current training batch loss: 0.6807 in epoch 1
2024-08-16 01:27:13,842 : INFO : Current training batch loss: 0.5766 in epoch 1
2024-08-16 01:27:24,702 : INFO : Current training batch loss: 0.3173 in epoch 1
2024-08-16 01:27:35,566 : INFO : Current training batch loss: 0.3192 in epoch 1
2024-08-16 01:27:46,433 : INFO : Current training batch loss: 0.3774 in epoch 1
2024-08-16 01:27:57,313 : INFO : Current training batch loss: 0.2005 in epoch 1
2024-08-16 01:28:08,179 : INFO : Current training batch loss: 0.3024 in epoch 1
2024-08-16 01:28:19,049 : INFO : Current training batch loss: 0.1770 in epoch 1
2024-08-16 01:28:29,933 : INFO : Current training batch loss: 0.1475 in epoch 1
2024-08-16 01:28:40,817 : INFO : Current training batch loss: 0.2571 in epoch 1
2024-08-16 01:28:51,702 : INFO : Current training batch loss: 0.2381 in epoch 1
2024-08-16 01:29:02,586 : INFO : Current training batch loss: 0.2351 in epoch 1
2024-08-16 01:29:13,473 : INFO : Current training batch loss: 0.1595 in epoch 1
2024-08-16 01:29:24,370 : INFO : Current training batch loss: 0.2416 in epoch 1
2024-08-16 01:29:35,252 : INFO : Current training batch loss: 0.1348 in epoch 1
2024-08-16 01:29:46,130 : INFO : Current training batch loss: 0.2455 in epoch 1
2024-08-16 01:29:57,006 : INFO : Current training batch loss: 0.2149 in epoch 1
2024-08-16 01:30:07,866 : INFO : Current training batch loss: 0.1190 in epoch 1
2024-08-16 01:30:18,732 : INFO : Current training batch loss: 0.2397 in epoch 1
2024-08-16 01:30:29,604 : INFO : Current training batch loss: 0.1261 in epoch 1
2024-08-16 01:30:40,473 : INFO : Current training batch loss: 0.1853 in epoch 1
2024-08-16 01:30:51,351 : INFO : Current training batch loss: 0.1390 in epoch 1
2024-08-16 01:31:02,226 : INFO : Current training batch loss: 0.2114 in epoch 1
2024-08-16 01:31:13,098 : INFO : Current training batch loss: 0.3781 in epoch 1
2024-08-16 01:31:23,977 : INFO : Current training batch loss: 0.0952 in epoch 1
2024-08-16 01:31:34,842 : INFO : Current training batch loss: 0.1792 in epoch 1
2024-08-16 01:31:45,707 : INFO : Current training batch loss: 0.3442 in epoch 1
2024-08-16 01:31:56,583 : INFO : Current training batch loss: 0.1508 in epoch 1
2024-08-16 01:32:07,464 : INFO : Current training batch loss: 0.1689 in epoch 1
2024-08-16 01:32:09,885 : INFO : Epoch finished, average loss over training batches: 0.2924
2024-08-16 01:32:09,887 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:32:09,887 : INFO : Training metrics:
2024-08-16 01:32:09,887 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:32:10,197 : INFO : Accuracy: 0.8702
2024-08-16 01:32:10,197 : INFO : Precision: 0.8698
2024-08-16 01:32:10,198 : INFO : Recall: 0.8717
2024-08-16 01:32:10,198 : INFO : F1 score: 0.8707
2024-08-16 01:32:58,033 : INFO : Average loss over validation batches: 0.2089
2024-08-16 01:32:58,034 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:32:58,034 : INFO : Validation metrics:
2024-08-16 01:32:58,034 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:32:58,039 : INFO : Accuracy: 0.9192
2024-08-16 01:32:58,039 : INFO : Precision: 0.9012
2024-08-16 01:32:58,039 : INFO : Recall: 0.9399
2024-08-16 01:32:58,039 : INFO : F1 score: 0.9202
2024-08-16 01:32:58,040 : INFO : Validation metric decreased (inf --> 0.208861).  Saving model ...
2024-08-16 01:32:58,130 : INFO : Split 3 is finished, the score is: 0.9202
2024-08-16 01:32:58,130 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:32:58,130 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:32:58,130 : INFO : Starting training for split 4
2024-08-16 01:32:58,473 : INFO : Counting occurences of labels...
2024-08-16 01:33:21,999 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-16 01:33:29,730 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 01:33:30,157 : INFO : Starting epoch 1
2024-08-16 01:33:30,736 : INFO : Current training batch loss: 0.6455 in epoch 1
2024-08-16 01:33:41,537 : INFO : Current training batch loss: 0.6715 in epoch 1
2024-08-16 01:33:52,365 : INFO : Current training batch loss: 0.5378 in epoch 1
2024-08-16 01:34:03,225 : INFO : Current training batch loss: 0.3247 in epoch 1
2024-08-16 01:34:14,104 : INFO : Current training batch loss: 0.4556 in epoch 1
2024-08-16 01:34:24,973 : INFO : Current training batch loss: 0.2347 in epoch 1
2024-08-16 01:34:35,841 : INFO : Current training batch loss: 0.2279 in epoch 1
2024-08-16 01:34:46,700 : INFO : Current training batch loss: 0.3014 in epoch 1
2024-08-16 01:34:57,568 : INFO : Current training batch loss: 0.1623 in epoch 1
2024-08-16 01:35:08,450 : INFO : Current training batch loss: 0.1729 in epoch 1
2024-08-16 01:35:19,329 : INFO : Current training batch loss: 0.2410 in epoch 1
2024-08-16 01:35:30,209 : INFO : Current training batch loss: 0.2519 in epoch 1
2024-08-16 01:35:41,089 : INFO : Current training batch loss: 0.3684 in epoch 1
2024-08-16 01:35:51,971 : INFO : Current training batch loss: 0.1519 in epoch 1
2024-08-16 01:36:02,860 : INFO : Current training batch loss: 0.2821 in epoch 1
2024-08-16 01:36:13,739 : INFO : Current training batch loss: 0.1570 in epoch 1
2024-08-16 01:36:24,621 : INFO : Current training batch loss: 0.2840 in epoch 1
2024-08-16 01:36:35,507 : INFO : Current training batch loss: 0.2274 in epoch 1
2024-08-16 01:36:46,379 : INFO : Current training batch loss: 0.0941 in epoch 1
2024-08-16 01:36:57,257 : INFO : Current training batch loss: 0.2489 in epoch 1
2024-08-16 01:37:08,137 : INFO : Current training batch loss: 0.1900 in epoch 1
2024-08-16 01:37:19,019 : INFO : Current training batch loss: 0.3001 in epoch 1
2024-08-16 01:37:29,900 : INFO : Current training batch loss: 0.2295 in epoch 1
2024-08-16 01:37:40,780 : INFO : Current training batch loss: 0.2530 in epoch 1
2024-08-16 01:37:51,666 : INFO : Current training batch loss: 0.1167 in epoch 1
2024-08-16 01:38:02,542 : INFO : Current training batch loss: 0.2401 in epoch 1
2024-08-16 01:38:13,424 : INFO : Current training batch loss: 0.3462 in epoch 1
2024-08-16 01:38:24,309 : INFO : Current training batch loss: 0.2390 in epoch 1
2024-08-16 01:38:35,189 : INFO : Current training batch loss: 0.3640 in epoch 1
2024-08-16 01:38:46,058 : INFO : Current training batch loss: 0.2428 in epoch 1
2024-08-16 01:38:48,478 : INFO : Epoch finished, average loss over training batches: 0.2836
2024-08-16 01:38:48,479 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:38:48,479 : INFO : Training metrics:
2024-08-16 01:38:48,479 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:38:48,795 : INFO : Accuracy: 0.8743
2024-08-16 01:38:48,795 : INFO : Precision: 0.8749
2024-08-16 01:38:48,795 : INFO : Recall: 0.8722
2024-08-16 01:38:48,795 : INFO : F1 score: 0.8735
2024-08-16 01:39:36,409 : INFO : Average loss over validation batches: 0.2118
2024-08-16 01:39:36,410 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:39:36,410 : INFO : Validation metrics:
2024-08-16 01:39:36,410 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:39:36,415 : INFO : Accuracy: 0.9189
2024-08-16 01:39:36,415 : INFO : Precision: 0.9207
2024-08-16 01:39:36,415 : INFO : Recall: 0.9193
2024-08-16 01:39:36,415 : INFO : F1 score: 0.9200
2024-08-16 01:39:36,415 : INFO : Validation metric decreased (inf --> 0.211770).  Saving model ...
2024-08-16 01:39:36,501 : INFO : Split 4 is finished, the score is: 0.9200
2024-08-16 01:39:36,502 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-16 01:39:36,508] Trial 7 finished with value: 0.9210164975230329 and parameters: {'n_epochs': 1, 'learning_rate': 0.0001015694145303661, 'classifier_dropout': 0.73097753921967, 'warmup_step_fraction': 0.02145618580916333, 'use_gradient_clipping': False}. Best is trial 5 with value: 0.9241835973410469.
2024-08-16 01:39:36,508 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:39:36,508 : INFO : Starting training for split 1
2024-08-16 01:39:36,828 : INFO : Counting occurences of labels...
2024-08-16 01:40:00,108 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-16 01:40:07,877 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 01:40:08,314 : INFO : Starting epoch 1
2024-08-16 01:40:08,905 : INFO : Current training batch loss: 0.6958 in epoch 1
2024-08-16 01:40:19,744 : INFO : Current training batch loss: 0.6799 in epoch 1
2024-08-16 01:40:30,609 : INFO : Current training batch loss: 0.7386 in epoch 1
2024-08-16 01:40:41,477 : INFO : Current training batch loss: 0.6463 in epoch 1
2024-08-16 01:40:52,341 : INFO : Current training batch loss: 0.6285 in epoch 1
2024-08-16 01:41:03,212 : INFO : Current training batch loss: 0.3553 in epoch 1
2024-08-16 01:41:14,083 : INFO : Current training batch loss: 0.6194 in epoch 1
2024-08-16 01:41:24,960 : INFO : Current training batch loss: 0.3827 in epoch 1
2024-08-16 01:41:35,837 : INFO : Current training batch loss: 0.4890 in epoch 1
2024-08-16 01:41:46,717 : INFO : Current training batch loss: 0.2390 in epoch 1
2024-08-16 01:41:57,604 : INFO : Current training batch loss: 0.1916 in epoch 1
2024-08-16 01:42:08,489 : INFO : Current training batch loss: 0.3047 in epoch 1
2024-08-16 01:42:19,368 : INFO : Current training batch loss: 0.1622 in epoch 1
2024-08-16 01:42:30,255 : INFO : Current training batch loss: 0.0894 in epoch 1
2024-08-16 01:42:41,154 : INFO : Current training batch loss: 0.2560 in epoch 1
2024-08-16 01:42:52,034 : INFO : Current training batch loss: 0.0545 in epoch 1
2024-08-16 01:43:02,925 : INFO : Current training batch loss: 0.3516 in epoch 1
2024-08-16 01:43:13,811 : INFO : Current training batch loss: 0.2197 in epoch 1
2024-08-16 01:43:24,697 : INFO : Current training batch loss: 0.1554 in epoch 1
2024-08-16 01:43:35,582 : INFO : Current training batch loss: 0.4392 in epoch 1
2024-08-16 01:43:46,471 : INFO : Current training batch loss: 0.2455 in epoch 1
2024-08-16 01:43:57,352 : INFO : Current training batch loss: 0.2614 in epoch 1
2024-08-16 01:44:08,246 : INFO : Current training batch loss: 0.3528 in epoch 1
2024-08-16 01:44:19,133 : INFO : Current training batch loss: 0.1827 in epoch 1
2024-08-16 01:44:30,020 : INFO : Current training batch loss: 0.2090 in epoch 1
2024-08-16 01:44:40,912 : INFO : Current training batch loss: 0.1860 in epoch 1
2024-08-16 01:44:51,791 : INFO : Current training batch loss: 0.3220 in epoch 1
2024-08-16 01:45:02,669 : INFO : Current training batch loss: 0.4225 in epoch 1
2024-08-16 01:45:13,561 : INFO : Current training batch loss: 0.1050 in epoch 1
2024-08-16 01:45:24,456 : INFO : Current training batch loss: 0.3271 in epoch 1
2024-08-16 01:45:26,881 : INFO : Epoch finished, average loss over training batches: 0.3334
2024-08-16 01:45:26,883 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:45:26,883 : INFO : Training metrics:
2024-08-16 01:45:26,883 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:45:27,190 : INFO : Accuracy: 0.8465
2024-08-16 01:45:27,191 : INFO : Precision: 0.8508
2024-08-16 01:45:27,191 : INFO : Recall: 0.8391
2024-08-16 01:45:27,191 : INFO : F1 score: 0.8449
2024-08-16 01:46:14,860 : INFO : Average loss over validation batches: 0.2188
2024-08-16 01:46:14,861 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:46:14,861 : INFO : Validation metrics:
2024-08-16 01:46:14,861 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:46:14,866 : INFO : Accuracy: 0.9150
2024-08-16 01:46:14,866 : INFO : Precision: 0.8983
2024-08-16 01:46:14,866 : INFO : Recall: 0.9379
2024-08-16 01:46:14,866 : INFO : F1 score: 0.9177
2024-08-16 01:46:14,866 : INFO : Validation metric decreased (inf --> 0.218826).  Saving model ...
2024-08-16 01:46:14,952 : INFO : Starting epoch 2
2024-08-16 01:46:23,131 : INFO : Current training batch loss: 0.2931 in epoch 2
2024-08-16 01:46:34,011 : INFO : Current training batch loss: 0.2807 in epoch 2
2024-08-16 01:46:44,895 : INFO : Current training batch loss: 0.4037 in epoch 2
2024-08-16 01:46:55,782 : INFO : Current training batch loss: 0.0983 in epoch 2
2024-08-16 01:47:06,662 : INFO : Current training batch loss: 0.3060 in epoch 2
2024-08-16 01:47:17,549 : INFO : Current training batch loss: 0.1949 in epoch 2
2024-08-16 01:47:28,428 : INFO : Current training batch loss: 0.1271 in epoch 2
2024-08-16 01:47:39,306 : INFO : Current training batch loss: 0.2051 in epoch 2
2024-08-16 01:47:50,176 : INFO : Current training batch loss: 0.1027 in epoch 2
2024-08-16 01:48:01,052 : INFO : Current training batch loss: 0.1201 in epoch 2
2024-08-16 01:48:11,939 : INFO : Current training batch loss: 0.0212 in epoch 2
2024-08-16 01:48:22,820 : INFO : Current training batch loss: 0.1422 in epoch 2
2024-08-16 01:48:33,700 : INFO : Current training batch loss: 0.0178 in epoch 2
2024-08-16 01:48:44,583 : INFO : Current training batch loss: 0.0098 in epoch 2
2024-08-16 01:48:55,456 : INFO : Current training batch loss: 0.1127 in epoch 2
2024-08-16 01:49:06,332 : INFO : Current training batch loss: 0.2960 in epoch 2
2024-08-16 01:49:17,212 : INFO : Current training batch loss: 0.1533 in epoch 2
2024-08-16 01:49:28,095 : INFO : Current training batch loss: 0.0893 in epoch 2
2024-08-16 01:49:38,982 : INFO : Current training batch loss: 0.0587 in epoch 2
2024-08-16 01:49:49,860 : INFO : Current training batch loss: 0.3482 in epoch 2
2024-08-16 01:50:00,739 : INFO : Current training batch loss: 0.0321 in epoch 2
2024-08-16 01:50:11,631 : INFO : Current training batch loss: 0.3632 in epoch 2
2024-08-16 01:50:22,507 : INFO : Current training batch loss: 0.0325 in epoch 2
2024-08-16 01:50:33,386 : INFO : Current training batch loss: 0.0219 in epoch 2
2024-08-16 01:50:44,275 : INFO : Current training batch loss: 0.1201 in epoch 2
2024-08-16 01:50:55,165 : INFO : Current training batch loss: 0.0067 in epoch 2
2024-08-16 01:51:06,040 : INFO : Current training batch loss: 0.0984 in epoch 2
2024-08-16 01:51:16,919 : INFO : Current training batch loss: 0.0296 in epoch 2
2024-08-16 01:51:27,803 : INFO : Current training batch loss: 0.0352 in epoch 2
2024-08-16 01:51:33,478 : INFO : Epoch finished, average loss over training batches: 0.1634
2024-08-16 01:51:33,480 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:51:33,480 : INFO : Training metrics:
2024-08-16 01:51:33,480 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:51:33,787 : INFO : Accuracy: 0.9419
2024-08-16 01:51:33,788 : INFO : Precision: 0.9409
2024-08-16 01:51:33,788 : INFO : Recall: 0.9425
2024-08-16 01:51:33,788 : INFO : F1 score: 0.9417
2024-08-16 01:52:21,453 : INFO : Average loss over validation batches: 0.2677
2024-08-16 01:52:21,453 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:52:21,454 : INFO : Validation metrics:
2024-08-16 01:52:21,454 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:52:21,459 : INFO : Accuracy: 0.9155
2024-08-16 01:52:21,459 : INFO : Precision: 0.9371
2024-08-16 01:52:21,459 : INFO : Recall: 0.8926
2024-08-16 01:52:21,459 : INFO : F1 score: 0.9143
2024-08-16 01:52:21,459 : INFO : EarlyStopping counter: 1 out of 3
2024-08-16 01:52:21,459 : INFO : Starting epoch 3
2024-08-16 01:52:26,388 : INFO : Current training batch loss: 0.2803 in epoch 3
2024-08-16 01:52:37,265 : INFO : Current training batch loss: 0.0925 in epoch 3
2024-08-16 01:52:48,146 : INFO : Current training batch loss: 0.1676 in epoch 3
2024-08-16 01:52:59,026 : INFO : Current training batch loss: 0.0056 in epoch 3
2024-08-16 01:53:09,919 : INFO : Current training batch loss: 0.0104 in epoch 3
2024-08-16 01:53:20,802 : INFO : Current training batch loss: 0.0091 in epoch 3
2024-08-16 01:53:31,684 : INFO : Current training batch loss: 0.0077 in epoch 3
2024-08-16 01:53:42,568 : INFO : Current training batch loss: 0.0045 in epoch 3
2024-08-16 01:53:53,446 : INFO : Current training batch loss: 0.0129 in epoch 3
2024-08-16 01:54:04,338 : INFO : Current training batch loss: 0.1439 in epoch 3
2024-08-16 01:54:15,221 : INFO : Current training batch loss: 0.0018 in epoch 3
2024-08-16 01:54:26,104 : INFO : Current training batch loss: 0.2032 in epoch 3
2024-08-16 01:54:36,987 : INFO : Current training batch loss: 0.0451 in epoch 3
2024-08-16 01:54:47,870 : INFO : Current training batch loss: 0.0034 in epoch 3
2024-08-16 01:54:58,754 : INFO : Current training batch loss: 0.0016 in epoch 3
2024-08-16 01:55:09,631 : INFO : Current training batch loss: 0.0023 in epoch 3
2024-08-16 01:55:20,519 : INFO : Current training batch loss: 0.3384 in epoch 3
2024-08-16 01:55:31,405 : INFO : Current training batch loss: 0.0244 in epoch 3
2024-08-16 01:55:42,297 : INFO : Current training batch loss: 0.0112 in epoch 3
2024-08-16 01:55:53,182 : INFO : Current training batch loss: 0.2572 in epoch 3
2024-08-16 01:56:04,077 : INFO : Current training batch loss: 0.0021 in epoch 3
2024-08-16 01:56:14,964 : INFO : Current training batch loss: 0.1348 in epoch 3
2024-08-16 01:56:25,850 : INFO : Current training batch loss: 0.0066 in epoch 3
2024-08-16 01:56:36,736 : INFO : Current training batch loss: 0.0067 in epoch 3
2024-08-16 01:56:47,619 : INFO : Current training batch loss: 0.1616 in epoch 3
2024-08-16 01:56:58,501 : INFO : Current training batch loss: 0.0089 in epoch 3
2024-08-16 01:57:09,389 : INFO : Current training batch loss: 0.0093 in epoch 3
2024-08-16 01:57:20,270 : INFO : Current training batch loss: 0.0015 in epoch 3
2024-08-16 01:57:31,153 : INFO : Current training batch loss: 0.2171 in epoch 3
2024-08-16 01:57:40,085 : INFO : Epoch finished, average loss over training batches: 0.0709
2024-08-16 01:57:40,087 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:57:40,087 : INFO : Training metrics:
2024-08-16 01:57:40,087 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:57:40,395 : INFO : Accuracy: 0.9789
2024-08-16 01:57:40,395 : INFO : Precision: 0.9789
2024-08-16 01:57:40,395 : INFO : Recall: 0.9788
2024-08-16 01:57:40,395 : INFO : F1 score: 0.9789
2024-08-16 01:58:28,092 : INFO : Average loss over validation batches: 0.3633
2024-08-16 01:58:28,092 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:58:28,092 : INFO : Validation metrics:
2024-08-16 01:58:28,092 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 01:58:28,097 : INFO : Accuracy: 0.9024
2024-08-16 01:58:28,097 : INFO : Precision: 0.8610
2024-08-16 01:58:28,097 : INFO : Recall: 0.9620
2024-08-16 01:58:28,097 : INFO : F1 score: 0.9087
2024-08-16 01:58:28,097 : INFO : EarlyStopping counter: 2 out of 3
2024-08-16 01:58:28,097 : INFO : Starting epoch 4
2024-08-16 01:58:29,777 : INFO : Current training batch loss: 0.2097 in epoch 4
2024-08-16 01:58:40,654 : INFO : Current training batch loss: 0.1568 in epoch 4
2024-08-16 01:58:51,537 : INFO : Current training batch loss: 0.0027 in epoch 4
2024-08-16 01:59:02,418 : INFO : Current training batch loss: 0.0067 in epoch 4
2024-08-16 01:59:13,311 : INFO : Current training batch loss: 0.0044 in epoch 4
2024-08-16 01:59:24,208 : INFO : Current training batch loss: 0.0241 in epoch 4
2024-08-16 01:59:35,094 : INFO : Current training batch loss: 0.1717 in epoch 4
2024-08-16 01:59:45,998 : INFO : Current training batch loss: 0.0783 in epoch 4
2024-08-16 01:59:56,877 : INFO : Current training batch loss: 0.0181 in epoch 4
2024-08-16 02:00:07,765 : INFO : Current training batch loss: 0.0055 in epoch 4
2024-08-16 02:00:18,652 : INFO : Current training batch loss: 0.0063 in epoch 4
2024-08-16 02:00:29,533 : INFO : Current training batch loss: 0.0691 in epoch 4
2024-08-16 02:00:40,414 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-16 02:00:51,297 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-16 02:01:02,185 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-16 02:01:13,065 : INFO : Current training batch loss: 0.0022 in epoch 4
2024-08-16 02:01:23,951 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-16 02:01:34,834 : INFO : Current training batch loss: 0.0899 in epoch 4
2024-08-16 02:01:45,721 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-16 02:01:56,605 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:02:07,501 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-16 02:02:18,383 : INFO : Current training batch loss: 0.0108 in epoch 4
2024-08-16 02:02:29,263 : INFO : Current training batch loss: 0.0030 in epoch 4
2024-08-16 02:02:40,139 : INFO : Current training batch loss: 0.0011 in epoch 4
2024-08-16 02:02:51,020 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:03:01,908 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:03:12,788 : INFO : Current training batch loss: 0.0017 in epoch 4
2024-08-16 02:03:23,673 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:03:34,560 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 02:03:45,459 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:03:46,803 : INFO : Epoch finished, average loss over training batches: 0.0257
2024-08-16 02:03:46,804 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:03:46,804 : INFO : Training metrics:
2024-08-16 02:03:46,804 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:03:47,112 : INFO : Accuracy: 0.9935
2024-08-16 02:03:47,112 : INFO : Precision: 0.9925
2024-08-16 02:03:47,112 : INFO : Recall: 0.9945
2024-08-16 02:03:47,112 : INFO : F1 score: 0.9935
2024-08-16 02:04:34,798 : INFO : Average loss over validation batches: 0.3703
2024-08-16 02:04:34,799 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:04:34,799 : INFO : Validation metrics:
2024-08-16 02:04:34,799 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:04:34,804 : INFO : Accuracy: 0.9218
2024-08-16 02:04:34,804 : INFO : Precision: 0.9385
2024-08-16 02:04:34,804 : INFO : Recall: 0.9043
2024-08-16 02:04:34,804 : INFO : F1 score: 0.9211
2024-08-16 02:04:34,804 : INFO : EarlyStopping counter: 3 out of 3
2024-08-16 02:04:34,804 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 02:04:35,824 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-16 02:05:22,505 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:05:22,505 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-16 02:05:22,505 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:05:22,510 : INFO : Accuracy: 0.9150
2024-08-16 02:05:22,510 : INFO : Precision: 0.8983
2024-08-16 02:05:22,510 : INFO : Recall: 0.9379
2024-08-16 02:05:22,510 : INFO : F1 score: 0.9177
2024-08-16 02:05:22,510 : INFO : Determined score from best model, ending training.
2024-08-16 02:05:22,512 : INFO : Split 1 is finished, the score is: 0.9177
2024-08-16 02:05:22,512 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:05:22,512 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:05:22,512 : INFO : Starting training for split 2
2024-08-16 02:05:22,797 : INFO : Counting occurences of labels...
2024-08-16 02:05:46,057 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-16 02:05:53,788 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 02:05:54,220 : INFO : Starting epoch 1
2024-08-16 02:05:54,801 : INFO : Current training batch loss: 0.7060 in epoch 1
2024-08-16 02:06:05,651 : INFO : Current training batch loss: 0.6792 in epoch 1
2024-08-16 02:06:16,502 : INFO : Current training batch loss: 0.6803 in epoch 1
2024-08-16 02:06:27,364 : INFO : Current training batch loss: 0.6010 in epoch 1
2024-08-16 02:06:38,237 : INFO : Current training batch loss: 0.4565 in epoch 1
2024-08-16 02:06:49,114 : INFO : Current training batch loss: 0.5912 in epoch 1
2024-08-16 02:07:00,003 : INFO : Current training batch loss: 0.3496 in epoch 1
2024-08-16 02:07:10,878 : INFO : Current training batch loss: 0.3035 in epoch 1
2024-08-16 02:07:21,756 : INFO : Current training batch loss: 0.3715 in epoch 1
2024-08-16 02:07:32,645 : INFO : Current training batch loss: 0.2536 in epoch 1
2024-08-16 02:07:43,533 : INFO : Current training batch loss: 0.3933 in epoch 1
2024-08-16 02:07:54,417 : INFO : Current training batch loss: 0.4735 in epoch 1
2024-08-16 02:08:05,294 : INFO : Current training batch loss: 0.1869 in epoch 1
2024-08-16 02:08:16,175 : INFO : Current training batch loss: 0.1968 in epoch 1
2024-08-16 02:08:27,069 : INFO : Current training batch loss: 0.2079 in epoch 1
2024-08-16 02:08:37,941 : INFO : Current training batch loss: 0.1135 in epoch 1
2024-08-16 02:08:48,828 : INFO : Current training batch loss: 0.2454 in epoch 1
2024-08-16 02:08:59,713 : INFO : Current training batch loss: 0.1147 in epoch 1
2024-08-16 02:09:10,593 : INFO : Current training batch loss: 0.1581 in epoch 1
2024-08-16 02:09:21,479 : INFO : Current training batch loss: 0.3170 in epoch 1
2024-08-16 02:09:32,367 : INFO : Current training batch loss: 0.1732 in epoch 1
2024-08-16 02:09:43,251 : INFO : Current training batch loss: 0.2376 in epoch 1
2024-08-16 02:09:54,147 : INFO : Current training batch loss: 0.3509 in epoch 1
2024-08-16 02:10:05,037 : INFO : Current training batch loss: 0.2907 in epoch 1
2024-08-16 02:10:15,929 : INFO : Current training batch loss: 0.2472 in epoch 1
2024-08-16 02:10:26,827 : INFO : Current training batch loss: 0.1687 in epoch 1
2024-08-16 02:10:37,710 : INFO : Current training batch loss: 0.2231 in epoch 1
2024-08-16 02:10:48,595 : INFO : Current training batch loss: 0.3664 in epoch 1
2024-08-16 02:10:59,492 : INFO : Current training batch loss: 0.0788 in epoch 1
2024-08-16 02:11:10,390 : INFO : Current training batch loss: 0.2221 in epoch 1
2024-08-16 02:11:12,818 : INFO : Epoch finished, average loss over training batches: 0.3487
2024-08-16 02:11:12,819 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:11:12,819 : INFO : Training metrics:
2024-08-16 02:11:12,819 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:11:13,127 : INFO : Accuracy: 0.8403
2024-08-16 02:11:13,127 : INFO : Precision: 0.8426
2024-08-16 02:11:13,127 : INFO : Recall: 0.8389
2024-08-16 02:11:13,127 : INFO : F1 score: 0.8408
2024-08-16 02:12:00,800 : INFO : Average loss over validation batches: 0.2590
2024-08-16 02:12:00,800 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:12:00,800 : INFO : Validation metrics:
2024-08-16 02:12:00,800 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:12:00,806 : INFO : Accuracy: 0.8998
2024-08-16 02:12:00,806 : INFO : Precision: 0.8537
2024-08-16 02:12:00,806 : INFO : Recall: 0.9613
2024-08-16 02:12:00,806 : INFO : F1 score: 0.9043
2024-08-16 02:12:00,806 : INFO : Validation metric decreased (inf --> 0.259008).  Saving model ...
2024-08-16 02:12:00,892 : INFO : Starting epoch 2
2024-08-16 02:12:09,064 : INFO : Current training batch loss: 0.0776 in epoch 2
2024-08-16 02:12:19,949 : INFO : Current training batch loss: 0.2741 in epoch 2
2024-08-16 02:12:30,832 : INFO : Current training batch loss: 0.1152 in epoch 2
2024-08-16 02:12:41,723 : INFO : Current training batch loss: 0.2338 in epoch 2
2024-08-16 02:12:52,616 : INFO : Current training batch loss: 0.2898 in epoch 2
2024-08-16 02:13:03,509 : INFO : Current training batch loss: 0.2245 in epoch 2
2024-08-16 02:13:14,395 : INFO : Current training batch loss: 0.1639 in epoch 2
2024-08-16 02:13:25,280 : INFO : Current training batch loss: 0.2933 in epoch 2
2024-08-16 02:13:36,166 : INFO : Current training batch loss: 0.0410 in epoch 2
2024-08-16 02:13:47,058 : INFO : Current training batch loss: 0.0663 in epoch 2
2024-08-16 02:13:57,953 : INFO : Current training batch loss: 0.1096 in epoch 2
2024-08-16 02:14:08,847 : INFO : Current training batch loss: 0.1462 in epoch 2
2024-08-16 02:14:19,737 : INFO : Current training batch loss: 0.0756 in epoch 2
2024-08-16 02:14:30,627 : INFO : Current training batch loss: 0.1403 in epoch 2
2024-08-16 02:14:41,506 : INFO : Current training batch loss: 0.1402 in epoch 2
2024-08-16 02:14:52,382 : INFO : Current training batch loss: 0.1714 in epoch 2
2024-08-16 02:15:03,263 : INFO : Current training batch loss: 0.0828 in epoch 2
2024-08-16 02:15:14,146 : INFO : Current training batch loss: 0.0104 in epoch 2
2024-08-16 02:15:25,033 : INFO : Current training batch loss: 0.0949 in epoch 2
2024-08-16 02:15:35,906 : INFO : Current training batch loss: 0.2938 in epoch 2
2024-08-16 02:15:46,782 : INFO : Current training batch loss: 0.0520 in epoch 2
2024-08-16 02:15:57,672 : INFO : Current training batch loss: 0.3286 in epoch 2
2024-08-16 02:16:08,544 : INFO : Current training batch loss: 0.0686 in epoch 2
2024-08-16 02:16:19,417 : INFO : Current training batch loss: 0.0122 in epoch 2
2024-08-16 02:16:30,300 : INFO : Current training batch loss: 0.0196 in epoch 2
2024-08-16 02:16:41,182 : INFO : Current training batch loss: 0.0097 in epoch 2
2024-08-16 02:16:52,052 : INFO : Current training batch loss: 0.0300 in epoch 2
2024-08-16 02:17:02,924 : INFO : Current training batch loss: 0.0120 in epoch 2
2024-08-16 02:17:13,802 : INFO : Current training batch loss: 0.1182 in epoch 2
2024-08-16 02:17:19,477 : INFO : Epoch finished, average loss over training batches: 0.1665
2024-08-16 02:17:19,479 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:17:19,479 : INFO : Training metrics:
2024-08-16 02:17:19,479 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:17:19,786 : INFO : Accuracy: 0.9407
2024-08-16 02:17:19,786 : INFO : Precision: 0.9404
2024-08-16 02:17:19,786 : INFO : Recall: 0.9417
2024-08-16 02:17:19,786 : INFO : F1 score: 0.9411
2024-08-16 02:18:07,398 : INFO : Average loss over validation batches: 0.2411
2024-08-16 02:18:07,399 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:18:07,399 : INFO : Validation metrics:
2024-08-16 02:18:07,399 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:18:07,405 : INFO : Accuracy: 0.9218
2024-08-16 02:18:07,405 : INFO : Precision: 0.9351
2024-08-16 02:18:07,405 : INFO : Recall: 0.9038
2024-08-16 02:18:07,405 : INFO : F1 score: 0.9192
2024-08-16 02:18:07,405 : INFO : Validation metric decreased (0.259008 --> 0.241085).  Saving model ...
2024-08-16 02:18:07,490 : INFO : Starting epoch 3
2024-08-16 02:18:12,402 : INFO : Current training batch loss: 0.2013 in epoch 3
2024-08-16 02:18:23,267 : INFO : Current training batch loss: 0.0822 in epoch 3
2024-08-16 02:18:34,136 : INFO : Current training batch loss: 0.0674 in epoch 3
2024-08-16 02:18:45,008 : INFO : Current training batch loss: 0.1233 in epoch 3
2024-08-16 02:18:55,879 : INFO : Current training batch loss: 0.1049 in epoch 3
2024-08-16 02:19:06,748 : INFO : Current training batch loss: 0.1055 in epoch 3
2024-08-16 02:19:17,626 : INFO : Current training batch loss: 0.0091 in epoch 3
2024-08-16 02:19:28,499 : INFO : Current training batch loss: 0.0035 in epoch 3
2024-08-16 02:19:39,373 : INFO : Current training batch loss: 0.1348 in epoch 3
2024-08-16 02:19:50,259 : INFO : Current training batch loss: 0.0055 in epoch 3
2024-08-16 02:20:01,142 : INFO : Current training batch loss: 0.0019 in epoch 3
2024-08-16 02:20:12,018 : INFO : Current training batch loss: 0.2677 in epoch 3
2024-08-16 02:20:22,893 : INFO : Current training batch loss: 0.1727 in epoch 3
2024-08-16 02:20:33,770 : INFO : Current training batch loss: 0.0019 in epoch 3
2024-08-16 02:20:44,650 : INFO : Current training batch loss: 0.0290 in epoch 3
2024-08-16 02:20:55,526 : INFO : Current training batch loss: 0.0270 in epoch 3
2024-08-16 02:21:06,414 : INFO : Current training batch loss: 0.3928 in epoch 3
2024-08-16 02:21:17,299 : INFO : Current training batch loss: 0.0122 in epoch 3
2024-08-16 02:21:28,191 : INFO : Current training batch loss: 0.0019 in epoch 3
2024-08-16 02:21:39,077 : INFO : Current training batch loss: 0.1053 in epoch 3
2024-08-16 02:21:49,973 : INFO : Current training batch loss: 0.0970 in epoch 3
2024-08-16 02:22:00,861 : INFO : Current training batch loss: 0.0378 in epoch 3
2024-08-16 02:22:11,749 : INFO : Current training batch loss: 0.0033 in epoch 3
2024-08-16 02:22:22,637 : INFO : Current training batch loss: 0.0065 in epoch 3
2024-08-16 02:22:33,525 : INFO : Current training batch loss: 0.1347 in epoch 3
2024-08-16 02:22:44,409 : INFO : Current training batch loss: 0.1483 in epoch 3
2024-08-16 02:22:55,300 : INFO : Current training batch loss: 0.0021 in epoch 3
2024-08-16 02:23:06,184 : INFO : Current training batch loss: 0.0025 in epoch 3
2024-08-16 02:23:17,069 : INFO : Current training batch loss: 0.1874 in epoch 3
2024-08-16 02:23:26,001 : INFO : Epoch finished, average loss over training batches: 0.0760
2024-08-16 02:23:26,003 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:23:26,003 : INFO : Training metrics:
2024-08-16 02:23:26,003 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:23:26,310 : INFO : Accuracy: 0.9771
2024-08-16 02:23:26,310 : INFO : Precision: 0.9786
2024-08-16 02:23:26,310 : INFO : Recall: 0.9758
2024-08-16 02:23:26,310 : INFO : F1 score: 0.9772
2024-08-16 02:24:13,913 : INFO : Average loss over validation batches: 0.3372
2024-08-16 02:24:13,914 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:24:13,914 : INFO : Validation metrics:
2024-08-16 02:24:13,914 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:24:13,919 : INFO : Accuracy: 0.9130
2024-08-16 02:24:13,919 : INFO : Precision: 0.8858
2024-08-16 02:24:13,919 : INFO : Recall: 0.9451
2024-08-16 02:24:13,919 : INFO : F1 score: 0.9145
2024-08-16 02:24:13,919 : INFO : EarlyStopping counter: 1 out of 3
2024-08-16 02:24:13,919 : INFO : Starting epoch 4
2024-08-16 02:24:15,585 : INFO : Current training batch loss: 0.0031 in epoch 4
2024-08-16 02:24:26,457 : INFO : Current training batch loss: 0.0025 in epoch 4
2024-08-16 02:24:37,344 : INFO : Current training batch loss: 0.0021 in epoch 4
2024-08-16 02:24:48,230 : INFO : Current training batch loss: 0.0327 in epoch 4
2024-08-16 02:24:59,113 : INFO : Current training batch loss: 0.1276 in epoch 4
2024-08-16 02:25:10,001 : INFO : Current training batch loss: 0.0034 in epoch 4
2024-08-16 02:25:20,885 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-16 02:25:31,772 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-16 02:25:42,676 : INFO : Current training batch loss: 0.1734 in epoch 4
2024-08-16 02:25:53,557 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-16 02:26:04,453 : INFO : Current training batch loss: 0.2310 in epoch 4
2024-08-16 02:26:15,339 : INFO : Current training batch loss: 0.0088 in epoch 4
2024-08-16 02:26:26,225 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:26:37,112 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 02:26:48,003 : INFO : Current training batch loss: 0.0499 in epoch 4
2024-08-16 02:26:58,890 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:27:09,776 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-16 02:27:20,662 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 02:27:31,551 : INFO : Current training batch loss: 0.0019 in epoch 4
2024-08-16 02:27:42,435 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:27:53,332 : INFO : Current training batch loss: 0.0031 in epoch 4
2024-08-16 02:28:04,217 : INFO : Current training batch loss: 0.3881 in epoch 4
2024-08-16 02:28:15,101 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 02:28:25,978 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-16 02:28:36,863 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-16 02:28:47,757 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-16 02:28:58,641 : INFO : Current training batch loss: 0.0612 in epoch 4
2024-08-16 02:29:09,532 : INFO : Current training batch loss: 0.0048 in epoch 4
2024-08-16 02:29:20,425 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-16 02:29:31,328 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 02:29:32,672 : INFO : Epoch finished, average loss over training batches: 0.0265
2024-08-16 02:29:32,674 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:29:32,674 : INFO : Training metrics:
2024-08-16 02:29:32,674 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:29:32,982 : INFO : Accuracy: 0.9933
2024-08-16 02:29:32,982 : INFO : Precision: 0.9936
2024-08-16 02:29:32,982 : INFO : Recall: 0.9931
2024-08-16 02:29:32,982 : INFO : F1 score: 0.9934
2024-08-16 02:30:20,600 : INFO : Average loss over validation batches: 0.3997
2024-08-16 02:30:20,600 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:30:20,601 : INFO : Validation metrics:
2024-08-16 02:30:20,601 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:30:20,606 : INFO : Accuracy: 0.9152
2024-08-16 02:30:20,606 : INFO : Precision: 0.8891
2024-08-16 02:30:20,606 : INFO : Recall: 0.9457
2024-08-16 02:30:20,606 : INFO : F1 score: 0.9166
2024-08-16 02:30:20,606 : INFO : EarlyStopping counter: 2 out of 3
2024-08-16 02:30:20,606 : INFO : Starting epoch 5
2024-08-16 02:30:29,859 : INFO : Current training batch loss: 0.0017 in epoch 5
2024-08-16 02:30:40,746 : INFO : Current training batch loss: 0.0011 in epoch 5
2024-08-16 02:30:51,636 : INFO : Current training batch loss: 0.0011 in epoch 5
2024-08-16 02:31:02,530 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-16 02:31:13,421 : INFO : Current training batch loss: 0.0012 in epoch 5
2024-08-16 02:31:24,316 : INFO : Current training batch loss: 0.0009 in epoch 5
2024-08-16 02:31:35,197 : INFO : Current training batch loss: 0.0007 in epoch 5
2024-08-16 02:31:46,085 : INFO : Current training batch loss: 0.0010 in epoch 5
2024-08-16 02:31:56,973 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-16 02:32:07,871 : INFO : Current training batch loss: 0.0007 in epoch 5
2024-08-16 02:32:18,761 : INFO : Current training batch loss: 0.0010 in epoch 5
2024-08-16 02:32:29,651 : INFO : Current training batch loss: 0.0006 in epoch 5
2024-08-16 02:32:40,546 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-16 02:32:51,443 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-16 02:33:02,330 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-16 02:33:13,225 : INFO : Current training batch loss: 0.0006 in epoch 5
2024-08-16 02:33:24,129 : INFO : Current training batch loss: 0.0006 in epoch 5
2024-08-16 02:33:35,031 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-16 02:33:45,922 : INFO : Current training batch loss: 0.0006 in epoch 5
2024-08-16 02:33:56,820 : INFO : Current training batch loss: 0.0013 in epoch 5
2024-08-16 02:34:07,709 : INFO : Current training batch loss: 0.0006 in epoch 5
2024-08-16 02:34:18,601 : INFO : Current training batch loss: 0.0006 in epoch 5
2024-08-16 02:34:29,486 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-16 02:34:40,378 : INFO : Current training batch loss: 0.0006 in epoch 5
2024-08-16 02:34:51,276 : INFO : Current training batch loss: 0.0007 in epoch 5
2024-08-16 02:35:02,167 : INFO : Current training batch loss: 0.0007 in epoch 5
2024-08-16 02:35:13,054 : INFO : Current training batch loss: 0.0007 in epoch 5
2024-08-16 02:35:23,944 : INFO : Current training batch loss: 0.0008 in epoch 5
2024-08-16 02:35:34,834 : INFO : Current training batch loss: 0.2141 in epoch 5
2024-08-16 02:35:39,431 : INFO : Epoch finished, average loss over training batches: 0.0088
2024-08-16 02:35:39,432 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:35:39,433 : INFO : Training metrics:
2024-08-16 02:35:39,433 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:35:39,741 : INFO : Accuracy: 0.9985
2024-08-16 02:35:39,741 : INFO : Precision: 0.9981
2024-08-16 02:35:39,741 : INFO : Recall: 0.9988
2024-08-16 02:35:39,741 : INFO : F1 score: 0.9985
2024-08-16 02:36:27,380 : INFO : Average loss over validation batches: 0.3725
2024-08-16 02:36:27,381 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:36:27,381 : INFO : Validation metrics:
2024-08-16 02:36:27,381 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:36:27,386 : INFO : Accuracy: 0.9235
2024-08-16 02:36:27,386 : INFO : Precision: 0.9202
2024-08-16 02:36:27,386 : INFO : Recall: 0.9250
2024-08-16 02:36:27,386 : INFO : F1 score: 0.9226
2024-08-16 02:36:27,386 : INFO : EarlyStopping counter: 3 out of 3
2024-08-16 02:36:27,386 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 02:36:27,893 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-16 02:37:14,228 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:37:14,228 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-16 02:37:14,228 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:37:14,233 : INFO : Accuracy: 0.9218
2024-08-16 02:37:14,233 : INFO : Precision: 0.9351
2024-08-16 02:37:14,233 : INFO : Recall: 0.9038
2024-08-16 02:37:14,233 : INFO : F1 score: 0.9192
2024-08-16 02:37:14,233 : INFO : Determined score from best model, ending training.
2024-08-16 02:37:14,235 : INFO : Split 2 is finished, the score is: 0.9192
2024-08-16 02:37:14,235 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:37:14,235 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:37:14,235 : INFO : Starting training for split 3
2024-08-16 02:37:14,509 : INFO : Counting occurences of labels...
2024-08-16 02:37:37,637 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-16 02:37:45,470 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 02:37:45,901 : INFO : Starting epoch 1
2024-08-16 02:37:46,482 : INFO : Current training batch loss: 0.7631 in epoch 1
2024-08-16 02:37:57,334 : INFO : Current training batch loss: 0.6763 in epoch 1
2024-08-16 02:38:08,180 : INFO : Current training batch loss: 0.6719 in epoch 1
2024-08-16 02:38:19,038 : INFO : Current training batch loss: 0.5933 in epoch 1
2024-08-16 02:38:29,912 : INFO : Current training batch loss: 0.4328 in epoch 1
2024-08-16 02:38:40,787 : INFO : Current training batch loss: 0.5145 in epoch 1
2024-08-16 02:38:51,672 : INFO : Current training batch loss: 0.4166 in epoch 1
2024-08-16 02:39:02,543 : INFO : Current training batch loss: 0.2880 in epoch 1
2024-08-16 02:39:13,420 : INFO : Current training batch loss: 0.2481 in epoch 1
2024-08-16 02:39:24,309 : INFO : Current training batch loss: 0.1416 in epoch 1
2024-08-16 02:39:35,198 : INFO : Current training batch loss: 0.2041 in epoch 1
2024-08-16 02:39:46,091 : INFO : Current training batch loss: 0.2357 in epoch 1
2024-08-16 02:39:56,983 : INFO : Current training batch loss: 0.5980 in epoch 1
2024-08-16 02:40:07,874 : INFO : Current training batch loss: 0.2641 in epoch 1
2024-08-16 02:40:18,769 : INFO : Current training batch loss: 0.3064 in epoch 1
2024-08-16 02:40:29,655 : INFO : Current training batch loss: 0.1922 in epoch 1
2024-08-16 02:40:40,541 : INFO : Current training batch loss: 0.2297 in epoch 1
2024-08-16 02:40:51,432 : INFO : Current training batch loss: 0.2947 in epoch 1
2024-08-16 02:41:02,307 : INFO : Current training batch loss: 0.2635 in epoch 1
2024-08-16 02:41:13,192 : INFO : Current training batch loss: 0.3235 in epoch 1
2024-08-16 02:41:24,081 : INFO : Current training batch loss: 0.1610 in epoch 1
2024-08-16 02:41:34,969 : INFO : Current training batch loss: 0.2482 in epoch 1
2024-08-16 02:41:45,865 : INFO : Current training batch loss: 0.2358 in epoch 1
2024-08-16 02:41:56,756 : INFO : Current training batch loss: 0.1851 in epoch 1
2024-08-16 02:42:07,647 : INFO : Current training batch loss: 0.2240 in epoch 1
2024-08-16 02:42:18,547 : INFO : Current training batch loss: 0.2740 in epoch 1
2024-08-16 02:42:29,432 : INFO : Current training batch loss: 0.2367 in epoch 1
2024-08-16 02:42:40,318 : INFO : Current training batch loss: 0.4284 in epoch 1
2024-08-16 02:42:51,219 : INFO : Current training batch loss: 0.0871 in epoch 1
2024-08-16 02:43:02,118 : INFO : Current training batch loss: 0.1297 in epoch 1
2024-08-16 02:43:04,547 : INFO : Epoch finished, average loss over training batches: 0.3525
2024-08-16 02:43:04,548 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:43:04,549 : INFO : Training metrics:
2024-08-16 02:43:04,549 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:43:04,877 : INFO : Accuracy: 0.8383
2024-08-16 02:43:04,877 : INFO : Precision: 0.8378
2024-08-16 02:43:04,877 : INFO : Recall: 0.8404
2024-08-16 02:43:04,877 : INFO : F1 score: 0.8391
2024-08-16 02:43:52,696 : INFO : Average loss over validation batches: 0.2182
2024-08-16 02:43:52,696 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:43:52,696 : INFO : Validation metrics:
2024-08-16 02:43:52,696 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:43:52,702 : INFO : Accuracy: 0.9146
2024-08-16 02:43:52,702 : INFO : Precision: 0.8882
2024-08-16 02:43:52,702 : INFO : Recall: 0.9467
2024-08-16 02:43:52,702 : INFO : F1 score: 0.9165
2024-08-16 02:43:52,702 : INFO : Validation metric decreased (inf --> 0.218181).  Saving model ...
2024-08-16 02:43:52,789 : INFO : Starting epoch 2
2024-08-16 02:44:00,955 : INFO : Current training batch loss: 0.0815 in epoch 2
2024-08-16 02:44:11,833 : INFO : Current training batch loss: 0.3297 in epoch 2
2024-08-16 02:44:22,706 : INFO : Current training batch loss: 0.1089 in epoch 2
2024-08-16 02:44:33,587 : INFO : Current training batch loss: 0.1220 in epoch 2
2024-08-16 02:44:44,472 : INFO : Current training batch loss: 0.5397 in epoch 2
2024-08-16 02:44:55,362 : INFO : Current training batch loss: 0.4110 in epoch 2
2024-08-16 02:45:06,244 : INFO : Current training batch loss: 0.2017 in epoch 2
2024-08-16 02:45:17,120 : INFO : Current training batch loss: 0.3318 in epoch 2
2024-08-16 02:45:27,997 : INFO : Current training batch loss: 0.1363 in epoch 2
2024-08-16 02:45:38,881 : INFO : Current training batch loss: 0.0683 in epoch 2
2024-08-16 02:45:49,775 : INFO : Current training batch loss: 0.1432 in epoch 2
2024-08-16 02:46:00,656 : INFO : Current training batch loss: 0.2315 in epoch 2
2024-08-16 02:46:11,538 : INFO : Current training batch loss: 0.0249 in epoch 2
2024-08-16 02:46:22,420 : INFO : Current training batch loss: 0.0620 in epoch 2
2024-08-16 02:46:33,301 : INFO : Current training batch loss: 0.0596 in epoch 2
2024-08-16 02:46:44,193 : INFO : Current training batch loss: 0.1301 in epoch 2
2024-08-16 02:46:55,074 : INFO : Current training batch loss: 0.1096 in epoch 2
2024-08-16 02:47:05,957 : INFO : Current training batch loss: 0.3220 in epoch 2
2024-08-16 02:47:16,842 : INFO : Current training batch loss: 0.1154 in epoch 2
2024-08-16 02:47:27,733 : INFO : Current training batch loss: 0.2337 in epoch 2
2024-08-16 02:47:38,620 : INFO : Current training batch loss: 0.0725 in epoch 2
2024-08-16 02:47:49,517 : INFO : Current training batch loss: 0.2096 in epoch 2
2024-08-16 02:48:00,402 : INFO : Current training batch loss: 0.0297 in epoch 2
2024-08-16 02:48:11,289 : INFO : Current training batch loss: 0.0306 in epoch 2
2024-08-16 02:48:22,182 : INFO : Current training batch loss: 0.0791 in epoch 2
2024-08-16 02:48:33,077 : INFO : Current training batch loss: 0.0904 in epoch 2
2024-08-16 02:48:43,958 : INFO : Current training batch loss: 0.0436 in epoch 2
2024-08-16 02:48:54,846 : INFO : Current training batch loss: 0.0199 in epoch 2
2024-08-16 02:49:05,734 : INFO : Current training batch loss: 0.0143 in epoch 2
2024-08-16 02:49:11,415 : INFO : Epoch finished, average loss over training batches: 0.1706
2024-08-16 02:49:11,417 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:49:11,417 : INFO : Training metrics:
2024-08-16 02:49:11,417 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:49:11,727 : INFO : Accuracy: 0.9390
2024-08-16 02:49:11,727 : INFO : Precision: 0.9386
2024-08-16 02:49:11,727 : INFO : Recall: 0.9398
2024-08-16 02:49:11,727 : INFO : F1 score: 0.9392
2024-08-16 02:49:59,573 : INFO : Average loss over validation batches: 0.2467
2024-08-16 02:49:59,574 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:49:59,574 : INFO : Validation metrics:
2024-08-16 02:49:59,574 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:49:59,579 : INFO : Accuracy: 0.9218
2024-08-16 02:49:59,579 : INFO : Precision: 0.9166
2024-08-16 02:49:59,579 : INFO : Recall: 0.9264
2024-08-16 02:49:59,579 : INFO : F1 score: 0.9214
2024-08-16 02:49:59,579 : INFO : EarlyStopping counter: 1 out of 3
2024-08-16 02:49:59,579 : INFO : Starting epoch 3
2024-08-16 02:50:04,499 : INFO : Current training batch loss: 0.1891 in epoch 3
2024-08-16 02:50:15,383 : INFO : Current training batch loss: 0.0275 in epoch 3
2024-08-16 02:50:26,275 : INFO : Current training batch loss: 0.1692 in epoch 3
2024-08-16 02:50:37,169 : INFO : Current training batch loss: 0.1651 in epoch 3
2024-08-16 02:50:48,057 : INFO : Current training batch loss: 0.0388 in epoch 3
2024-08-16 02:50:58,945 : INFO : Current training batch loss: 0.0232 in epoch 3
2024-08-16 02:51:09,839 : INFO : Current training batch loss: 0.0183 in epoch 3
2024-08-16 02:51:20,730 : INFO : Current training batch loss: 0.0054 in epoch 3
2024-08-16 02:51:31,616 : INFO : Current training batch loss: 0.0666 in epoch 3
2024-08-16 02:51:42,518 : INFO : Current training batch loss: 0.0100 in epoch 3
2024-08-16 02:51:53,413 : INFO : Current training batch loss: 0.0026 in epoch 3
2024-08-16 02:52:04,302 : INFO : Current training batch loss: 0.0053 in epoch 3
2024-08-16 02:52:15,188 : INFO : Current training batch loss: 0.0878 in epoch 3
2024-08-16 02:52:26,075 : INFO : Current training batch loss: 0.4120 in epoch 3
2024-08-16 02:52:36,972 : INFO : Current training batch loss: 0.0016 in epoch 3
2024-08-16 02:52:47,864 : INFO : Current training batch loss: 0.2753 in epoch 3
2024-08-16 02:52:58,765 : INFO : Current training batch loss: 0.1452 in epoch 3
2024-08-16 02:53:09,658 : INFO : Current training batch loss: 0.0209 in epoch 3
2024-08-16 02:53:20,550 : INFO : Current training batch loss: 0.0052 in epoch 3
2024-08-16 02:53:31,437 : INFO : Current training batch loss: 0.0014 in epoch 3
2024-08-16 02:53:42,334 : INFO : Current training batch loss: 0.0024 in epoch 3
2024-08-16 02:53:53,223 : INFO : Current training batch loss: 0.1629 in epoch 3
2024-08-16 02:54:04,115 : INFO : Current training batch loss: 0.0507 in epoch 3
2024-08-16 02:54:15,007 : INFO : Current training batch loss: 0.0047 in epoch 3
2024-08-16 02:54:25,895 : INFO : Current training batch loss: 0.0305 in epoch 3
2024-08-16 02:54:36,783 : INFO : Current training batch loss: 0.0523 in epoch 3
2024-08-16 02:54:47,678 : INFO : Current training batch loss: 0.1503 in epoch 3
2024-08-16 02:54:58,563 : INFO : Current training batch loss: 0.0014 in epoch 3
2024-08-16 02:55:09,452 : INFO : Current training batch loss: 0.4614 in epoch 3
2024-08-16 02:55:18,387 : INFO : Epoch finished, average loss over training batches: 0.0769
2024-08-16 02:55:18,389 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:55:18,389 : INFO : Training metrics:
2024-08-16 02:55:18,389 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:55:18,699 : INFO : Accuracy: 0.9767
2024-08-16 02:55:18,699 : INFO : Precision: 0.9760
2024-08-16 02:55:18,699 : INFO : Recall: 0.9777
2024-08-16 02:55:18,699 : INFO : F1 score: 0.9768
2024-08-16 02:56:06,561 : INFO : Average loss over validation batches: 0.2908
2024-08-16 02:56:06,561 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:56:06,562 : INFO : Validation metrics:
2024-08-16 02:56:06,562 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 02:56:06,567 : INFO : Accuracy: 0.9243
2024-08-16 02:56:06,567 : INFO : Precision: 0.9282
2024-08-16 02:56:06,567 : INFO : Recall: 0.9183
2024-08-16 02:56:06,567 : INFO : F1 score: 0.9232
2024-08-16 02:56:06,567 : INFO : EarlyStopping counter: 2 out of 3
2024-08-16 02:56:06,567 : INFO : Starting epoch 4
2024-08-16 02:56:08,235 : INFO : Current training batch loss: 0.0030 in epoch 4
2024-08-16 02:56:19,115 : INFO : Current training batch loss: 0.0699 in epoch 4
2024-08-16 02:56:30,002 : INFO : Current training batch loss: 0.0018 in epoch 4
2024-08-16 02:56:40,889 : INFO : Current training batch loss: 0.0867 in epoch 4
2024-08-16 02:56:51,774 : INFO : Current training batch loss: 0.0086 in epoch 4
2024-08-16 02:57:02,664 : INFO : Current training batch loss: 0.0017 in epoch 4
2024-08-16 02:57:13,554 : INFO : Current training batch loss: 0.0071 in epoch 4
2024-08-16 02:57:24,444 : INFO : Current training batch loss: 0.0637 in epoch 4
2024-08-16 02:57:35,351 : INFO : Current training batch loss: 0.0035 in epoch 4
2024-08-16 02:57:46,236 : INFO : Current training batch loss: 0.0022 in epoch 4
2024-08-16 02:57:57,135 : INFO : Current training batch loss: 0.0114 in epoch 4
2024-08-16 02:58:08,027 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-16 02:58:18,929 : INFO : Current training batch loss: 0.0023 in epoch 4
2024-08-16 02:58:29,824 : INFO : Current training batch loss: 0.0017 in epoch 4
2024-08-16 02:58:40,712 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 02:58:51,603 : INFO : Current training batch loss: 0.0012 in epoch 4
2024-08-16 02:59:02,503 : INFO : Current training batch loss: 0.0010 in epoch 4
2024-08-16 02:59:13,394 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-16 02:59:24,282 : INFO : Current training batch loss: 0.0372 in epoch 4
2024-08-16 02:59:35,173 : INFO : Current training batch loss: 0.0006 in epoch 4
2024-08-16 02:59:46,069 : INFO : Current training batch loss: 0.0234 in epoch 4
2024-08-16 02:59:56,958 : INFO : Current training batch loss: 0.4379 in epoch 4
2024-08-16 03:00:07,846 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-16 03:00:18,729 : INFO : Current training batch loss: 0.0071 in epoch 4
2024-08-16 03:00:29,615 : INFO : Current training batch loss: 0.0019 in epoch 4
2024-08-16 03:00:40,509 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 03:00:51,397 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-16 03:01:02,289 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 03:01:13,181 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 03:01:24,083 : INFO : Current training batch loss: 0.0210 in epoch 4
2024-08-16 03:01:25,427 : INFO : Epoch finished, average loss over training batches: 0.0300
2024-08-16 03:01:25,429 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:01:25,429 : INFO : Training metrics:
2024-08-16 03:01:25,429 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:01:25,739 : INFO : Accuracy: 0.9921
2024-08-16 03:01:25,740 : INFO : Precision: 0.9922
2024-08-16 03:01:25,740 : INFO : Recall: 0.9920
2024-08-16 03:01:25,740 : INFO : F1 score: 0.9921
2024-08-16 03:02:13,593 : INFO : Average loss over validation batches: 0.3168
2024-08-16 03:02:13,594 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:02:13,594 : INFO : Validation metrics:
2024-08-16 03:02:13,594 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:02:13,599 : INFO : Accuracy: 0.9251
2024-08-16 03:02:13,599 : INFO : Precision: 0.9418
2024-08-16 03:02:13,599 : INFO : Recall: 0.9047
2024-08-16 03:02:13,600 : INFO : F1 score: 0.9229
2024-08-16 03:02:13,600 : INFO : EarlyStopping counter: 3 out of 3
2024-08-16 03:02:13,600 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 03:02:14,189 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-16 03:03:00,993 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:03:00,994 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-16 03:03:00,994 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:03:00,999 : INFO : Accuracy: 0.9146
2024-08-16 03:03:00,999 : INFO : Precision: 0.8882
2024-08-16 03:03:00,999 : INFO : Recall: 0.9467
2024-08-16 03:03:00,999 : INFO : F1 score: 0.9165
2024-08-16 03:03:00,999 : INFO : Determined score from best model, ending training.
2024-08-16 03:03:01,001 : INFO : Split 3 is finished, the score is: 0.9165
2024-08-16 03:03:01,001 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:03:01,004 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:03:01,004 : INFO : Starting training for split 4
2024-08-16 03:03:01,276 : INFO : Counting occurences of labels...
2024-08-16 03:03:24,473 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-16 03:03:32,121 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 03:03:32,576 : INFO : Starting epoch 1
2024-08-16 03:03:33,156 : INFO : Current training batch loss: 0.6896 in epoch 1
2024-08-16 03:03:44,005 : INFO : Current training batch loss: 0.6953 in epoch 1
2024-08-16 03:03:54,853 : INFO : Current training batch loss: 0.6816 in epoch 1
2024-08-16 03:04:05,718 : INFO : Current training batch loss: 0.6906 in epoch 1
2024-08-16 03:04:16,593 : INFO : Current training batch loss: 0.5825 in epoch 1
2024-08-16 03:04:27,471 : INFO : Current training batch loss: 0.4857 in epoch 1
2024-08-16 03:04:38,356 : INFO : Current training batch loss: 0.3231 in epoch 1
2024-08-16 03:04:49,229 : INFO : Current training batch loss: 0.4433 in epoch 1
2024-08-16 03:05:00,108 : INFO : Current training batch loss: 0.2722 in epoch 1
2024-08-16 03:05:10,998 : INFO : Current training batch loss: 0.2088 in epoch 1
2024-08-16 03:05:21,888 : INFO : Current training batch loss: 0.2360 in epoch 1
2024-08-16 03:05:32,778 : INFO : Current training batch loss: 0.2625 in epoch 1
2024-08-16 03:05:43,670 : INFO : Current training batch loss: 0.5290 in epoch 1
2024-08-16 03:05:54,558 : INFO : Current training batch loss: 0.2337 in epoch 1
2024-08-16 03:06:05,454 : INFO : Current training batch loss: 0.3102 in epoch 1
2024-08-16 03:06:16,342 : INFO : Current training batch loss: 0.2422 in epoch 1
2024-08-16 03:06:27,229 : INFO : Current training batch loss: 0.2874 in epoch 1
2024-08-16 03:06:38,119 : INFO : Current training batch loss: 0.2838 in epoch 1
2024-08-16 03:06:48,993 : INFO : Current training batch loss: 0.2604 in epoch 1
2024-08-16 03:06:59,873 : INFO : Current training batch loss: 0.3427 in epoch 1
2024-08-16 03:07:10,757 : INFO : Current training batch loss: 0.4151 in epoch 1
2024-08-16 03:07:21,636 : INFO : Current training batch loss: 0.3747 in epoch 1
2024-08-16 03:07:32,517 : INFO : Current training batch loss: 0.2420 in epoch 1
2024-08-16 03:07:43,394 : INFO : Current training batch loss: 0.3654 in epoch 1
2024-08-16 03:07:54,282 : INFO : Current training batch loss: 0.1971 in epoch 1
2024-08-16 03:08:05,160 : INFO : Current training batch loss: 0.2327 in epoch 1
2024-08-16 03:08:16,046 : INFO : Current training batch loss: 0.3744 in epoch 1
2024-08-16 03:08:26,935 : INFO : Current training batch loss: 0.3524 in epoch 1
2024-08-16 03:08:37,829 : INFO : Current training batch loss: 0.3820 in epoch 1
2024-08-16 03:08:48,710 : INFO : Current training batch loss: 0.2962 in epoch 1
2024-08-16 03:08:51,138 : INFO : Epoch finished, average loss over training batches: 0.3520
2024-08-16 03:08:51,140 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:08:51,140 : INFO : Training metrics:
2024-08-16 03:08:51,140 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:08:51,487 : INFO : Accuracy: 0.8315
2024-08-16 03:08:51,487 : INFO : Precision: 0.8331
2024-08-16 03:08:51,487 : INFO : Recall: 0.8269
2024-08-16 03:08:51,487 : INFO : F1 score: 0.8300
2024-08-16 03:09:39,181 : INFO : Average loss over validation batches: 0.2215
2024-08-16 03:09:39,181 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:09:39,181 : INFO : Validation metrics:
2024-08-16 03:09:39,181 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:09:39,186 : INFO : Accuracy: 0.9147
2024-08-16 03:09:39,186 : INFO : Precision: 0.9190
2024-08-16 03:09:39,186 : INFO : Recall: 0.9123
2024-08-16 03:09:39,186 : INFO : F1 score: 0.9157
2024-08-16 03:09:39,186 : INFO : Validation metric decreased (inf --> 0.221458).  Saving model ...
2024-08-16 03:09:39,272 : INFO : Starting epoch 2
2024-08-16 03:09:47,444 : INFO : Current training batch loss: 0.0817 in epoch 2
2024-08-16 03:09:58,330 : INFO : Current training batch loss: 0.2476 in epoch 2
2024-08-16 03:10:09,205 : INFO : Current training batch loss: 0.1470 in epoch 2
2024-08-16 03:10:20,091 : INFO : Current training batch loss: 0.1301 in epoch 2
2024-08-16 03:10:30,982 : INFO : Current training batch loss: 0.1400 in epoch 2
2024-08-16 03:10:41,874 : INFO : Current training batch loss: 0.2581 in epoch 2
2024-08-16 03:10:52,757 : INFO : Current training batch loss: 0.1023 in epoch 2
2024-08-16 03:11:03,634 : INFO : Current training batch loss: 0.2088 in epoch 2
2024-08-16 03:11:14,509 : INFO : Current training batch loss: 0.2210 in epoch 2
2024-08-16 03:11:25,391 : INFO : Current training batch loss: 0.1521 in epoch 2
2024-08-16 03:11:36,285 : INFO : Current training batch loss: 0.1530 in epoch 2
2024-08-16 03:11:47,168 : INFO : Current training batch loss: 0.2628 in epoch 2
2024-08-16 03:11:58,051 : INFO : Current training batch loss: 0.0176 in epoch 2
2024-08-16 03:12:08,936 : INFO : Current training batch loss: 0.1382 in epoch 2
2024-08-16 03:12:19,819 : INFO : Current training batch loss: 0.0985 in epoch 2
2024-08-16 03:12:30,713 : INFO : Current training batch loss: 0.0372 in epoch 2
2024-08-16 03:12:41,598 : INFO : Current training batch loss: 0.1381 in epoch 2
2024-08-16 03:12:52,479 : INFO : Current training batch loss: 0.2329 in epoch 2
2024-08-16 03:13:03,365 : INFO : Current training batch loss: 0.1682 in epoch 2
2024-08-16 03:13:14,253 : INFO : Current training batch loss: 0.0214 in epoch 2
2024-08-16 03:13:25,144 : INFO : Current training batch loss: 0.1155 in epoch 2
2024-08-16 03:13:36,028 : INFO : Current training batch loss: 0.0373 in epoch 2
2024-08-16 03:13:46,914 : INFO : Current training batch loss: 0.1193 in epoch 2
2024-08-16 03:13:57,807 : INFO : Current training batch loss: 0.0595 in epoch 2
2024-08-16 03:14:08,683 : INFO : Current training batch loss: 0.2337 in epoch 2
2024-08-16 03:14:19,568 : INFO : Current training batch loss: 0.1795 in epoch 2
2024-08-16 03:14:30,456 : INFO : Current training batch loss: 0.0629 in epoch 2
2024-08-16 03:14:41,340 : INFO : Current training batch loss: 0.0504 in epoch 2
2024-08-16 03:14:52,218 : INFO : Current training batch loss: 0.7148 in epoch 2
2024-08-16 03:14:57,914 : INFO : Epoch finished, average loss over training batches: 0.1604
2024-08-16 03:14:57,916 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:14:57,916 : INFO : Training metrics:
2024-08-16 03:14:57,916 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:14:58,226 : INFO : Accuracy: 0.9409
2024-08-16 03:14:58,226 : INFO : Precision: 0.9428
2024-08-16 03:14:58,226 : INFO : Recall: 0.9380
2024-08-16 03:14:58,226 : INFO : F1 score: 0.9404
2024-08-16 03:15:45,872 : INFO : Average loss over validation batches: 0.2642
2024-08-16 03:15:45,873 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:15:45,873 : INFO : Validation metrics:
2024-08-16 03:15:45,873 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:15:45,878 : INFO : Accuracy: 0.9107
2024-08-16 03:15:45,878 : INFO : Precision: 0.8797
2024-08-16 03:15:45,878 : INFO : Recall: 0.9546
2024-08-16 03:15:45,878 : INFO : F1 score: 0.9156
2024-08-16 03:15:45,878 : INFO : EarlyStopping counter: 1 out of 3
2024-08-16 03:15:45,878 : INFO : Starting epoch 3
2024-08-16 03:15:50,791 : INFO : Current training batch loss: 0.2119 in epoch 3
2024-08-16 03:16:01,660 : INFO : Current training batch loss: 0.0082 in epoch 3
2024-08-16 03:16:12,534 : INFO : Current training batch loss: 0.1196 in epoch 3
2024-08-16 03:16:23,410 : INFO : Current training batch loss: 0.1567 in epoch 3
2024-08-16 03:16:34,282 : INFO : Current training batch loss: 0.1336 in epoch 3
2024-08-16 03:16:45,155 : INFO : Current training batch loss: 0.0554 in epoch 3
2024-08-16 03:16:56,036 : INFO : Current training batch loss: 0.0023 in epoch 3
2024-08-16 03:17:06,917 : INFO : Current training batch loss: 0.0919 in epoch 3
2024-08-16 03:17:17,796 : INFO : Current training batch loss: 0.0031 in epoch 3
2024-08-16 03:17:28,689 : INFO : Current training batch loss: 0.0022 in epoch 3
2024-08-16 03:17:39,579 : INFO : Current training batch loss: 0.0115 in epoch 3
2024-08-16 03:17:50,463 : INFO : Current training batch loss: 0.0094 in epoch 3
2024-08-16 03:18:01,342 : INFO : Current training batch loss: 0.0086 in epoch 3
2024-08-16 03:18:12,223 : INFO : Current training batch loss: 0.3355 in epoch 3
2024-08-16 03:18:23,111 : INFO : Current training batch loss: 0.0062 in epoch 3
2024-08-16 03:18:33,992 : INFO : Current training batch loss: 0.0038 in epoch 3
2024-08-16 03:18:44,882 : INFO : Current training batch loss: 0.0580 in epoch 3
2024-08-16 03:18:55,764 : INFO : Current training batch loss: 0.0081 in epoch 3
2024-08-16 03:19:06,647 : INFO : Current training batch loss: 0.0078 in epoch 3
2024-08-16 03:19:17,529 : INFO : Current training batch loss: 0.0010 in epoch 3
2024-08-16 03:19:28,417 : INFO : Current training batch loss: 0.1199 in epoch 3
2024-08-16 03:19:39,299 : INFO : Current training batch loss: 0.2162 in epoch 3
2024-08-16 03:19:50,180 : INFO : Current training batch loss: 0.0076 in epoch 3
2024-08-16 03:20:01,051 : INFO : Current training batch loss: 0.0518 in epoch 3
2024-08-16 03:20:11,921 : INFO : Current training batch loss: 0.0019 in epoch 3
2024-08-16 03:20:22,800 : INFO : Current training batch loss: 0.0032 in epoch 3
2024-08-16 03:20:33,683 : INFO : Current training batch loss: 0.0024 in epoch 3
2024-08-16 03:20:44,582 : INFO : Current training batch loss: 0.2294 in epoch 3
2024-08-16 03:20:55,464 : INFO : Current training batch loss: 0.0015 in epoch 3
2024-08-16 03:21:04,392 : INFO : Epoch finished, average loss over training batches: 0.0705
2024-08-16 03:21:04,394 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:21:04,394 : INFO : Training metrics:
2024-08-16 03:21:04,394 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:21:04,704 : INFO : Accuracy: 0.9774
2024-08-16 03:21:04,704 : INFO : Precision: 0.9769
2024-08-16 03:21:04,704 : INFO : Recall: 0.9778
2024-08-16 03:21:04,704 : INFO : F1 score: 0.9773
2024-08-16 03:21:52,369 : INFO : Average loss over validation batches: 0.3105
2024-08-16 03:21:52,369 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:21:52,369 : INFO : Validation metrics:
2024-08-16 03:21:52,369 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:21:52,374 : INFO : Accuracy: 0.9178
2024-08-16 03:21:52,374 : INFO : Precision: 0.9354
2024-08-16 03:21:52,374 : INFO : Recall: 0.9000
2024-08-16 03:21:52,374 : INFO : F1 score: 0.9174
2024-08-16 03:21:52,374 : INFO : EarlyStopping counter: 2 out of 3
2024-08-16 03:21:52,374 : INFO : Starting epoch 4
2024-08-16 03:21:54,039 : INFO : Current training batch loss: 0.0026 in epoch 4
2024-08-16 03:22:04,899 : INFO : Current training batch loss: 0.0571 in epoch 4
2024-08-16 03:22:15,767 : INFO : Current training batch loss: 0.0019 in epoch 4
2024-08-16 03:22:26,639 : INFO : Current training batch loss: 0.0822 in epoch 4
2024-08-16 03:22:37,508 : INFO : Current training batch loss: 0.0015 in epoch 4
2024-08-16 03:22:48,384 : INFO : Current training batch loss: 0.0166 in epoch 4
2024-08-16 03:22:59,260 : INFO : Current training batch loss: 0.0023 in epoch 4
2024-08-16 03:23:10,139 : INFO : Current training batch loss: 0.0244 in epoch 4
2024-08-16 03:23:21,037 : INFO : Current training batch loss: 0.0044 in epoch 4
2024-08-16 03:23:31,915 : INFO : Current training batch loss: 0.0036 in epoch 4
2024-08-16 03:23:42,807 : INFO : Current training batch loss: 0.0020 in epoch 4
2024-08-16 03:23:53,696 : INFO : Current training batch loss: 0.0112 in epoch 4
2024-08-16 03:24:04,591 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-16 03:24:15,484 : INFO : Current training batch loss: 0.0016 in epoch 4
2024-08-16 03:24:26,370 : INFO : Current training batch loss: 0.0128 in epoch 4
2024-08-16 03:24:37,254 : INFO : Current training batch loss: 0.0013 in epoch 4
2024-08-16 03:24:48,146 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 03:24:59,030 : INFO : Current training batch loss: 0.0123 in epoch 4
2024-08-16 03:25:09,907 : INFO : Current training batch loss: 0.1234 in epoch 4
2024-08-16 03:25:20,788 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 03:25:31,673 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 03:25:42,555 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 03:25:53,440 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 03:26:04,316 : INFO : Current training batch loss: 0.0008 in epoch 4
2024-08-16 03:26:15,188 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 03:26:26,077 : INFO : Current training batch loss: 0.0009 in epoch 4
2024-08-16 03:26:36,964 : INFO : Current training batch loss: 0.0007 in epoch 4
2024-08-16 03:26:47,856 : INFO : Current training batch loss: 0.0005 in epoch 4
2024-08-16 03:26:58,748 : INFO : Current training batch loss: 0.0007 in epoch 4
2024-08-16 03:27:09,629 : INFO : Current training batch loss: 0.0005 in epoch 4
2024-08-16 03:27:10,965 : INFO : Epoch finished, average loss over training batches: 0.0229
2024-08-16 03:27:10,967 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:27:10,967 : INFO : Training metrics:
2024-08-16 03:27:10,967 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:27:11,277 : INFO : Accuracy: 0.9941
2024-08-16 03:27:11,277 : INFO : Precision: 0.9937
2024-08-16 03:27:11,277 : INFO : Recall: 0.9945
2024-08-16 03:27:11,277 : INFO : F1 score: 0.9941
2024-08-16 03:27:58,933 : INFO : Average loss over validation batches: 0.4215
2024-08-16 03:27:58,933 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:27:58,934 : INFO : Validation metrics:
2024-08-16 03:27:58,934 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:27:58,939 : INFO : Accuracy: 0.9174
2024-08-16 03:27:58,939 : INFO : Precision: 0.9474
2024-08-16 03:27:58,939 : INFO : Recall: 0.8865
2024-08-16 03:27:58,939 : INFO : F1 score: 0.9159
2024-08-16 03:27:58,939 : INFO : EarlyStopping counter: 3 out of 3
2024-08-16 03:27:58,939 : INFO : Early stopping, loading best model from before and determine score...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 03:27:59,414 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-16 03:28:46,025 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:28:46,026 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-16 03:28:46,026 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:28:46,031 : INFO : Accuracy: 0.9147
2024-08-16 03:28:46,031 : INFO : Precision: 0.9190
2024-08-16 03:28:46,031 : INFO : Recall: 0.9123
2024-08-16 03:28:46,031 : INFO : F1 score: 0.9157
2024-08-16 03:28:46,031 : INFO : Determined score from best model, ending training.
2024-08-16 03:28:46,032 : INFO : Split 4 is finished, the score is: 0.9157
2024-08-16 03:28:46,032 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-16 03:28:46,042] Trial 8 finished with value: 0.9172591989094528 and parameters: {'n_epochs': 5, 'learning_rate': 0.00010502545633304343, 'classifier_dropout': 0.1642663184774058, 'warmup_step_fraction': 0.05201442725327292, 'use_gradient_clipping': True}. Best is trial 5 with value: 0.9241835973410469.
2024-08-16 03:28:46,042 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:28:46,042 : INFO : Starting training for split 1
2024-08-16 03:28:46,311 : INFO : Counting occurences of labels...
2024-08-16 03:29:09,565 : INFO : Occurence of labels for training data: (array([0, 1]), array([9405, 9345]))
2024-08-16 03:29:17,353 : INFO : Occurence of labels for test data: (array([0, 1]), array([3095, 3155]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 03:29:17,808 : INFO : Starting epoch 1
2024-08-16 03:29:18,398 : INFO : Current training batch loss: 0.7189 in epoch 1
2024-08-16 03:29:29,206 : INFO : Current training batch loss: 0.6834 in epoch 1
2024-08-16 03:29:40,053 : INFO : Current training batch loss: 0.5910 in epoch 1
2024-08-16 03:29:50,928 : INFO : Current training batch loss: 0.5156 in epoch 1
2024-08-16 03:30:01,791 : INFO : Current training batch loss: 0.4471 in epoch 1
2024-08-16 03:30:12,652 : INFO : Current training batch loss: 0.3813 in epoch 1
2024-08-16 03:30:23,516 : INFO : Current training batch loss: 0.3437 in epoch 1
2024-08-16 03:30:34,387 : INFO : Current training batch loss: 0.3378 in epoch 1
2024-08-16 03:30:45,261 : INFO : Current training batch loss: 0.5778 in epoch 1
2024-08-16 03:30:56,138 : INFO : Current training batch loss: 0.1998 in epoch 1
2024-08-16 03:31:07,021 : INFO : Current training batch loss: 0.1728 in epoch 1
2024-08-16 03:31:17,902 : INFO : Current training batch loss: 0.3902 in epoch 1
2024-08-16 03:31:28,781 : INFO : Current training batch loss: 0.2281 in epoch 1
2024-08-16 03:31:39,664 : INFO : Current training batch loss: 0.2212 in epoch 1
2024-08-16 03:31:50,553 : INFO : Current training batch loss: 0.2885 in epoch 1
2024-08-16 03:32:01,417 : INFO : Current training batch loss: 0.1403 in epoch 1
2024-08-16 03:32:12,295 : INFO : Current training batch loss: 0.2806 in epoch 1
2024-08-16 03:32:23,169 : INFO : Current training batch loss: 0.1739 in epoch 1
2024-08-16 03:32:34,039 : INFO : Current training batch loss: 0.1698 in epoch 1
2024-08-16 03:32:44,912 : INFO : Current training batch loss: 0.6102 in epoch 1
2024-08-16 03:32:55,785 : INFO : Current training batch loss: 0.2762 in epoch 1
2024-08-16 03:33:06,655 : INFO : Current training batch loss: 0.2696 in epoch 1
2024-08-16 03:33:17,536 : INFO : Current training batch loss: 0.2960 in epoch 1
2024-08-16 03:33:28,409 : INFO : Current training batch loss: 0.1707 in epoch 1
2024-08-16 03:33:39,284 : INFO : Current training batch loss: 0.2320 in epoch 1
2024-08-16 03:33:50,163 : INFO : Current training batch loss: 0.2562 in epoch 1
2024-08-16 03:34:01,029 : INFO : Current training batch loss: 0.1905 in epoch 1
2024-08-16 03:34:11,895 : INFO : Current training batch loss: 0.4096 in epoch 1
2024-08-16 03:34:22,774 : INFO : Current training batch loss: 0.0850 in epoch 1
2024-08-16 03:34:33,653 : INFO : Current training batch loss: 0.3356 in epoch 1
2024-08-16 03:34:36,076 : INFO : Epoch finished, average loss over training batches: 0.3394
2024-08-16 03:34:36,078 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:34:36,078 : INFO : Training metrics:
2024-08-16 03:34:36,078 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:34:36,385 : INFO : Accuracy: 0.8459
2024-08-16 03:34:36,385 : INFO : Precision: 0.8445
2024-08-16 03:34:36,385 : INFO : Recall: 0.8468
2024-08-16 03:34:36,385 : INFO : F1 score: 0.8456
2024-08-16 03:35:24,057 : INFO : Average loss over validation batches: 0.2330
2024-08-16 03:35:24,058 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:35:24,058 : INFO : Validation metrics:
2024-08-16 03:35:24,058 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:35:24,063 : INFO : Accuracy: 0.9074
2024-08-16 03:35:24,063 : INFO : Precision: 0.9040
2024-08-16 03:35:24,063 : INFO : Recall: 0.9135
2024-08-16 03:35:24,063 : INFO : F1 score: 0.9087
2024-08-16 03:35:24,063 : INFO : Validation metric decreased (inf --> 0.233016).  Saving model ...
2024-08-16 03:35:24,155 : INFO : Starting epoch 2
2024-08-16 03:35:32,341 : INFO : Current training batch loss: 0.2690 in epoch 2
2024-08-16 03:35:43,227 : INFO : Current training batch loss: 0.3146 in epoch 2
2024-08-16 03:35:54,115 : INFO : Current training batch loss: 0.2618 in epoch 2
2024-08-16 03:36:05,001 : INFO : Current training batch loss: 0.0898 in epoch 2
2024-08-16 03:36:15,888 : INFO : Current training batch loss: 0.1269 in epoch 2
2024-08-16 03:36:26,783 : INFO : Current training batch loss: 0.3200 in epoch 2
2024-08-16 03:36:37,674 : INFO : Current training batch loss: 0.0800 in epoch 2
2024-08-16 03:36:48,534 : INFO : Current training batch loss: 0.1545 in epoch 2
2024-08-16 03:36:59,385 : INFO : Current training batch loss: 0.1803 in epoch 2
2024-08-16 03:37:10,239 : INFO : Current training batch loss: 0.1377 in epoch 2
2024-08-16 03:37:21,103 : INFO : Current training batch loss: 0.0483 in epoch 2
2024-08-16 03:37:31,965 : INFO : Current training batch loss: 0.1414 in epoch 2
2024-08-16 03:37:42,826 : INFO : Current training batch loss: 0.0554 in epoch 2
2024-08-16 03:37:53,692 : INFO : Current training batch loss: 0.0662 in epoch 2
2024-08-16 03:38:04,546 : INFO : Current training batch loss: 0.0995 in epoch 2
2024-08-16 03:38:15,404 : INFO : Current training batch loss: 0.2404 in epoch 2
2024-08-16 03:38:26,271 : INFO : Current training batch loss: 0.0358 in epoch 2
2024-08-16 03:38:37,139 : INFO : Current training batch loss: 0.0918 in epoch 2
2024-08-16 03:38:48,014 : INFO : Current training batch loss: 0.1175 in epoch 2
2024-08-16 03:38:58,878 : INFO : Current training batch loss: 0.2760 in epoch 2
2024-08-16 03:39:09,745 : INFO : Current training batch loss: 0.1299 in epoch 2
2024-08-16 03:39:20,628 : INFO : Current training batch loss: 0.1741 in epoch 2
2024-08-16 03:39:31,495 : INFO : Current training batch loss: 0.0714 in epoch 2
2024-08-16 03:39:42,365 : INFO : Current training batch loss: 0.0438 in epoch 2
2024-08-16 03:39:53,246 : INFO : Current training batch loss: 0.0832 in epoch 2
2024-08-16 03:40:04,125 : INFO : Current training batch loss: 0.0421 in epoch 2
2024-08-16 03:40:14,991 : INFO : Current training batch loss: 0.0346 in epoch 2
2024-08-16 03:40:25,861 : INFO : Current training batch loss: 0.0838 in epoch 2
2024-08-16 03:40:36,733 : INFO : Current training batch loss: 0.0156 in epoch 2
2024-08-16 03:40:42,403 : INFO : Epoch finished, average loss over training batches: 0.1648
2024-08-16 03:40:42,405 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:40:42,405 : INFO : Training metrics:
2024-08-16 03:40:42,405 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:40:42,712 : INFO : Accuracy: 0.9407
2024-08-16 03:40:42,712 : INFO : Precision: 0.9398
2024-08-16 03:40:42,712 : INFO : Recall: 0.9415
2024-08-16 03:40:42,712 : INFO : F1 score: 0.9406
2024-08-16 03:41:30,397 : INFO : Average loss over validation batches: 0.2406
2024-08-16 03:41:30,398 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:41:30,398 : INFO : Validation metrics:
2024-08-16 03:41:30,398 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:41:30,403 : INFO : Accuracy: 0.9203
2024-08-16 03:41:30,403 : INFO : Precision: 0.9174
2024-08-16 03:41:30,403 : INFO : Recall: 0.9255
2024-08-16 03:41:30,403 : INFO : F1 score: 0.9214
2024-08-16 03:41:30,403 : INFO : EarlyStopping counter: 1 out of 3
2024-08-16 03:41:30,403 : INFO : Starting epoch 3
2024-08-16 03:41:35,336 : INFO : Current training batch loss: 0.1207 in epoch 3
2024-08-16 03:41:46,217 : INFO : Current training batch loss: 0.2570 in epoch 3
2024-08-16 03:41:57,075 : INFO : Current training batch loss: 0.1029 in epoch 3
2024-08-16 03:42:07,936 : INFO : Current training batch loss: 0.0344 in epoch 3
2024-08-16 03:42:18,810 : INFO : Current training batch loss: 0.0213 in epoch 3
2024-08-16 03:42:29,676 : INFO : Current training batch loss: 0.0041 in epoch 3
2024-08-16 03:42:40,547 : INFO : Current training batch loss: 0.0054 in epoch 3
2024-08-16 03:42:51,419 : INFO : Current training batch loss: 0.0418 in epoch 3
2024-08-16 03:43:02,287 : INFO : Current training batch loss: 0.0635 in epoch 3
2024-08-16 03:43:13,167 : INFO : Current training batch loss: 0.1707 in epoch 3
2024-08-16 03:43:24,036 : INFO : Current training batch loss: 0.0044 in epoch 3
2024-08-16 03:43:34,907 : INFO : Current training batch loss: 0.0037 in epoch 3
2024-08-16 03:43:45,779 : INFO : Current training batch loss: 0.0047 in epoch 3
2024-08-16 03:43:56,653 : INFO : Current training batch loss: 0.0016 in epoch 3
2024-08-16 03:44:07,529 : INFO : Current training batch loss: 0.0136 in epoch 3
2024-08-16 03:44:18,400 : INFO : Current training batch loss: 0.0033 in epoch 3
2024-08-16 03:44:29,283 : INFO : Current training batch loss: 0.4215 in epoch 3
2024-08-16 03:44:40,165 : INFO : Current training batch loss: 0.0466 in epoch 3
2024-08-16 03:44:51,054 : INFO : Current training batch loss: 0.0014 in epoch 3
2024-08-16 03:45:01,935 : INFO : Current training batch loss: 0.2978 in epoch 3
2024-08-16 03:45:12,824 : INFO : Current training batch loss: 0.0024 in epoch 3
2024-08-16 03:45:23,705 : INFO : Current training batch loss: 0.0026 in epoch 3
2024-08-16 03:45:34,589 : INFO : Current training batch loss: 0.0027 in epoch 3
2024-08-16 03:45:45,472 : INFO : Current training batch loss: 0.0451 in epoch 3
2024-08-16 03:45:56,351 : INFO : Current training batch loss: 0.0140 in epoch 3
2024-08-16 03:46:07,231 : INFO : Current training batch loss: 0.0252 in epoch 3
2024-08-16 03:46:18,117 : INFO : Current training batch loss: 0.0066 in epoch 3
2024-08-16 03:46:28,997 : INFO : Current training batch loss: 0.0016 in epoch 3
2024-08-16 03:46:39,883 : INFO : Current training batch loss: 0.4196 in epoch 3
2024-08-16 03:46:48,815 : INFO : Epoch finished, average loss over training batches: 0.0594
2024-08-16 03:46:48,817 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:46:48,817 : INFO : Training metrics:
2024-08-16 03:46:48,817 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:46:49,124 : INFO : Accuracy: 0.9830
2024-08-16 03:46:49,124 : INFO : Precision: 0.9821
2024-08-16 03:46:49,124 : INFO : Recall: 0.9838
2024-08-16 03:46:49,124 : INFO : F1 score: 0.9829
2024-08-16 03:47:36,813 : INFO : Average loss over validation batches: 0.2853
2024-08-16 03:47:36,814 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:47:36,814 : INFO : Validation metrics:
2024-08-16 03:47:36,814 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:47:36,819 : INFO : Accuracy: 0.9216
2024-08-16 03:47:36,819 : INFO : Precision: 0.9385
2024-08-16 03:47:36,819 : INFO : Recall: 0.9040
2024-08-16 03:47:36,819 : INFO : F1 score: 0.9209
2024-08-16 03:47:36,819 : INFO : EarlyStopping counter: 2 out of 3
2024-08-16 03:47:36,819 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 03:47:37,452 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-16 03:48:24,279 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:48:24,279 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-16 03:48:24,279 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:48:24,288 : INFO : Accuracy: 0.9074
2024-08-16 03:48:24,288 : INFO : Precision: 0.9040
2024-08-16 03:48:24,288 : INFO : Recall: 0.9135
2024-08-16 03:48:24,288 : INFO : F1 score: 0.9087
2024-08-16 03:48:24,288 : INFO : Determined score from best model, ending training.
2024-08-16 03:48:24,290 : INFO : Split 1 is finished, the score is: 0.9087
2024-08-16 03:48:24,290 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:48:24,292 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:48:24,292 : INFO : Starting training for split 2
2024-08-16 03:48:24,587 : INFO : Counting occurences of labels...
2024-08-16 03:48:47,866 : INFO : Occurence of labels for training data: (array([0, 1]), array([9328, 9422]))
2024-08-16 03:48:55,600 : INFO : Occurence of labels for test data: (array([0, 1]), array([3172, 3078]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 03:48:56,029 : INFO : Starting epoch 1
2024-08-16 03:48:56,610 : INFO : Current training batch loss: 0.7372 in epoch 1
2024-08-16 03:49:07,460 : INFO : Current training batch loss: 0.6711 in epoch 1
2024-08-16 03:49:18,309 : INFO : Current training batch loss: 0.6019 in epoch 1
2024-08-16 03:49:29,168 : INFO : Current training batch loss: 0.3643 in epoch 1
2024-08-16 03:49:40,036 : INFO : Current training batch loss: 0.4153 in epoch 1
2024-08-16 03:49:50,908 : INFO : Current training batch loss: 0.3021 in epoch 1
2024-08-16 03:50:01,793 : INFO : Current training batch loss: 0.2437 in epoch 1
2024-08-16 03:50:12,664 : INFO : Current training batch loss: 0.3906 in epoch 1
2024-08-16 03:50:23,538 : INFO : Current training batch loss: 0.1323 in epoch 1
2024-08-16 03:50:34,424 : INFO : Current training batch loss: 0.1379 in epoch 1
2024-08-16 03:50:45,307 : INFO : Current training batch loss: 0.2968 in epoch 1
2024-08-16 03:50:56,191 : INFO : Current training batch loss: 0.4496 in epoch 1
2024-08-16 03:51:07,069 : INFO : Current training batch loss: 0.2258 in epoch 1
2024-08-16 03:51:17,950 : INFO : Current training batch loss: 0.1412 in epoch 1
2024-08-16 03:51:28,847 : INFO : Current training batch loss: 0.1747 in epoch 1
2024-08-16 03:51:39,723 : INFO : Current training batch loss: 0.1643 in epoch 1
2024-08-16 03:51:50,616 : INFO : Current training batch loss: 0.3529 in epoch 1
2024-08-16 03:52:01,505 : INFO : Current training batch loss: 0.1569 in epoch 1
2024-08-16 03:52:12,391 : INFO : Current training batch loss: 0.0999 in epoch 1
2024-08-16 03:52:23,277 : INFO : Current training batch loss: 0.3519 in epoch 1
2024-08-16 03:52:34,169 : INFO : Current training batch loss: 0.2961 in epoch 1
2024-08-16 03:52:45,055 : INFO : Current training batch loss: 0.2957 in epoch 1
2024-08-16 03:52:55,953 : INFO : Current training batch loss: 0.2117 in epoch 1
2024-08-16 03:53:06,842 : INFO : Current training batch loss: 0.1828 in epoch 1
2024-08-16 03:53:17,732 : INFO : Current training batch loss: 0.2595 in epoch 1
2024-08-16 03:53:28,628 : INFO : Current training batch loss: 0.2144 in epoch 1
2024-08-16 03:53:39,512 : INFO : Current training batch loss: 0.2515 in epoch 1
2024-08-16 03:53:50,396 : INFO : Current training batch loss: 0.5098 in epoch 1
2024-08-16 03:54:01,293 : INFO : Current training batch loss: 0.1602 in epoch 1
2024-08-16 03:54:12,193 : INFO : Current training batch loss: 0.1333 in epoch 1
2024-08-16 03:54:14,620 : INFO : Epoch finished, average loss over training batches: 0.3369
2024-08-16 03:54:14,621 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:54:14,621 : INFO : Training metrics:
2024-08-16 03:54:14,621 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:54:14,949 : INFO : Accuracy: 0.8513
2024-08-16 03:54:14,949 : INFO : Precision: 0.8499
2024-08-16 03:54:14,949 : INFO : Recall: 0.8550
2024-08-16 03:54:14,949 : INFO : F1 score: 0.8524
2024-08-16 03:55:02,587 : INFO : Average loss over validation batches: 0.2170
2024-08-16 03:55:02,587 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:55:02,587 : INFO : Validation metrics:
2024-08-16 03:55:02,587 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 03:55:02,593 : INFO : Accuracy: 0.9141
2024-08-16 03:55:02,593 : INFO : Precision: 0.8977
2024-08-16 03:55:02,593 : INFO : Recall: 0.9318
2024-08-16 03:55:02,593 : INFO : F1 score: 0.9144
2024-08-16 03:55:02,593 : INFO : Validation metric decreased (inf --> 0.217035).  Saving model ...
2024-08-16 03:55:02,679 : INFO : Starting epoch 2
2024-08-16 03:55:10,852 : INFO : Current training batch loss: 0.0985 in epoch 2
2024-08-16 03:55:21,739 : INFO : Current training batch loss: 0.2610 in epoch 2
2024-08-16 03:55:32,619 : INFO : Current training batch loss: 0.0423 in epoch 2
2024-08-16 03:55:43,507 : INFO : Current training batch loss: 0.1788 in epoch 2
2024-08-16 03:55:54,397 : INFO : Current training batch loss: 0.3011 in epoch 2
2024-08-16 03:56:05,292 : INFO : Current training batch loss: 0.2323 in epoch 2
2024-08-16 03:56:16,182 : INFO : Current training batch loss: 0.2311 in epoch 2
2024-08-16 03:56:27,067 : INFO : Current training batch loss: 0.4180 in epoch 2
2024-08-16 03:56:37,950 : INFO : Current training batch loss: 0.1584 in epoch 2
2024-08-16 03:56:48,840 : INFO : Current training batch loss: 0.0666 in epoch 2
2024-08-16 03:56:59,736 : INFO : Current training batch loss: 0.1096 in epoch 2
2024-08-16 03:57:10,628 : INFO : Current training batch loss: 0.1439 in epoch 2
2024-08-16 03:57:21,516 : INFO : Current training batch loss: 0.0253 in epoch 2
2024-08-16 03:57:32,409 : INFO : Current training batch loss: 0.0318 in epoch 2
2024-08-16 03:57:43,293 : INFO : Current training batch loss: 0.1467 in epoch 2
2024-08-16 03:57:54,177 : INFO : Current training batch loss: 0.3101 in epoch 2
2024-08-16 03:58:05,064 : INFO : Current training batch loss: 0.1413 in epoch 2
2024-08-16 03:58:15,954 : INFO : Current training batch loss: 0.0339 in epoch 2
2024-08-16 03:58:26,849 : INFO : Current training batch loss: 0.0608 in epoch 2
2024-08-16 03:58:37,733 : INFO : Current training batch loss: 0.4171 in epoch 2
2024-08-16 03:58:48,621 : INFO : Current training batch loss: 0.0785 in epoch 2
2024-08-16 03:58:59,522 : INFO : Current training batch loss: 0.1775 in epoch 2
2024-08-16 03:59:10,410 : INFO : Current training batch loss: 0.0135 in epoch 2
2024-08-16 03:59:21,302 : INFO : Current training batch loss: 0.0492 in epoch 2
2024-08-16 03:59:32,203 : INFO : Current training batch loss: 0.1733 in epoch 2
2024-08-16 03:59:43,103 : INFO : Current training batch loss: 0.0448 in epoch 2
2024-08-16 03:59:53,986 : INFO : Current training batch loss: 0.0339 in epoch 2
2024-08-16 04:00:04,878 : INFO : Current training batch loss: 0.0569 in epoch 2
2024-08-16 04:00:15,774 : INFO : Current training batch loss: 0.0178 in epoch 2
2024-08-16 04:00:21,457 : INFO : Epoch finished, average loss over training batches: 0.1666
2024-08-16 04:00:21,459 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:00:21,459 : INFO : Training metrics:
2024-08-16 04:00:21,459 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:00:21,767 : INFO : Accuracy: 0.9399
2024-08-16 04:00:21,767 : INFO : Precision: 0.9414
2024-08-16 04:00:21,767 : INFO : Recall: 0.9389
2024-08-16 04:00:21,767 : INFO : F1 score: 0.9401
2024-08-16 04:01:09,411 : INFO : Average loss over validation batches: 0.2228
2024-08-16 04:01:09,412 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:01:09,412 : INFO : Validation metrics:
2024-08-16 04:01:09,412 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:01:09,417 : INFO : Accuracy: 0.9242
2024-08-16 04:01:09,417 : INFO : Precision: 0.9225
2024-08-16 04:01:09,417 : INFO : Recall: 0.9237
2024-08-16 04:01:09,417 : INFO : F1 score: 0.9231
2024-08-16 04:01:09,418 : INFO : EarlyStopping counter: 1 out of 3
2024-08-16 04:01:09,418 : INFO : Starting epoch 3
2024-08-16 04:01:14,337 : INFO : Current training batch loss: 0.2694 in epoch 3
2024-08-16 04:01:25,218 : INFO : Current training batch loss: 0.0155 in epoch 3
2024-08-16 04:01:36,106 : INFO : Current training batch loss: 0.1122 in epoch 3
2024-08-16 04:01:46,995 : INFO : Current training batch loss: 0.1722 in epoch 3
2024-08-16 04:01:57,876 : INFO : Current training batch loss: 0.0102 in epoch 3
2024-08-16 04:02:08,761 : INFO : Current training batch loss: 0.1899 in epoch 3
2024-08-16 04:02:19,654 : INFO : Current training batch loss: 0.0079 in epoch 3
2024-08-16 04:02:30,545 : INFO : Current training batch loss: 0.0054 in epoch 3
2024-08-16 04:02:41,431 : INFO : Current training batch loss: 0.0931 in epoch 3
2024-08-16 04:02:52,331 : INFO : Current training batch loss: 0.0057 in epoch 3
2024-08-16 04:03:03,227 : INFO : Current training batch loss: 0.0097 in epoch 3
2024-08-16 04:03:14,112 : INFO : Current training batch loss: 0.0063 in epoch 3
2024-08-16 04:03:24,997 : INFO : Current training batch loss: 0.0215 in epoch 3
2024-08-16 04:03:35,885 : INFO : Current training batch loss: 0.0013 in epoch 3
2024-08-16 04:03:46,772 : INFO : Current training batch loss: 0.0021 in epoch 3
2024-08-16 04:03:57,655 : INFO : Current training batch loss: 0.0752 in epoch 3
2024-08-16 04:04:08,549 : INFO : Current training batch loss: 0.4063 in epoch 3
2024-08-16 04:04:19,439 : INFO : Current training batch loss: 0.0041 in epoch 3
2024-08-16 04:04:30,338 : INFO : Current training batch loss: 0.0031 in epoch 3
2024-08-16 04:04:41,229 : INFO : Current training batch loss: 0.1920 in epoch 3
2024-08-16 04:04:52,127 : INFO : Current training batch loss: 0.0022 in epoch 3
2024-08-16 04:05:03,019 : INFO : Current training batch loss: 0.1163 in epoch 3
2024-08-16 04:05:13,911 : INFO : Current training batch loss: 0.0049 in epoch 3
2024-08-16 04:05:24,804 : INFO : Current training batch loss: 0.0033 in epoch 3
2024-08-16 04:05:35,690 : INFO : Current training batch loss: 0.0223 in epoch 3
2024-08-16 04:05:46,577 : INFO : Current training batch loss: 0.0025 in epoch 3
2024-08-16 04:05:57,466 : INFO : Current training batch loss: 0.1068 in epoch 3
2024-08-16 04:06:08,349 : INFO : Current training batch loss: 0.0017 in epoch 3
2024-08-16 04:06:19,238 : INFO : Current training batch loss: 0.3483 in epoch 3
2024-08-16 04:06:28,171 : INFO : Epoch finished, average loss over training batches: 0.0588
2024-08-16 04:06:28,172 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:06:28,172 : INFO : Training metrics:
2024-08-16 04:06:28,172 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:06:28,480 : INFO : Accuracy: 0.9815
2024-08-16 04:06:28,480 : INFO : Precision: 0.9810
2024-08-16 04:06:28,480 : INFO : Recall: 0.9823
2024-08-16 04:06:28,480 : INFO : F1 score: 0.9817
2024-08-16 04:07:16,140 : INFO : Average loss over validation batches: 0.2868
2024-08-16 04:07:16,141 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:07:16,141 : INFO : Validation metrics:
2024-08-16 04:07:16,141 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:07:16,146 : INFO : Accuracy: 0.9251
2024-08-16 04:07:16,146 : INFO : Precision: 0.9237
2024-08-16 04:07:16,146 : INFO : Recall: 0.9243
2024-08-16 04:07:16,146 : INFO : F1 score: 0.9240
2024-08-16 04:07:16,147 : INFO : EarlyStopping counter: 2 out of 3
2024-08-16 04:07:16,147 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 04:07:16,626 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-16 04:08:03,436 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:08:03,436 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-16 04:08:03,436 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:08:03,446 : INFO : Accuracy: 0.9141
2024-08-16 04:08:03,446 : INFO : Precision: 0.8977
2024-08-16 04:08:03,446 : INFO : Recall: 0.9318
2024-08-16 04:08:03,446 : INFO : F1 score: 0.9144
2024-08-16 04:08:03,446 : INFO : Determined score from best model, ending training.
2024-08-16 04:08:03,447 : INFO : Split 2 is finished, the score is: 0.9144
2024-08-16 04:08:03,447 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:08:03,448 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:08:03,448 : INFO : Starting training for split 3
2024-08-16 04:08:03,787 : INFO : Counting occurences of labels...
2024-08-16 04:08:26,861 : INFO : Occurence of labels for training data: (array([0, 1]), array([9346, 9404]))
2024-08-16 04:08:34,695 : INFO : Occurence of labels for test data: (array([0, 1]), array([3154, 3096]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 04:08:35,122 : INFO : Starting epoch 1
2024-08-16 04:08:35,704 : INFO : Current training batch loss: 0.7074 in epoch 1
2024-08-16 04:08:46,559 : INFO : Current training batch loss: 0.6865 in epoch 1
2024-08-16 04:08:57,432 : INFO : Current training batch loss: 0.5622 in epoch 1
2024-08-16 04:09:08,294 : INFO : Current training batch loss: 0.3508 in epoch 1
2024-08-16 04:09:19,168 : INFO : Current training batch loss: 0.6092 in epoch 1
2024-08-16 04:09:30,046 : INFO : Current training batch loss: 0.4537 in epoch 1
2024-08-16 04:09:40,935 : INFO : Current training batch loss: 0.2555 in epoch 1
2024-08-16 04:09:51,811 : INFO : Current training batch loss: 0.2558 in epoch 1
2024-08-16 04:10:02,691 : INFO : Current training batch loss: 0.2658 in epoch 1
2024-08-16 04:10:13,583 : INFO : Current training batch loss: 0.1450 in epoch 1
2024-08-16 04:10:24,471 : INFO : Current training batch loss: 0.3071 in epoch 1
2024-08-16 04:10:35,360 : INFO : Current training batch loss: 0.2921 in epoch 1
2024-08-16 04:10:46,248 : INFO : Current training batch loss: 0.7005 in epoch 1
2024-08-16 04:10:57,138 : INFO : Current training batch loss: 0.1699 in epoch 1
2024-08-16 04:11:08,037 : INFO : Current training batch loss: 0.3108 in epoch 1
2024-08-16 04:11:18,926 : INFO : Current training batch loss: 0.2239 in epoch 1
2024-08-16 04:11:29,815 : INFO : Current training batch loss: 0.2559 in epoch 1
2024-08-16 04:11:40,703 : INFO : Current training batch loss: 0.2731 in epoch 1
2024-08-16 04:11:51,578 : INFO : Current training batch loss: 0.2165 in epoch 1
2024-08-16 04:12:02,463 : INFO : Current training batch loss: 0.3182 in epoch 1
2024-08-16 04:12:13,355 : INFO : Current training batch loss: 0.2201 in epoch 1
2024-08-16 04:12:24,245 : INFO : Current training batch loss: 0.1662 in epoch 1
2024-08-16 04:12:35,145 : INFO : Current training batch loss: 0.3202 in epoch 1
2024-08-16 04:12:46,040 : INFO : Current training batch loss: 0.2165 in epoch 1
2024-08-16 04:12:56,934 : INFO : Current training batch loss: 0.1658 in epoch 1
2024-08-16 04:13:07,833 : INFO : Current training batch loss: 0.1728 in epoch 1
2024-08-16 04:13:18,719 : INFO : Current training batch loss: 0.2765 in epoch 1
2024-08-16 04:13:29,605 : INFO : Current training batch loss: 0.4040 in epoch 1
2024-08-16 04:13:40,505 : INFO : Current training batch loss: 0.0650 in epoch 1
2024-08-16 04:13:51,406 : INFO : Current training batch loss: 0.2458 in epoch 1
2024-08-16 04:13:53,833 : INFO : Epoch finished, average loss over training batches: 0.3432
2024-08-16 04:13:53,835 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:13:53,835 : INFO : Training metrics:
2024-08-16 04:13:53,835 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:13:54,182 : INFO : Accuracy: 0.8424
2024-08-16 04:13:54,182 : INFO : Precision: 0.8459
2024-08-16 04:13:54,182 : INFO : Recall: 0.8386
2024-08-16 04:13:54,182 : INFO : F1 score: 0.8422
2024-08-16 04:14:42,041 : INFO : Average loss over validation batches: 0.2757
2024-08-16 04:14:42,042 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:14:42,042 : INFO : Validation metrics:
2024-08-16 04:14:42,042 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:14:42,047 : INFO : Accuracy: 0.8842
2024-08-16 04:14:42,047 : INFO : Precision: 0.8410
2024-08-16 04:14:42,047 : INFO : Recall: 0.9448
2024-08-16 04:14:42,047 : INFO : F1 score: 0.8899
2024-08-16 04:14:42,047 : INFO : Validation metric decreased (inf --> 0.275668).  Saving model ...
2024-08-16 04:14:42,133 : INFO : Starting epoch 2
2024-08-16 04:14:50,301 : INFO : Current training batch loss: 0.0842 in epoch 2
2024-08-16 04:15:01,176 : INFO : Current training batch loss: 0.2368 in epoch 2
2024-08-16 04:15:12,048 : INFO : Current training batch loss: 0.1244 in epoch 2
2024-08-16 04:15:22,924 : INFO : Current training batch loss: 0.1362 in epoch 2
2024-08-16 04:15:33,803 : INFO : Current training batch loss: 0.2048 in epoch 2
2024-08-16 04:15:44,686 : INFO : Current training batch loss: 0.3051 in epoch 2
2024-08-16 04:15:55,565 : INFO : Current training batch loss: 0.1958 in epoch 2
2024-08-16 04:16:06,440 : INFO : Current training batch loss: 0.3624 in epoch 2
2024-08-16 04:16:17,315 : INFO : Current training batch loss: 0.1797 in epoch 2
2024-08-16 04:16:28,199 : INFO : Current training batch loss: 0.1629 in epoch 2
2024-08-16 04:16:39,092 : INFO : Current training batch loss: 0.1131 in epoch 2
2024-08-16 04:16:49,981 : INFO : Current training batch loss: 0.3339 in epoch 2
2024-08-16 04:17:00,864 : INFO : Current training batch loss: 0.0436 in epoch 2
2024-08-16 04:17:11,745 : INFO : Current training batch loss: 0.0889 in epoch 2
2024-08-16 04:17:22,626 : INFO : Current training batch loss: 0.1032 in epoch 2
2024-08-16 04:17:33,518 : INFO : Current training batch loss: 0.0337 in epoch 2
2024-08-16 04:17:44,401 : INFO : Current training batch loss: 0.0787 in epoch 2
2024-08-16 04:17:55,280 : INFO : Current training batch loss: 0.2581 in epoch 2
2024-08-16 04:18:06,162 : INFO : Current training batch loss: 0.1845 in epoch 2
2024-08-16 04:18:17,050 : INFO : Current training batch loss: 0.4016 in epoch 2
2024-08-16 04:18:27,934 : INFO : Current training batch loss: 0.1998 in epoch 2
2024-08-16 04:18:38,833 : INFO : Current training batch loss: 0.1747 in epoch 2
2024-08-16 04:18:49,718 : INFO : Current training batch loss: 0.1338 in epoch 2
2024-08-16 04:19:00,605 : INFO : Current training batch loss: 0.0511 in epoch 2
2024-08-16 04:19:11,502 : INFO : Current training batch loss: 0.0299 in epoch 2
2024-08-16 04:19:22,398 : INFO : Current training batch loss: 0.0185 in epoch 2
2024-08-16 04:19:33,279 : INFO : Current training batch loss: 0.0064 in epoch 2
2024-08-16 04:19:44,169 : INFO : Current training batch loss: 0.0272 in epoch 2
2024-08-16 04:19:55,062 : INFO : Current training batch loss: 0.1759 in epoch 2
2024-08-16 04:20:00,743 : INFO : Epoch finished, average loss over training batches: 0.1773
2024-08-16 04:20:00,745 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:20:00,745 : INFO : Training metrics:
2024-08-16 04:20:00,745 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:20:01,055 : INFO : Accuracy: 0.9362
2024-08-16 04:20:01,055 : INFO : Precision: 0.9353
2024-08-16 04:20:01,055 : INFO : Recall: 0.9376
2024-08-16 04:20:01,055 : INFO : F1 score: 0.9364
2024-08-16 04:20:48,960 : INFO : Average loss over validation batches: 0.2495
2024-08-16 04:20:48,961 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:20:48,961 : INFO : Validation metrics:
2024-08-16 04:20:48,961 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:20:48,966 : INFO : Accuracy: 0.9122
2024-08-16 04:20:48,966 : INFO : Precision: 0.8872
2024-08-16 04:20:48,966 : INFO : Recall: 0.9425
2024-08-16 04:20:48,966 : INFO : F1 score: 0.9140
2024-08-16 04:20:48,966 : INFO : Validation metric decreased (0.275668 --> 0.249524).  Saving model ...
2024-08-16 04:20:49,053 : INFO : Starting epoch 3
2024-08-16 04:20:53,970 : INFO : Current training batch loss: 0.2867 in epoch 3
2024-08-16 04:21:04,847 : INFO : Current training batch loss: 0.0729 in epoch 3
2024-08-16 04:21:15,730 : INFO : Current training batch loss: 0.0884 in epoch 3
2024-08-16 04:21:26,616 : INFO : Current training batch loss: 0.0872 in epoch 3
2024-08-16 04:21:37,495 : INFO : Current training batch loss: 0.1230 in epoch 3
2024-08-16 04:21:48,374 : INFO : Current training batch loss: 0.1395 in epoch 3
2024-08-16 04:21:59,263 : INFO : Current training batch loss: 0.0047 in epoch 3
2024-08-16 04:22:10,150 : INFO : Current training batch loss: 0.0042 in epoch 3
2024-08-16 04:22:21,036 : INFO : Current training batch loss: 0.0599 in epoch 3
2024-08-16 04:22:31,938 : INFO : Current training batch loss: 0.0118 in epoch 3
2024-08-16 04:22:42,834 : INFO : Current training batch loss: 0.0056 in epoch 3
2024-08-16 04:22:53,719 : INFO : Current training batch loss: 0.0256 in epoch 3
2024-08-16 04:23:04,605 : INFO : Current training batch loss: 0.0085 in epoch 3
2024-08-16 04:23:15,488 : INFO : Current training batch loss: 0.3199 in epoch 3
2024-08-16 04:23:26,381 : INFO : Current training batch loss: 0.0304 in epoch 3
2024-08-16 04:23:37,268 : INFO : Current training batch loss: 0.0086 in epoch 3
2024-08-16 04:23:48,165 : INFO : Current training batch loss: 0.1895 in epoch 3
2024-08-16 04:23:59,052 : INFO : Current training batch loss: 0.0069 in epoch 3
2024-08-16 04:24:09,939 : INFO : Current training batch loss: 0.0055 in epoch 3
2024-08-16 04:24:20,828 : INFO : Current training batch loss: 0.0020 in epoch 3
2024-08-16 04:24:31,730 : INFO : Current training batch loss: 0.0075 in epoch 3
2024-08-16 04:24:42,619 : INFO : Current training batch loss: 0.0098 in epoch 3
2024-08-16 04:24:53,509 : INFO : Current training batch loss: 0.0067 in epoch 3
2024-08-16 04:25:04,393 : INFO : Current training batch loss: 0.0182 in epoch 3
2024-08-16 04:25:15,275 : INFO : Current training batch loss: 0.0300 in epoch 3
2024-08-16 04:25:26,154 : INFO : Current training batch loss: 0.0039 in epoch 3
2024-08-16 04:25:37,038 : INFO : Current training batch loss: 0.0089 in epoch 3
2024-08-16 04:25:47,913 : INFO : Current training batch loss: 0.0036 in epoch 3
2024-08-16 04:25:58,786 : INFO : Current training batch loss: 0.3921 in epoch 3
2024-08-16 04:26:07,704 : INFO : Epoch finished, average loss over training batches: 0.0734
2024-08-16 04:26:07,705 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:26:07,705 : INFO : Training metrics:
2024-08-16 04:26:07,705 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:26:08,019 : INFO : Accuracy: 0.9774
2024-08-16 04:26:08,019 : INFO : Precision: 0.9768
2024-08-16 04:26:08,019 : INFO : Recall: 0.9781
2024-08-16 04:26:08,019 : INFO : F1 score: 0.9775
2024-08-16 04:26:55,874 : INFO : Average loss over validation batches: 0.2768
2024-08-16 04:26:55,874 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:26:55,874 : INFO : Validation metrics:
2024-08-16 04:26:55,874 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:26:55,879 : INFO : Accuracy: 0.9243
2024-08-16 04:26:55,879 : INFO : Precision: 0.9248
2024-08-16 04:26:55,879 : INFO : Recall: 0.9222
2024-08-16 04:26:55,879 : INFO : F1 score: 0.9235
2024-08-16 04:26:55,879 : INFO : EarlyStopping counter: 1 out of 3
2024-08-16 04:26:55,879 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 04:26:56,368 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-16 04:27:43,381 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:27:43,381 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-16 04:27:43,381 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:27:43,386 : INFO : Accuracy: 0.9122
2024-08-16 04:27:43,386 : INFO : Precision: 0.8872
2024-08-16 04:27:43,386 : INFO : Recall: 0.9425
2024-08-16 04:27:43,386 : INFO : F1 score: 0.9140
2024-08-16 04:27:43,386 : INFO : Determined score from best model, ending training.
2024-08-16 04:27:43,391 : INFO : Split 3 is finished, the score is: 0.9140
2024-08-16 04:27:43,391 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:27:43,391 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:27:43,391 : INFO : Starting training for split 4
2024-08-16 04:27:43,666 : INFO : Counting occurences of labels...
2024-08-16 04:28:07,022 : INFO : Occurence of labels for training data: (array([0, 1]), array([9421, 9329]))
2024-08-16 04:28:14,764 : INFO : Occurence of labels for test data: (array([0, 1]), array([3079, 3171]))
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 04:28:15,214 : INFO : Starting epoch 1
2024-08-16 04:28:15,794 : INFO : Current training batch loss: 0.7026 in epoch 1
2024-08-16 04:28:26,597 : INFO : Current training batch loss: 0.6916 in epoch 1
2024-08-16 04:28:37,398 : INFO : Current training batch loss: 0.6219 in epoch 1
2024-08-16 04:28:48,226 : INFO : Current training batch loss: 0.5104 in epoch 1
2024-08-16 04:28:59,073 : INFO : Current training batch loss: 0.3925 in epoch 1
2024-08-16 04:29:09,928 : INFO : Current training batch loss: 0.3187 in epoch 1
2024-08-16 04:29:20,793 : INFO : Current training batch loss: 0.1755 in epoch 1
2024-08-16 04:29:31,644 : INFO : Current training batch loss: 0.2377 in epoch 1
2024-08-16 04:29:42,497 : INFO : Current training batch loss: 0.3578 in epoch 1
2024-08-16 04:29:53,362 : INFO : Current training batch loss: 0.1222 in epoch 1
2024-08-16 04:30:04,222 : INFO : Current training batch loss: 0.3995 in epoch 1
2024-08-16 04:30:15,086 : INFO : Current training batch loss: 0.2802 in epoch 1
2024-08-16 04:30:25,949 : INFO : Current training batch loss: 0.3191 in epoch 1
2024-08-16 04:30:36,815 : INFO : Current training batch loss: 0.2143 in epoch 1
2024-08-16 04:30:47,681 : INFO : Current training batch loss: 0.3927 in epoch 1
2024-08-16 04:30:58,539 : INFO : Current training batch loss: 0.3486 in epoch 1
2024-08-16 04:31:09,395 : INFO : Current training batch loss: 0.2911 in epoch 1
2024-08-16 04:31:20,259 : INFO : Current training batch loss: 0.2398 in epoch 1
2024-08-16 04:31:31,108 : INFO : Current training batch loss: 0.1961 in epoch 1
2024-08-16 04:31:41,964 : INFO : Current training batch loss: 0.3112 in epoch 1
2024-08-16 04:31:52,826 : INFO : Current training batch loss: 0.3406 in epoch 1
2024-08-16 04:32:03,684 : INFO : Current training batch loss: 0.4375 in epoch 1
2024-08-16 04:32:14,539 : INFO : Current training batch loss: 0.2457 in epoch 1
2024-08-16 04:32:25,391 : INFO : Current training batch loss: 0.2803 in epoch 1
2024-08-16 04:32:36,253 : INFO : Current training batch loss: 0.2223 in epoch 1
2024-08-16 04:32:47,108 : INFO : Current training batch loss: 0.2190 in epoch 1
2024-08-16 04:32:57,968 : INFO : Current training batch loss: 0.3443 in epoch 1
2024-08-16 04:33:08,833 : INFO : Current training batch loss: 0.2680 in epoch 1
2024-08-16 04:33:19,698 : INFO : Current training batch loss: 0.4345 in epoch 1
2024-08-16 04:33:30,555 : INFO : Current training batch loss: 0.3378 in epoch 1
2024-08-16 04:33:32,975 : INFO : Epoch finished, average loss over training batches: 0.3470
2024-08-16 04:33:32,976 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:33:32,976 : INFO : Training metrics:
2024-08-16 04:33:32,976 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:33:33,291 : INFO : Accuracy: 0.8429
2024-08-16 04:33:33,291 : INFO : Precision: 0.8389
2024-08-16 04:33:33,291 : INFO : Recall: 0.8470
2024-08-16 04:33:33,291 : INFO : F1 score: 0.8429
2024-08-16 04:34:20,976 : INFO : Average loss over validation batches: 0.2509
2024-08-16 04:34:20,977 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:34:20,977 : INFO : Validation metrics:
2024-08-16 04:34:20,977 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:34:20,982 : INFO : Accuracy: 0.9019
2024-08-16 04:34:20,982 : INFO : Precision: 0.9315
2024-08-16 04:34:20,982 : INFO : Recall: 0.8707
2024-08-16 04:34:20,982 : INFO : F1 score: 0.9001
2024-08-16 04:34:20,982 : INFO : Validation metric decreased (inf --> 0.250872).  Saving model ...
2024-08-16 04:34:21,073 : INFO : Starting epoch 2
2024-08-16 04:34:29,242 : INFO : Current training batch loss: 0.0833 in epoch 2
2024-08-16 04:34:40,125 : INFO : Current training batch loss: 0.3205 in epoch 2
2024-08-16 04:34:51,008 : INFO : Current training batch loss: 0.1300 in epoch 2
2024-08-16 04:35:01,901 : INFO : Current training batch loss: 0.3163 in epoch 2
2024-08-16 04:35:12,796 : INFO : Current training batch loss: 0.2341 in epoch 2
2024-08-16 04:35:23,694 : INFO : Current training batch loss: 0.2670 in epoch 2
2024-08-16 04:35:34,569 : INFO : Current training batch loss: 0.2098 in epoch 2
2024-08-16 04:35:45,425 : INFO : Current training batch loss: 0.0979 in epoch 2
2024-08-16 04:35:56,277 : INFO : Current training batch loss: 0.2499 in epoch 2
2024-08-16 04:36:07,139 : INFO : Current training batch loss: 0.2522 in epoch 2
2024-08-16 04:36:18,010 : INFO : Current training batch loss: 0.1064 in epoch 2
2024-08-16 04:36:28,872 : INFO : Current training batch loss: 0.1584 in epoch 2
2024-08-16 04:36:39,730 : INFO : Current training batch loss: 0.0952 in epoch 2
2024-08-16 04:36:50,589 : INFO : Current training batch loss: 0.1301 in epoch 2
2024-08-16 04:37:01,445 : INFO : Current training batch loss: 0.0779 in epoch 2
2024-08-16 04:37:12,314 : INFO : Current training batch loss: 0.1024 in epoch 2
2024-08-16 04:37:23,173 : INFO : Current training batch loss: 0.1248 in epoch 2
2024-08-16 04:37:34,029 : INFO : Current training batch loss: 0.3443 in epoch 2
2024-08-16 04:37:44,890 : INFO : Current training batch loss: 0.2067 in epoch 2
2024-08-16 04:37:55,756 : INFO : Current training batch loss: 0.1018 in epoch 2
2024-08-16 04:38:06,626 : INFO : Current training batch loss: 0.1205 in epoch 2
2024-08-16 04:38:17,491 : INFO : Current training batch loss: 0.0596 in epoch 2
2024-08-16 04:38:28,357 : INFO : Current training batch loss: 0.2456 in epoch 2
2024-08-16 04:38:39,232 : INFO : Current training batch loss: 0.0178 in epoch 2
2024-08-16 04:38:50,084 : INFO : Current training batch loss: 0.0173 in epoch 2
2024-08-16 04:39:00,944 : INFO : Current training batch loss: 0.0518 in epoch 2
2024-08-16 04:39:11,810 : INFO : Current training batch loss: 0.1135 in epoch 2
2024-08-16 04:39:22,673 : INFO : Current training batch loss: 0.1354 in epoch 2
2024-08-16 04:39:33,533 : INFO : Current training batch loss: 0.2804 in epoch 2
2024-08-16 04:39:39,222 : INFO : Epoch finished, average loss over training batches: 0.1637
2024-08-16 04:39:39,223 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:39:39,223 : INFO : Training metrics:
2024-08-16 04:39:39,223 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:39:39,533 : INFO : Accuracy: 0.9392
2024-08-16 04:39:39,533 : INFO : Precision: 0.9393
2024-08-16 04:39:39,533 : INFO : Recall: 0.9385
2024-08-16 04:39:39,533 : INFO : F1 score: 0.9389
2024-08-16 04:40:27,196 : INFO : Average loss over validation batches: 0.2604
2024-08-16 04:40:27,196 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:40:27,196 : INFO : Validation metrics:
2024-08-16 04:40:27,196 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:40:27,201 : INFO : Accuracy: 0.9082
2024-08-16 04:40:27,202 : INFO : Precision: 0.8818
2024-08-16 04:40:27,202 : INFO : Recall: 0.9458
2024-08-16 04:40:27,202 : INFO : F1 score: 0.9127
2024-08-16 04:40:27,202 : INFO : EarlyStopping counter: 1 out of 3
2024-08-16 04:40:27,202 : INFO : Starting epoch 3
2024-08-16 04:40:32,125 : INFO : Current training batch loss: 0.2884 in epoch 3
2024-08-16 04:40:43,011 : INFO : Current training batch loss: 0.0356 in epoch 3
2024-08-16 04:40:53,878 : INFO : Current training batch loss: 0.1277 in epoch 3
2024-08-16 04:41:04,747 : INFO : Current training batch loss: 0.0533 in epoch 3
2024-08-16 04:41:15,613 : INFO : Current training batch loss: 0.0193 in epoch 3
2024-08-16 04:41:26,485 : INFO : Current training batch loss: 0.0088 in epoch 3
2024-08-16 04:41:37,364 : INFO : Current training batch loss: 0.0025 in epoch 3
2024-08-16 04:41:48,244 : INFO : Current training batch loss: 0.0060 in epoch 3
2024-08-16 04:41:59,121 : INFO : Current training batch loss: 0.0033 in epoch 3
2024-08-16 04:42:10,012 : INFO : Current training batch loss: 0.0077 in epoch 3
2024-08-16 04:42:20,901 : INFO : Current training batch loss: 0.1172 in epoch 3
2024-08-16 04:42:31,779 : INFO : Current training batch loss: 0.0074 in epoch 3
2024-08-16 04:42:42,650 : INFO : Current training batch loss: 0.0297 in epoch 3
2024-08-16 04:42:53,521 : INFO : Current training batch loss: 0.2359 in epoch 3
2024-08-16 04:43:04,397 : INFO : Current training batch loss: 0.0389 in epoch 3
2024-08-16 04:43:15,267 : INFO : Current training batch loss: 0.0267 in epoch 3
2024-08-16 04:43:26,148 : INFO : Current training batch loss: 0.1339 in epoch 3
2024-08-16 04:43:37,018 : INFO : Current training batch loss: 0.0032 in epoch 3
2024-08-16 04:43:47,888 : INFO : Current training batch loss: 0.0029 in epoch 3
2024-08-16 04:43:58,755 : INFO : Current training batch loss: 0.0018 in epoch 3
2024-08-16 04:44:09,628 : INFO : Current training batch loss: 0.0099 in epoch 3
2024-08-16 04:44:20,493 : INFO : Current training batch loss: 0.0614 in epoch 3
2024-08-16 04:44:31,361 : INFO : Current training batch loss: 0.0075 in epoch 3
2024-08-16 04:44:42,215 : INFO : Current training batch loss: 0.0028 in epoch 3
2024-08-16 04:44:53,069 : INFO : Current training batch loss: 0.0337 in epoch 3
2024-08-16 04:45:03,930 : INFO : Current training batch loss: 0.0016 in epoch 3
2024-08-16 04:45:14,800 : INFO : Current training batch loss: 0.0017 in epoch 3
2024-08-16 04:45:25,675 : INFO : Current training batch loss: 0.2031 in epoch 3
2024-08-16 04:45:36,536 : INFO : Current training batch loss: 0.0012 in epoch 3
2024-08-16 04:45:45,444 : INFO : Epoch finished, average loss over training batches: 0.0581
2024-08-16 04:45:45,446 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:45:45,446 : INFO : Training metrics:
2024-08-16 04:45:45,446 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:45:45,759 : INFO : Accuracy: 0.9826
2024-08-16 04:45:45,759 : INFO : Precision: 0.9809
2024-08-16 04:45:45,759 : INFO : Recall: 0.9842
2024-08-16 04:45:45,759 : INFO : F1 score: 0.9826
2024-08-16 04:46:33,436 : INFO : Average loss over validation batches: 0.3083
2024-08-16 04:46:33,436 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:46:33,436 : INFO : Validation metrics:
2024-08-16 04:46:33,436 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:46:33,442 : INFO : Accuracy: 0.9219
2024-08-16 04:46:33,442 : INFO : Precision: 0.9233
2024-08-16 04:46:33,442 : INFO : Recall: 0.9227
2024-08-16 04:46:33,442 : INFO : F1 score: 0.9230
2024-08-16 04:46:33,442 : INFO : EarlyStopping counter: 2 out of 3
2024-08-16 04:46:33,442 : INFO : Last epoch reached, validation loss was better before, loading best model during training.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 04:46:33,939 : INFO : Loading model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/current_split_model/checkpoint.pth
2024-08-16 04:47:20,752 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:47:20,752 : INFO : Validation metrics after reloading the model before ending this training:
2024-08-16 04:47:20,752 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:47:20,758 : INFO : Accuracy: 0.9019
2024-08-16 04:47:20,758 : INFO : Precision: 0.9315
2024-08-16 04:47:20,758 : INFO : Recall: 0.8707
2024-08-16 04:47:20,758 : INFO : F1 score: 0.9001
2024-08-16 04:47:20,758 : INFO : Determined score from best model, ending training.
2024-08-16 04:47:20,759 : INFO : Split 4 is finished, the score is: 0.9001
2024-08-16 04:47:20,759 : INFO : ----------------------------------------------------------------------------------------------------
[I 2024-08-16 04:47:20,765] Trial 9 finished with value: 0.9093030064711334 and parameters: {'n_epochs': 3, 'learning_rate': 0.0001894057343836654, 'classifier_dropout': 0.6371982390754583, 'warmup_step_fraction': 0.03820887064738893, 'use_gradient_clipping': True}. Best is trial 5 with value: 0.9241835973410469.
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 04:47:21,198 : INFO : Starting epoch 1
2024-08-16 04:47:21,782 : INFO : Current training batch loss: 0.7679 in epoch 1
2024-08-16 04:47:32,656 : INFO : Current training batch loss: 0.7154 in epoch 1
2024-08-16 04:47:43,523 : INFO : Current training batch loss: 0.7308 in epoch 1
2024-08-16 04:47:54,387 : INFO : Current training batch loss: 0.4635 in epoch 1
2024-08-16 04:48:05,232 : INFO : Current training batch loss: 0.3702 in epoch 1
2024-08-16 04:48:16,078 : INFO : Current training batch loss: 0.5583 in epoch 1
2024-08-16 04:48:26,934 : INFO : Current training batch loss: 0.3567 in epoch 1
2024-08-16 04:48:37,778 : INFO : Current training batch loss: 0.2599 in epoch 1
2024-08-16 04:48:48,625 : INFO : Current training batch loss: 0.1711 in epoch 1
2024-08-16 04:48:59,486 : INFO : Current training batch loss: 0.1849 in epoch 1
2024-08-16 04:49:10,345 : INFO : Current training batch loss: 0.2730 in epoch 1
2024-08-16 04:49:21,206 : INFO : Current training batch loss: 0.4218 in epoch 1
2024-08-16 04:49:32,066 : INFO : Current training batch loss: 0.3856 in epoch 1
2024-08-16 04:49:42,931 : INFO : Current training batch loss: 0.2010 in epoch 1
2024-08-16 04:49:53,804 : INFO : Current training batch loss: 0.2805 in epoch 1
2024-08-16 04:50:04,669 : INFO : Current training batch loss: 0.1840 in epoch 1
2024-08-16 04:50:15,534 : INFO : Current training batch loss: 0.1935 in epoch 1
2024-08-16 04:50:26,403 : INFO : Current training batch loss: 0.2477 in epoch 1
2024-08-16 04:50:37,256 : INFO : Current training batch loss: 0.1294 in epoch 1
2024-08-16 04:50:48,118 : INFO : Current training batch loss: 0.3661 in epoch 1
2024-08-16 04:50:58,982 : INFO : Current training batch loss: 0.2121 in epoch 1
2024-08-16 04:51:09,845 : INFO : Current training batch loss: 0.3633 in epoch 1
2024-08-16 04:51:20,705 : INFO : Current training batch loss: 0.3070 in epoch 1
2024-08-16 04:51:31,567 : INFO : Current training batch loss: 0.2077 in epoch 1
2024-08-16 04:51:42,436 : INFO : Current training batch loss: 0.1991 in epoch 1
2024-08-16 04:51:53,296 : INFO : Current training batch loss: 0.3565 in epoch 1
2024-08-16 04:52:04,160 : INFO : Current training batch loss: 0.2729 in epoch 1
2024-08-16 04:52:15,029 : INFO : Current training batch loss: 0.4879 in epoch 1
2024-08-16 04:52:25,896 : INFO : Current training batch loss: 0.3924 in epoch 1
2024-08-16 04:52:36,757 : INFO : Current training batch loss: 0.3447 in epoch 1
2024-08-16 04:52:47,636 : INFO : Current training batch loss: 0.2440 in epoch 1
2024-08-16 04:52:58,501 : INFO : Current training batch loss: 0.4941 in epoch 1
2024-08-16 04:53:09,363 : INFO : Current training batch loss: 0.2180 in epoch 1
2024-08-16 04:53:20,234 : INFO : Current training batch loss: 0.3637 in epoch 1
2024-08-16 04:53:31,104 : INFO : Current training batch loss: 0.1667 in epoch 1
2024-08-16 04:53:41,973 : INFO : Current training batch loss: 0.1982 in epoch 1
2024-08-16 04:53:52,838 : INFO : Current training batch loss: 0.2009 in epoch 1
2024-08-16 04:54:03,714 : INFO : Current training batch loss: 0.2802 in epoch 1
2024-08-16 04:54:14,578 : INFO : Current training batch loss: 0.1230 in epoch 1
2024-08-16 04:54:25,451 : INFO : Current training batch loss: 0.1505 in epoch 1
2024-08-16 04:54:25,529 : INFO : Epoch finished, average loss over training batches: 0.3104
2024-08-16 04:54:25,531 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:54:25,531 : INFO : Training metrics:
2024-08-16 04:54:25,531 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:54:25,614 : INFO : Accuracy: 0.8650
2024-08-16 04:54:25,614 : INFO : Precision: 0.8684
2024-08-16 04:54:25,614 : INFO : Recall: 0.8604
2024-08-16 04:54:25,614 : INFO : F1 score: 0.8644
2024-08-16 04:57:36,307 : INFO : Average loss over validation batches: 0.2182
2024-08-16 04:57:36,308 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:57:36,309 : INFO : Validation metrics:
2024-08-16 04:57:36,309 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 04:57:36,323 : INFO : Accuracy: 0.9142
2024-08-16 04:57:36,323 : INFO : Precision: 0.8876
2024-08-16 04:57:36,323 : INFO : Recall: 0.9484
2024-08-16 04:57:36,323 : INFO : F1 score: 0.9170
2024-08-16 04:57:36,323 : INFO : Validation metric decreased (inf --> 0.218165).  Saving model ...
2024-08-16 04:57:36,387 : INFO : Starting epoch 2
2024-08-16 04:57:46,710 : INFO : Current training batch loss: 0.1475 in epoch 2
2024-08-16 04:57:57,576 : INFO : Current training batch loss: 0.1440 in epoch 2
2024-08-16 04:58:08,445 : INFO : Current training batch loss: 0.1372 in epoch 2
2024-08-16 04:58:19,307 : INFO : Current training batch loss: 0.2739 in epoch 2
2024-08-16 04:58:30,173 : INFO : Current training batch loss: 0.2399 in epoch 2
2024-08-16 04:58:41,040 : INFO : Current training batch loss: 0.2751 in epoch 2
2024-08-16 04:58:51,912 : INFO : Current training batch loss: 0.0433 in epoch 2
2024-08-16 04:59:02,786 : INFO : Current training batch loss: 0.1203 in epoch 2
2024-08-16 04:59:13,650 : INFO : Current training batch loss: 0.1252 in epoch 2
2024-08-16 04:59:24,519 : INFO : Current training batch loss: 0.4906 in epoch 2
2024-08-16 04:59:35,394 : INFO : Current training batch loss: 0.2410 in epoch 2
2024-08-16 04:59:46,262 : INFO : Current training batch loss: 0.3525 in epoch 2
2024-08-16 04:59:57,130 : INFO : Current training batch loss: 0.1746 in epoch 2
2024-08-16 05:00:07,998 : INFO : Current training batch loss: 0.0867 in epoch 2
2024-08-16 05:00:18,876 : INFO : Current training batch loss: 0.0617 in epoch 2
2024-08-16 05:00:29,740 : INFO : Current training batch loss: 0.2218 in epoch 2
2024-08-16 05:00:40,613 : INFO : Current training batch loss: 0.1452 in epoch 2
2024-08-16 05:00:51,487 : INFO : Current training batch loss: 0.0850 in epoch 2
2024-08-16 05:01:02,349 : INFO : Current training batch loss: 0.0235 in epoch 2
2024-08-16 05:01:13,224 : INFO : Current training batch loss: 0.2330 in epoch 2
2024-08-16 05:01:24,098 : INFO : Current training batch loss: 0.2660 in epoch 2
2024-08-16 05:01:34,975 : INFO : Current training batch loss: 0.0727 in epoch 2
2024-08-16 05:01:45,843 : INFO : Current training batch loss: 0.0646 in epoch 2
2024-08-16 05:01:56,721 : INFO : Current training batch loss: 0.0321 in epoch 2
2024-08-16 05:02:07,592 : INFO : Current training batch loss: 0.0627 in epoch 2
2024-08-16 05:02:18,468 : INFO : Current training batch loss: 0.0353 in epoch 2
2024-08-16 05:02:29,338 : INFO : Current training batch loss: 0.2145 in epoch 2
2024-08-16 05:02:40,205 : INFO : Current training batch loss: 0.1525 in epoch 2
2024-08-16 05:02:51,056 : INFO : Current training batch loss: 0.1237 in epoch 2
2024-08-16 05:03:01,929 : INFO : Current training batch loss: 0.1673 in epoch 2
2024-08-16 05:03:12,785 : INFO : Current training batch loss: 0.5930 in epoch 2
2024-08-16 05:03:23,642 : INFO : Current training batch loss: 0.0251 in epoch 2
2024-08-16 05:03:34,499 : INFO : Current training batch loss: 0.0654 in epoch 2
2024-08-16 05:03:45,356 : INFO : Current training batch loss: 0.4302 in epoch 2
2024-08-16 05:03:56,221 : INFO : Current training batch loss: 0.0203 in epoch 2
2024-08-16 05:04:07,082 : INFO : Current training batch loss: 0.0574 in epoch 2
2024-08-16 05:04:17,953 : INFO : Current training batch loss: 0.0984 in epoch 2
2024-08-16 05:04:28,820 : INFO : Current training batch loss: 0.0050 in epoch 2
2024-08-16 05:04:39,705 : INFO : Current training batch loss: 0.2933 in epoch 2
2024-08-16 05:04:40,891 : INFO : Epoch finished, average loss over training batches: 0.1317
2024-08-16 05:04:40,893 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 05:04:40,893 : INFO : Training metrics:
2024-08-16 05:04:40,893 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 05:04:40,976 : INFO : Accuracy: 0.9535
2024-08-16 05:04:40,976 : INFO : Precision: 0.9540
2024-08-16 05:04:40,976 : INFO : Recall: 0.9530
2024-08-16 05:04:40,976 : INFO : F1 score: 0.9535
2024-08-16 05:07:51,601 : INFO : Average loss over validation batches: 0.2142
2024-08-16 05:07:51,603 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 05:07:51,603 : INFO : Validation metrics:
2024-08-16 05:07:51,603 : INFO : ----------------------------------------------------------------------------------------------------
2024-08-16 05:07:51,617 : INFO : Accuracy: 0.9288
2024-08-16 05:07:51,617 : INFO : Precision: 0.9339
2024-08-16 05:07:51,617 : INFO : Recall: 0.9228
2024-08-16 05:07:51,617 : INFO : F1 score: 0.9283
2024-08-16 05:07:51,617 : INFO : Validation metric decreased (0.218165 --> 0.214164).  Saving model ...
Some weights of ElectraDocumentClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['LayerNorm.bias', 'LayerNorm.weight', 'attention.output.LayerNorm.bias', 'attention.output.LayerNorm.weight', 'attention.output.dense.bias', 'attention.output.dense.weight', 'attention.self.key.bias', 'attention.self.key.weight', 'attention.self.query.bias', 'attention.self.query.weight', 'attention.self.value.bias', 'attention.self.value.weight', 'out_projection.bias', 'out_projection.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2024-08-16 05:07:52,236 : INFO : Loading finetuned model from checkpoint.
2024-08-16 05:07:52,375 : INFO : Final model from /data/language_models/pretrained_models_downstreaming/stanford_imdb/electra_small_discriminator_document_predictions/finetuned_model is loaded.
2024-08-16 05:07:52,382 : INFO : Determining training scores of final model.
2024-08-16 05:10:31,417 : INFO : Accuracy: 0.9873
2024-08-16 05:10:31,417 : INFO : Precision: 0.9893
2024-08-16 05:10:31,417 : INFO : Recall: 0.9853
2024-08-16 05:10:31,417 : INFO : F1 score: 0.9873
2024-08-16 05:10:31,417 : INFO : Determining test scores of final model.
2024-08-16 05:13:10,482 : INFO : Accuracy: 0.9288
2024-08-16 05:13:10,483 : INFO : Precision: 0.9339
2024-08-16 05:13:10,483 : INFO : Recall: 0.9228
2024-08-16 05:13:10,483 : INFO : F1 score: 0.9283
