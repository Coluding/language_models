<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 14.6.0"/>
    <title>finlm.models API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../finlm.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;finlm</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#PretrainLM">PretrainLM</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PretrainLM.__init__">PretrainLM</a>
                        </li>
                        <li>
                                <a class="variable" href="#PretrainLM.config">config</a>
                        </li>
                        <li>
                                <a class="variable" href="#PretrainLM.dataset_config">dataset_config</a>
                        </li>
                        <li>
                                <a class="variable" href="#PretrainLM.model_config">model_config</a>
                        </li>
                        <li>
                                <a class="variable" href="#PretrainLM.optimization_config">optimization_config</a>
                        </li>
                        <li>
                                <a class="variable" href="#PretrainLM.save_root_path">save_root_path</a>
                        </li>
                        <li>
                                <a class="variable" href="#PretrainLM.logger">logger</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainLM.load_dataset">load_dataset</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainLM.mask_tokens">mask_tokens</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PretrainMLM">PretrainMLM</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PretrainMLM.__init__">PretrainMLM</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainMLM.load_model">load_model</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainMLM.load_optimization">load_optimization</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainMLM.prepare_data_model_optimizer">prepare_data_model_optimizer</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainMLM.train">train</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PretrainDiscriminator">PretrainDiscriminator</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PretrainDiscriminator.__init__">PretrainDiscriminator</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainDiscriminator.load_model">load_model</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainDiscriminator.load_optimization">load_optimization</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainDiscriminator.prepare_data_model_optimizer">prepare_data_model_optimizer</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainDiscriminator.replace_masked_tokens_randomly">replace_masked_tokens_randomly</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainDiscriminator.train">train</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PretrainElectra">PretrainElectra</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PretrainElectra.__init__">PretrainElectra</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainElectra.load_model">load_model</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainElectra.load_optimization">load_optimization</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainElectra.prepare_data_model_optimizer">prepare_data_model_optimizer</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainElectra.replace_masked_tokens_from_generator">replace_masked_tokens_from_generator</a>
                        </li>
                        <li>
                                <a class="function" href="#PretrainElectra.train">train</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ElectraSimpleAttention">ElectraSimpleAttention</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ElectraSimpleAttention.__init__">ElectraSimpleAttention</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttention.hidden_size">hidden_size</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttention.query">query</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttention.key">key</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttention.value">value</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttention.dropout">dropout</a>
                        </li>
                        <li>
                                <a class="function" href="#ElectraSimpleAttention.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ElectraSimpleAttentionOutput">ElectraSimpleAttentionOutput</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ElectraSimpleAttentionOutput.__init__">ElectraSimpleAttentionOutput</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttentionOutput.dense">dense</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttentionOutput.dropout">dropout</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttentionOutput.LayerNorm">LayerNorm</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttentionOutput.out_projection">out_projection</a>
                        </li>
                        <li>
                                <a class="function" href="#ElectraSimpleAttentionOutput.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ElectraSimpleAttentionHead">ElectraSimpleAttentionHead</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ElectraSimpleAttentionHead.__init__">ElectraSimpleAttentionHead</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttentionHead.simple_attention">simple_attention</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraSimpleAttentionHead.attention_output">attention_output</a>
                        </li>
                        <li>
                                <a class="function" href="#ElectraSimpleAttentionHead.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ElectraForAggregatePredictionWithAttention">ElectraForAggregatePredictionWithAttention</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ElectraForAggregatePredictionWithAttention.__init__">ElectraForAggregatePredictionWithAttention</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraForAggregatePredictionWithAttention.config">config</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraForAggregatePredictionWithAttention.num_labels">num_labels</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraForAggregatePredictionWithAttention.electra">electra</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraForAggregatePredictionWithAttention.head">head</a>
                        </li>
                        <li>
                                <a class="function" href="#ElectraForAggregatePredictionWithAttention.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ElectraAggregationHead">ElectraAggregationHead</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ElectraAggregationHead.__init__">ElectraAggregationHead</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraAggregationHead.dense">dense</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraAggregationHead.dropout">dropout</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraAggregationHead.activation">activation</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraAggregationHead.out_projection">out_projection</a>
                        </li>
                        <li>
                                <a class="function" href="#ElectraAggregationHead.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ElectraForAggregatePrediction">ElectraForAggregatePrediction</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ElectraForAggregatePrediction.__init__">ElectraForAggregatePrediction</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraForAggregatePrediction.config">config</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraForAggregatePrediction.num_labels">num_labels</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraForAggregatePrediction.electra">electra</a>
                        </li>
                        <li>
                                <a class="variable" href="#ElectraForAggregatePrediction.head">head</a>
                        </li>
                        <li>
                                <a class="function" href="#ElectraForAggregatePrediction.forward">forward</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../finlm.html">finlm</a><wbr>.models    </h1>

                
                        <input id="mod-models-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-models-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">   1</span></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">   2</span></a><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">asdict</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">   3</span></a><span class="kn">from</span> <span class="nn">finlm.dataset</span> <span class="kn">import</span> <span class="n">FinLMDataset</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">   4</span></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">ElectraConfig</span><span class="p">,</span> <span class="n">ElectraForMaskedLM</span><span class="p">,</span> <span class="n">ElectraForPreTraining</span><span class="p">,</span> <span class="n">ElectraPreTrainedModel</span><span class="p">,</span> <span class="n">ElectraModel</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">   5</span></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">get_linear_schedule_with_warmup</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">   6</span></a><span class="kn">from</span> <span class="nn">finlm.config</span> <span class="kn">import</span> <span class="n">FinLMConfig</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">   7</span></a><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">   8</span></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">   9</span></a><span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">  10</span></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">  11</span></a><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">BCEWithLogitsLoss</span><span class="p">,</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="n">MSELoss</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">  12</span></a><span class="kn">from</span> <span class="nn">torcheval.metrics.functional</span> <span class="kn">import</span> <span class="n">binary_precision</span><span class="p">,</span> <span class="n">binary_recall</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">  13</span></a><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">  14</span></a><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos">  15</span></a><span class="kn">import</span> <span class="nn">math</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos">  16</span></a><span class="kn">import</span> <span class="nn">logging</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos">  17</span></a><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> : </span><span class="si">%(levelname)s</span><span class="s1"> : </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos">  18</span></a>
</span><span id="L-19"><a href="#L-19"><span class="linenos">  19</span></a><span class="c1">#########################################################################################################################</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos">  20</span></a><span class="c1"># Models for pretraining</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">  21</span></a><span class="c1">#########################################################################################################################</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">  22</span></a>
</span><span id="L-23"><a href="#L-23"><span class="linenos">  23</span></a><span class="k">class</span> <span class="nc">PretrainLM</span><span class="p">:</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos">  24</span></a>
</span><span id="L-25"><a href="#L-25"><span class="linenos">  25</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos">  26</span></a><span class="sd">    A class for pretraining a language model using the configurations provided in FinLMConfig.</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos">  27</span></a>
</span><span id="L-28"><a href="#L-28"><span class="linenos">  28</span></a><span class="sd">    This class handles the setup of the dataset, model configurations, and optimization settings </span>
</span><span id="L-29"><a href="#L-29"><span class="linenos">  29</span></a><span class="sd">    for pretraining a language model. It also includes utility methods for token masking and </span>
</span><span id="L-30"><a href="#L-30"><span class="linenos">  30</span></a><span class="sd">    directory management.</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos">  31</span></a>
</span><span id="L-32"><a href="#L-32"><span class="linenos">  32</span></a><span class="sd">    Attributes</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos">  33</span></a><span class="sd">    ----------</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos">  34</span></a><span class="sd">    config : FinLMConfig</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos">  35</span></a><span class="sd">        Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos">  36</span></a><span class="sd">    dataset_config : DatasetConfig</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos">  37</span></a><span class="sd">        Configuration for the dataset.</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos">  38</span></a><span class="sd">    model_config : ModelConfig</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos">  39</span></a><span class="sd">        Configuration for the model architecture.</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos">  40</span></a><span class="sd">    optimization_config : OptimizationConfig</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos">  41</span></a><span class="sd">        Configuration for the optimization settings.</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos">  42</span></a><span class="sd">    save_root_path : str</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos">  43</span></a><span class="sd">        Path where models and results will be saved.</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos">  44</span></a><span class="sd">    logger : logging.Logger</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos">  45</span></a><span class="sd">        Logger instance for logging messages related to the pretraining process.</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos">  46</span></a><span class="sd">    device : torch.device</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos">  47</span></a><span class="sd">        Device on which computations will be performed (CPU or CUDA).</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos">  48</span></a>
</span><span id="L-49"><a href="#L-49"><span class="linenos">  49</span></a><span class="sd">    Methods</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos">  50</span></a><span class="sd">    -------</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos">  51</span></a><span class="sd">    load_dataset() -&gt; None</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos">  52</span></a><span class="sd">        Loads the dataset based on the configuration.</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos">  53</span></a><span class="sd">    mask_tokens(inputs, mlm_probability, mask_token_id, special_token_ids, n_tokens, ignore_index=-100, hard_masking=False) -&gt; Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos">  54</span></a><span class="sd">        Applies masked language modeling (MLM) to the input tokens.</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos">  55</span></a><span class="sd">    _create_directory_and_return_save_path(model_type: str) -&gt; str</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos">  56</span></a><span class="sd">        Creates a directory for saving the model and returns the path.</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos">  57</span></a><span class="sd">    _set_device() -&gt; None</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos">  58</span></a><span class="sd">        Sets the device to CUDA if available; otherwise, defaults to CPU.</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos">  59</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos">  60</span></a>
</span><span id="L-61"><a href="#L-61"><span class="linenos">  61</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">FinLMConfig</span><span class="p">):</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos">  62</span></a>
</span><span id="L-63"><a href="#L-63"><span class="linenos">  63</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos">  64</span></a><span class="sd">        Initializes the PretrainLM class with the given configuration.</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos">  65</span></a>
</span><span id="L-66"><a href="#L-66"><span class="linenos">  66</span></a><span class="sd">        Parameters</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos">  67</span></a><span class="sd">        ----------</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos">  68</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos">  69</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos">  70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos">  71</span></a>
</span><span id="L-72"><a href="#L-72"><span class="linenos">  72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos">  73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_config</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos">  74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_config</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos">  75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">optimization_config</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos">  76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">save_models_and_results_to</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos">  77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos">  78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_device</span><span class="p">()</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos">  79</span></a>
</span><span id="L-80"><a href="#L-80"><span class="linenos">  80</span></a>    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos">  81</span></a>
</span><span id="L-82"><a href="#L-82"><span class="linenos">  82</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos">  83</span></a><span class="sd">        Loads the dataset based on the dataset configuration.</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos">  84</span></a>
</span><span id="L-85"><a href="#L-85"><span class="linenos">  85</span></a><span class="sd">        This method initializes the FinLMDataset using the dataset configuration provided in </span>
</span><span id="L-86"><a href="#L-86"><span class="linenos">  86</span></a><span class="sd">        the FinLMConfig object.</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos">  87</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos">  88</span></a>            
</span><span id="L-89"><a href="#L-89"><span class="linenos">  89</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">FinLMDataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_config</span><span class="p">))</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos">  90</span></a>
</span><span id="L-91"><a href="#L-91"><span class="linenos">  91</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos">  92</span></a>    <span class="k">def</span> <span class="nf">mask_tokens</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="n">special_token_ids</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos">  93</span></a>
</span><span id="L-94"><a href="#L-94"><span class="linenos">  94</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos">  95</span></a><span class="sd">        Applies masked language modeling (MLM) to the input tokens.</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos">  96</span></a>
</span><span id="L-97"><a href="#L-97"><span class="linenos">  97</span></a><span class="sd">        This method randomly masks a portion of the input tokens according to the specified </span>
</span><span id="L-98"><a href="#L-98"><span class="linenos">  98</span></a><span class="sd">        probability, and optionally replaces some tokens with random words or keeps them unchanged.</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos">  99</span></a>
</span><span id="L-100"><a href="#L-100"><span class="linenos"> 100</span></a><span class="sd">        Parameters</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos"> 101</span></a><span class="sd">        ----------</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos"> 102</span></a><span class="sd">        inputs : torch.Tensor</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos"> 103</span></a><span class="sd">            Tensor containing the input token IDs.</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos"> 104</span></a><span class="sd">        mlm_probability : float</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos"> 105</span></a><span class="sd">            Probability of masking a token for MLM.</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos"> 106</span></a><span class="sd">        mask_token_id : int</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos"> 107</span></a><span class="sd">            The token ID to use for masking (typically the ID for the [MASK] token).</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos"> 108</span></a><span class="sd">        special_token_ids : list[int]</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos"> 109</span></a><span class="sd">            List of token IDs that should not be masked (e.g., special tokens like [CLS], [SEP]).</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos"> 110</span></a><span class="sd">        n_tokens : int</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos"> 111</span></a><span class="sd">            The total number of tokens in the vocabulary (used for selecting random tokens).</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos"> 112</span></a><span class="sd">        ignore_index : int, optional</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos"> 113</span></a><span class="sd">            The index to ignore in the loss calculation (default is -100).</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos"> 114</span></a><span class="sd">        hard_masking : bool, optional</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos"> 115</span></a><span class="sd">            If True, all masked tokens are replaced by the mask token; otherwise, some tokens may be </span>
</span><span id="L-116"><a href="#L-116"><span class="linenos"> 116</span></a><span class="sd">            replaced by random tokens or left unchanged (default is False).</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos"> 117</span></a>
</span><span id="L-118"><a href="#L-118"><span class="linenos"> 118</span></a><span class="sd">        Returns</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos"> 119</span></a><span class="sd">        -------</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos"> 120</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos"> 121</span></a><span class="sd">            A tuple containing the masked input tensor and the corresponding labels tensor.</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos"> 122</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos"> 123</span></a>        
</span><span id="L-124"><a href="#L-124"><span class="linenos"> 124</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos"> 125</span></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="L-126"><a href="#L-126"><span class="linenos"> 126</span></a>        <span class="n">probability_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos"> 127</span></a>        <span class="c1"># create special_token_mask, first set all entries to false</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos"> 128</span></a>        <span class="n">special_tokens_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos"> 129</span></a>        <span class="c1"># flag all special tokens as true</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos"> 130</span></a>        <span class="k">for</span> <span class="n">sp_id</span> <span class="ow">in</span> <span class="n">special_token_ids</span><span class="p">:</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos"> 131</span></a>            <span class="n">special_tokens_mask</span> <span class="o">=</span> <span class="n">special_tokens_mask</span> <span class="o">|</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">==</span> <span class="n">sp_id</span><span class="p">)</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos"> 132</span></a>
</span><span id="L-133"><a href="#L-133"><span class="linenos"> 133</span></a>        <span class="n">probability_matrix</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">special_tokens_mask</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos"> 134</span></a>        <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">probability_matrix</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos"> 135</span></a>        <span class="k">if</span> <span class="n">ignore_index</span><span class="p">:</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos"> 136</span></a>            <span class="n">labels</span><span class="p">[</span><span class="o">~</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">ignore_index</span>  <span class="c1"># We only compute loss on masked tokens</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos"> 137</span></a>
</span><span id="L-138"><a href="#L-138"><span class="linenos"> 138</span></a>        <span class="k">if</span> <span class="n">hard_masking</span><span class="p">:</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos"> 139</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_token_id</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos"> 140</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos"> 141</span></a>            <span class="c1"># 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos"> 142</span></a>            <span class="n">indices_replaced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">masked_indices</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos"> 143</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">indices_replaced</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_token_id</span> 
</span><span id="L-144"><a href="#L-144"><span class="linenos"> 144</span></a>
</span><span id="L-145"><a href="#L-145"><span class="linenos"> 145</span></a>            <span class="c1"># 10% of the time, we replace masked input tokens with random word</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos"> 146</span></a>            <span class="n">indices_random</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">masked_indices</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">indices_replaced</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos"> 147</span></a>            <span class="n">random_words</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_tokens</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos"> 148</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">indices_random</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_words</span><span class="p">[</span><span class="n">indices_random</span><span class="p">]</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos"> 149</span></a>
</span><span id="L-150"><a href="#L-150"><span class="linenos"> 150</span></a>        <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos"> 151</span></a>
</span><span id="L-152"><a href="#L-152"><span class="linenos"> 152</span></a>    <span class="k">def</span> <span class="nf">_create_directory_and_return_save_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_type</span><span class="p">):</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos"> 153</span></a>
</span><span id="L-154"><a href="#L-154"><span class="linenos"> 154</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos"> 155</span></a><span class="sd">        Creates a directory for saving the model and returns the path.</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos"> 156</span></a>
</span><span id="L-157"><a href="#L-157"><span class="linenos"> 157</span></a><span class="sd">        This method creates a new directory within the save root path for storing the model checkpoints </span>
</span><span id="L-158"><a href="#L-158"><span class="linenos"> 158</span></a><span class="sd">        and results. The directory name is based on the model type and an incremented index.</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos"> 159</span></a>
</span><span id="L-160"><a href="#L-160"><span class="linenos"> 160</span></a><span class="sd">        Parameters</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos"> 161</span></a><span class="sd">        ----------</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos"> 162</span></a><span class="sd">        model_type : str</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos"> 163</span></a><span class="sd">            The type of model being saved (used in the directory name).</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos"> 164</span></a>
</span><span id="L-165"><a href="#L-165"><span class="linenos"> 165</span></a><span class="sd">        Returns</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos"> 166</span></a><span class="sd">        -------</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos"> 167</span></a><span class="sd">        str</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos"> 168</span></a><span class="sd">            The path to the newly created directory.</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos"> 169</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos"> 170</span></a>            
</span><span id="L-171"><a href="#L-171"><span class="linenos"> 171</span></a>        <span class="n">current_model_folder_paths</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span><span class="p">)</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos"> 172</span></a>        <span class="n">current_model_type_folder_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">current_model_folder_paths</span> <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">model_type</span><span class="p">)]</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos"> 173</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_model_type_folder_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos"> 174</span></a>            <span class="n">current_model_type_index</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">model_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">current_model_type_folder_names</span><span class="p">])</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos"> 175</span></a>            <span class="n">new_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span> <span class="o">+</span> <span class="n">model_type</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">current_model_type_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos"> 176</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos"> 177</span></a>            <span class="n">new_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span> <span class="o">+</span> <span class="n">model_type</span> <span class="o">+</span> <span class="s2">&quot;_00/&quot;</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos"> 178</span></a>        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">new_model_path</span><span class="p">)</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos"> 179</span></a>        <span class="k">return</span> <span class="n">new_model_path</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos"> 180</span></a>
</span><span id="L-181"><a href="#L-181"><span class="linenos"> 181</span></a>    <span class="k">def</span> <span class="nf">_set_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos"> 182</span></a>
</span><span id="L-183"><a href="#L-183"><span class="linenos"> 183</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos"> 184</span></a><span class="sd">        Sets the device to CUDA if available; otherwise, defaults to CPU.</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos"> 185</span></a>
</span><span id="L-186"><a href="#L-186"><span class="linenos"> 186</span></a><span class="sd">        This method checks if a GPU is available and sets the device accordingly. If a GPU is not </span>
</span><span id="L-187"><a href="#L-187"><span class="linenos"> 187</span></a><span class="sd">        available, a warning is logged and the device is set to CPU.</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos"> 188</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos"> 189</span></a>        
</span><span id="L-190"><a href="#L-190"><span class="linenos"> 190</span></a>        <span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()):</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos"> 191</span></a>            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;GPU seems to be unavailable.&quot;</span><span class="p">)</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos"> 192</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos"> 193</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos"> 194</span></a>
</span><span id="L-195"><a href="#L-195"><span class="linenos"> 195</span></a>
</span><span id="L-196"><a href="#L-196"><span class="linenos"> 196</span></a><span class="k">class</span> <span class="nc">PretrainMLM</span><span class="p">(</span><span class="n">PretrainLM</span><span class="p">):</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos"> 197</span></a>
</span><span id="L-198"><a href="#L-198"><span class="linenos"> 198</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos"> 199</span></a><span class="sd">    A class for pretraining a Masked Language Model (MLM) using the FinLM framework.</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos"> 200</span></a>
</span><span id="L-201"><a href="#L-201"><span class="linenos"> 201</span></a><span class="sd">    This class inherits from `PretrainLM` and provides specific implementations for </span>
</span><span id="L-202"><a href="#L-202"><span class="linenos"> 202</span></a><span class="sd">    preparing data, loading the model, and training the Masked Language Model (MLM). </span>
</span><span id="L-203"><a href="#L-203"><span class="linenos"> 203</span></a>
</span><span id="L-204"><a href="#L-204"><span class="linenos"> 204</span></a><span class="sd">    Attributes</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos"> 205</span></a><span class="sd">    ----------</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos"> 206</span></a><span class="sd">    config : FinLMConfig</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos"> 207</span></a><span class="sd">        Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos"> 208</span></a><span class="sd">    dataset : FinLMDataset</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos"> 209</span></a><span class="sd">        The dataset prepared for MLM training.</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos"> 210</span></a><span class="sd">    model : ElectraForMaskedLM</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos"> 211</span></a><span class="sd">        The Electra model configured for masked language modeling.</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos"> 212</span></a><span class="sd">    optimizer : torch.optim.Optimizer</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos"> 213</span></a><span class="sd">        The optimizer used for training.</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos"> 214</span></a><span class="sd">    scheduler : torch.optim.lr_scheduler.LambdaLR</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos"> 215</span></a><span class="sd">        The learning rate scheduler used during training.</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos"> 216</span></a><span class="sd">    iteration_steps_per_epoch : int</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos"> 217</span></a><span class="sd">        Number of iteration steps per training epoch.</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos"> 218</span></a><span class="sd">    logger : logging.Logger</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos"> 219</span></a><span class="sd">        Logger instance for logging messages related to training.</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos"> 220</span></a><span class="sd">    device : torch.device</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos"> 221</span></a><span class="sd">        Device on which computations will be performed (CPU or CUDA).</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos"> 222</span></a>
</span><span id="L-223"><a href="#L-223"><span class="linenos"> 223</span></a><span class="sd">    Methods</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos"> 224</span></a><span class="sd">    -------</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos"> 225</span></a><span class="sd">    load_model() -&gt; None</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos"> 226</span></a><span class="sd">        Loads and configures the Electra model for masked language modeling.</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos"> 227</span></a><span class="sd">    load_optimization() -&gt; None</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos"> 228</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos"> 229</span></a><span class="sd">    prepare_data_model_optimizer() -&gt; None</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos"> 230</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos"> 231</span></a><span class="sd">    train() -&gt; None</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos"> 232</span></a><span class="sd">        Trains the masked language model and saves the results and model.</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos"> 233</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos"> 234</span></a>
</span><span id="L-235"><a href="#L-235"><span class="linenos"> 235</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos"> 236</span></a>
</span><span id="L-237"><a href="#L-237"><span class="linenos"> 237</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos"> 238</span></a><span class="sd">        Initializes the PretrainMLM class with the given configuration.</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos"> 239</span></a>
</span><span id="L-240"><a href="#L-240"><span class="linenos"> 240</span></a><span class="sd">        Parameters</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos"> 241</span></a><span class="sd">        ----------</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos"> 242</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos"> 243</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos"> 244</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos"> 245</span></a>
</span><span id="L-246"><a href="#L-246"><span class="linenos"> 246</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos"> 247</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos"> 248</span></a>
</span><span id="L-249"><a href="#L-249"><span class="linenos"> 249</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos"> 250</span></a>
</span><span id="L-251"><a href="#L-251"><span class="linenos"> 251</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos"> 252</span></a><span class="sd">        Loads and configures the Electra model for masked language modeling.</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos"> 253</span></a>
</span><span id="L-254"><a href="#L-254"><span class="linenos"> 254</span></a><span class="sd">        This method initializes the Electra model using the configuration settings, </span>
</span><span id="L-255"><a href="#L-255"><span class="linenos"> 255</span></a><span class="sd">        including vocabulary size, embedding size, hidden size, and other model parameters. </span>
</span><span id="L-256"><a href="#L-256"><span class="linenos"> 256</span></a><span class="sd">        The model is then moved to the appropriate device (CPU or GPU).</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos"> 257</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos"> 258</span></a>            
</span><span id="L-259"><a href="#L-259"><span class="linenos"> 259</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos"> 260</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos"> 261</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos"> 262</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="L-263"><a href="#L-263"><span class="linenos"> 263</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos"> 264</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos"> 265</span></a>            <span class="n">intermediate_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">intermediate_size</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos"> 266</span></a>        <span class="p">)</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos"> 267</span></a>
</span><span id="L-268"><a href="#L-268"><span class="linenos"> 268</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ElectraForMaskedLM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
</span><span id="L-269"><a href="#L-269"><span class="linenos"> 269</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos"> 270</span></a>
</span><span id="L-271"><a href="#L-271"><span class="linenos"> 271</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos"> 272</span></a>
</span><span id="L-273"><a href="#L-273"><span class="linenos"> 273</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos"> 274</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos"> 275</span></a>
</span><span id="L-276"><a href="#L-276"><span class="linenos"> 276</span></a><span class="sd">        This method calculates the total number of training steps, initializes the AdamW optimizer, </span>
</span><span id="L-277"><a href="#L-277"><span class="linenos"> 277</span></a><span class="sd">        and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos"> 278</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos"> 279</span></a>
</span><span id="L-280"><a href="#L-280"><span class="linenos"> 280</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos"> 281</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos"> 282</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos"> 283</span></a>
</span><span id="L-284"><a href="#L-284"><span class="linenos"> 284</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos"> 285</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span>  
</span><span id="L-286"><a href="#L-286"><span class="linenos"> 286</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="L-287"><a href="#L-287"><span class="linenos"> 287</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos"> 288</span></a>
</span><span id="L-289"><a href="#L-289"><span class="linenos"> 289</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos"> 290</span></a>
</span><span id="L-291"><a href="#L-291"><span class="linenos"> 291</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos"> 292</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos"> 293</span></a>
</span><span id="L-294"><a href="#L-294"><span class="linenos"> 294</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the model, </span>
</span><span id="L-295"><a href="#L-295"><span class="linenos"> 295</span></a><span class="sd">        and set up the optimizer and learning rate scheduler.</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos"> 296</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos"> 297</span></a>            
</span><span id="L-298"><a href="#L-298"><span class="linenos"> 298</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos"> 299</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos"> 300</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos"> 301</span></a>
</span><span id="L-302"><a href="#L-302"><span class="linenos"> 302</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos"> 303</span></a>
</span><span id="L-304"><a href="#L-304"><span class="linenos"> 304</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos"> 305</span></a><span class="sd">        Trains the masked language model and saves the results and model.</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos"> 306</span></a>
</span><span id="L-307"><a href="#L-307"><span class="linenos"> 307</span></a><span class="sd">        This method handles the training loop, including masking input tokens, calculating </span>
</span><span id="L-308"><a href="#L-308"><span class="linenos"> 308</span></a><span class="sd">        the MLM loss, updating model parameters, and logging training metrics. After training </span>
</span><span id="L-309"><a href="#L-309"><span class="linenos"> 309</span></a><span class="sd">        is complete, it saves the model, training metrics, and plots of the loss and accuracy.</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos"> 310</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos"> 311</span></a>
</span><span id="L-312"><a href="#L-312"><span class="linenos"> 312</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos"> 313</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-314"><a href="#L-314"><span class="linenos"> 314</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos"> 315</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos"> 316</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-317"><a href="#L-317"><span class="linenos"> 317</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos"> 318</span></a>
</span><span id="L-319"><a href="#L-319"><span class="linenos"> 319</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="L-320"><a href="#L-320"><span class="linenos"> 320</span></a>
</span><span id="L-321"><a href="#L-321"><span class="linenos"> 321</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="L-322"><a href="#L-322"><span class="linenos"> 322</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos"> 323</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos"> 324</span></a>
</span><span id="L-325"><a href="#L-325"><span class="linenos"> 325</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos"> 326</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos"> 327</span></a>
</span><span id="L-328"><a href="#L-328"><span class="linenos"> 328</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="L-329"><a href="#L-329"><span class="linenos"> 329</span></a>                    <span class="n">inputs</span><span class="p">,</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos"> 330</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos"> 331</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos"> 332</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos"> 333</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos"> 334</span></a>
</span><span id="L-335"><a href="#L-335"><span class="linenos"> 335</span></a>                <span class="n">mlm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos"> 336</span></a>                <span class="n">mlm_loss</span><span class="p">,</span> <span class="n">mlm_logits</span> <span class="o">=</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos"> 337</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos"> 338</span></a>
</span><span id="L-339"><a href="#L-339"><span class="linenos"> 339</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="L-340"><a href="#L-340"><span class="linenos"> 340</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos"> 341</span></a>
</span><span id="L-342"><a href="#L-342"><span class="linenos"> 342</span></a>                <span class="c1"># determine gradients</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos"> 343</span></a>                <span class="n">mlm_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos"> 344</span></a>
</span><span id="L-345"><a href="#L-345"><span class="linenos"> 345</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos"> 346</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos"> 347</span></a>
</span><span id="L-348"><a href="#L-348"><span class="linenos"> 348</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos"> 349</span></a>                <span class="n">mlm_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos"> 350</span></a>                <span class="n">mlm_grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">mlm_grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos"> 351</span></a>
</span><span id="L-352"><a href="#L-352"><span class="linenos"> 352</span></a>                <span class="c1"># update parameters        </span>
</span><span id="L-353"><a href="#L-353"><span class="linenos"> 353</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos"> 354</span></a>                <span class="c1"># update learning rate</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos"> 355</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos"> 356</span></a>
</span><span id="L-357"><a href="#L-357"><span class="linenos"> 357</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos"> 358</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="L-359"><a href="#L-359"><span class="linenos"> 359</span></a>                    <span class="c1"># mask to identify ids which have been masked before</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos"> 360</span></a>                    <span class="n">masked_ids_mask</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos"> 361</span></a>                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos"> 362</span></a>                    <span class="n">mlm_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">]</span> <span class="o">==</span> <span class="n">labels</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos"> 363</span></a>
</span><span id="L-364"><a href="#L-364"><span class="linenos"> 364</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos"> 365</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos"> 366</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos"> 367</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos"> 368</span></a>
</span><span id="L-369"><a href="#L-369"><span class="linenos"> 369</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos"> 370</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="L-371"><a href="#L-371"><span class="linenos"> 371</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MLM loss: </span><span class="si">{</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos"> 372</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">mlm_grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos"> 373</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos"> 374</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for masking task: </span><span class="si">{</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos"> 375</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="L-376"><a href="#L-376"><span class="linenos"> 376</span></a>
</span><span id="L-377"><a href="#L-377"><span class="linenos"> 377</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos"> 378</span></a>
</span><span id="L-379"><a href="#L-379"><span class="linenos"> 379</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;mlm&quot;</span><span class="p">)</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos"> 380</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos"> 381</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos"> 382</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos"> 383</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos"> 384</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos"> 385</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos"> 386</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;mlm_model&quot;</span><span class="p">)</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos"> 387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos"> 388</span></a>
</span><span id="L-389"><a href="#L-389"><span class="linenos"> 389</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos"> 390</span></a>
</span><span id="L-391"><a href="#L-391"><span class="linenos"> 391</span></a>
</span><span id="L-392"><a href="#L-392"><span class="linenos"> 392</span></a><span class="k">class</span> <span class="nc">PretrainDiscriminator</span><span class="p">(</span><span class="n">PretrainLM</span><span class="p">):</span>
</span><span id="L-393"><a href="#L-393"><span class="linenos"> 393</span></a>
</span><span id="L-394"><a href="#L-394"><span class="linenos"> 394</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos"> 395</span></a><span class="sd">    A class for pretraining a discriminator model in the Electra framework using the FinLM setup.</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos"> 396</span></a>
</span><span id="L-397"><a href="#L-397"><span class="linenos"> 397</span></a><span class="sd">    This class inherits from `PretrainLM` and provides specific implementations for </span>
</span><span id="L-398"><a href="#L-398"><span class="linenos"> 398</span></a><span class="sd">    preparing data, loading the discriminator model, and training the model.</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos"> 399</span></a>
</span><span id="L-400"><a href="#L-400"><span class="linenos"> 400</span></a><span class="sd">    Attributes</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos"> 401</span></a><span class="sd">    ----------</span>
</span><span id="L-402"><a href="#L-402"><span class="linenos"> 402</span></a><span class="sd">    config : FinLMConfig</span>
</span><span id="L-403"><a href="#L-403"><span class="linenos"> 403</span></a><span class="sd">        Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos"> 404</span></a><span class="sd">    dataset : FinLMDataset</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos"> 405</span></a><span class="sd">        The dataset prepared for discriminator training.</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos"> 406</span></a><span class="sd">    model : ElectraForPreTraining</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos"> 407</span></a><span class="sd">        The Electra model configured for discriminator pretraining.</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos"> 408</span></a><span class="sd">    optimizer : torch.optim.Optimizer</span>
</span><span id="L-409"><a href="#L-409"><span class="linenos"> 409</span></a><span class="sd">        The optimizer used for training.</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos"> 410</span></a><span class="sd">    scheduler : torch.optim.lr_scheduler.LambdaLR</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos"> 411</span></a><span class="sd">        The learning rate scheduler used during training.</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos"> 412</span></a><span class="sd">    iteration_steps_per_epoch : int</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos"> 413</span></a><span class="sd">        Number of iteration steps per training epoch.</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos"> 414</span></a><span class="sd">    logger : logging.Logger</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos"> 415</span></a><span class="sd">        Logger instance for logging messages related to training.</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos"> 416</span></a><span class="sd">    device : torch.device</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos"> 417</span></a><span class="sd">        Device on which computations will be performed (CPU or CUDA).</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos"> 418</span></a>
</span><span id="L-419"><a href="#L-419"><span class="linenos"> 419</span></a><span class="sd">    Methods</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos"> 420</span></a><span class="sd">    -------</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos"> 421</span></a><span class="sd">    load_model() -&gt; None</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos"> 422</span></a><span class="sd">        Loads and configures the Electra discriminator model.</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos"> 423</span></a><span class="sd">    load_optimization() -&gt; None</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos"> 424</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos"> 425</span></a><span class="sd">    prepare_data_model_optimizer() -&gt; None</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos"> 426</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos"> 427</span></a><span class="sd">    replace_masked_tokens_randomly(inputs: torch.Tensor, mlm_probability: float, mask_token_id: int, special_token_ids: list[int], n_tokens: int, hard_masking: bool = True) -&gt; Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos"> 428</span></a><span class="sd">        Replaces masked tokens with random tokens and generates labels for discriminator training.</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos"> 429</span></a><span class="sd">    train() -&gt; None</span>
</span><span id="L-430"><a href="#L-430"><span class="linenos"> 430</span></a><span class="sd">        Trains the discriminator model and saves the results and model.</span>
</span><span id="L-431"><a href="#L-431"><span class="linenos"> 431</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos"> 432</span></a>
</span><span id="L-433"><a href="#L-433"><span class="linenos"> 433</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-434"><a href="#L-434"><span class="linenos"> 434</span></a>
</span><span id="L-435"><a href="#L-435"><span class="linenos"> 435</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos"> 436</span></a><span class="sd">        Initializes the PretrainDiscriminator class with the given configuration.</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos"> 437</span></a>
</span><span id="L-438"><a href="#L-438"><span class="linenos"> 438</span></a><span class="sd">        Parameters</span>
</span><span id="L-439"><a href="#L-439"><span class="linenos"> 439</span></a><span class="sd">        ----------</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos"> 440</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos"> 441</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos"> 442</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-443"><a href="#L-443"><span class="linenos"> 443</span></a>
</span><span id="L-444"><a href="#L-444"><span class="linenos"> 444</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos"> 445</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos"> 446</span></a>
</span><span id="L-447"><a href="#L-447"><span class="linenos"> 447</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos"> 448</span></a>
</span><span id="L-449"><a href="#L-449"><span class="linenos"> 449</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos"> 450</span></a><span class="sd">        Loads and configures the Electra discriminator model.</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos"> 451</span></a>
</span><span id="L-452"><a href="#L-452"><span class="linenos"> 452</span></a><span class="sd">        This method initializes the Electra model for discriminator pretraining using the configuration settings, </span>
</span><span id="L-453"><a href="#L-453"><span class="linenos"> 453</span></a><span class="sd">        including vocabulary size, embedding size, hidden size, and other model parameters. The model is then moved </span>
</span><span id="L-454"><a href="#L-454"><span class="linenos"> 454</span></a><span class="sd">        to the appropriate device (CPU or GPU).</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos"> 455</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos"> 456</span></a>        
</span><span id="L-457"><a href="#L-457"><span class="linenos"> 457</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos"> 458</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos"> 459</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos"> 460</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="L-461"><a href="#L-461"><span class="linenos"> 461</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos"> 462</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos"> 463</span></a>        <span class="p">)</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos"> 464</span></a>
</span><span id="L-465"><a href="#L-465"><span class="linenos"> 465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ElectraForPreTraining</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos"> 466</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos"> 467</span></a>
</span><span id="L-468"><a href="#L-468"><span class="linenos"> 468</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-469"><a href="#L-469"><span class="linenos"> 469</span></a>
</span><span id="L-470"><a href="#L-470"><span class="linenos"> 470</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos"> 471</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos"> 472</span></a>
</span><span id="L-473"><a href="#L-473"><span class="linenos"> 473</span></a><span class="sd">        This method calculates the total number of training steps, initializes the AdamW optimizer, </span>
</span><span id="L-474"><a href="#L-474"><span class="linenos"> 474</span></a><span class="sd">        and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos"> 475</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos"> 476</span></a>
</span><span id="L-477"><a href="#L-477"><span class="linenos"> 477</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos"> 478</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos"> 479</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos"> 480</span></a>
</span><span id="L-481"><a href="#L-481"><span class="linenos"> 481</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos"> 482</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span>  
</span><span id="L-483"><a href="#L-483"><span class="linenos"> 483</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="L-484"><a href="#L-484"><span class="linenos"> 484</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos"> 485</span></a>
</span><span id="L-486"><a href="#L-486"><span class="linenos"> 486</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos"> 487</span></a>
</span><span id="L-488"><a href="#L-488"><span class="linenos"> 488</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos"> 489</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos"> 490</span></a>
</span><span id="L-491"><a href="#L-491"><span class="linenos"> 491</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the model, </span>
</span><span id="L-492"><a href="#L-492"><span class="linenos"> 492</span></a><span class="sd">        and set up the optimizer and learning rate scheduler.</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos"> 493</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos"> 494</span></a>        
</span><span id="L-495"><a href="#L-495"><span class="linenos"> 495</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="L-496"><a href="#L-496"><span class="linenos"> 496</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos"> 497</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos"> 498</span></a>
</span><span id="L-499"><a href="#L-499"><span class="linenos"> 499</span></a>
</span><span id="L-500"><a href="#L-500"><span class="linenos"> 500</span></a>    <span class="k">def</span> <span class="nf">replace_masked_tokens_randomly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="n">special_token_ids</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos"> 501</span></a>
</span><span id="L-502"><a href="#L-502"><span class="linenos"> 502</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos"> 503</span></a><span class="sd">        Replaces masked tokens with random tokens and generates labels for discriminator training.</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos"> 504</span></a>
</span><span id="L-505"><a href="#L-505"><span class="linenos"> 505</span></a><span class="sd">        This method first applies masked language modeling (MLM) to the input tokens. It then replaces </span>
</span><span id="L-506"><a href="#L-506"><span class="linenos"> 506</span></a><span class="sd">        the masked tokens with random tokens and generates labels indicating whether a token has been </span>
</span><span id="L-507"><a href="#L-507"><span class="linenos"> 507</span></a><span class="sd">        replaced (1) or not (0).</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos"> 508</span></a>
</span><span id="L-509"><a href="#L-509"><span class="linenos"> 509</span></a><span class="sd">        Parameters</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos"> 510</span></a><span class="sd">        ----------</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos"> 511</span></a><span class="sd">        inputs : torch.Tensor</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos"> 512</span></a><span class="sd">            Tensor containing the input token IDs.</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos"> 513</span></a><span class="sd">        mlm_probability : float</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos"> 514</span></a><span class="sd">            Probability of masking a token for MLM.</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos"> 515</span></a><span class="sd">        mask_token_id : int</span>
</span><span id="L-516"><a href="#L-516"><span class="linenos"> 516</span></a><span class="sd">            The token ID to use for masking (typically the ID for the [MASK] token).</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos"> 517</span></a><span class="sd">        special_token_ids : list[int]</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos"> 518</span></a><span class="sd">            List of token IDs that should not be masked (e.g., special tokens like [CLS], [SEP]).</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos"> 519</span></a><span class="sd">        n_tokens : int</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos"> 520</span></a><span class="sd">            The total number of tokens in the vocabulary (used for selecting random tokens).</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos"> 521</span></a><span class="sd">        hard_masking : bool, optional</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos"> 522</span></a><span class="sd">            If True, all masked tokens are replaced by the mask token; otherwise, some tokens may be </span>
</span><span id="L-523"><a href="#L-523"><span class="linenos"> 523</span></a><span class="sd">            replaced by random tokens or left unchanged (default is True).</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos"> 524</span></a>
</span><span id="L-525"><a href="#L-525"><span class="linenos"> 525</span></a><span class="sd">        Returns</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos"> 526</span></a><span class="sd">        -------</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos"> 527</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos"> 528</span></a><span class="sd">            A tuple containing the corrupted input tensor and the corresponding labels tensor.</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos"> 529</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos"> 530</span></a>         
</span><span id="L-531"><a href="#L-531"><span class="linenos"> 531</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos"> 532</span></a>        <span class="n">masked_inputs</span><span class="p">,</span> <span class="n">original_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos"> 533</span></a>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos"> 534</span></a>            <span class="n">mlm_probability</span> <span class="o">=</span> <span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos"> 535</span></a>            <span class="n">mask_token_id</span> <span class="o">=</span> <span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos"> 536</span></a>            <span class="n">special_token_ids</span> <span class="o">=</span> <span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos"> 537</span></a>            <span class="n">n_tokens</span> <span class="o">=</span> <span class="n">n_tokens</span><span class="p">,</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos"> 538</span></a>            <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos"> 539</span></a>            <span class="n">hard_masking</span> <span class="o">=</span> <span class="n">hard_masking</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos"> 540</span></a>            <span class="p">)</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos"> 541</span></a>        
</span><span id="L-542"><a href="#L-542"><span class="linenos"> 542</span></a>        <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">masked_inputs</span> <span class="o">==</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="L-543"><a href="#L-543"><span class="linenos"> 543</span></a>        <span class="n">random_words</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_tokens</span><span class="p">,</span> <span class="n">original_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos"> 544</span></a>        <span class="n">corrupted_inputs</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos"> 545</span></a>        <span class="n">corrupted_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_words</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos"> 546</span></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">corrupted_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos"> 547</span></a>        <span class="n">labels</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">!=</span> <span class="n">corrupted_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos"> 548</span></a>
</span><span id="L-549"><a href="#L-549"><span class="linenos"> 549</span></a>        <span class="k">return</span> <span class="n">corrupted_inputs</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos"> 550</span></a>
</span><span id="L-551"><a href="#L-551"><span class="linenos"> 551</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos"> 552</span></a>
</span><span id="L-553"><a href="#L-553"><span class="linenos"> 553</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos"> 554</span></a><span class="sd">        Trains the discriminator model and saves the results and model.</span>
</span><span id="L-555"><a href="#L-555"><span class="linenos"> 555</span></a>
</span><span id="L-556"><a href="#L-556"><span class="linenos"> 556</span></a><span class="sd">        This method handles the training loop, including replacing masked tokens, calculating </span>
</span><span id="L-557"><a href="#L-557"><span class="linenos"> 557</span></a><span class="sd">        the discriminator loss, updating model parameters, and logging training metrics. After </span>
</span><span id="L-558"><a href="#L-558"><span class="linenos"> 558</span></a><span class="sd">        training is complete, it saves the model, training metrics, and plots of the loss, accuracy, </span>
</span><span id="L-559"><a href="#L-559"><span class="linenos"> 559</span></a><span class="sd">        precision, and recall.</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos"> 560</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos"> 561</span></a>        
</span><span id="L-562"><a href="#L-562"><span class="linenos"> 562</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="L-563"><a href="#L-563"><span class="linenos"> 563</span></a>
</span><span id="L-564"><a href="#L-564"><span class="linenos"> 564</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-565"><a href="#L-565"><span class="linenos"> 565</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos"> 566</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos"> 567</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos"> 568</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos"> 569</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos"> 570</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos"> 571</span></a>
</span><span id="L-572"><a href="#L-572"><span class="linenos"> 572</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="L-573"><a href="#L-573"><span class="linenos"> 573</span></a>
</span><span id="L-574"><a href="#L-574"><span class="linenos"> 574</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="L-575"><a href="#L-575"><span class="linenos"> 575</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="L-576"><a href="#L-576"><span class="linenos"> 576</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos"> 577</span></a>
</span><span id="L-578"><a href="#L-578"><span class="linenos"> 578</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos"> 579</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos"> 580</span></a>
</span><span id="L-581"><a href="#L-581"><span class="linenos"> 581</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_masked_tokens_randomly</span><span class="p">(</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos"> 582</span></a>                    <span class="n">inputs</span><span class="p">,</span> 
</span><span id="L-583"><a href="#L-583"><span class="linenos"> 583</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos"> 584</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos"> 585</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="L-586"><a href="#L-586"><span class="linenos"> 586</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos"> 587</span></a>                    <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos"> 588</span></a>                <span class="p">)</span>
</span><span id="L-589"><a href="#L-589"><span class="linenos"> 589</span></a>
</span><span id="L-590"><a href="#L-590"><span class="linenos"> 590</span></a>                <span class="n">discriminator_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos"> 591</span></a>                <span class="n">discriminator_loss</span><span class="p">,</span> <span class="n">discriminator_logits</span> <span class="o">=</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="L-592"><a href="#L-592"><span class="linenos"> 592</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-593"><a href="#L-593"><span class="linenos"> 593</span></a>
</span><span id="L-594"><a href="#L-594"><span class="linenos"> 594</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos"> 595</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos"> 596</span></a>
</span><span id="L-597"><a href="#L-597"><span class="linenos"> 597</span></a>                <span class="c1"># determine gradients</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos"> 598</span></a>                <span class="n">discriminator_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos"> 599</span></a>
</span><span id="L-600"><a href="#L-600"><span class="linenos"> 600</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="L-601"><a href="#L-601"><span class="linenos"> 601</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos"> 602</span></a>
</span><span id="L-603"><a href="#L-603"><span class="linenos"> 603</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos"> 604</span></a>                <span class="n">discriminator_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
</span><span id="L-605"><a href="#L-605"><span class="linenos"> 605</span></a>                <span class="n">discriminator_grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">discriminator_grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos"> 606</span></a>
</span><span id="L-607"><a href="#L-607"><span class="linenos"> 607</span></a>                <span class="c1"># update parameters        </span>
</span><span id="L-608"><a href="#L-608"><span class="linenos"> 608</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos"> 609</span></a>                <span class="c1"># update learning rate</span>
</span><span id="L-610"><a href="#L-610"><span class="linenos"> 610</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos"> 611</span></a>
</span><span id="L-612"><a href="#L-612"><span class="linenos"> 612</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos"> 613</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos"> 614</span></a>                    <span class="n">active_loss</span> <span class="o">=</span> <span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos"> 615</span></a>                    <span class="n">active_logits</span> <span class="o">=</span> <span class="n">discriminator_logits</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos"> 616</span></a>                    <span class="n">active_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">active_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos"> 617</span></a>                    <span class="n">active_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos"> 618</span></a>
</span><span id="L-619"><a href="#L-619"><span class="linenos"> 619</span></a>                    <span class="n">discriminator_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">active_predictions</span> <span class="o">==</span> <span class="n">active_labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos"> 620</span></a>                    <span class="n">discriminator_precision</span> <span class="o">=</span> <span class="n">binary_precision</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos"> 621</span></a>                    <span class="n">discriminator_recall</span> <span class="o">=</span> <span class="n">binary_recall</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="L-622"><a href="#L-622"><span class="linenos"> 622</span></a>
</span><span id="L-623"><a href="#L-623"><span class="linenos"> 623</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos"> 624</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-625"><a href="#L-625"><span class="linenos"> 625</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos"> 626</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos"> 627</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos"> 628</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos"> 629</span></a>
</span><span id="L-630"><a href="#L-630"><span class="linenos"> 630</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-631"><a href="#L-631"><span class="linenos"> 631</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos"> 632</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Discriminator loss: </span><span class="si">{</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-633"><a href="#L-633"><span class="linenos"> 633</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">discriminator_grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos"> 634</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos"> 635</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for replacement task: </span><span class="si">{</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos"> 636</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision for replacement task: </span><span class="si">{</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-637"><a href="#L-637"><span class="linenos"> 637</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall for replacement task: </span><span class="si">{</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos"> 638</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="L-639"><a href="#L-639"><span class="linenos"> 639</span></a>
</span><span id="L-640"><a href="#L-640"><span class="linenos"> 640</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos"> 641</span></a>        
</span><span id="L-642"><a href="#L-642"><span class="linenos"> 642</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;discriminator&quot;</span><span class="p">)</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos"> 643</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos"> 644</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos"> 645</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos"> 646</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="L-647"><a href="#L-647"><span class="linenos"> 647</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos"> 648</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos"> 649</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;discriminator_model&quot;</span><span class="p">)</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos"> 650</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="L-651"><a href="#L-651"><span class="linenos"> 651</span></a>
</span><span id="L-652"><a href="#L-652"><span class="linenos"> 652</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span><span id="L-653"><a href="#L-653"><span class="linenos"> 653</span></a>        
</span><span id="L-654"><a href="#L-654"><span class="linenos"> 654</span></a>
</span><span id="L-655"><a href="#L-655"><span class="linenos"> 655</span></a><span class="k">class</span> <span class="nc">PretrainElectra</span><span class="p">(</span><span class="n">PretrainLM</span><span class="p">):</span>
</span><span id="L-656"><a href="#L-656"><span class="linenos"> 656</span></a>
</span><span id="L-657"><a href="#L-657"><span class="linenos"> 657</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-658"><a href="#L-658"><span class="linenos"> 658</span></a><span class="sd">    A class for pretraining the Electra model using the FinLM setup.</span>
</span><span id="L-659"><a href="#L-659"><span class="linenos"> 659</span></a>
</span><span id="L-660"><a href="#L-660"><span class="linenos"> 660</span></a><span class="sd">    This class inherits from `PretrainLM` and provides specific implementations for </span>
</span><span id="L-661"><a href="#L-661"><span class="linenos"> 661</span></a><span class="sd">    preparing data, loading both the generator and discriminator models, and training </span>
</span><span id="L-662"><a href="#L-662"><span class="linenos"> 662</span></a><span class="sd">    the Electra model, which includes both components.</span>
</span><span id="L-663"><a href="#L-663"><span class="linenos"> 663</span></a>
</span><span id="L-664"><a href="#L-664"><span class="linenos"> 664</span></a><span class="sd">    Attributes</span>
</span><span id="L-665"><a href="#L-665"><span class="linenos"> 665</span></a><span class="sd">    ----------</span>
</span><span id="L-666"><a href="#L-666"><span class="linenos"> 666</span></a><span class="sd">    config : FinLMConfig</span>
</span><span id="L-667"><a href="#L-667"><span class="linenos"> 667</span></a><span class="sd">        Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="L-668"><a href="#L-668"><span class="linenos"> 668</span></a><span class="sd">    dataset : FinLMDataset</span>
</span><span id="L-669"><a href="#L-669"><span class="linenos"> 669</span></a><span class="sd">        The dataset prepared for Electra model training.</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos"> 670</span></a><span class="sd">    generator : ElectraForMaskedLM</span>
</span><span id="L-671"><a href="#L-671"><span class="linenos"> 671</span></a><span class="sd">        The generator model in the Electra framework configured for masked language modeling.</span>
</span><span id="L-672"><a href="#L-672"><span class="linenos"> 672</span></a><span class="sd">    discriminator : ElectraForPreTraining</span>
</span><span id="L-673"><a href="#L-673"><span class="linenos"> 673</span></a><span class="sd">        The discriminator model in the Electra framework configured for identifying replaced tokens.</span>
</span><span id="L-674"><a href="#L-674"><span class="linenos"> 674</span></a><span class="sd">    optimizer : torch.optim.Optimizer</span>
</span><span id="L-675"><a href="#L-675"><span class="linenos"> 675</span></a><span class="sd">        The optimizer used for training.</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos"> 676</span></a><span class="sd">    scheduler : torch.optim.lr_scheduler.LambdaLR</span>
</span><span id="L-677"><a href="#L-677"><span class="linenos"> 677</span></a><span class="sd">        The learning rate scheduler used during training.</span>
</span><span id="L-678"><a href="#L-678"><span class="linenos"> 678</span></a><span class="sd">    iteration_steps_per_epoch : int</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos"> 679</span></a><span class="sd">        Number of iteration steps per training epoch.</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos"> 680</span></a><span class="sd">    logger : logging.Logger</span>
</span><span id="L-681"><a href="#L-681"><span class="linenos"> 681</span></a><span class="sd">        Logger instance for logging messages related to training.</span>
</span><span id="L-682"><a href="#L-682"><span class="linenos"> 682</span></a><span class="sd">    device : torch.device</span>
</span><span id="L-683"><a href="#L-683"><span class="linenos"> 683</span></a><span class="sd">        Device on which computations will be performed (CPU or CUDA).</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos"> 684</span></a>
</span><span id="L-685"><a href="#L-685"><span class="linenos"> 685</span></a><span class="sd">    Methods</span>
</span><span id="L-686"><a href="#L-686"><span class="linenos"> 686</span></a><span class="sd">    -------</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos"> 687</span></a><span class="sd">    load_model() -&gt; None</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos"> 688</span></a><span class="sd">        Loads and configures the Electra generator and discriminator models.</span>
</span><span id="L-689"><a href="#L-689"><span class="linenos"> 689</span></a><span class="sd">    load_optimization() -&gt; None</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos"> 690</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="L-691"><a href="#L-691"><span class="linenos"> 691</span></a><span class="sd">    prepare_data_model_optimizer() -&gt; None</span>
</span><span id="L-692"><a href="#L-692"><span class="linenos"> 692</span></a><span class="sd">        Prepares the dataset, models, and optimizer for training.</span>
</span><span id="L-693"><a href="#L-693"><span class="linenos"> 693</span></a><span class="sd">    replace_masked_tokens_from_generator(masked_inputs: torch.Tensor, original_inputs: torch.Tensor, logits: torch.Tensor, special_mask_id: int, discriminator_sampling: str = &quot;multinomial&quot;) -&gt; Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos"> 694</span></a><span class="sd">        Replaces masked tokens with tokens sampled from the generator and generates labels for discriminator training.</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos"> 695</span></a><span class="sd">    train() -&gt; None</span>
</span><span id="L-696"><a href="#L-696"><span class="linenos"> 696</span></a><span class="sd">        Trains the Electra model, which includes both the generator and discriminator, and saves the results and models.</span>
</span><span id="L-697"><a href="#L-697"><span class="linenos"> 697</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-698"><a href="#L-698"><span class="linenos"> 698</span></a>
</span><span id="L-699"><a href="#L-699"><span class="linenos"> 699</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-700"><a href="#L-700"><span class="linenos"> 700</span></a>
</span><span id="L-701"><a href="#L-701"><span class="linenos"> 701</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos"> 702</span></a><span class="sd">        Initializes the PretrainElectra class with the given configuration.</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos"> 703</span></a>
</span><span id="L-704"><a href="#L-704"><span class="linenos"> 704</span></a><span class="sd">        Parameters</span>
</span><span id="L-705"><a href="#L-705"><span class="linenos"> 705</span></a><span class="sd">        ----------</span>
</span><span id="L-706"><a href="#L-706"><span class="linenos"> 706</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="L-707"><a href="#L-707"><span class="linenos"> 707</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="L-708"><a href="#L-708"><span class="linenos"> 708</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos"> 709</span></a>
</span><span id="L-710"><a href="#L-710"><span class="linenos"> 710</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-711"><a href="#L-711"><span class="linenos"> 711</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span><span id="L-712"><a href="#L-712"><span class="linenos"> 712</span></a>
</span><span id="L-713"><a href="#L-713"><span class="linenos"> 713</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-714"><a href="#L-714"><span class="linenos"> 714</span></a>
</span><span id="L-715"><a href="#L-715"><span class="linenos"> 715</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos"> 716</span></a><span class="sd">        Loads and configures the Electra generator and discriminator models.</span>
</span><span id="L-717"><a href="#L-717"><span class="linenos"> 717</span></a>
</span><span id="L-718"><a href="#L-718"><span class="linenos"> 718</span></a><span class="sd">        This method initializes the Electra generator and discriminator models using the </span>
</span><span id="L-719"><a href="#L-719"><span class="linenos"> 719</span></a><span class="sd">        configuration settings, including vocabulary size, embedding size, hidden size, </span>
</span><span id="L-720"><a href="#L-720"><span class="linenos"> 720</span></a><span class="sd">        and other model parameters. The models are then moved to the appropriate device (CPU or GPU).</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos"> 721</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-722"><a href="#L-722"><span class="linenos"> 722</span></a>            
</span><span id="L-723"><a href="#L-723"><span class="linenos"> 723</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator_model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="L-724"><a href="#L-724"><span class="linenos"> 724</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="L-725"><a href="#L-725"><span class="linenos"> 725</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="L-726"><a href="#L-726"><span class="linenos"> 726</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">),</span> 
</span><span id="L-727"><a href="#L-727"><span class="linenos"> 727</span></a>            <span class="n">intermediate_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">),</span>
</span><span id="L-728"><a href="#L-728"><span class="linenos"> 728</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_layer_size</span><span class="p">),</span>
</span><span id="L-729"><a href="#L-729"><span class="linenos"> 729</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">)</span>
</span><span id="L-730"><a href="#L-730"><span class="linenos"> 730</span></a>        <span class="p">)</span>
</span><span id="L-731"><a href="#L-731"><span class="linenos"> 731</span></a>
</span><span id="L-732"><a href="#L-732"><span class="linenos"> 732</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator_model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="L-733"><a href="#L-733"><span class="linenos"> 733</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="L-734"><a href="#L-734"><span class="linenos"> 734</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="L-735"><a href="#L-735"><span class="linenos"> 735</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="L-736"><a href="#L-736"><span class="linenos"> 736</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="L-737"><a href="#L-737"><span class="linenos"> 737</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span>
</span><span id="L-738"><a href="#L-738"><span class="linenos"> 738</span></a>        <span class="p">)</span>
</span><span id="L-739"><a href="#L-739"><span class="linenos"> 739</span></a>
</span><span id="L-740"><a href="#L-740"><span class="linenos"> 740</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">ElectraForMaskedLM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">generator_model_config</span><span class="p">)</span>
</span><span id="L-741"><a href="#L-741"><span class="linenos"> 741</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">ElectraForPreTraining</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">discriminator_model_config</span><span class="p">)</span>
</span><span id="L-742"><a href="#L-742"><span class="linenos"> 742</span></a>        <span class="c1"># tie word and position embeddings</span>
</span><span id="L-743"><a href="#L-743"><span class="linenos"> 743</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span>
</span><span id="L-744"><a href="#L-744"><span class="linenos"> 744</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">position_embeddings</span>
</span><span id="L-745"><a href="#L-745"><span class="linenos"> 745</span></a>        <span class="c1"># add to device</span>
</span><span id="L-746"><a href="#L-746"><span class="linenos"> 746</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-747"><a href="#L-747"><span class="linenos"> 747</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-748"><a href="#L-748"><span class="linenos"> 748</span></a>
</span><span id="L-749"><a href="#L-749"><span class="linenos"> 749</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-750"><a href="#L-750"><span class="linenos"> 750</span></a>
</span><span id="L-751"><a href="#L-751"><span class="linenos"> 751</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-752"><a href="#L-752"><span class="linenos"> 752</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="L-753"><a href="#L-753"><span class="linenos"> 753</span></a>
</span><span id="L-754"><a href="#L-754"><span class="linenos"> 754</span></a><span class="sd">        This method identifies the trainable parameters, ensuring that the word and position embeddings </span>
</span><span id="L-755"><a href="#L-755"><span class="linenos"> 755</span></a><span class="sd">        are not duplicated. It then calculates the total number of training steps, initializes the AdamW </span>
</span><span id="L-756"><a href="#L-756"><span class="linenos"> 756</span></a><span class="sd">        optimizer, and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="L-757"><a href="#L-757"><span class="linenos"> 757</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-758"><a href="#L-758"><span class="linenos"> 758</span></a>        
</span><span id="L-759"><a href="#L-759"><span class="linenos"> 759</span></a>        <span class="c1"># identify trainable parameters without duplicating the embedding and position parameters</span>
</span><span id="L-760"><a href="#L-760"><span class="linenos"> 760</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-761"><a href="#L-761"><span class="linenos"> 761</span></a>        <span class="c1"># generator</span>
</span><span id="L-762"><a href="#L-762"><span class="linenos"> 762</span></a>        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="L-763"><a href="#L-763"><span class="linenos"> 763</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span><span id="L-764"><a href="#L-764"><span class="linenos"> 764</span></a>        <span class="c1"># discriminator</span>
</span><span id="L-765"><a href="#L-765"><span class="linenos"> 765</span></a>        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="L-766"><a href="#L-766"><span class="linenos"> 766</span></a>            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;word_embeddings.weight&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;position_embeddings.weight&quot;</span><span class="p">):</span>
</span><span id="L-767"><a href="#L-767"><span class="linenos"> 767</span></a>                <span class="k">continue</span>
</span><span id="L-768"><a href="#L-768"><span class="linenos"> 768</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-769"><a href="#L-769"><span class="linenos"> 769</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span><span id="L-770"><a href="#L-770"><span class="linenos"> 770</span></a>        
</span><span id="L-771"><a href="#L-771"><span class="linenos"> 771</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-772"><a href="#L-772"><span class="linenos"> 772</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="L-773"><a href="#L-773"><span class="linenos"> 773</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="L-774"><a href="#L-774"><span class="linenos"> 774</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="L-775"><a href="#L-775"><span class="linenos"> 775</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span> 
</span><span id="L-776"><a href="#L-776"><span class="linenos"> 776</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="L-777"><a href="#L-777"><span class="linenos"> 777</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span><span id="L-778"><a href="#L-778"><span class="linenos"> 778</span></a>
</span><span id="L-779"><a href="#L-779"><span class="linenos"> 779</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-780"><a href="#L-780"><span class="linenos"> 780</span></a>
</span><span id="L-781"><a href="#L-781"><span class="linenos"> 781</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-782"><a href="#L-782"><span class="linenos"> 782</span></a><span class="sd">        Prepares the dataset, models, and optimizer for training.</span>
</span><span id="L-783"><a href="#L-783"><span class="linenos"> 783</span></a>
</span><span id="L-784"><a href="#L-784"><span class="linenos"> 784</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the generator and </span>
</span><span id="L-785"><a href="#L-785"><span class="linenos"> 785</span></a><span class="sd">        discriminator models, and set up the optimizer and learning rate scheduler.</span>
</span><span id="L-786"><a href="#L-786"><span class="linenos"> 786</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-787"><a href="#L-787"><span class="linenos"> 787</span></a>
</span><span id="L-788"><a href="#L-788"><span class="linenos"> 788</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="L-789"><a href="#L-789"><span class="linenos"> 789</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="L-790"><a href="#L-790"><span class="linenos"> 790</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span><span id="L-791"><a href="#L-791"><span class="linenos"> 791</span></a>
</span><span id="L-792"><a href="#L-792"><span class="linenos"> 792</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-793"><a href="#L-793"><span class="linenos"> 793</span></a>    <span class="k">def</span> <span class="nf">replace_masked_tokens_from_generator</span><span class="p">(</span><span class="n">masked_inputs</span><span class="p">,</span> <span class="n">original_inputs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">special_mask_id</span><span class="p">,</span> <span class="n">discriminator_sampling</span> <span class="o">=</span> <span class="s2">&quot;gumbel_softmax&quot;</span><span class="p">):</span>
</span><span id="L-794"><a href="#L-794"><span class="linenos"> 794</span></a><span class="w">    </span>
</span><span id="L-795"><a href="#L-795"><span class="linenos"> 795</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-796"><a href="#L-796"><span class="linenos"> 796</span></a><span class="sd">        Replaces masked tokens with tokens sampled from the generator and generates labels for discriminator training.</span>
</span><span id="L-797"><a href="#L-797"><span class="linenos"> 797</span></a>
</span><span id="L-798"><a href="#L-798"><span class="linenos"> 798</span></a><span class="sd">        This method uses the generator&#39;s output logits to replace masked tokens in the input. It generates labels </span>
</span><span id="L-799"><a href="#L-799"><span class="linenos"> 799</span></a><span class="sd">        indicating whether a token has been replaced and whether the replacement matches the original token.</span>
</span><span id="L-800"><a href="#L-800"><span class="linenos"> 800</span></a>
</span><span id="L-801"><a href="#L-801"><span class="linenos"> 801</span></a><span class="sd">        Parameters</span>
</span><span id="L-802"><a href="#L-802"><span class="linenos"> 802</span></a><span class="sd">        ----------</span>
</span><span id="L-803"><a href="#L-803"><span class="linenos"> 803</span></a><span class="sd">        masked_inputs : torch.Tensor</span>
</span><span id="L-804"><a href="#L-804"><span class="linenos"> 804</span></a><span class="sd">            Tensor containing the masked input token IDs.</span>
</span><span id="L-805"><a href="#L-805"><span class="linenos"> 805</span></a><span class="sd">        original_inputs : torch.Tensor</span>
</span><span id="L-806"><a href="#L-806"><span class="linenos"> 806</span></a><span class="sd">            Tensor containing the original input token IDs before masking.</span>
</span><span id="L-807"><a href="#L-807"><span class="linenos"> 807</span></a><span class="sd">        logits : torch.Tensor</span>
</span><span id="L-808"><a href="#L-808"><span class="linenos"> 808</span></a><span class="sd">            Logits output by the generator model.</span>
</span><span id="L-809"><a href="#L-809"><span class="linenos"> 809</span></a><span class="sd">        special_mask_id : int</span>
</span><span id="L-810"><a href="#L-810"><span class="linenos"> 810</span></a><span class="sd">            The token ID used for masking (typically the ID for the [MASK] token).</span>
</span><span id="L-811"><a href="#L-811"><span class="linenos"> 811</span></a><span class="sd">        discriminator_sampling : str, optional</span>
</span><span id="L-812"><a href="#L-812"><span class="linenos"> 812</span></a><span class="sd">            The sampling strategy for selecting replacement tokens, either &quot;multinomial&quot; or another strategy like &quot;aggressive&quot; or &quot;gumbel_softmax&quot; (default is &quot;gumbel_softmax&quot;).</span>
</span><span id="L-813"><a href="#L-813"><span class="linenos"> 813</span></a>
</span><span id="L-814"><a href="#L-814"><span class="linenos"> 814</span></a><span class="sd">        Returns</span>
</span><span id="L-815"><a href="#L-815"><span class="linenos"> 815</span></a><span class="sd">        -------</span>
</span><span id="L-816"><a href="#L-816"><span class="linenos"> 816</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="L-817"><a href="#L-817"><span class="linenos"> 817</span></a><span class="sd">            A tuple containing the discriminator inputs (with replaced tokens) and the corresponding labels tensor.</span>
</span><span id="L-818"><a href="#L-818"><span class="linenos"> 818</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-819"><a href="#L-819"><span class="linenos"> 819</span></a>            
</span><span id="L-820"><a href="#L-820"><span class="linenos"> 820</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-821"><a href="#L-821"><span class="linenos"> 821</span></a>        <span class="n">discriminator_inputs</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="L-822"><a href="#L-822"><span class="linenos"> 822</span></a>        <span class="n">mask_indices</span> <span class="o">=</span> <span class="n">masked_inputs</span> <span class="o">==</span> <span class="n">special_mask_id</span>
</span><span id="L-823"><a href="#L-823"><span class="linenos"> 823</span></a>
</span><span id="L-824"><a href="#L-824"><span class="linenos"> 824</span></a>        <span class="k">if</span> <span class="n">discriminator_sampling</span> <span class="o">==</span> <span class="s2">&quot;aggressive&quot;</span><span class="p">:</span>
</span><span id="L-825"><a href="#L-825"><span class="linenos"> 825</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-826"><a href="#L-826"><span class="linenos"> 826</span></a>        <span class="k">elif</span> <span class="n">discriminator_sampling</span> <span class="o">==</span> <span class="s2">&quot;gumbel_softmax&quot;</span><span class="p">:</span>
</span><span id="L-827"><a href="#L-827"><span class="linenos"> 827</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gumbel_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">],</span> <span class="n">hard</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-828"><a href="#L-828"><span class="linenos"> 828</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-829"><a href="#L-829"><span class="linenos"> 829</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">],</span> <span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</span><span id="L-830"><a href="#L-830"><span class="linenos"> 830</span></a>
</span><span id="L-831"><a href="#L-831"><span class="linenos"> 831</span></a>        <span class="n">discriminator_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">sampled_ids</span>
</span><span id="L-832"><a href="#L-832"><span class="linenos"> 832</span></a>        <span class="c1"># initialize discriminator labels with False</span>
</span><span id="L-833"><a href="#L-833"><span class="linenos"> 833</span></a>        <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">masked_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-834"><a href="#L-834"><span class="linenos"> 834</span></a>        <span class="c1"># replace False with True if an id is sampled and not the same as the original one</span>
</span><span id="L-835"><a href="#L-835"><span class="linenos"> 835</span></a>        <span class="n">discriminator_labels</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">discriminator_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">!=</span> <span class="n">original_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span>
</span><span id="L-836"><a href="#L-836"><span class="linenos"> 836</span></a>        <span class="c1"># convert to float </span>
</span><span id="L-837"><a href="#L-837"><span class="linenos"> 837</span></a>        <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="L-838"><a href="#L-838"><span class="linenos"> 838</span></a>
</span><span id="L-839"><a href="#L-839"><span class="linenos"> 839</span></a>        <span class="k">return</span> <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">discriminator_labels</span>
</span><span id="L-840"><a href="#L-840"><span class="linenos"> 840</span></a>
</span><span id="L-841"><a href="#L-841"><span class="linenos"> 841</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-842"><a href="#L-842"><span class="linenos"> 842</span></a>
</span><span id="L-843"><a href="#L-843"><span class="linenos"> 843</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-844"><a href="#L-844"><span class="linenos"> 844</span></a><span class="sd">        Trains the Electra model, which includes both the generator and discriminator, and saves the results and models.</span>
</span><span id="L-845"><a href="#L-845"><span class="linenos"> 845</span></a>
</span><span id="L-846"><a href="#L-846"><span class="linenos"> 846</span></a><span class="sd">        This method handles the training loop, including masking input tokens, generating replacements using the generator, </span>
</span><span id="L-847"><a href="#L-847"><span class="linenos"> 847</span></a><span class="sd">        training the discriminator on identifying the replaced tokens, calculating losses, updating model parameters, and </span>
</span><span id="L-848"><a href="#L-848"><span class="linenos"> 848</span></a><span class="sd">        logging training metrics. After training is complete, it saves the models, training metrics, and plots of the loss, </span>
</span><span id="L-849"><a href="#L-849"><span class="linenos"> 849</span></a><span class="sd">        accuracy, precision, and recall.</span>
</span><span id="L-850"><a href="#L-850"><span class="linenos"> 850</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-851"><a href="#L-851"><span class="linenos"> 851</span></a>
</span><span id="L-852"><a href="#L-852"><span class="linenos"> 852</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="L-853"><a href="#L-853"><span class="linenos"> 853</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-854"><a href="#L-854"><span class="linenos"> 854</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-855"><a href="#L-855"><span class="linenos"> 855</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-856"><a href="#L-856"><span class="linenos"> 856</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-857"><a href="#L-857"><span class="linenos"> 857</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-858"><a href="#L-858"><span class="linenos"> 858</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-859"><a href="#L-859"><span class="linenos"> 859</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_precision&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-860"><a href="#L-860"><span class="linenos"> 860</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-861"><a href="#L-861"><span class="linenos"> 861</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-862"><a href="#L-862"><span class="linenos"> 862</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-863"><a href="#L-863"><span class="linenos"> 863</span></a>
</span><span id="L-864"><a href="#L-864"><span class="linenos"> 864</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="L-865"><a href="#L-865"><span class="linenos"> 865</span></a>            
</span><span id="L-866"><a href="#L-866"><span class="linenos"> 866</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="L-867"><a href="#L-867"><span class="linenos"> 867</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="L-868"><a href="#L-868"><span class="linenos"> 868</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="L-869"><a href="#L-869"><span class="linenos"> 869</span></a>
</span><span id="L-870"><a href="#L-870"><span class="linenos"> 870</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="L-871"><a href="#L-871"><span class="linenos"> 871</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-872"><a href="#L-872"><span class="linenos"> 872</span></a>
</span><span id="L-873"><a href="#L-873"><span class="linenos"> 873</span></a>                <span class="n">original_inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="L-874"><a href="#L-874"><span class="linenos"> 874</span></a>                <span class="n">generator_inputs</span><span class="p">,</span> <span class="n">generator_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="L-875"><a href="#L-875"><span class="linenos"> 875</span></a>                    <span class="n">inputs</span><span class="p">,</span>
</span><span id="L-876"><a href="#L-876"><span class="linenos"> 876</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="L-877"><a href="#L-877"><span class="linenos"> 877</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="L-878"><a href="#L-878"><span class="linenos"> 878</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="L-879"><a href="#L-879"><span class="linenos"> 879</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span><span id="L-880"><a href="#L-880"><span class="linenos"> 880</span></a>
</span><span id="L-881"><a href="#L-881"><span class="linenos"> 881</span></a>                <span class="n">mlm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">generator_inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">generator_labels</span><span class="p">)</span>
</span><span id="L-882"><a href="#L-882"><span class="linenos"> 882</span></a>                <span class="n">mlm_loss</span><span class="p">,</span> <span class="n">mlm_logits</span> <span class="o">=</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="L-883"><a href="#L-883"><span class="linenos"> 883</span></a>
</span><span id="L-884"><a href="#L-884"><span class="linenos"> 884</span></a>                <span class="n">sampling_logits</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span><span id="L-885"><a href="#L-885"><span class="linenos"> 885</span></a>                <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_masked_tokens_from_generator</span><span class="p">(</span>
</span><span id="L-886"><a href="#L-886"><span class="linenos"> 886</span></a>                    <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">generator_inputs</span><span class="p">,</span>
</span><span id="L-887"><a href="#L-887"><span class="linenos"> 887</span></a>                    <span class="n">original_inputs</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="p">,</span>
</span><span id="L-888"><a href="#L-888"><span class="linenos"> 888</span></a>                    <span class="n">logits</span> <span class="o">=</span> <span class="n">sampling_logits</span><span class="p">,</span>
</span><span id="L-889"><a href="#L-889"><span class="linenos"> 889</span></a>                    <span class="n">special_mask_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="L-890"><a href="#L-890"><span class="linenos"> 890</span></a>                    <span class="n">discriminator_sampling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">discriminator_sampling</span>
</span><span id="L-891"><a href="#L-891"><span class="linenos"> 891</span></a>                    <span class="p">)</span>
</span><span id="L-892"><a href="#L-892"><span class="linenos"> 892</span></a>                
</span><span id="L-893"><a href="#L-893"><span class="linenos"> 893</span></a>                <span class="n">discriminator_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="p">)</span>
</span><span id="L-894"><a href="#L-894"><span class="linenos"> 894</span></a>                <span class="n">discriminator_loss</span><span class="p">,</span> <span class="n">discriminator_logits</span> <span class="o">=</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="L-895"><a href="#L-895"><span class="linenos"> 895</span></a>
</span><span id="L-896"><a href="#L-896"><span class="linenos"> 896</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">mlm_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">discriminator_weight</span> <span class="o">*</span> <span class="n">discriminator_loss</span>
</span><span id="L-897"><a href="#L-897"><span class="linenos"> 897</span></a>
</span><span id="L-898"><a href="#L-898"><span class="linenos"> 898</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-899"><a href="#L-899"><span class="linenos"> 899</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-900"><a href="#L-900"><span class="linenos"> 900</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-901"><a href="#L-901"><span class="linenos"> 901</span></a>
</span><span id="L-902"><a href="#L-902"><span class="linenos"> 902</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="L-903"><a href="#L-903"><span class="linenos"> 903</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="L-904"><a href="#L-904"><span class="linenos"> 904</span></a>
</span><span id="L-905"><a href="#L-905"><span class="linenos"> 905</span></a>                <span class="c1"># determine gradients</span>
</span><span id="L-906"><a href="#L-906"><span class="linenos"> 906</span></a>                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="L-907"><a href="#L-907"><span class="linenos"> 907</span></a>
</span><span id="L-908"><a href="#L-908"><span class="linenos"> 908</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="L-909"><a href="#L-909"><span class="linenos"> 909</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">,</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-910"><a href="#L-910"><span class="linenos"> 910</span></a>
</span><span id="L-911"><a href="#L-911"><span class="linenos"> 911</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="L-912"><a href="#L-912"><span class="linenos"> 912</span></a>                <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">]</span>
</span><span id="L-913"><a href="#L-913"><span class="linenos"> 913</span></a>                <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="L-914"><a href="#L-914"><span class="linenos"> 914</span></a>
</span><span id="L-915"><a href="#L-915"><span class="linenos"> 915</span></a>
</span><span id="L-916"><a href="#L-916"><span class="linenos"> 916</span></a>                <span class="c1"># update parameters        </span>
</span><span id="L-917"><a href="#L-917"><span class="linenos"> 917</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="L-918"><a href="#L-918"><span class="linenos"> 918</span></a>                <span class="c1"># update learning rate</span>
</span><span id="L-919"><a href="#L-919"><span class="linenos"> 919</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="L-920"><a href="#L-920"><span class="linenos"> 920</span></a>
</span><span id="L-921"><a href="#L-921"><span class="linenos"> 921</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="L-922"><a href="#L-922"><span class="linenos"> 922</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="L-923"><a href="#L-923"><span class="linenos"> 923</span></a>                    <span class="c1"># mask to identify ids which have been masked before</span>
</span><span id="L-924"><a href="#L-924"><span class="linenos"> 924</span></a>                    <span class="n">masked_ids_mask</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span>
</span><span id="L-925"><a href="#L-925"><span class="linenos"> 925</span></a>                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-926"><a href="#L-926"><span class="linenos"> 926</span></a>                    <span class="n">mlm_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">]</span> <span class="o">==</span> <span class="n">generator_labels</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="L-927"><a href="#L-927"><span class="linenos"> 927</span></a>                    <span class="n">active_loss</span> <span class="o">=</span> <span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="L-928"><a href="#L-928"><span class="linenos"> 928</span></a>                    <span class="n">active_logits</span> <span class="o">=</span> <span class="n">discriminator_logits</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="L-929"><a href="#L-929"><span class="linenos"> 929</span></a>                    <span class="n">active_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">active_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
</span><span id="L-930"><a href="#L-930"><span class="linenos"> 930</span></a>                    <span class="n">active_labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="L-931"><a href="#L-931"><span class="linenos"> 931</span></a>                    <span class="n">discriminator_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">active_predictions</span> <span class="o">==</span> <span class="n">active_labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="L-932"><a href="#L-932"><span class="linenos"> 932</span></a>                    <span class="n">discriminator_precision</span> <span class="o">=</span> <span class="n">binary_precision</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="L-933"><a href="#L-933"><span class="linenos"> 933</span></a>                    <span class="n">discriminator_recall</span> <span class="o">=</span> <span class="n">binary_recall</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="L-934"><a href="#L-934"><span class="linenos"> 934</span></a>
</span><span id="L-935"><a href="#L-935"><span class="linenos"> 935</span></a>
</span><span id="L-936"><a href="#L-936"><span class="linenos"> 936</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-937"><a href="#L-937"><span class="linenos"> 937</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-938"><a href="#L-938"><span class="linenos"> 938</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-939"><a href="#L-939"><span class="linenos"> 939</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="L-940"><a href="#L-940"><span class="linenos"> 940</span></a>
</span><span id="L-941"><a href="#L-941"><span class="linenos"> 941</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="L-942"><a href="#L-942"><span class="linenos"> 942</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-943"><a href="#L-943"><span class="linenos"> 943</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="L-944"><a href="#L-944"><span class="linenos"> 944</span></a>
</span><span id="L-945"><a href="#L-945"><span class="linenos"> 945</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-946"><a href="#L-946"><span class="linenos"> 946</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="L-947"><a href="#L-947"><span class="linenos"> 947</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-948"><a href="#L-948"><span class="linenos"> 948</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MLM Loss: </span><span class="si">{</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-949"><a href="#L-949"><span class="linenos"> 949</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Discriminator Loss: </span><span class="si">{</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-950"><a href="#L-950"><span class="linenos"> 950</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-951"><a href="#L-951"><span class="linenos"> 951</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-952"><a href="#L-952"><span class="linenos"> 952</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for masking task: </span><span class="si">{</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-953"><a href="#L-953"><span class="linenos"> 953</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for replacement task: </span><span class="si">{</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-954"><a href="#L-954"><span class="linenos"> 954</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision for replacement task: </span><span class="si">{</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-955"><a href="#L-955"><span class="linenos"> 955</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall for replacement task: </span><span class="si">{</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-956"><a href="#L-956"><span class="linenos"> 956</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="L-957"><a href="#L-957"><span class="linenos"> 957</span></a>
</span><span id="L-958"><a href="#L-958"><span class="linenos"> 958</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="L-959"><a href="#L-959"><span class="linenos"> 959</span></a>
</span><span id="L-960"><a href="#L-960"><span class="linenos"> 960</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="L-961"><a href="#L-961"><span class="linenos"> 961</span></a>        
</span><span id="L-962"><a href="#L-962"><span class="linenos"> 962</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;electra&quot;</span><span class="p">)</span>
</span><span id="L-963"><a href="#L-963"><span class="linenos"> 963</span></a>        <span class="c1"># create a function for making an output directory which creates it and saves the csv and model</span>
</span><span id="L-964"><a href="#L-964"><span class="linenos"> 964</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="L-965"><a href="#L-965"><span class="linenos"> 965</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;mlm_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="L-966"><a href="#L-966"><span class="linenos"> 966</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="L-967"><a href="#L-967"><span class="linenos"> 967</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_precision&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="L-968"><a href="#L-968"><span class="linenos"> 968</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="L-969"><a href="#L-969"><span class="linenos"> 969</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;mlm_model&quot;</span><span class="p">)</span>
</span><span id="L-970"><a href="#L-970"><span class="linenos"> 970</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;discriminator_model&quot;</span><span class="p">)</span>
</span><span id="L-971"><a href="#L-971"><span class="linenos"> 971</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="L-972"><a href="#L-972"><span class="linenos"> 972</span></a>
</span><span id="L-973"><a href="#L-973"><span class="linenos"> 973</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span><span id="L-974"><a href="#L-974"><span class="linenos"> 974</span></a>
</span><span id="L-975"><a href="#L-975"><span class="linenos"> 975</span></a>
</span><span id="L-976"><a href="#L-976"><span class="linenos"> 976</span></a><span class="c1">#########################################################################################################################</span>
</span><span id="L-977"><a href="#L-977"><span class="linenos"> 977</span></a><span class="c1"># Models for finetuning</span>
</span><span id="L-978"><a href="#L-978"><span class="linenos"> 978</span></a><span class="c1">#########################################################################################################################</span>
</span><span id="L-979"><a href="#L-979"><span class="linenos"> 979</span></a>
</span><span id="L-980"><a href="#L-980"><span class="linenos"> 980</span></a><span class="k">class</span> <span class="nc">ElectraSimpleAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-981"><a href="#L-981"><span class="linenos"> 981</span></a><span class="w">    </span>
</span><span id="L-982"><a href="#L-982"><span class="linenos"> 982</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-983"><a href="#L-983"><span class="linenos"> 983</span></a><span class="sd">    A single-head attention layer for use in the Electra model.</span>
</span><span id="L-984"><a href="#L-984"><span class="linenos"> 984</span></a>
</span><span id="L-985"><a href="#L-985"><span class="linenos"> 985</span></a><span class="sd">    This class implements a simple attention mechanism, where attention scores are computed </span>
</span><span id="L-986"><a href="#L-986"><span class="linenos"> 986</span></a><span class="sd">    using a single attention head. The attention layer includes dropout and can optionally </span>
</span><span id="L-987"><a href="#L-987"><span class="linenos"> 987</span></a><span class="sd">    return attention probabilities.</span>
</span><span id="L-988"><a href="#L-988"><span class="linenos"> 988</span></a>
</span><span id="L-989"><a href="#L-989"><span class="linenos"> 989</span></a><span class="sd">    Attributes</span>
</span><span id="L-990"><a href="#L-990"><span class="linenos"> 990</span></a><span class="sd">    ----------</span>
</span><span id="L-991"><a href="#L-991"><span class="linenos"> 991</span></a><span class="sd">    hidden_size : int</span>
</span><span id="L-992"><a href="#L-992"><span class="linenos"> 992</span></a><span class="sd">        The size of the hidden layer in the attention mechanism.</span>
</span><span id="L-993"><a href="#L-993"><span class="linenos"> 993</span></a><span class="sd">    query : nn.Linear</span>
</span><span id="L-994"><a href="#L-994"><span class="linenos"> 994</span></a><span class="sd">        The linear layer that projects the input to the query space.</span>
</span><span id="L-995"><a href="#L-995"><span class="linenos"> 995</span></a><span class="sd">    key : nn.Linear</span>
</span><span id="L-996"><a href="#L-996"><span class="linenos"> 996</span></a><span class="sd">        The linear layer that projects the input to the key space.</span>
</span><span id="L-997"><a href="#L-997"><span class="linenos"> 997</span></a><span class="sd">    value : nn.Linear</span>
</span><span id="L-998"><a href="#L-998"><span class="linenos"> 998</span></a><span class="sd">        The linear layer that projects the input to the value space.</span>
</span><span id="L-999"><a href="#L-999"><span class="linenos"> 999</span></a><span class="sd">    dropout : nn.Dropout</span>
</span><span id="L-1000"><a href="#L-1000"><span class="linenos">1000</span></a><span class="sd">        Dropout applied to the attention probabilities.</span>
</span><span id="L-1001"><a href="#L-1001"><span class="linenos">1001</span></a>
</span><span id="L-1002"><a href="#L-1002"><span class="linenos">1002</span></a><span class="sd">    Methods</span>
</span><span id="L-1003"><a href="#L-1003"><span class="linenos">1003</span></a><span class="sd">    -------</span>
</span><span id="L-1004"><a href="#L-1004"><span class="linenos">1004</span></a><span class="sd">    forward(sequence_embeddings: torch.Tensor, return_attention: bool = True) -&gt; Tuple[torch.Tensor, ...]</span>
</span><span id="L-1005"><a href="#L-1005"><span class="linenos">1005</span></a><span class="sd">        Performs the forward pass, calculating the attention output and optionally returning the attention probabilities.</span>
</span><span id="L-1006"><a href="#L-1006"><span class="linenos">1006</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1007"><a href="#L-1007"><span class="linenos">1007</span></a>
</span><span id="L-1008"><a href="#L-1008"><span class="linenos">1008</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-1009"><a href="#L-1009"><span class="linenos">1009</span></a>
</span><span id="L-1010"><a href="#L-1010"><span class="linenos">1010</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1011"><a href="#L-1011"><span class="linenos">1011</span></a><span class="sd">        Initializes the ElectraSimpleAttention layer with the provided configuration.</span>
</span><span id="L-1012"><a href="#L-1012"><span class="linenos">1012</span></a>
</span><span id="L-1013"><a href="#L-1013"><span class="linenos">1013</span></a><span class="sd">        Parameters</span>
</span><span id="L-1014"><a href="#L-1014"><span class="linenos">1014</span></a><span class="sd">        ----------</span>
</span><span id="L-1015"><a href="#L-1015"><span class="linenos">1015</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="L-1016"><a href="#L-1016"><span class="linenos">1016</span></a><span class="sd">            The configuration object containing the hidden size and dropout probability.</span>
</span><span id="L-1017"><a href="#L-1017"><span class="linenos">1017</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1018"><a href="#L-1018"><span class="linenos">1018</span></a>
</span><span id="L-1019"><a href="#L-1019"><span class="linenos">1019</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-1020"><a href="#L-1020"><span class="linenos">1020</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
</span><span id="L-1021"><a href="#L-1021"><span class="linenos">1021</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-1022"><a href="#L-1022"><span class="linenos">1022</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-1023"><a href="#L-1023"><span class="linenos">1023</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-1024"><a href="#L-1024"><span class="linenos">1024</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span><span class="p">)</span>
</span><span id="L-1025"><a href="#L-1025"><span class="linenos">1025</span></a>
</span><span id="L-1026"><a href="#L-1026"><span class="linenos">1026</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="L-1027"><a href="#L-1027"><span class="linenos">1027</span></a>
</span><span id="L-1028"><a href="#L-1028"><span class="linenos">1028</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1029"><a href="#L-1029"><span class="linenos">1029</span></a><span class="sd">        Performs the forward pass of the attention layer.</span>
</span><span id="L-1030"><a href="#L-1030"><span class="linenos">1030</span></a>
</span><span id="L-1031"><a href="#L-1031"><span class="linenos">1031</span></a><span class="sd">        Parameters</span>
</span><span id="L-1032"><a href="#L-1032"><span class="linenos">1032</span></a><span class="sd">        ----------</span>
</span><span id="L-1033"><a href="#L-1033"><span class="linenos">1033</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="L-1034"><a href="#L-1034"><span class="linenos">1034</span></a><span class="sd">            The input sequence embeddings of shape (number of sequences over all batched documents, hidden_size).</span>
</span><span id="L-1035"><a href="#L-1035"><span class="linenos">1035</span></a><span class="sd">            Before this mechanism is applied the nested document sequences are flattened and sequence embeddings are extracted.</span>
</span><span id="L-1036"><a href="#L-1036"><span class="linenos">1036</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="L-1037"><a href="#L-1037"><span class="linenos">1037</span></a><span class="sd">            If True, returns the attention probabilities along with the context layer (default is True).</span>
</span><span id="L-1038"><a href="#L-1038"><span class="linenos">1038</span></a>
</span><span id="L-1039"><a href="#L-1039"><span class="linenos">1039</span></a><span class="sd">        Returns</span>
</span><span id="L-1040"><a href="#L-1040"><span class="linenos">1040</span></a><span class="sd">        -------</span>
</span><span id="L-1041"><a href="#L-1041"><span class="linenos">1041</span></a><span class="sd">        Tuple[torch.Tensor, ...]</span>
</span><span id="L-1042"><a href="#L-1042"><span class="linenos">1042</span></a><span class="sd">            The context layer and, optionally, the attention probabilities.</span>
</span><span id="L-1043"><a href="#L-1043"><span class="linenos">1043</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1044"><a href="#L-1044"><span class="linenos">1044</span></a>
</span><span id="L-1045"><a href="#L-1045"><span class="linenos">1045</span></a>        <span class="n">query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="L-1046"><a href="#L-1046"><span class="linenos">1046</span></a>        <span class="n">key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="L-1047"><a href="#L-1047"><span class="linenos">1047</span></a>        <span class="n">value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="L-1048"><a href="#L-1048"><span class="linenos">1048</span></a>
</span><span id="L-1049"><a href="#L-1049"><span class="linenos">1049</span></a>        <span class="c1"># determine attention scores and weights</span>
</span><span id="L-1050"><a href="#L-1050"><span class="linenos">1050</span></a>        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query_layer</span><span class="p">,</span> <span class="n">key_layer</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="L-1051"><a href="#L-1051"><span class="linenos">1051</span></a>        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-1052"><a href="#L-1052"><span class="linenos">1052</span></a>
</span><span id="L-1053"><a href="#L-1053"><span class="linenos">1053</span></a>        <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-1054"><a href="#L-1054"><span class="linenos">1054</span></a>        <span class="n">attention_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">)</span>
</span><span id="L-1055"><a href="#L-1055"><span class="linenos">1055</span></a>
</span><span id="L-1056"><a href="#L-1056"><span class="linenos">1056</span></a>        <span class="n">context_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">,</span> <span class="n">value_layer</span><span class="p">)</span> 
</span><span id="L-1057"><a href="#L-1057"><span class="linenos">1057</span></a>
</span><span id="L-1058"><a href="#L-1058"><span class="linenos">1058</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">context_layer</span><span class="p">,</span> <span class="n">attention_probs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">context_layer</span><span class="p">,</span> <span class="p">)</span>
</span><span id="L-1059"><a href="#L-1059"><span class="linenos">1059</span></a>
</span><span id="L-1060"><a href="#L-1060"><span class="linenos">1060</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="L-1061"><a href="#L-1061"><span class="linenos">1061</span></a>
</span><span id="L-1062"><a href="#L-1062"><span class="linenos">1062</span></a><span class="k">class</span> <span class="nc">ElectraSimpleAttentionOutput</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-1063"><a href="#L-1063"><span class="linenos">1063</span></a><span class="w">    </span>
</span><span id="L-1064"><a href="#L-1064"><span class="linenos">1064</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1065"><a href="#L-1065"><span class="linenos">1065</span></a><span class="sd">    Outputs from the ElectraSimpleAttention layer, with residual connections and aggregation.</span>
</span><span id="L-1066"><a href="#L-1066"><span class="linenos">1066</span></a>
</span><span id="L-1067"><a href="#L-1067"><span class="linenos">1067</span></a><span class="sd">    This class applies a dense layer, dropout, and LayerNorm to the sequence attention embeddings.</span>
</span><span id="L-1068"><a href="#L-1068"><span class="linenos">1068</span></a><span class="sd">    It also aggregates sequence embeddings by averaging and applies a residual connection.</span>
</span><span id="L-1069"><a href="#L-1069"><span class="linenos">1069</span></a>
</span><span id="L-1070"><a href="#L-1070"><span class="linenos">1070</span></a><span class="sd">    Attributes</span>
</span><span id="L-1071"><a href="#L-1071"><span class="linenos">1071</span></a><span class="sd">    ----------</span>
</span><span id="L-1072"><a href="#L-1072"><span class="linenos">1072</span></a><span class="sd">    dense : nn.Linear</span>
</span><span id="L-1073"><a href="#L-1073"><span class="linenos">1073</span></a><span class="sd">        A linear layer applied to the attention output.</span>
</span><span id="L-1074"><a href="#L-1074"><span class="linenos">1074</span></a><span class="sd">    dropout : nn.Dropout</span>
</span><span id="L-1075"><a href="#L-1075"><span class="linenos">1075</span></a><span class="sd">        Dropout applied to the attention output.</span>
</span><span id="L-1076"><a href="#L-1076"><span class="linenos">1076</span></a><span class="sd">    LayerNorm : nn.LayerNorm</span>
</span><span id="L-1077"><a href="#L-1077"><span class="linenos">1077</span></a><span class="sd">        Layer normalization applied after adding the residual connection.</span>
</span><span id="L-1078"><a href="#L-1078"><span class="linenos">1078</span></a><span class="sd">    out_projection : nn.Linear</span>
</span><span id="L-1079"><a href="#L-1079"><span class="linenos">1079</span></a><span class="sd">        A linear layer that projects the aggregated embeddings to the number of labels.</span>
</span><span id="L-1080"><a href="#L-1080"><span class="linenos">1080</span></a>
</span><span id="L-1081"><a href="#L-1081"><span class="linenos">1081</span></a><span class="sd">    Methods</span>
</span><span id="L-1082"><a href="#L-1082"><span class="linenos">1082</span></a><span class="sd">    -------</span>
</span><span id="L-1083"><a href="#L-1083"><span class="linenos">1083</span></a><span class="sd">    forward(sequence_attention_embeddings: torch.Tensor, sequence_embeddings: torch.Tensor, original_shapes: List[int]) -&gt; torch.Tensor</span>
</span><span id="L-1084"><a href="#L-1084"><span class="linenos">1084</span></a><span class="sd">        Performs the forward pass, applying the dense layer, residual connection, and aggregation.</span>
</span><span id="L-1085"><a href="#L-1085"><span class="linenos">1085</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1086"><a href="#L-1086"><span class="linenos">1086</span></a>
</span><span id="L-1087"><a href="#L-1087"><span class="linenos">1087</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-1088"><a href="#L-1088"><span class="linenos">1088</span></a>
</span><span id="L-1089"><a href="#L-1089"><span class="linenos">1089</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1090"><a href="#L-1090"><span class="linenos">1090</span></a><span class="sd">        Initializes the ElectraSimpleAttentionOutput layer with the provided configuration.</span>
</span><span id="L-1091"><a href="#L-1091"><span class="linenos">1091</span></a>
</span><span id="L-1092"><a href="#L-1092"><span class="linenos">1092</span></a><span class="sd">        Parameters</span>
</span><span id="L-1093"><a href="#L-1093"><span class="linenos">1093</span></a><span class="sd">        ----------</span>
</span><span id="L-1094"><a href="#L-1094"><span class="linenos">1094</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="L-1095"><a href="#L-1095"><span class="linenos">1095</span></a><span class="sd">            The configuration object containing the hidden size, dropout probability, and number of labels.</span>
</span><span id="L-1096"><a href="#L-1096"><span class="linenos">1096</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1097"><a href="#L-1097"><span class="linenos">1097</span></a>
</span><span id="L-1098"><a href="#L-1098"><span class="linenos">1098</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-1099"><a href="#L-1099"><span class="linenos">1099</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-1100"><a href="#L-1100"><span class="linenos">1100</span></a>        <span class="c1"># dropout</span>
</span><span id="L-1101"><a href="#L-1101"><span class="linenos">1101</span></a>        <span class="n">aggregation_head_dropout</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-1102"><a href="#L-1102"><span class="linenos">1102</span></a>            <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span>
</span><span id="L-1103"><a href="#L-1103"><span class="linenos">1103</span></a>        <span class="p">)</span>
</span><span id="L-1104"><a href="#L-1104"><span class="linenos">1104</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">aggregation_head_dropout</span><span class="p">)</span>
</span><span id="L-1105"><a href="#L-1105"><span class="linenos">1105</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>
</span><span id="L-1106"><a href="#L-1106"><span class="linenos">1106</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span><span id="L-1107"><a href="#L-1107"><span class="linenos">1107</span></a>
</span><span id="L-1108"><a href="#L-1108"><span class="linenos">1108</span></a>
</span><span id="L-1109"><a href="#L-1109"><span class="linenos">1109</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">):</span>
</span><span id="L-1110"><a href="#L-1110"><span class="linenos">1110</span></a><span class="w">        </span>
</span><span id="L-1111"><a href="#L-1111"><span class="linenos">1111</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1112"><a href="#L-1112"><span class="linenos">1112</span></a><span class="sd">        Performs the forward pass of the attention output layer.</span>
</span><span id="L-1113"><a href="#L-1113"><span class="linenos">1113</span></a>
</span><span id="L-1114"><a href="#L-1114"><span class="linenos">1114</span></a><span class="sd">        Parameters</span>
</span><span id="L-1115"><a href="#L-1115"><span class="linenos">1115</span></a><span class="sd">        ----------</span>
</span><span id="L-1116"><a href="#L-1116"><span class="linenos">1116</span></a><span class="sd">        sequence_attention_embeddings : torch.Tensor</span>
</span><span id="L-1117"><a href="#L-1117"><span class="linenos">1117</span></a><span class="sd">            The embeddings output from the attention layer.</span>
</span><span id="L-1118"><a href="#L-1118"><span class="linenos">1118</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="L-1119"><a href="#L-1119"><span class="linenos">1119</span></a><span class="sd">            The original sequence embeddings for the residual connection.</span>
</span><span id="L-1120"><a href="#L-1120"><span class="linenos">1120</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="L-1121"><a href="#L-1121"><span class="linenos">1121</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="L-1122"><a href="#L-1122"><span class="linenos">1122</span></a>
</span><span id="L-1123"><a href="#L-1123"><span class="linenos">1123</span></a><span class="sd">        Returns</span>
</span><span id="L-1124"><a href="#L-1124"><span class="linenos">1124</span></a><span class="sd">        -------</span>
</span><span id="L-1125"><a href="#L-1125"><span class="linenos">1125</span></a><span class="sd">        torch.Tensor</span>
</span><span id="L-1126"><a href="#L-1126"><span class="linenos">1126</span></a><span class="sd">            The logits for each aggregated sequence.</span>
</span><span id="L-1127"><a href="#L-1127"><span class="linenos">1127</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1128"><a href="#L-1128"><span class="linenos">1128</span></a>
</span><span id="L-1129"><a href="#L-1129"><span class="linenos">1129</span></a>        <span class="c1"># sequence attention embeddings are the ones coming from the simple attention layer</span>
</span><span id="L-1130"><a href="#L-1130"><span class="linenos">1130</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">)</span>
</span><span id="L-1131"><a href="#L-1131"><span class="linenos">1131</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">)</span>
</span><span id="L-1132"><a href="#L-1132"><span class="linenos">1132</span></a>        <span class="c1"># residual connection with the original sequence embeddings</span>
</span><span id="L-1133"><a href="#L-1133"><span class="linenos">1133</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span> <span class="o">+</span> <span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="L-1134"><a href="#L-1134"><span class="linenos">1134</span></a>        <span class="n">sequence_attention_embeddings_original_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="L-1135"><a href="#L-1135"><span class="linenos">1135</span></a>        <span class="n">sequence_attention_embeddings_aggregated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch_tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">torch_tensor</span> <span class="ow">in</span> <span class="n">sequence_attention_embeddings_original_shapes</span><span class="p">])</span>
</span><span id="L-1136"><a href="#L-1136"><span class="linenos">1136</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">sequence_attention_embeddings_aggregated</span><span class="p">)</span>
</span><span id="L-1137"><a href="#L-1137"><span class="linenos">1137</span></a> 
</span><span id="L-1138"><a href="#L-1138"><span class="linenos">1138</span></a>        <span class="k">return</span> <span class="n">logits</span>
</span><span id="L-1139"><a href="#L-1139"><span class="linenos">1139</span></a>
</span><span id="L-1140"><a href="#L-1140"><span class="linenos">1140</span></a>
</span><span id="L-1141"><a href="#L-1141"><span class="linenos">1141</span></a><span class="k">class</span> <span class="nc">ElectraSimpleAttentionHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-1142"><a href="#L-1142"><span class="linenos">1142</span></a><span class="w">    </span>
</span><span id="L-1143"><a href="#L-1143"><span class="linenos">1143</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1144"><a href="#L-1144"><span class="linenos">1144</span></a><span class="sd">    A combination of simple attention and output layers with aggregation.</span>
</span><span id="L-1145"><a href="#L-1145"><span class="linenos">1145</span></a>
</span><span id="L-1146"><a href="#L-1146"><span class="linenos">1146</span></a><span class="sd">    This class combines the ElectraSimpleAttention and ElectraSimpleAttentionOutput layers </span>
</span><span id="L-1147"><a href="#L-1147"><span class="linenos">1147</span></a><span class="sd">    to produce a final prediction for a sequence, with optional attention probability output.</span>
</span><span id="L-1148"><a href="#L-1148"><span class="linenos">1148</span></a>
</span><span id="L-1149"><a href="#L-1149"><span class="linenos">1149</span></a><span class="sd">    Attributes</span>
</span><span id="L-1150"><a href="#L-1150"><span class="linenos">1150</span></a><span class="sd">    ----------</span>
</span><span id="L-1151"><a href="#L-1151"><span class="linenos">1151</span></a><span class="sd">    simple_attention : ElectraSimpleAttention</span>
</span><span id="L-1152"><a href="#L-1152"><span class="linenos">1152</span></a><span class="sd">        The simple attention layer.</span>
</span><span id="L-1153"><a href="#L-1153"><span class="linenos">1153</span></a><span class="sd">    attention_output : ElectraSimpleAttentionOutput</span>
</span><span id="L-1154"><a href="#L-1154"><span class="linenos">1154</span></a><span class="sd">        The output layer that processes and aggregates the attention embeddings.</span>
</span><span id="L-1155"><a href="#L-1155"><span class="linenos">1155</span></a>
</span><span id="L-1156"><a href="#L-1156"><span class="linenos">1156</span></a><span class="sd">    Methods</span>
</span><span id="L-1157"><a href="#L-1157"><span class="linenos">1157</span></a><span class="sd">    -------</span>
</span><span id="L-1158"><a href="#L-1158"><span class="linenos">1158</span></a><span class="sd">    forward(sequence_embeddings: torch.Tensor, original_shapes: List[int], return_attention: bool = True) -&gt; Tuple[torch.Tensor, ...]</span>
</span><span id="L-1159"><a href="#L-1159"><span class="linenos">1159</span></a><span class="sd">        Performs the forward pass through the attention and output layers.</span>
</span><span id="L-1160"><a href="#L-1160"><span class="linenos">1160</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1161"><a href="#L-1161"><span class="linenos">1161</span></a>
</span><span id="L-1162"><a href="#L-1162"><span class="linenos">1162</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-1163"><a href="#L-1163"><span class="linenos">1163</span></a>
</span><span id="L-1164"><a href="#L-1164"><span class="linenos">1164</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1165"><a href="#L-1165"><span class="linenos">1165</span></a><span class="sd">        Initializes the ElectraSimpleAttentionHead with the provided configuration.</span>
</span><span id="L-1166"><a href="#L-1166"><span class="linenos">1166</span></a>
</span><span id="L-1167"><a href="#L-1167"><span class="linenos">1167</span></a><span class="sd">        Parameters</span>
</span><span id="L-1168"><a href="#L-1168"><span class="linenos">1168</span></a><span class="sd">        ----------</span>
</span><span id="L-1169"><a href="#L-1169"><span class="linenos">1169</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="L-1170"><a href="#L-1170"><span class="linenos">1170</span></a><span class="sd">            The configuration object containing the necessary model parameters.</span>
</span><span id="L-1171"><a href="#L-1171"><span class="linenos">1171</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1172"><a href="#L-1172"><span class="linenos">1172</span></a>
</span><span id="L-1173"><a href="#L-1173"><span class="linenos">1173</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-1174"><a href="#L-1174"><span class="linenos">1174</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">simple_attention</span> <span class="o">=</span> <span class="n">ElectraSimpleAttention</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-1175"><a href="#L-1175"><span class="linenos">1175</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_output</span> <span class="o">=</span> <span class="n">ElectraSimpleAttentionOutput</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-1176"><a href="#L-1176"><span class="linenos">1176</span></a>
</span><span id="L-1177"><a href="#L-1177"><span class="linenos">1177</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="L-1178"><a href="#L-1178"><span class="linenos">1178</span></a>
</span><span id="L-1179"><a href="#L-1179"><span class="linenos">1179</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1180"><a href="#L-1180"><span class="linenos">1180</span></a><span class="sd">        Performs the forward pass through the attention and output layers.</span>
</span><span id="L-1181"><a href="#L-1181"><span class="linenos">1181</span></a>
</span><span id="L-1182"><a href="#L-1182"><span class="linenos">1182</span></a><span class="sd">        Parameters</span>
</span><span id="L-1183"><a href="#L-1183"><span class="linenos">1183</span></a><span class="sd">        ----------</span>
</span><span id="L-1184"><a href="#L-1184"><span class="linenos">1184</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="L-1185"><a href="#L-1185"><span class="linenos">1185</span></a><span class="sd">            The flattened input sequence embeddings of shape (number of sequences over all batched documents, hidden_size).</span>
</span><span id="L-1186"><a href="#L-1186"><span class="linenos">1186</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="L-1187"><a href="#L-1187"><span class="linenos">1187</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="L-1188"><a href="#L-1188"><span class="linenos">1188</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="L-1189"><a href="#L-1189"><span class="linenos">1189</span></a><span class="sd">            If True, returns the attention probabilities along with the logits (default is True).</span>
</span><span id="L-1190"><a href="#L-1190"><span class="linenos">1190</span></a>
</span><span id="L-1191"><a href="#L-1191"><span class="linenos">1191</span></a><span class="sd">        Returns</span>
</span><span id="L-1192"><a href="#L-1192"><span class="linenos">1192</span></a><span class="sd">        -------</span>
</span><span id="L-1193"><a href="#L-1193"><span class="linenos">1193</span></a><span class="sd">        Tuple[torch.Tensor, ...]</span>
</span><span id="L-1194"><a href="#L-1194"><span class="linenos">1194</span></a><span class="sd">            The logits for each sequence and, optionally, the attention probabilities.</span>
</span><span id="L-1195"><a href="#L-1195"><span class="linenos">1195</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1196"><a href="#L-1196"><span class="linenos">1196</span></a>
</span><span id="L-1197"><a href="#L-1197"><span class="linenos">1197</span></a>
</span><span id="L-1198"><a href="#L-1198"><span class="linenos">1198</span></a>        <span class="c1"># determine simple attention output and attention probabilities (if return_attention is set to True)</span>
</span><span id="L-1199"><a href="#L-1199"><span class="linenos">1199</span></a>        <span class="n">simple_attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">simple_attention</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="n">return_attention</span><span class="p">)</span>
</span><span id="L-1200"><a href="#L-1200"><span class="linenos">1200</span></a>
</span><span id="L-1201"><a href="#L-1201"><span class="linenos">1201</span></a>        <span class="c1"># get sequence attention embeddings after simple attention layer</span>
</span><span id="L-1202"><a href="#L-1202"><span class="linenos">1202</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="n">simple_attention_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-1203"><a href="#L-1203"><span class="linenos">1203</span></a>
</span><span id="L-1204"><a href="#L-1204"><span class="linenos">1204</span></a>        <span class="k">if</span> <span class="n">return_attention</span><span class="p">:</span>
</span><span id="L-1205"><a href="#L-1205"><span class="linenos">1205</span></a>            <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">simple_attention_output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-1206"><a href="#L-1206"><span class="linenos">1206</span></a>
</span><span id="L-1207"><a href="#L-1207"><span class="linenos">1207</span></a>        <span class="c1"># process sequence attention embeddings through a dense layer and create a residual connection with the original sequence embeddings</span>
</span><span id="L-1208"><a href="#L-1208"><span class="linenos">1208</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_output</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">)</span>
</span><span id="L-1209"><a href="#L-1209"><span class="linenos">1209</span></a>        
</span><span id="L-1210"><a href="#L-1210"><span class="linenos">1210</span></a>        <span class="c1"># output prediction and optionally the attention probabilities</span>
</span><span id="L-1211"><a href="#L-1211"><span class="linenos">1211</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">attention_probs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">logits</span><span class="p">,)</span>
</span><span id="L-1212"><a href="#L-1212"><span class="linenos">1212</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="L-1213"><a href="#L-1213"><span class="linenos">1213</span></a>
</span><span id="L-1214"><a href="#L-1214"><span class="linenos">1214</span></a>
</span><span id="L-1215"><a href="#L-1215"><span class="linenos">1215</span></a><span class="k">class</span> <span class="nc">ElectraForAggregatePredictionWithAttention</span><span class="p">(</span><span class="n">ElectraPreTrainedModel</span><span class="p">):</span>
</span><span id="L-1216"><a href="#L-1216"><span class="linenos">1216</span></a>
</span><span id="L-1217"><a href="#L-1217"><span class="linenos">1217</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1218"><a href="#L-1218"><span class="linenos">1218</span></a><span class="sd">    An Electra model with aggregate prediction using attention mechanisms.</span>
</span><span id="L-1219"><a href="#L-1219"><span class="linenos">1219</span></a>
</span><span id="L-1220"><a href="#L-1220"><span class="linenos">1220</span></a><span class="sd">    This class extends the Electra model by adding a custom head for aggregate prediction.</span>
</span><span id="L-1221"><a href="#L-1221"><span class="linenos">1221</span></a><span class="sd">    It combines token embeddings into sequence embeddings, applies attention, and makes </span>
</span><span id="L-1222"><a href="#L-1222"><span class="linenos">1222</span></a><span class="sd">    predictions for entire documents which consist of sequences.</span>
</span><span id="L-1223"><a href="#L-1223"><span class="linenos">1223</span></a>
</span><span id="L-1224"><a href="#L-1224"><span class="linenos">1224</span></a><span class="sd">    Attributes</span>
</span><span id="L-1225"><a href="#L-1225"><span class="linenos">1225</span></a><span class="sd">    ----------</span>
</span><span id="L-1226"><a href="#L-1226"><span class="linenos">1226</span></a><span class="sd">    config : ElectraConfig</span>
</span><span id="L-1227"><a href="#L-1227"><span class="linenos">1227</span></a><span class="sd">        The configuration object for the Electra model.</span>
</span><span id="L-1228"><a href="#L-1228"><span class="linenos">1228</span></a><span class="sd">    num_labels : int</span>
</span><span id="L-1229"><a href="#L-1229"><span class="linenos">1229</span></a><span class="sd">        The number of labels for classification tasks.</span>
</span><span id="L-1230"><a href="#L-1230"><span class="linenos">1230</span></a><span class="sd">    electra : ElectraModel</span>
</span><span id="L-1231"><a href="#L-1231"><span class="linenos">1231</span></a><span class="sd">        The Electra encoder model for generating token embeddings.</span>
</span><span id="L-1232"><a href="#L-1232"><span class="linenos">1232</span></a><span class="sd">    head : ElectraSimpleAttentionHead</span>
</span><span id="L-1233"><a href="#L-1233"><span class="linenos">1233</span></a><span class="sd">        The custom head for making aggregate predictions with attention.</span>
</span><span id="L-1234"><a href="#L-1234"><span class="linenos">1234</span></a>
</span><span id="L-1235"><a href="#L-1235"><span class="linenos">1235</span></a><span class="sd">    Methods</span>
</span><span id="L-1236"><a href="#L-1236"><span class="linenos">1236</span></a><span class="sd">    -------</span>
</span><span id="L-1237"><a href="#L-1237"><span class="linenos">1237</span></a><span class="sd">    forward(input_ids: List[List[Tensor]], attention_mask: List[List[Tensor]], labels: Optional[torch.Tensor] = None, return_attention: bool = True) -&gt; Any</span>
</span><span id="L-1238"><a href="#L-1238"><span class="linenos">1238</span></a><span class="sd">        Performs the forward pass, generating sequence embeddings and making predictions.</span>
</span><span id="L-1239"><a href="#L-1239"><span class="linenos">1239</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1240"><a href="#L-1240"><span class="linenos">1240</span></a>
</span><span id="L-1241"><a href="#L-1241"><span class="linenos">1241</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-1242"><a href="#L-1242"><span class="linenos">1242</span></a>
</span><span id="L-1243"><a href="#L-1243"><span class="linenos">1243</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1244"><a href="#L-1244"><span class="linenos">1244</span></a><span class="sd">        Initializes the ElectraForAggregatePredictionWithAttention model.</span>
</span><span id="L-1245"><a href="#L-1245"><span class="linenos">1245</span></a>
</span><span id="L-1246"><a href="#L-1246"><span class="linenos">1246</span></a><span class="sd">        Parameters</span>
</span><span id="L-1247"><a href="#L-1247"><span class="linenos">1247</span></a><span class="sd">        ----------</span>
</span><span id="L-1248"><a href="#L-1248"><span class="linenos">1248</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="L-1249"><a href="#L-1249"><span class="linenos">1249</span></a><span class="sd">            The configuration object for the Electra model.</span>
</span><span id="L-1250"><a href="#L-1250"><span class="linenos">1250</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1251"><a href="#L-1251"><span class="linenos">1251</span></a>
</span><span id="L-1252"><a href="#L-1252"><span class="linenos">1252</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-1253"><a href="#L-1253"><span class="linenos">1253</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="L-1254"><a href="#L-1254"><span class="linenos">1254</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
</span><span id="L-1255"><a href="#L-1255"><span class="linenos">1255</span></a>        <span class="c1"># the encoder for creating token embeddings</span>
</span><span id="L-1256"><a href="#L-1256"><span class="linenos">1256</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">electra</span> <span class="o">=</span> <span class="n">ElectraModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-1257"><a href="#L-1257"><span class="linenos">1257</span></a>        <span class="c1"># the head for creating a single prediction for a batch of embeddings, in our case a batch of sequence embeddings</span>
</span><span id="L-1258"><a href="#L-1258"><span class="linenos">1258</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">ElectraSimpleAttentionHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-1259"><a href="#L-1259"><span class="linenos">1259</span></a>
</span><span id="L-1260"><a href="#L-1260"><span class="linenos">1260</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>
</span><span id="L-1261"><a href="#L-1261"><span class="linenos">1261</span></a>
</span><span id="L-1262"><a href="#L-1262"><span class="linenos">1262</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span><span id="L-1263"><a href="#L-1263"><span class="linenos">1263</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="L-1264"><a href="#L-1264"><span class="linenos">1264</span></a>        <span class="n">input_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1265"><a href="#L-1265"><span class="linenos">1265</span></a>        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1266"><a href="#L-1266"><span class="linenos">1266</span></a>        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1267"><a href="#L-1267"><span class="linenos">1267</span></a>        <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-1268"><a href="#L-1268"><span class="linenos">1268</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="L-1269"><a href="#L-1269"><span class="linenos">1269</span></a><span class="w">        </span>
</span><span id="L-1270"><a href="#L-1270"><span class="linenos">1270</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1271"><a href="#L-1271"><span class="linenos">1271</span></a><span class="sd">        Performs the forward pass of the Electra model with aggregate prediction.</span>
</span><span id="L-1272"><a href="#L-1272"><span class="linenos">1272</span></a>
</span><span id="L-1273"><a href="#L-1273"><span class="linenos">1273</span></a><span class="sd">        Parameters</span>
</span><span id="L-1274"><a href="#L-1274"><span class="linenos">1274</span></a><span class="sd">        ----------</span>
</span><span id="L-1275"><a href="#L-1275"><span class="linenos">1275</span></a><span class="sd">        input_ids : List[List[Tensor]]</span>
</span><span id="L-1276"><a href="#L-1276"><span class="linenos">1276</span></a><span class="sd">            A batch of input token IDs.</span>
</span><span id="L-1277"><a href="#L-1277"><span class="linenos">1277</span></a><span class="sd">        attention_mask : List[List[Tensor]]</span>
</span><span id="L-1278"><a href="#L-1278"><span class="linenos">1278</span></a><span class="sd">            A batch of attention masks corresponding to the input IDs.</span>
</span><span id="L-1279"><a href="#L-1279"><span class="linenos">1279</span></a><span class="sd">        labels : Optional[torch.Tensor], optional</span>
</span><span id="L-1280"><a href="#L-1280"><span class="linenos">1280</span></a><span class="sd">            Ground truth labels for the input sequences (default is None).</span>
</span><span id="L-1281"><a href="#L-1281"><span class="linenos">1281</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="L-1282"><a href="#L-1282"><span class="linenos">1282</span></a><span class="sd">            If True, returns attention probabilities along with the logits (default is True).</span>
</span><span id="L-1283"><a href="#L-1283"><span class="linenos">1283</span></a>
</span><span id="L-1284"><a href="#L-1284"><span class="linenos">1284</span></a><span class="sd">        Returns</span>
</span><span id="L-1285"><a href="#L-1285"><span class="linenos">1285</span></a><span class="sd">        -------</span>
</span><span id="L-1286"><a href="#L-1286"><span class="linenos">1286</span></a><span class="sd">        Any</span>
</span><span id="L-1287"><a href="#L-1287"><span class="linenos">1287</span></a><span class="sd">            The loss (if labels are provided), logits, and optionally the attention probabilities.</span>
</span><span id="L-1288"><a href="#L-1288"><span class="linenos">1288</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1289"><a href="#L-1289"><span class="linenos">1289</span></a>
</span><span id="L-1290"><a href="#L-1290"><span class="linenos">1290</span></a>       
</span><span id="L-1291"><a href="#L-1291"><span class="linenos">1291</span></a>        <span class="n">input_id_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_input_ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_input_ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
</span><span id="L-1292"><a href="#L-1292"><span class="linenos">1292</span></a>        <span class="n">attention_mask_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_attention_mask</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_attention_mask</span> <span class="ow">in</span> <span class="n">attention_mask</span><span class="p">]</span>
</span><span id="L-1293"><a href="#L-1293"><span class="linenos">1293</span></a>        <span class="c1"># Store the original shapes</span>
</span><span id="L-1294"><a href="#L-1294"><span class="linenos">1294</span></a>        <span class="n">original_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_ids_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">input_ids_tensor</span> <span class="ow">in</span> <span class="n">input_id_tensors</span><span class="p">]</span>
</span><span id="L-1295"><a href="#L-1295"><span class="linenos">1295</span></a>
</span><span id="L-1296"><a href="#L-1296"><span class="linenos">1296</span></a>        <span class="c1"># Step 2: Concatenate the tensors along the first dimension</span>
</span><span id="L-1297"><a href="#L-1297"><span class="linenos">1297</span></a>        <span class="n">flattened_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_id_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="L-1298"><a href="#L-1298"><span class="linenos">1298</span></a>        <span class="n">flattened_attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attention_mask_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="L-1299"><a href="#L-1299"><span class="linenos">1299</span></a>
</span><span id="L-1300"><a href="#L-1300"><span class="linenos">1300</span></a>        <span class="n">discriminator_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">electra</span><span class="p">(</span>
</span><span id="L-1301"><a href="#L-1301"><span class="linenos">1301</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">flattened_input_ids</span><span class="p">,</span>
</span><span id="L-1302"><a href="#L-1302"><span class="linenos">1302</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">flattened_attention_mask</span><span class="p">,</span>
</span><span id="L-1303"><a href="#L-1303"><span class="linenos">1303</span></a>        <span class="p">)</span>
</span><span id="L-1304"><a href="#L-1304"><span class="linenos">1304</span></a>
</span><span id="L-1305"><a href="#L-1305"><span class="linenos">1305</span></a>        <span class="c1"># collect all token embeddings </span>
</span><span id="L-1306"><a href="#L-1306"><span class="linenos">1306</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">discriminator_hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-1307"><a href="#L-1307"><span class="linenos">1307</span></a>        <span class="c1"># collect the sequence embeddings, only assuming the first token is a seq token</span>
</span><span id="L-1308"><a href="#L-1308"><span class="linenos">1308</span></a>        <span class="n">sequence_embeddings</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="L-1309"><a href="#L-1309"><span class="linenos">1309</span></a>
</span><span id="L-1310"><a href="#L-1310"><span class="linenos">1310</span></a>        <span class="c1"># logits is the real valued prediction</span>
</span><span id="L-1311"><a href="#L-1311"><span class="linenos">1311</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="n">return_attention</span><span class="p">)</span>
</span><span id="L-1312"><a href="#L-1312"><span class="linenos">1312</span></a>    
</span><span id="L-1313"><a href="#L-1313"><span class="linenos">1313</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-1314"><a href="#L-1314"><span class="linenos">1314</span></a>    
</span><span id="L-1315"><a href="#L-1315"><span class="linenos">1315</span></a>        <span class="k">if</span> <span class="n">return_attention</span><span class="p">:</span>
</span><span id="L-1316"><a href="#L-1316"><span class="linenos">1316</span></a>            <span class="n">attention_probabilities</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-1317"><a href="#L-1317"><span class="linenos">1317</span></a>
</span><span id="L-1318"><a href="#L-1318"><span class="linenos">1318</span></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1319"><a href="#L-1319"><span class="linenos">1319</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1320"><a href="#L-1320"><span class="linenos">1320</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1321"><a href="#L-1321"><span class="linenos">1321</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-1322"><a href="#L-1322"><span class="linenos">1322</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;regression&quot;</span>
</span><span id="L-1323"><a href="#L-1323"><span class="linenos">1323</span></a>                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span> <span class="ow">or</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">):</span>
</span><span id="L-1324"><a href="#L-1324"><span class="linenos">1324</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;single_label_classification&quot;</span>
</span><span id="L-1325"><a href="#L-1325"><span class="linenos">1325</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1326"><a href="#L-1326"><span class="linenos">1326</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>
</span><span id="L-1327"><a href="#L-1327"><span class="linenos">1327</span></a>
</span><span id="L-1328"><a href="#L-1328"><span class="linenos">1328</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
</span><span id="L-1329"><a href="#L-1329"><span class="linenos">1329</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
</span><span id="L-1330"><a href="#L-1330"><span class="linenos">1330</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-1331"><a href="#L-1331"><span class="linenos">1331</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</span><span id="L-1332"><a href="#L-1332"><span class="linenos">1332</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1333"><a href="#L-1333"><span class="linenos">1333</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="L-1334"><a href="#L-1334"><span class="linenos">1334</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;single_label_classification&quot;</span><span class="p">:</span>
</span><span id="L-1335"><a href="#L-1335"><span class="linenos">1335</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="L-1336"><a href="#L-1336"><span class="linenos">1336</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-1337"><a href="#L-1337"><span class="linenos">1337</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;multi_label_classification&quot;</span><span class="p">:</span>
</span><span id="L-1338"><a href="#L-1338"><span class="linenos">1338</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="L-1339"><a href="#L-1339"><span class="linenos">1339</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="L-1340"><a href="#L-1340"><span class="linenos">1340</span></a>
</span><span id="L-1341"><a href="#L-1341"><span class="linenos">1341</span></a>        <span class="n">full_output</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">attention_probabilities</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
</span><span id="L-1342"><a href="#L-1342"><span class="linenos">1342</span></a>
</span><span id="L-1343"><a href="#L-1343"><span class="linenos">1343</span></a>        <span class="k">return</span> <span class="n">full_output</span>
</span><span id="L-1344"><a href="#L-1344"><span class="linenos">1344</span></a>
</span><span id="L-1345"><a href="#L-1345"><span class="linenos">1345</span></a>
</span><span id="L-1346"><a href="#L-1346"><span class="linenos">1346</span></a><span class="k">class</span> <span class="nc">ElectraAggregationHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-1347"><a href="#L-1347"><span class="linenos">1347</span></a><span class="w">    </span>
</span><span id="L-1348"><a href="#L-1348"><span class="linenos">1348</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1349"><a href="#L-1349"><span class="linenos">1349</span></a><span class="sd">    Head to aggregate sequence embeddings of a batch of documents with sequences into predictions for each document.</span>
</span><span id="L-1350"><a href="#L-1350"><span class="linenos">1350</span></a>
</span><span id="L-1351"><a href="#L-1351"><span class="linenos">1351</span></a><span class="sd">    This class takes sequence embeddings as input and aggregates them by averaging. </span>
</span><span id="L-1352"><a href="#L-1352"><span class="linenos">1352</span></a><span class="sd">    It then passes the aggregated embeddings through a dense layer, applies dropout </span>
</span><span id="L-1353"><a href="#L-1353"><span class="linenos">1353</span></a><span class="sd">    and activation, and finally projects the result to the number of output labels.</span>
</span><span id="L-1354"><a href="#L-1354"><span class="linenos">1354</span></a>
</span><span id="L-1355"><a href="#L-1355"><span class="linenos">1355</span></a><span class="sd">    Attributes</span>
</span><span id="L-1356"><a href="#L-1356"><span class="linenos">1356</span></a><span class="sd">    ----------</span>
</span><span id="L-1357"><a href="#L-1357"><span class="linenos">1357</span></a><span class="sd">    dense : nn.Linear</span>
</span><span id="L-1358"><a href="#L-1358"><span class="linenos">1358</span></a><span class="sd">        A linear layer that densely connects all sequence embeddings.</span>
</span><span id="L-1359"><a href="#L-1359"><span class="linenos">1359</span></a><span class="sd">    dropout : nn.Dropout</span>
</span><span id="L-1360"><a href="#L-1360"><span class="linenos">1360</span></a><span class="sd">        Dropout applied to the output of the dense layer.</span>
</span><span id="L-1361"><a href="#L-1361"><span class="linenos">1361</span></a><span class="sd">    activation : nn.GELU</span>
</span><span id="L-1362"><a href="#L-1362"><span class="linenos">1362</span></a><span class="sd">        Activation function applied after the dropout.</span>
</span><span id="L-1363"><a href="#L-1363"><span class="linenos">1363</span></a><span class="sd">    out_projection : nn.Linear</span>
</span><span id="L-1364"><a href="#L-1364"><span class="linenos">1364</span></a><span class="sd">        A linear layer that projects the aggregated embeddings to the number of labels.</span>
</span><span id="L-1365"><a href="#L-1365"><span class="linenos">1365</span></a>
</span><span id="L-1366"><a href="#L-1366"><span class="linenos">1366</span></a><span class="sd">    Methods</span>
</span><span id="L-1367"><a href="#L-1367"><span class="linenos">1367</span></a><span class="sd">    -------</span>
</span><span id="L-1368"><a href="#L-1368"><span class="linenos">1368</span></a><span class="sd">    forward(hidden_states: torch.Tensor, original_shapes: List[int]) -&gt; torch.Tensor</span>
</span><span id="L-1369"><a href="#L-1369"><span class="linenos">1369</span></a><span class="sd">        Performs the forward pass, aggregating the sequence embeddings and generating logits.</span>
</span><span id="L-1370"><a href="#L-1370"><span class="linenos">1370</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1371"><a href="#L-1371"><span class="linenos">1371</span></a>
</span><span id="L-1372"><a href="#L-1372"><span class="linenos">1372</span></a>
</span><span id="L-1373"><a href="#L-1373"><span class="linenos">1373</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-1374"><a href="#L-1374"><span class="linenos">1374</span></a>
</span><span id="L-1375"><a href="#L-1375"><span class="linenos">1375</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1376"><a href="#L-1376"><span class="linenos">1376</span></a><span class="sd">        Initializes the ElectraAggregationHead with the provided configuration.</span>
</span><span id="L-1377"><a href="#L-1377"><span class="linenos">1377</span></a>
</span><span id="L-1378"><a href="#L-1378"><span class="linenos">1378</span></a><span class="sd">        Parameters</span>
</span><span id="L-1379"><a href="#L-1379"><span class="linenos">1379</span></a><span class="sd">        ----------</span>
</span><span id="L-1380"><a href="#L-1380"><span class="linenos">1380</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="L-1381"><a href="#L-1381"><span class="linenos">1381</span></a><span class="sd">            The configuration object containing the hidden size, dropout probability, </span>
</span><span id="L-1382"><a href="#L-1382"><span class="linenos">1382</span></a><span class="sd">            and number of labels.</span>
</span><span id="L-1383"><a href="#L-1383"><span class="linenos">1383</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1384"><a href="#L-1384"><span class="linenos">1384</span></a>
</span><span id="L-1385"><a href="#L-1385"><span class="linenos">1385</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-1386"><a href="#L-1386"><span class="linenos">1386</span></a>        <span class="c1"># densely connect all sequence embeddings</span>
</span><span id="L-1387"><a href="#L-1387"><span class="linenos">1387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-1388"><a href="#L-1388"><span class="linenos">1388</span></a>        <span class="c1"># dropout</span>
</span><span id="L-1389"><a href="#L-1389"><span class="linenos">1389</span></a>        <span class="n">aggregation_head_dropout</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-1390"><a href="#L-1390"><span class="linenos">1390</span></a>            <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span>
</span><span id="L-1391"><a href="#L-1391"><span class="linenos">1391</span></a>        <span class="p">)</span>
</span><span id="L-1392"><a href="#L-1392"><span class="linenos">1392</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">aggregation_head_dropout</span><span class="p">)</span>
</span><span id="L-1393"><a href="#L-1393"><span class="linenos">1393</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
</span><span id="L-1394"><a href="#L-1394"><span class="linenos">1394</span></a>        <span class="c1"># project the average aggregate of sequence embeddings after the dense layer</span>
</span><span id="L-1395"><a href="#L-1395"><span class="linenos">1395</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span><span id="L-1396"><a href="#L-1396"><span class="linenos">1396</span></a>
</span><span id="L-1397"><a href="#L-1397"><span class="linenos">1397</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">):</span>
</span><span id="L-1398"><a href="#L-1398"><span class="linenos">1398</span></a>
</span><span id="L-1399"><a href="#L-1399"><span class="linenos">1399</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1400"><a href="#L-1400"><span class="linenos">1400</span></a><span class="sd">        Performs the forward pass, aggregating the sequence embeddings and generating logits.</span>
</span><span id="L-1401"><a href="#L-1401"><span class="linenos">1401</span></a>
</span><span id="L-1402"><a href="#L-1402"><span class="linenos">1402</span></a><span class="sd">        Parameters</span>
</span><span id="L-1403"><a href="#L-1403"><span class="linenos">1403</span></a><span class="sd">        ----------</span>
</span><span id="L-1404"><a href="#L-1404"><span class="linenos">1404</span></a><span class="sd">        hidden_states : torch.Tensor</span>
</span><span id="L-1405"><a href="#L-1405"><span class="linenos">1405</span></a><span class="sd">            The input sequence embeddings of shape (batch_size, hidden_size).</span>
</span><span id="L-1406"><a href="#L-1406"><span class="linenos">1406</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="L-1407"><a href="#L-1407"><span class="linenos">1407</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="L-1408"><a href="#L-1408"><span class="linenos">1408</span></a>
</span><span id="L-1409"><a href="#L-1409"><span class="linenos">1409</span></a><span class="sd">        Returns</span>
</span><span id="L-1410"><a href="#L-1410"><span class="linenos">1410</span></a><span class="sd">        -------</span>
</span><span id="L-1411"><a href="#L-1411"><span class="linenos">1411</span></a><span class="sd">        torch.Tensor</span>
</span><span id="L-1412"><a href="#L-1412"><span class="linenos">1412</span></a><span class="sd">            The logits for each aggregated sequence.</span>
</span><span id="L-1413"><a href="#L-1413"><span class="linenos">1413</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1414"><a href="#L-1414"><span class="linenos">1414</span></a>
</span><span id="L-1415"><a href="#L-1415"><span class="linenos">1415</span></a>        <span class="c1"># process flattened input embedding states through dense layer</span>
</span><span id="L-1416"><a href="#L-1416"><span class="linenos">1416</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
</span><span id="L-1417"><a href="#L-1417"><span class="linenos">1417</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-1418"><a href="#L-1418"><span class="linenos">1418</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-1419"><a href="#L-1419"><span class="linenos">1419</span></a>        <span class="n">x_original_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="L-1420"><a href="#L-1420"><span class="linenos">1420</span></a>        <span class="n">x_aggregated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch_tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">torch_tensor</span> <span class="ow">in</span> <span class="n">x_original_shapes</span><span class="p">])</span>
</span><span id="L-1421"><a href="#L-1421"><span class="linenos">1421</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">x_aggregated</span><span class="p">)</span>
</span><span id="L-1422"><a href="#L-1422"><span class="linenos">1422</span></a>        <span class="k">return</span> <span class="n">logits</span>
</span><span id="L-1423"><a href="#L-1423"><span class="linenos">1423</span></a>    
</span><span id="L-1424"><a href="#L-1424"><span class="linenos">1424</span></a>
</span><span id="L-1425"><a href="#L-1425"><span class="linenos">1425</span></a><span class="k">class</span> <span class="nc">ElectraForAggregatePrediction</span><span class="p">(</span><span class="n">ElectraPreTrainedModel</span><span class="p">):</span>
</span><span id="L-1426"><a href="#L-1426"><span class="linenos">1426</span></a>
</span><span id="L-1427"><a href="#L-1427"><span class="linenos">1427</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1428"><a href="#L-1428"><span class="linenos">1428</span></a><span class="sd">    An Electra model with aggregate prediction for sequence embeddings.</span>
</span><span id="L-1429"><a href="#L-1429"><span class="linenos">1429</span></a>
</span><span id="L-1430"><a href="#L-1430"><span class="linenos">1430</span></a><span class="sd">    This class extends the Electra model by adding a custom head for aggregate prediction.</span>
</span><span id="L-1431"><a href="#L-1431"><span class="linenos">1431</span></a><span class="sd">    It takes token embeddings, aggregates sequence embeddings, and makes predictions </span>
</span><span id="L-1432"><a href="#L-1432"><span class="linenos">1432</span></a><span class="sd">    for entire sequences or documents.</span>
</span><span id="L-1433"><a href="#L-1433"><span class="linenos">1433</span></a>
</span><span id="L-1434"><a href="#L-1434"><span class="linenos">1434</span></a><span class="sd">    Attributes</span>
</span><span id="L-1435"><a href="#L-1435"><span class="linenos">1435</span></a><span class="sd">    ----------</span>
</span><span id="L-1436"><a href="#L-1436"><span class="linenos">1436</span></a><span class="sd">    config : ElectraConfig</span>
</span><span id="L-1437"><a href="#L-1437"><span class="linenos">1437</span></a><span class="sd">        The configuration object for the Electra model.</span>
</span><span id="L-1438"><a href="#L-1438"><span class="linenos">1438</span></a><span class="sd">    num_labels : int</span>
</span><span id="L-1439"><a href="#L-1439"><span class="linenos">1439</span></a><span class="sd">        The number of labels for classification tasks.</span>
</span><span id="L-1440"><a href="#L-1440"><span class="linenos">1440</span></a><span class="sd">    electra : ElectraModel</span>
</span><span id="L-1441"><a href="#L-1441"><span class="linenos">1441</span></a><span class="sd">        The Electra encoder model for generating token embeddings.</span>
</span><span id="L-1442"><a href="#L-1442"><span class="linenos">1442</span></a><span class="sd">    head : ElectraAggregationHead</span>
</span><span id="L-1443"><a href="#L-1443"><span class="linenos">1443</span></a><span class="sd">        The custom head for making aggregate predictions with sequence embeddings.</span>
</span><span id="L-1444"><a href="#L-1444"><span class="linenos">1444</span></a>
</span><span id="L-1445"><a href="#L-1445"><span class="linenos">1445</span></a><span class="sd">    Methods</span>
</span><span id="L-1446"><a href="#L-1446"><span class="linenos">1446</span></a><span class="sd">    -------</span>
</span><span id="L-1447"><a href="#L-1447"><span class="linenos">1447</span></a><span class="sd">    forward(input_ids: List[List[Tensor]], attention_mask: List[List[Tensor]], labels: Optional[torch.Tensor] = None) -&gt; Any</span>
</span><span id="L-1448"><a href="#L-1448"><span class="linenos">1448</span></a><span class="sd">        Performs the forward pass, generating sequence embeddings and making predictions.</span>
</span><span id="L-1449"><a href="#L-1449"><span class="linenos">1449</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1450"><a href="#L-1450"><span class="linenos">1450</span></a>
</span><span id="L-1451"><a href="#L-1451"><span class="linenos">1451</span></a>    
</span><span id="L-1452"><a href="#L-1452"><span class="linenos">1452</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-1453"><a href="#L-1453"><span class="linenos">1453</span></a>
</span><span id="L-1454"><a href="#L-1454"><span class="linenos">1454</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1455"><a href="#L-1455"><span class="linenos">1455</span></a><span class="sd">        Initializes the ElectraForAggregatePrediction model.</span>
</span><span id="L-1456"><a href="#L-1456"><span class="linenos">1456</span></a>
</span><span id="L-1457"><a href="#L-1457"><span class="linenos">1457</span></a><span class="sd">        Parameters</span>
</span><span id="L-1458"><a href="#L-1458"><span class="linenos">1458</span></a><span class="sd">        ----------</span>
</span><span id="L-1459"><a href="#L-1459"><span class="linenos">1459</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="L-1460"><a href="#L-1460"><span class="linenos">1460</span></a><span class="sd">            The configuration object for the Electra model.</span>
</span><span id="L-1461"><a href="#L-1461"><span class="linenos">1461</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1462"><a href="#L-1462"><span class="linenos">1462</span></a>
</span><span id="L-1463"><a href="#L-1463"><span class="linenos">1463</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-1464"><a href="#L-1464"><span class="linenos">1464</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="L-1465"><a href="#L-1465"><span class="linenos">1465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
</span><span id="L-1466"><a href="#L-1466"><span class="linenos">1466</span></a>        <span class="c1"># the encoder for creating token embeddings</span>
</span><span id="L-1467"><a href="#L-1467"><span class="linenos">1467</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">electra</span> <span class="o">=</span> <span class="n">ElectraModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-1468"><a href="#L-1468"><span class="linenos">1468</span></a>        <span class="c1"># the head for creating a single prediction for a batch of embeddings, in our case a batch of sequence embeddings</span>
</span><span id="L-1469"><a href="#L-1469"><span class="linenos">1469</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">ElectraAggregationHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-1470"><a href="#L-1470"><span class="linenos">1470</span></a>
</span><span id="L-1471"><a href="#L-1471"><span class="linenos">1471</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>
</span><span id="L-1472"><a href="#L-1472"><span class="linenos">1472</span></a>
</span><span id="L-1473"><a href="#L-1473"><span class="linenos">1473</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span><span id="L-1474"><a href="#L-1474"><span class="linenos">1474</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="L-1475"><a href="#L-1475"><span class="linenos">1475</span></a>        <span class="n">input_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1476"><a href="#L-1476"><span class="linenos">1476</span></a>        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-1477"><a href="#L-1477"><span class="linenos">1477</span></a>        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1478"><a href="#L-1478"><span class="linenos">1478</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="L-1479"><a href="#L-1479"><span class="linenos">1479</span></a><span class="w">        </span>
</span><span id="L-1480"><a href="#L-1480"><span class="linenos">1480</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1481"><a href="#L-1481"><span class="linenos">1481</span></a><span class="sd">        Performs the forward pass of the Electra model with aggregate prediction.</span>
</span><span id="L-1482"><a href="#L-1482"><span class="linenos">1482</span></a>
</span><span id="L-1483"><a href="#L-1483"><span class="linenos">1483</span></a><span class="sd">        Parameters</span>
</span><span id="L-1484"><a href="#L-1484"><span class="linenos">1484</span></a><span class="sd">        ----------</span>
</span><span id="L-1485"><a href="#L-1485"><span class="linenos">1485</span></a><span class="sd">        input_ids : List[List[Tensor]]</span>
</span><span id="L-1486"><a href="#L-1486"><span class="linenos">1486</span></a><span class="sd">            A batch of input token IDs.</span>
</span><span id="L-1487"><a href="#L-1487"><span class="linenos">1487</span></a><span class="sd">        attention_mask : List[List[Tensor]]</span>
</span><span id="L-1488"><a href="#L-1488"><span class="linenos">1488</span></a><span class="sd">            A batch of attention masks corresponding to the input IDs.</span>
</span><span id="L-1489"><a href="#L-1489"><span class="linenos">1489</span></a><span class="sd">        labels : Optional[torch.Tensor], optional</span>
</span><span id="L-1490"><a href="#L-1490"><span class="linenos">1490</span></a><span class="sd">            Ground truth labels for the input sequences (default is None).</span>
</span><span id="L-1491"><a href="#L-1491"><span class="linenos">1491</span></a>
</span><span id="L-1492"><a href="#L-1492"><span class="linenos">1492</span></a><span class="sd">        Returns</span>
</span><span id="L-1493"><a href="#L-1493"><span class="linenos">1493</span></a><span class="sd">        -------</span>
</span><span id="L-1494"><a href="#L-1494"><span class="linenos">1494</span></a><span class="sd">        Any</span>
</span><span id="L-1495"><a href="#L-1495"><span class="linenos">1495</span></a><span class="sd">            The loss (if labels are provided) and logits.</span>
</span><span id="L-1496"><a href="#L-1496"><span class="linenos">1496</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1497"><a href="#L-1497"><span class="linenos">1497</span></a>       
</span><span id="L-1498"><a href="#L-1498"><span class="linenos">1498</span></a>        <span class="n">input_id_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_input_ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_input_ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
</span><span id="L-1499"><a href="#L-1499"><span class="linenos">1499</span></a>        <span class="n">attention_mask_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_attention_mask</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_attention_mask</span> <span class="ow">in</span> <span class="n">attention_mask</span><span class="p">]</span>
</span><span id="L-1500"><a href="#L-1500"><span class="linenos">1500</span></a>        <span class="c1"># Store the original shapes</span>
</span><span id="L-1501"><a href="#L-1501"><span class="linenos">1501</span></a>        <span class="n">original_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_ids_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">input_ids_tensor</span> <span class="ow">in</span> <span class="n">input_id_tensors</span><span class="p">]</span>
</span><span id="L-1502"><a href="#L-1502"><span class="linenos">1502</span></a>
</span><span id="L-1503"><a href="#L-1503"><span class="linenos">1503</span></a>        <span class="c1"># Step 2: Concatenate the tensors along the first dimension</span>
</span><span id="L-1504"><a href="#L-1504"><span class="linenos">1504</span></a>        <span class="n">flattened_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_id_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="L-1505"><a href="#L-1505"><span class="linenos">1505</span></a>        <span class="n">flattened_attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attention_mask_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="L-1506"><a href="#L-1506"><span class="linenos">1506</span></a>
</span><span id="L-1507"><a href="#L-1507"><span class="linenos">1507</span></a>        <span class="n">discriminator_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">electra</span><span class="p">(</span>
</span><span id="L-1508"><a href="#L-1508"><span class="linenos">1508</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">flattened_input_ids</span><span class="p">,</span>
</span><span id="L-1509"><a href="#L-1509"><span class="linenos">1509</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">flattened_attention_mask</span><span class="p">,</span>
</span><span id="L-1510"><a href="#L-1510"><span class="linenos">1510</span></a>        <span class="p">)</span>
</span><span id="L-1511"><a href="#L-1511"><span class="linenos">1511</span></a>
</span><span id="L-1512"><a href="#L-1512"><span class="linenos">1512</span></a>        <span class="c1"># collect all token embeddings </span>
</span><span id="L-1513"><a href="#L-1513"><span class="linenos">1513</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">discriminator_hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-1514"><a href="#L-1514"><span class="linenos">1514</span></a>        <span class="c1"># collect the sequence embeddings, only assuming the first token is a seq token</span>
</span><span id="L-1515"><a href="#L-1515"><span class="linenos">1515</span></a>        <span class="n">sequence_embeddings</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="L-1516"><a href="#L-1516"><span class="linenos">1516</span></a>        <span class="c1"># logits is the real valued prediction</span>
</span><span id="L-1517"><a href="#L-1517"><span class="linenos">1517</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">)</span>
</span><span id="L-1518"><a href="#L-1518"><span class="linenos">1518</span></a>
</span><span id="L-1519"><a href="#L-1519"><span class="linenos">1519</span></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1520"><a href="#L-1520"><span class="linenos">1520</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1521"><a href="#L-1521"><span class="linenos">1521</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1522"><a href="#L-1522"><span class="linenos">1522</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-1523"><a href="#L-1523"><span class="linenos">1523</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;regression&quot;</span>
</span><span id="L-1524"><a href="#L-1524"><span class="linenos">1524</span></a>                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span> <span class="ow">or</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">):</span>
</span><span id="L-1525"><a href="#L-1525"><span class="linenos">1525</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;single_label_classification&quot;</span>
</span><span id="L-1526"><a href="#L-1526"><span class="linenos">1526</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1527"><a href="#L-1527"><span class="linenos">1527</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>
</span><span id="L-1528"><a href="#L-1528"><span class="linenos">1528</span></a>
</span><span id="L-1529"><a href="#L-1529"><span class="linenos">1529</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
</span><span id="L-1530"><a href="#L-1530"><span class="linenos">1530</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
</span><span id="L-1531"><a href="#L-1531"><span class="linenos">1531</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-1532"><a href="#L-1532"><span class="linenos">1532</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</span><span id="L-1533"><a href="#L-1533"><span class="linenos">1533</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1534"><a href="#L-1534"><span class="linenos">1534</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="L-1535"><a href="#L-1535"><span class="linenos">1535</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;single_label_classification&quot;</span><span class="p">:</span>
</span><span id="L-1536"><a href="#L-1536"><span class="linenos">1536</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="L-1537"><a href="#L-1537"><span class="linenos">1537</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-1538"><a href="#L-1538"><span class="linenos">1538</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;multi_label_classification&quot;</span><span class="p">:</span>
</span><span id="L-1539"><a href="#L-1539"><span class="linenos">1539</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="L-1540"><a href="#L-1540"><span class="linenos">1540</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="L-1541"><a href="#L-1541"><span class="linenos">1541</span></a>
</span><span id="L-1542"><a href="#L-1542"><span class="linenos">1542</span></a>        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
</span></pre></div>


            </section>
                <section id="PretrainLM">
                            <input id="PretrainLM-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PretrainLM</span>:

                <label class="view-source-button" for="PretrainLM-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainLM"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainLM-24"><a href="#PretrainLM-24"><span class="linenos"> 24</span></a><span class="k">class</span> <span class="nc">PretrainLM</span><span class="p">:</span>
</span><span id="PretrainLM-25"><a href="#PretrainLM-25"><span class="linenos"> 25</span></a>
</span><span id="PretrainLM-26"><a href="#PretrainLM-26"><span class="linenos"> 26</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM-27"><a href="#PretrainLM-27"><span class="linenos"> 27</span></a><span class="sd">    A class for pretraining a language model using the configurations provided in FinLMConfig.</span>
</span><span id="PretrainLM-28"><a href="#PretrainLM-28"><span class="linenos"> 28</span></a>
</span><span id="PretrainLM-29"><a href="#PretrainLM-29"><span class="linenos"> 29</span></a><span class="sd">    This class handles the setup of the dataset, model configurations, and optimization settings </span>
</span><span id="PretrainLM-30"><a href="#PretrainLM-30"><span class="linenos"> 30</span></a><span class="sd">    for pretraining a language model. It also includes utility methods for token masking and </span>
</span><span id="PretrainLM-31"><a href="#PretrainLM-31"><span class="linenos"> 31</span></a><span class="sd">    directory management.</span>
</span><span id="PretrainLM-32"><a href="#PretrainLM-32"><span class="linenos"> 32</span></a>
</span><span id="PretrainLM-33"><a href="#PretrainLM-33"><span class="linenos"> 33</span></a><span class="sd">    Attributes</span>
</span><span id="PretrainLM-34"><a href="#PretrainLM-34"><span class="linenos"> 34</span></a><span class="sd">    ----------</span>
</span><span id="PretrainLM-35"><a href="#PretrainLM-35"><span class="linenos"> 35</span></a><span class="sd">    config : FinLMConfig</span>
</span><span id="PretrainLM-36"><a href="#PretrainLM-36"><span class="linenos"> 36</span></a><span class="sd">        Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainLM-37"><a href="#PretrainLM-37"><span class="linenos"> 37</span></a><span class="sd">    dataset_config : DatasetConfig</span>
</span><span id="PretrainLM-38"><a href="#PretrainLM-38"><span class="linenos"> 38</span></a><span class="sd">        Configuration for the dataset.</span>
</span><span id="PretrainLM-39"><a href="#PretrainLM-39"><span class="linenos"> 39</span></a><span class="sd">    model_config : ModelConfig</span>
</span><span id="PretrainLM-40"><a href="#PretrainLM-40"><span class="linenos"> 40</span></a><span class="sd">        Configuration for the model architecture.</span>
</span><span id="PretrainLM-41"><a href="#PretrainLM-41"><span class="linenos"> 41</span></a><span class="sd">    optimization_config : OptimizationConfig</span>
</span><span id="PretrainLM-42"><a href="#PretrainLM-42"><span class="linenos"> 42</span></a><span class="sd">        Configuration for the optimization settings.</span>
</span><span id="PretrainLM-43"><a href="#PretrainLM-43"><span class="linenos"> 43</span></a><span class="sd">    save_root_path : str</span>
</span><span id="PretrainLM-44"><a href="#PretrainLM-44"><span class="linenos"> 44</span></a><span class="sd">        Path where models and results will be saved.</span>
</span><span id="PretrainLM-45"><a href="#PretrainLM-45"><span class="linenos"> 45</span></a><span class="sd">    logger : logging.Logger</span>
</span><span id="PretrainLM-46"><a href="#PretrainLM-46"><span class="linenos"> 46</span></a><span class="sd">        Logger instance for logging messages related to the pretraining process.</span>
</span><span id="PretrainLM-47"><a href="#PretrainLM-47"><span class="linenos"> 47</span></a><span class="sd">    device : torch.device</span>
</span><span id="PretrainLM-48"><a href="#PretrainLM-48"><span class="linenos"> 48</span></a><span class="sd">        Device on which computations will be performed (CPU or CUDA).</span>
</span><span id="PretrainLM-49"><a href="#PretrainLM-49"><span class="linenos"> 49</span></a>
</span><span id="PretrainLM-50"><a href="#PretrainLM-50"><span class="linenos"> 50</span></a><span class="sd">    Methods</span>
</span><span id="PretrainLM-51"><a href="#PretrainLM-51"><span class="linenos"> 51</span></a><span class="sd">    -------</span>
</span><span id="PretrainLM-52"><a href="#PretrainLM-52"><span class="linenos"> 52</span></a><span class="sd">    load_dataset() -&gt; None</span>
</span><span id="PretrainLM-53"><a href="#PretrainLM-53"><span class="linenos"> 53</span></a><span class="sd">        Loads the dataset based on the configuration.</span>
</span><span id="PretrainLM-54"><a href="#PretrainLM-54"><span class="linenos"> 54</span></a><span class="sd">    mask_tokens(inputs, mlm_probability, mask_token_id, special_token_ids, n_tokens, ignore_index=-100, hard_masking=False) -&gt; Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainLM-55"><a href="#PretrainLM-55"><span class="linenos"> 55</span></a><span class="sd">        Applies masked language modeling (MLM) to the input tokens.</span>
</span><span id="PretrainLM-56"><a href="#PretrainLM-56"><span class="linenos"> 56</span></a><span class="sd">    _create_directory_and_return_save_path(model_type: str) -&gt; str</span>
</span><span id="PretrainLM-57"><a href="#PretrainLM-57"><span class="linenos"> 57</span></a><span class="sd">        Creates a directory for saving the model and returns the path.</span>
</span><span id="PretrainLM-58"><a href="#PretrainLM-58"><span class="linenos"> 58</span></a><span class="sd">    _set_device() -&gt; None</span>
</span><span id="PretrainLM-59"><a href="#PretrainLM-59"><span class="linenos"> 59</span></a><span class="sd">        Sets the device to CUDA if available; otherwise, defaults to CPU.</span>
</span><span id="PretrainLM-60"><a href="#PretrainLM-60"><span class="linenos"> 60</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PretrainLM-61"><a href="#PretrainLM-61"><span class="linenos"> 61</span></a>
</span><span id="PretrainLM-62"><a href="#PretrainLM-62"><span class="linenos"> 62</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">FinLMConfig</span><span class="p">):</span>
</span><span id="PretrainLM-63"><a href="#PretrainLM-63"><span class="linenos"> 63</span></a>
</span><span id="PretrainLM-64"><a href="#PretrainLM-64"><span class="linenos"> 64</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM-65"><a href="#PretrainLM-65"><span class="linenos"> 65</span></a><span class="sd">        Initializes the PretrainLM class with the given configuration.</span>
</span><span id="PretrainLM-66"><a href="#PretrainLM-66"><span class="linenos"> 66</span></a>
</span><span id="PretrainLM-67"><a href="#PretrainLM-67"><span class="linenos"> 67</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainLM-68"><a href="#PretrainLM-68"><span class="linenos"> 68</span></a><span class="sd">        ----------</span>
</span><span id="PretrainLM-69"><a href="#PretrainLM-69"><span class="linenos"> 69</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="PretrainLM-70"><a href="#PretrainLM-70"><span class="linenos"> 70</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainLM-71"><a href="#PretrainLM-71"><span class="linenos"> 71</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainLM-72"><a href="#PretrainLM-72"><span class="linenos"> 72</span></a>
</span><span id="PretrainLM-73"><a href="#PretrainLM-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="PretrainLM-74"><a href="#PretrainLM-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_config</span>
</span><span id="PretrainLM-75"><a href="#PretrainLM-75"><span class="linenos"> 75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_config</span>
</span><span id="PretrainLM-76"><a href="#PretrainLM-76"><span class="linenos"> 76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">optimization_config</span>
</span><span id="PretrainLM-77"><a href="#PretrainLM-77"><span class="linenos"> 77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">save_models_and_results_to</span>
</span><span id="PretrainLM-78"><a href="#PretrainLM-78"><span class="linenos"> 78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="PretrainLM-79"><a href="#PretrainLM-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_device</span><span class="p">()</span>
</span><span id="PretrainLM-80"><a href="#PretrainLM-80"><span class="linenos"> 80</span></a>
</span><span id="PretrainLM-81"><a href="#PretrainLM-81"><span class="linenos"> 81</span></a>    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainLM-82"><a href="#PretrainLM-82"><span class="linenos"> 82</span></a>
</span><span id="PretrainLM-83"><a href="#PretrainLM-83"><span class="linenos"> 83</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM-84"><a href="#PretrainLM-84"><span class="linenos"> 84</span></a><span class="sd">        Loads the dataset based on the dataset configuration.</span>
</span><span id="PretrainLM-85"><a href="#PretrainLM-85"><span class="linenos"> 85</span></a>
</span><span id="PretrainLM-86"><a href="#PretrainLM-86"><span class="linenos"> 86</span></a><span class="sd">        This method initializes the FinLMDataset using the dataset configuration provided in </span>
</span><span id="PretrainLM-87"><a href="#PretrainLM-87"><span class="linenos"> 87</span></a><span class="sd">        the FinLMConfig object.</span>
</span><span id="PretrainLM-88"><a href="#PretrainLM-88"><span class="linenos"> 88</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainLM-89"><a href="#PretrainLM-89"><span class="linenos"> 89</span></a>            
</span><span id="PretrainLM-90"><a href="#PretrainLM-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">FinLMDataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_config</span><span class="p">))</span>
</span><span id="PretrainLM-91"><a href="#PretrainLM-91"><span class="linenos"> 91</span></a>
</span><span id="PretrainLM-92"><a href="#PretrainLM-92"><span class="linenos"> 92</span></a>    <span class="nd">@staticmethod</span>
</span><span id="PretrainLM-93"><a href="#PretrainLM-93"><span class="linenos"> 93</span></a>    <span class="k">def</span> <span class="nf">mask_tokens</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="n">special_token_ids</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="PretrainLM-94"><a href="#PretrainLM-94"><span class="linenos"> 94</span></a>
</span><span id="PretrainLM-95"><a href="#PretrainLM-95"><span class="linenos"> 95</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM-96"><a href="#PretrainLM-96"><span class="linenos"> 96</span></a><span class="sd">        Applies masked language modeling (MLM) to the input tokens.</span>
</span><span id="PretrainLM-97"><a href="#PretrainLM-97"><span class="linenos"> 97</span></a>
</span><span id="PretrainLM-98"><a href="#PretrainLM-98"><span class="linenos"> 98</span></a><span class="sd">        This method randomly masks a portion of the input tokens according to the specified </span>
</span><span id="PretrainLM-99"><a href="#PretrainLM-99"><span class="linenos"> 99</span></a><span class="sd">        probability, and optionally replaces some tokens with random words or keeps them unchanged.</span>
</span><span id="PretrainLM-100"><a href="#PretrainLM-100"><span class="linenos">100</span></a>
</span><span id="PretrainLM-101"><a href="#PretrainLM-101"><span class="linenos">101</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainLM-102"><a href="#PretrainLM-102"><span class="linenos">102</span></a><span class="sd">        ----------</span>
</span><span id="PretrainLM-103"><a href="#PretrainLM-103"><span class="linenos">103</span></a><span class="sd">        inputs : torch.Tensor</span>
</span><span id="PretrainLM-104"><a href="#PretrainLM-104"><span class="linenos">104</span></a><span class="sd">            Tensor containing the input token IDs.</span>
</span><span id="PretrainLM-105"><a href="#PretrainLM-105"><span class="linenos">105</span></a><span class="sd">        mlm_probability : float</span>
</span><span id="PretrainLM-106"><a href="#PretrainLM-106"><span class="linenos">106</span></a><span class="sd">            Probability of masking a token for MLM.</span>
</span><span id="PretrainLM-107"><a href="#PretrainLM-107"><span class="linenos">107</span></a><span class="sd">        mask_token_id : int</span>
</span><span id="PretrainLM-108"><a href="#PretrainLM-108"><span class="linenos">108</span></a><span class="sd">            The token ID to use for masking (typically the ID for the [MASK] token).</span>
</span><span id="PretrainLM-109"><a href="#PretrainLM-109"><span class="linenos">109</span></a><span class="sd">        special_token_ids : list[int]</span>
</span><span id="PretrainLM-110"><a href="#PretrainLM-110"><span class="linenos">110</span></a><span class="sd">            List of token IDs that should not be masked (e.g., special tokens like [CLS], [SEP]).</span>
</span><span id="PretrainLM-111"><a href="#PretrainLM-111"><span class="linenos">111</span></a><span class="sd">        n_tokens : int</span>
</span><span id="PretrainLM-112"><a href="#PretrainLM-112"><span class="linenos">112</span></a><span class="sd">            The total number of tokens in the vocabulary (used for selecting random tokens).</span>
</span><span id="PretrainLM-113"><a href="#PretrainLM-113"><span class="linenos">113</span></a><span class="sd">        ignore_index : int, optional</span>
</span><span id="PretrainLM-114"><a href="#PretrainLM-114"><span class="linenos">114</span></a><span class="sd">            The index to ignore in the loss calculation (default is -100).</span>
</span><span id="PretrainLM-115"><a href="#PretrainLM-115"><span class="linenos">115</span></a><span class="sd">        hard_masking : bool, optional</span>
</span><span id="PretrainLM-116"><a href="#PretrainLM-116"><span class="linenos">116</span></a><span class="sd">            If True, all masked tokens are replaced by the mask token; otherwise, some tokens may be </span>
</span><span id="PretrainLM-117"><a href="#PretrainLM-117"><span class="linenos">117</span></a><span class="sd">            replaced by random tokens or left unchanged (default is False).</span>
</span><span id="PretrainLM-118"><a href="#PretrainLM-118"><span class="linenos">118</span></a>
</span><span id="PretrainLM-119"><a href="#PretrainLM-119"><span class="linenos">119</span></a><span class="sd">        Returns</span>
</span><span id="PretrainLM-120"><a href="#PretrainLM-120"><span class="linenos">120</span></a><span class="sd">        -------</span>
</span><span id="PretrainLM-121"><a href="#PretrainLM-121"><span class="linenos">121</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainLM-122"><a href="#PretrainLM-122"><span class="linenos">122</span></a><span class="sd">            A tuple containing the masked input tensor and the corresponding labels tensor.</span>
</span><span id="PretrainLM-123"><a href="#PretrainLM-123"><span class="linenos">123</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainLM-124"><a href="#PretrainLM-124"><span class="linenos">124</span></a>        
</span><span id="PretrainLM-125"><a href="#PretrainLM-125"><span class="linenos">125</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="PretrainLM-126"><a href="#PretrainLM-126"><span class="linenos">126</span></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="PretrainLM-127"><a href="#PretrainLM-127"><span class="linenos">127</span></a>        <span class="n">probability_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainLM-128"><a href="#PretrainLM-128"><span class="linenos">128</span></a>        <span class="c1"># create special_token_mask, first set all entries to false</span>
</span><span id="PretrainLM-129"><a href="#PretrainLM-129"><span class="linenos">129</span></a>        <span class="n">special_tokens_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="PretrainLM-130"><a href="#PretrainLM-130"><span class="linenos">130</span></a>        <span class="c1"># flag all special tokens as true</span>
</span><span id="PretrainLM-131"><a href="#PretrainLM-131"><span class="linenos">131</span></a>        <span class="k">for</span> <span class="n">sp_id</span> <span class="ow">in</span> <span class="n">special_token_ids</span><span class="p">:</span>
</span><span id="PretrainLM-132"><a href="#PretrainLM-132"><span class="linenos">132</span></a>            <span class="n">special_tokens_mask</span> <span class="o">=</span> <span class="n">special_tokens_mask</span> <span class="o">|</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">==</span> <span class="n">sp_id</span><span class="p">)</span>
</span><span id="PretrainLM-133"><a href="#PretrainLM-133"><span class="linenos">133</span></a>
</span><span id="PretrainLM-134"><a href="#PretrainLM-134"><span class="linenos">134</span></a>        <span class="n">probability_matrix</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">special_tokens_mask</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</span><span id="PretrainLM-135"><a href="#PretrainLM-135"><span class="linenos">135</span></a>        <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">probability_matrix</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span id="PretrainLM-136"><a href="#PretrainLM-136"><span class="linenos">136</span></a>        <span class="k">if</span> <span class="n">ignore_index</span><span class="p">:</span>
</span><span id="PretrainLM-137"><a href="#PretrainLM-137"><span class="linenos">137</span></a>            <span class="n">labels</span><span class="p">[</span><span class="o">~</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">ignore_index</span>  <span class="c1"># We only compute loss on masked tokens</span>
</span><span id="PretrainLM-138"><a href="#PretrainLM-138"><span class="linenos">138</span></a>
</span><span id="PretrainLM-139"><a href="#PretrainLM-139"><span class="linenos">139</span></a>        <span class="k">if</span> <span class="n">hard_masking</span><span class="p">:</span>
</span><span id="PretrainLM-140"><a href="#PretrainLM-140"><span class="linenos">140</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_token_id</span>
</span><span id="PretrainLM-141"><a href="#PretrainLM-141"><span class="linenos">141</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="PretrainLM-142"><a href="#PretrainLM-142"><span class="linenos">142</span></a>            <span class="c1"># 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])</span>
</span><span id="PretrainLM-143"><a href="#PretrainLM-143"><span class="linenos">143</span></a>            <span class="n">indices_replaced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">masked_indices</span>
</span><span id="PretrainLM-144"><a href="#PretrainLM-144"><span class="linenos">144</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">indices_replaced</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_token_id</span> 
</span><span id="PretrainLM-145"><a href="#PretrainLM-145"><span class="linenos">145</span></a>
</span><span id="PretrainLM-146"><a href="#PretrainLM-146"><span class="linenos">146</span></a>            <span class="c1"># 10% of the time, we replace masked input tokens with random word</span>
</span><span id="PretrainLM-147"><a href="#PretrainLM-147"><span class="linenos">147</span></a>            <span class="n">indices_random</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">masked_indices</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">indices_replaced</span>
</span><span id="PretrainLM-148"><a href="#PretrainLM-148"><span class="linenos">148</span></a>            <span class="n">random_words</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_tokens</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="PretrainLM-149"><a href="#PretrainLM-149"><span class="linenos">149</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">indices_random</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_words</span><span class="p">[</span><span class="n">indices_random</span><span class="p">]</span>
</span><span id="PretrainLM-150"><a href="#PretrainLM-150"><span class="linenos">150</span></a>
</span><span id="PretrainLM-151"><a href="#PretrainLM-151"><span class="linenos">151</span></a>        <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span>
</span><span id="PretrainLM-152"><a href="#PretrainLM-152"><span class="linenos">152</span></a>
</span><span id="PretrainLM-153"><a href="#PretrainLM-153"><span class="linenos">153</span></a>    <span class="k">def</span> <span class="nf">_create_directory_and_return_save_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_type</span><span class="p">):</span>
</span><span id="PretrainLM-154"><a href="#PretrainLM-154"><span class="linenos">154</span></a>
</span><span id="PretrainLM-155"><a href="#PretrainLM-155"><span class="linenos">155</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM-156"><a href="#PretrainLM-156"><span class="linenos">156</span></a><span class="sd">        Creates a directory for saving the model and returns the path.</span>
</span><span id="PretrainLM-157"><a href="#PretrainLM-157"><span class="linenos">157</span></a>
</span><span id="PretrainLM-158"><a href="#PretrainLM-158"><span class="linenos">158</span></a><span class="sd">        This method creates a new directory within the save root path for storing the model checkpoints </span>
</span><span id="PretrainLM-159"><a href="#PretrainLM-159"><span class="linenos">159</span></a><span class="sd">        and results. The directory name is based on the model type and an incremented index.</span>
</span><span id="PretrainLM-160"><a href="#PretrainLM-160"><span class="linenos">160</span></a>
</span><span id="PretrainLM-161"><a href="#PretrainLM-161"><span class="linenos">161</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainLM-162"><a href="#PretrainLM-162"><span class="linenos">162</span></a><span class="sd">        ----------</span>
</span><span id="PretrainLM-163"><a href="#PretrainLM-163"><span class="linenos">163</span></a><span class="sd">        model_type : str</span>
</span><span id="PretrainLM-164"><a href="#PretrainLM-164"><span class="linenos">164</span></a><span class="sd">            The type of model being saved (used in the directory name).</span>
</span><span id="PretrainLM-165"><a href="#PretrainLM-165"><span class="linenos">165</span></a>
</span><span id="PretrainLM-166"><a href="#PretrainLM-166"><span class="linenos">166</span></a><span class="sd">        Returns</span>
</span><span id="PretrainLM-167"><a href="#PretrainLM-167"><span class="linenos">167</span></a><span class="sd">        -------</span>
</span><span id="PretrainLM-168"><a href="#PretrainLM-168"><span class="linenos">168</span></a><span class="sd">        str</span>
</span><span id="PretrainLM-169"><a href="#PretrainLM-169"><span class="linenos">169</span></a><span class="sd">            The path to the newly created directory.</span>
</span><span id="PretrainLM-170"><a href="#PretrainLM-170"><span class="linenos">170</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainLM-171"><a href="#PretrainLM-171"><span class="linenos">171</span></a>            
</span><span id="PretrainLM-172"><a href="#PretrainLM-172"><span class="linenos">172</span></a>        <span class="n">current_model_folder_paths</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span><span class="p">)</span>
</span><span id="PretrainLM-173"><a href="#PretrainLM-173"><span class="linenos">173</span></a>        <span class="n">current_model_type_folder_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">current_model_folder_paths</span> <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">model_type</span><span class="p">)]</span>
</span><span id="PretrainLM-174"><a href="#PretrainLM-174"><span class="linenos">174</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_model_type_folder_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="PretrainLM-175"><a href="#PretrainLM-175"><span class="linenos">175</span></a>            <span class="n">current_model_type_index</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">model_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">current_model_type_folder_names</span><span class="p">])</span>
</span><span id="PretrainLM-176"><a href="#PretrainLM-176"><span class="linenos">176</span></a>            <span class="n">new_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span> <span class="o">+</span> <span class="n">model_type</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">current_model_type_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span>
</span><span id="PretrainLM-177"><a href="#PretrainLM-177"><span class="linenos">177</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="PretrainLM-178"><a href="#PretrainLM-178"><span class="linenos">178</span></a>            <span class="n">new_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span> <span class="o">+</span> <span class="n">model_type</span> <span class="o">+</span> <span class="s2">&quot;_00/&quot;</span>
</span><span id="PretrainLM-179"><a href="#PretrainLM-179"><span class="linenos">179</span></a>        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">new_model_path</span><span class="p">)</span>
</span><span id="PretrainLM-180"><a href="#PretrainLM-180"><span class="linenos">180</span></a>        <span class="k">return</span> <span class="n">new_model_path</span>
</span><span id="PretrainLM-181"><a href="#PretrainLM-181"><span class="linenos">181</span></a>
</span><span id="PretrainLM-182"><a href="#PretrainLM-182"><span class="linenos">182</span></a>    <span class="k">def</span> <span class="nf">_set_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainLM-183"><a href="#PretrainLM-183"><span class="linenos">183</span></a>
</span><span id="PretrainLM-184"><a href="#PretrainLM-184"><span class="linenos">184</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM-185"><a href="#PretrainLM-185"><span class="linenos">185</span></a><span class="sd">        Sets the device to CUDA if available; otherwise, defaults to CPU.</span>
</span><span id="PretrainLM-186"><a href="#PretrainLM-186"><span class="linenos">186</span></a>
</span><span id="PretrainLM-187"><a href="#PretrainLM-187"><span class="linenos">187</span></a><span class="sd">        This method checks if a GPU is available and sets the device accordingly. If a GPU is not </span>
</span><span id="PretrainLM-188"><a href="#PretrainLM-188"><span class="linenos">188</span></a><span class="sd">        available, a warning is logged and the device is set to CPU.</span>
</span><span id="PretrainLM-189"><a href="#PretrainLM-189"><span class="linenos">189</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainLM-190"><a href="#PretrainLM-190"><span class="linenos">190</span></a>        
</span><span id="PretrainLM-191"><a href="#PretrainLM-191"><span class="linenos">191</span></a>        <span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()):</span>
</span><span id="PretrainLM-192"><a href="#PretrainLM-192"><span class="linenos">192</span></a>            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;GPU seems to be unavailable.&quot;</span><span class="p">)</span>
</span><span id="PretrainLM-193"><a href="#PretrainLM-193"><span class="linenos">193</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="PretrainLM-194"><a href="#PretrainLM-194"><span class="linenos">194</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class for pretraining a language model using the configurations provided in FinLMConfig.</p>

<p>This class handles the setup of the dataset, model configurations, and optimization settings 
for pretraining a language model. It also includes utility methods for token masking and 
directory management.</p>

<h2 id="attributes">Attributes</h2>

<p>config : FinLMConfig
    Configuration object containing dataset, model, and optimization configurations.
dataset_config : DatasetConfig
    Configuration for the dataset.
model_config : ModelConfig
    Configuration for the model architecture.
optimization_config : OptimizationConfig
    Configuration for the optimization settings.
save_root_path : str
    Path where models and results will be saved.
logger : logging.Logger
    Logger instance for logging messages related to the pretraining process.
device : torch.device
    Device on which computations will be performed (CPU or CUDA).</p>

<h2 id="methods">Methods</h2>

<p>load_dataset() -> None
    Loads the dataset based on the configuration.
mask_tokens(inputs, mlm_probability, mask_token_id, special_token_ids, n_tokens, ignore_index=-100, hard_masking=False) -> Tuple[torch.Tensor, torch.Tensor]
    Applies masked language modeling (MLM) to the input tokens.
_create_directory_and_return_save_path(model_type: str) -> str
    Creates a directory for saving the model and returns the path.
_set_device() -> None
    Sets the device to CUDA if available; otherwise, defaults to CPU.</p>
</div>


                            <div id="PretrainLM.__init__" class="classattr">
                                        <input id="PretrainLM.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">PretrainLM</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span><span class="p">:</span> <span class="n"><a href="config.html#FinLMConfig">finlm.config.FinLMConfig</a></span></span>)</span>

                <label class="view-source-button" for="PretrainLM.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainLM.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainLM.__init__-62"><a href="#PretrainLM.__init__-62"><span class="linenos">62</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">FinLMConfig</span><span class="p">):</span>
</span><span id="PretrainLM.__init__-63"><a href="#PretrainLM.__init__-63"><span class="linenos">63</span></a>
</span><span id="PretrainLM.__init__-64"><a href="#PretrainLM.__init__-64"><span class="linenos">64</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM.__init__-65"><a href="#PretrainLM.__init__-65"><span class="linenos">65</span></a><span class="sd">        Initializes the PretrainLM class with the given configuration.</span>
</span><span id="PretrainLM.__init__-66"><a href="#PretrainLM.__init__-66"><span class="linenos">66</span></a>
</span><span id="PretrainLM.__init__-67"><a href="#PretrainLM.__init__-67"><span class="linenos">67</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainLM.__init__-68"><a href="#PretrainLM.__init__-68"><span class="linenos">68</span></a><span class="sd">        ----------</span>
</span><span id="PretrainLM.__init__-69"><a href="#PretrainLM.__init__-69"><span class="linenos">69</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="PretrainLM.__init__-70"><a href="#PretrainLM.__init__-70"><span class="linenos">70</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainLM.__init__-71"><a href="#PretrainLM.__init__-71"><span class="linenos">71</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainLM.__init__-72"><a href="#PretrainLM.__init__-72"><span class="linenos">72</span></a>
</span><span id="PretrainLM.__init__-73"><a href="#PretrainLM.__init__-73"><span class="linenos">73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="PretrainLM.__init__-74"><a href="#PretrainLM.__init__-74"><span class="linenos">74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_config</span>
</span><span id="PretrainLM.__init__-75"><a href="#PretrainLM.__init__-75"><span class="linenos">75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_config</span>
</span><span id="PretrainLM.__init__-76"><a href="#PretrainLM.__init__-76"><span class="linenos">76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">optimization_config</span>
</span><span id="PretrainLM.__init__-77"><a href="#PretrainLM.__init__-77"><span class="linenos">77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">save_root_path</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">save_models_and_results_to</span>
</span><span id="PretrainLM.__init__-78"><a href="#PretrainLM.__init__-78"><span class="linenos">78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="PretrainLM.__init__-79"><a href="#PretrainLM.__init__-79"><span class="linenos">79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_device</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the PretrainLM class with the given configuration.</p>

<h2 id="parameters">Parameters</h2>

<p>config : FinLMConfig
    Configuration object containing dataset, model, and optimization configurations.</p>
</div>


                            </div>
                            <div id="PretrainLM.config" class="classattr">
                                <div class="attr variable">
            <span class="name">config</span>

        
    </div>
    <a class="headerlink" href="#PretrainLM.config"></a>
    
    

                            </div>
                            <div id="PretrainLM.dataset_config" class="classattr">
                                <div class="attr variable">
            <span class="name">dataset_config</span>

        
    </div>
    <a class="headerlink" href="#PretrainLM.dataset_config"></a>
    
    

                            </div>
                            <div id="PretrainLM.model_config" class="classattr">
                                <div class="attr variable">
            <span class="name">model_config</span>

        
    </div>
    <a class="headerlink" href="#PretrainLM.model_config"></a>
    
    

                            </div>
                            <div id="PretrainLM.optimization_config" class="classattr">
                                <div class="attr variable">
            <span class="name">optimization_config</span>

        
    </div>
    <a class="headerlink" href="#PretrainLM.optimization_config"></a>
    
    

                            </div>
                            <div id="PretrainLM.save_root_path" class="classattr">
                                <div class="attr variable">
            <span class="name">save_root_path</span>

        
    </div>
    <a class="headerlink" href="#PretrainLM.save_root_path"></a>
    
    

                            </div>
                            <div id="PretrainLM.logger" class="classattr">
                                <div class="attr variable">
            <span class="name">logger</span>

        
    </div>
    <a class="headerlink" href="#PretrainLM.logger"></a>
    
    

                            </div>
                            <div id="PretrainLM.load_dataset" class="classattr">
                                        <input id="PretrainLM.load_dataset-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_dataset</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainLM.load_dataset-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainLM.load_dataset"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainLM.load_dataset-81"><a href="#PretrainLM.load_dataset-81"><span class="linenos">81</span></a>    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainLM.load_dataset-82"><a href="#PretrainLM.load_dataset-82"><span class="linenos">82</span></a>
</span><span id="PretrainLM.load_dataset-83"><a href="#PretrainLM.load_dataset-83"><span class="linenos">83</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM.load_dataset-84"><a href="#PretrainLM.load_dataset-84"><span class="linenos">84</span></a><span class="sd">        Loads the dataset based on the dataset configuration.</span>
</span><span id="PretrainLM.load_dataset-85"><a href="#PretrainLM.load_dataset-85"><span class="linenos">85</span></a>
</span><span id="PretrainLM.load_dataset-86"><a href="#PretrainLM.load_dataset-86"><span class="linenos">86</span></a><span class="sd">        This method initializes the FinLMDataset using the dataset configuration provided in </span>
</span><span id="PretrainLM.load_dataset-87"><a href="#PretrainLM.load_dataset-87"><span class="linenos">87</span></a><span class="sd">        the FinLMConfig object.</span>
</span><span id="PretrainLM.load_dataset-88"><a href="#PretrainLM.load_dataset-88"><span class="linenos">88</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainLM.load_dataset-89"><a href="#PretrainLM.load_dataset-89"><span class="linenos">89</span></a>            
</span><span id="PretrainLM.load_dataset-90"><a href="#PretrainLM.load_dataset-90"><span class="linenos">90</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">FinLMDataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_config</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Loads the dataset based on the dataset configuration.</p>

<p>This method initializes the FinLMDataset using the dataset configuration provided in 
the FinLMConfig object.</p>
</div>


                            </div>
                            <div id="PretrainLM.mask_tokens" class="classattr">
                                        <input id="PretrainLM.mask_tokens-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@staticmethod</div>

        <span class="def">def</span>
        <span class="name">mask_tokens</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">inputs</span>,</span><span class="param">	<span class="n">mlm_probability</span>,</span><span class="param">	<span class="n">mask_token_id</span>,</span><span class="param">	<span class="n">special_token_ids</span>,</span><span class="param">	<span class="n">n_tokens</span>,</span><span class="param">	<span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span>,</span><span class="param">	<span class="n">hard_masking</span><span class="o">=</span><span class="kc">False</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainLM.mask_tokens-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainLM.mask_tokens"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainLM.mask_tokens-92"><a href="#PretrainLM.mask_tokens-92"><span class="linenos"> 92</span></a>    <span class="nd">@staticmethod</span>
</span><span id="PretrainLM.mask_tokens-93"><a href="#PretrainLM.mask_tokens-93"><span class="linenos"> 93</span></a>    <span class="k">def</span> <span class="nf">mask_tokens</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="n">special_token_ids</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="PretrainLM.mask_tokens-94"><a href="#PretrainLM.mask_tokens-94"><span class="linenos"> 94</span></a>
</span><span id="PretrainLM.mask_tokens-95"><a href="#PretrainLM.mask_tokens-95"><span class="linenos"> 95</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainLM.mask_tokens-96"><a href="#PretrainLM.mask_tokens-96"><span class="linenos"> 96</span></a><span class="sd">        Applies masked language modeling (MLM) to the input tokens.</span>
</span><span id="PretrainLM.mask_tokens-97"><a href="#PretrainLM.mask_tokens-97"><span class="linenos"> 97</span></a>
</span><span id="PretrainLM.mask_tokens-98"><a href="#PretrainLM.mask_tokens-98"><span class="linenos"> 98</span></a><span class="sd">        This method randomly masks a portion of the input tokens according to the specified </span>
</span><span id="PretrainLM.mask_tokens-99"><a href="#PretrainLM.mask_tokens-99"><span class="linenos"> 99</span></a><span class="sd">        probability, and optionally replaces some tokens with random words or keeps them unchanged.</span>
</span><span id="PretrainLM.mask_tokens-100"><a href="#PretrainLM.mask_tokens-100"><span class="linenos">100</span></a>
</span><span id="PretrainLM.mask_tokens-101"><a href="#PretrainLM.mask_tokens-101"><span class="linenos">101</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainLM.mask_tokens-102"><a href="#PretrainLM.mask_tokens-102"><span class="linenos">102</span></a><span class="sd">        ----------</span>
</span><span id="PretrainLM.mask_tokens-103"><a href="#PretrainLM.mask_tokens-103"><span class="linenos">103</span></a><span class="sd">        inputs : torch.Tensor</span>
</span><span id="PretrainLM.mask_tokens-104"><a href="#PretrainLM.mask_tokens-104"><span class="linenos">104</span></a><span class="sd">            Tensor containing the input token IDs.</span>
</span><span id="PretrainLM.mask_tokens-105"><a href="#PretrainLM.mask_tokens-105"><span class="linenos">105</span></a><span class="sd">        mlm_probability : float</span>
</span><span id="PretrainLM.mask_tokens-106"><a href="#PretrainLM.mask_tokens-106"><span class="linenos">106</span></a><span class="sd">            Probability of masking a token for MLM.</span>
</span><span id="PretrainLM.mask_tokens-107"><a href="#PretrainLM.mask_tokens-107"><span class="linenos">107</span></a><span class="sd">        mask_token_id : int</span>
</span><span id="PretrainLM.mask_tokens-108"><a href="#PretrainLM.mask_tokens-108"><span class="linenos">108</span></a><span class="sd">            The token ID to use for masking (typically the ID for the [MASK] token).</span>
</span><span id="PretrainLM.mask_tokens-109"><a href="#PretrainLM.mask_tokens-109"><span class="linenos">109</span></a><span class="sd">        special_token_ids : list[int]</span>
</span><span id="PretrainLM.mask_tokens-110"><a href="#PretrainLM.mask_tokens-110"><span class="linenos">110</span></a><span class="sd">            List of token IDs that should not be masked (e.g., special tokens like [CLS], [SEP]).</span>
</span><span id="PretrainLM.mask_tokens-111"><a href="#PretrainLM.mask_tokens-111"><span class="linenos">111</span></a><span class="sd">        n_tokens : int</span>
</span><span id="PretrainLM.mask_tokens-112"><a href="#PretrainLM.mask_tokens-112"><span class="linenos">112</span></a><span class="sd">            The total number of tokens in the vocabulary (used for selecting random tokens).</span>
</span><span id="PretrainLM.mask_tokens-113"><a href="#PretrainLM.mask_tokens-113"><span class="linenos">113</span></a><span class="sd">        ignore_index : int, optional</span>
</span><span id="PretrainLM.mask_tokens-114"><a href="#PretrainLM.mask_tokens-114"><span class="linenos">114</span></a><span class="sd">            The index to ignore in the loss calculation (default is -100).</span>
</span><span id="PretrainLM.mask_tokens-115"><a href="#PretrainLM.mask_tokens-115"><span class="linenos">115</span></a><span class="sd">        hard_masking : bool, optional</span>
</span><span id="PretrainLM.mask_tokens-116"><a href="#PretrainLM.mask_tokens-116"><span class="linenos">116</span></a><span class="sd">            If True, all masked tokens are replaced by the mask token; otherwise, some tokens may be </span>
</span><span id="PretrainLM.mask_tokens-117"><a href="#PretrainLM.mask_tokens-117"><span class="linenos">117</span></a><span class="sd">            replaced by random tokens or left unchanged (default is False).</span>
</span><span id="PretrainLM.mask_tokens-118"><a href="#PretrainLM.mask_tokens-118"><span class="linenos">118</span></a>
</span><span id="PretrainLM.mask_tokens-119"><a href="#PretrainLM.mask_tokens-119"><span class="linenos">119</span></a><span class="sd">        Returns</span>
</span><span id="PretrainLM.mask_tokens-120"><a href="#PretrainLM.mask_tokens-120"><span class="linenos">120</span></a><span class="sd">        -------</span>
</span><span id="PretrainLM.mask_tokens-121"><a href="#PretrainLM.mask_tokens-121"><span class="linenos">121</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainLM.mask_tokens-122"><a href="#PretrainLM.mask_tokens-122"><span class="linenos">122</span></a><span class="sd">            A tuple containing the masked input tensor and the corresponding labels tensor.</span>
</span><span id="PretrainLM.mask_tokens-123"><a href="#PretrainLM.mask_tokens-123"><span class="linenos">123</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainLM.mask_tokens-124"><a href="#PretrainLM.mask_tokens-124"><span class="linenos">124</span></a>        
</span><span id="PretrainLM.mask_tokens-125"><a href="#PretrainLM.mask_tokens-125"><span class="linenos">125</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="PretrainLM.mask_tokens-126"><a href="#PretrainLM.mask_tokens-126"><span class="linenos">126</span></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="PretrainLM.mask_tokens-127"><a href="#PretrainLM.mask_tokens-127"><span class="linenos">127</span></a>        <span class="n">probability_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainLM.mask_tokens-128"><a href="#PretrainLM.mask_tokens-128"><span class="linenos">128</span></a>        <span class="c1"># create special_token_mask, first set all entries to false</span>
</span><span id="PretrainLM.mask_tokens-129"><a href="#PretrainLM.mask_tokens-129"><span class="linenos">129</span></a>        <span class="n">special_tokens_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="PretrainLM.mask_tokens-130"><a href="#PretrainLM.mask_tokens-130"><span class="linenos">130</span></a>        <span class="c1"># flag all special tokens as true</span>
</span><span id="PretrainLM.mask_tokens-131"><a href="#PretrainLM.mask_tokens-131"><span class="linenos">131</span></a>        <span class="k">for</span> <span class="n">sp_id</span> <span class="ow">in</span> <span class="n">special_token_ids</span><span class="p">:</span>
</span><span id="PretrainLM.mask_tokens-132"><a href="#PretrainLM.mask_tokens-132"><span class="linenos">132</span></a>            <span class="n">special_tokens_mask</span> <span class="o">=</span> <span class="n">special_tokens_mask</span> <span class="o">|</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">==</span> <span class="n">sp_id</span><span class="p">)</span>
</span><span id="PretrainLM.mask_tokens-133"><a href="#PretrainLM.mask_tokens-133"><span class="linenos">133</span></a>
</span><span id="PretrainLM.mask_tokens-134"><a href="#PretrainLM.mask_tokens-134"><span class="linenos">134</span></a>        <span class="n">probability_matrix</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">special_tokens_mask</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</span><span id="PretrainLM.mask_tokens-135"><a href="#PretrainLM.mask_tokens-135"><span class="linenos">135</span></a>        <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">probability_matrix</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span id="PretrainLM.mask_tokens-136"><a href="#PretrainLM.mask_tokens-136"><span class="linenos">136</span></a>        <span class="k">if</span> <span class="n">ignore_index</span><span class="p">:</span>
</span><span id="PretrainLM.mask_tokens-137"><a href="#PretrainLM.mask_tokens-137"><span class="linenos">137</span></a>            <span class="n">labels</span><span class="p">[</span><span class="o">~</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">ignore_index</span>  <span class="c1"># We only compute loss on masked tokens</span>
</span><span id="PretrainLM.mask_tokens-138"><a href="#PretrainLM.mask_tokens-138"><span class="linenos">138</span></a>
</span><span id="PretrainLM.mask_tokens-139"><a href="#PretrainLM.mask_tokens-139"><span class="linenos">139</span></a>        <span class="k">if</span> <span class="n">hard_masking</span><span class="p">:</span>
</span><span id="PretrainLM.mask_tokens-140"><a href="#PretrainLM.mask_tokens-140"><span class="linenos">140</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_token_id</span>
</span><span id="PretrainLM.mask_tokens-141"><a href="#PretrainLM.mask_tokens-141"><span class="linenos">141</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="PretrainLM.mask_tokens-142"><a href="#PretrainLM.mask_tokens-142"><span class="linenos">142</span></a>            <span class="c1"># 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])</span>
</span><span id="PretrainLM.mask_tokens-143"><a href="#PretrainLM.mask_tokens-143"><span class="linenos">143</span></a>            <span class="n">indices_replaced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">masked_indices</span>
</span><span id="PretrainLM.mask_tokens-144"><a href="#PretrainLM.mask_tokens-144"><span class="linenos">144</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">indices_replaced</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_token_id</span> 
</span><span id="PretrainLM.mask_tokens-145"><a href="#PretrainLM.mask_tokens-145"><span class="linenos">145</span></a>
</span><span id="PretrainLM.mask_tokens-146"><a href="#PretrainLM.mask_tokens-146"><span class="linenos">146</span></a>            <span class="c1"># 10% of the time, we replace masked input tokens with random word</span>
</span><span id="PretrainLM.mask_tokens-147"><a href="#PretrainLM.mask_tokens-147"><span class="linenos">147</span></a>            <span class="n">indices_random</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">masked_indices</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">indices_replaced</span>
</span><span id="PretrainLM.mask_tokens-148"><a href="#PretrainLM.mask_tokens-148"><span class="linenos">148</span></a>            <span class="n">random_words</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_tokens</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="PretrainLM.mask_tokens-149"><a href="#PretrainLM.mask_tokens-149"><span class="linenos">149</span></a>            <span class="n">inputs</span><span class="p">[</span><span class="n">indices_random</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_words</span><span class="p">[</span><span class="n">indices_random</span><span class="p">]</span>
</span><span id="PretrainLM.mask_tokens-150"><a href="#PretrainLM.mask_tokens-150"><span class="linenos">150</span></a>
</span><span id="PretrainLM.mask_tokens-151"><a href="#PretrainLM.mask_tokens-151"><span class="linenos">151</span></a>        <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span>
</span></pre></div>


            <div class="docstring"><p>Applies masked language modeling (MLM) to the input tokens.</p>

<p>This method randomly masks a portion of the input tokens according to the specified 
probability, and optionally replaces some tokens with random words or keeps them unchanged.</p>

<h2 id="parameters">Parameters</h2>

<p>inputs : torch.Tensor
    Tensor containing the input token IDs.
mlm_probability : float
    Probability of masking a token for MLM.
mask_token_id : int
    The token ID to use for masking (typically the ID for the [MASK] token).
special_token_ids : list[int]
    List of token IDs that should not be masked (e.g., special tokens like [CLS], [SEP]).
n_tokens : int
    The total number of tokens in the vocabulary (used for selecting random tokens).
ignore_index : int, optional
    The index to ignore in the loss calculation (default is -100).
hard_masking : bool, optional
    If True, all masked tokens are replaced by the mask token; otherwise, some tokens may be 
    replaced by random tokens or left unchanged (default is False).</p>

<h2 id="returns">Returns</h2>

<p>Tuple[torch.Tensor, torch.Tensor]
    A tuple containing the masked input tensor and the corresponding labels tensor.</p>
</div>


                            </div>
                </section>
                <section id="PretrainMLM">
                            <input id="PretrainMLM-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PretrainMLM</span><wbr>(<span class="base"><a href="#PretrainLM">PretrainLM</a></span>):

                <label class="view-source-button" for="PretrainMLM-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainMLM"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainMLM-197"><a href="#PretrainMLM-197"><span class="linenos">197</span></a><span class="k">class</span> <span class="nc">PretrainMLM</span><span class="p">(</span><span class="n">PretrainLM</span><span class="p">):</span>
</span><span id="PretrainMLM-198"><a href="#PretrainMLM-198"><span class="linenos">198</span></a>
</span><span id="PretrainMLM-199"><a href="#PretrainMLM-199"><span class="linenos">199</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM-200"><a href="#PretrainMLM-200"><span class="linenos">200</span></a><span class="sd">    A class for pretraining a Masked Language Model (MLM) using the FinLM framework.</span>
</span><span id="PretrainMLM-201"><a href="#PretrainMLM-201"><span class="linenos">201</span></a>
</span><span id="PretrainMLM-202"><a href="#PretrainMLM-202"><span class="linenos">202</span></a><span class="sd">    This class inherits from `PretrainLM` and provides specific implementations for </span>
</span><span id="PretrainMLM-203"><a href="#PretrainMLM-203"><span class="linenos">203</span></a><span class="sd">    preparing data, loading the model, and training the Masked Language Model (MLM). </span>
</span><span id="PretrainMLM-204"><a href="#PretrainMLM-204"><span class="linenos">204</span></a>
</span><span id="PretrainMLM-205"><a href="#PretrainMLM-205"><span class="linenos">205</span></a><span class="sd">    Attributes</span>
</span><span id="PretrainMLM-206"><a href="#PretrainMLM-206"><span class="linenos">206</span></a><span class="sd">    ----------</span>
</span><span id="PretrainMLM-207"><a href="#PretrainMLM-207"><span class="linenos">207</span></a><span class="sd">    config : FinLMConfig</span>
</span><span id="PretrainMLM-208"><a href="#PretrainMLM-208"><span class="linenos">208</span></a><span class="sd">        Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainMLM-209"><a href="#PretrainMLM-209"><span class="linenos">209</span></a><span class="sd">    dataset : FinLMDataset</span>
</span><span id="PretrainMLM-210"><a href="#PretrainMLM-210"><span class="linenos">210</span></a><span class="sd">        The dataset prepared for MLM training.</span>
</span><span id="PretrainMLM-211"><a href="#PretrainMLM-211"><span class="linenos">211</span></a><span class="sd">    model : ElectraForMaskedLM</span>
</span><span id="PretrainMLM-212"><a href="#PretrainMLM-212"><span class="linenos">212</span></a><span class="sd">        The Electra model configured for masked language modeling.</span>
</span><span id="PretrainMLM-213"><a href="#PretrainMLM-213"><span class="linenos">213</span></a><span class="sd">    optimizer : torch.optim.Optimizer</span>
</span><span id="PretrainMLM-214"><a href="#PretrainMLM-214"><span class="linenos">214</span></a><span class="sd">        The optimizer used for training.</span>
</span><span id="PretrainMLM-215"><a href="#PretrainMLM-215"><span class="linenos">215</span></a><span class="sd">    scheduler : torch.optim.lr_scheduler.LambdaLR</span>
</span><span id="PretrainMLM-216"><a href="#PretrainMLM-216"><span class="linenos">216</span></a><span class="sd">        The learning rate scheduler used during training.</span>
</span><span id="PretrainMLM-217"><a href="#PretrainMLM-217"><span class="linenos">217</span></a><span class="sd">    iteration_steps_per_epoch : int</span>
</span><span id="PretrainMLM-218"><a href="#PretrainMLM-218"><span class="linenos">218</span></a><span class="sd">        Number of iteration steps per training epoch.</span>
</span><span id="PretrainMLM-219"><a href="#PretrainMLM-219"><span class="linenos">219</span></a><span class="sd">    logger : logging.Logger</span>
</span><span id="PretrainMLM-220"><a href="#PretrainMLM-220"><span class="linenos">220</span></a><span class="sd">        Logger instance for logging messages related to training.</span>
</span><span id="PretrainMLM-221"><a href="#PretrainMLM-221"><span class="linenos">221</span></a><span class="sd">    device : torch.device</span>
</span><span id="PretrainMLM-222"><a href="#PretrainMLM-222"><span class="linenos">222</span></a><span class="sd">        Device on which computations will be performed (CPU or CUDA).</span>
</span><span id="PretrainMLM-223"><a href="#PretrainMLM-223"><span class="linenos">223</span></a>
</span><span id="PretrainMLM-224"><a href="#PretrainMLM-224"><span class="linenos">224</span></a><span class="sd">    Methods</span>
</span><span id="PretrainMLM-225"><a href="#PretrainMLM-225"><span class="linenos">225</span></a><span class="sd">    -------</span>
</span><span id="PretrainMLM-226"><a href="#PretrainMLM-226"><span class="linenos">226</span></a><span class="sd">    load_model() -&gt; None</span>
</span><span id="PretrainMLM-227"><a href="#PretrainMLM-227"><span class="linenos">227</span></a><span class="sd">        Loads and configures the Electra model for masked language modeling.</span>
</span><span id="PretrainMLM-228"><a href="#PretrainMLM-228"><span class="linenos">228</span></a><span class="sd">    load_optimization() -&gt; None</span>
</span><span id="PretrainMLM-229"><a href="#PretrainMLM-229"><span class="linenos">229</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainMLM-230"><a href="#PretrainMLM-230"><span class="linenos">230</span></a><span class="sd">    prepare_data_model_optimizer() -&gt; None</span>
</span><span id="PretrainMLM-231"><a href="#PretrainMLM-231"><span class="linenos">231</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="PretrainMLM-232"><a href="#PretrainMLM-232"><span class="linenos">232</span></a><span class="sd">    train() -&gt; None</span>
</span><span id="PretrainMLM-233"><a href="#PretrainMLM-233"><span class="linenos">233</span></a><span class="sd">        Trains the masked language model and saves the results and model.</span>
</span><span id="PretrainMLM-234"><a href="#PretrainMLM-234"><span class="linenos">234</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PretrainMLM-235"><a href="#PretrainMLM-235"><span class="linenos">235</span></a>
</span><span id="PretrainMLM-236"><a href="#PretrainMLM-236"><span class="linenos">236</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="PretrainMLM-237"><a href="#PretrainMLM-237"><span class="linenos">237</span></a>
</span><span id="PretrainMLM-238"><a href="#PretrainMLM-238"><span class="linenos">238</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM-239"><a href="#PretrainMLM-239"><span class="linenos">239</span></a><span class="sd">        Initializes the PretrainMLM class with the given configuration.</span>
</span><span id="PretrainMLM-240"><a href="#PretrainMLM-240"><span class="linenos">240</span></a>
</span><span id="PretrainMLM-241"><a href="#PretrainMLM-241"><span class="linenos">241</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainMLM-242"><a href="#PretrainMLM-242"><span class="linenos">242</span></a><span class="sd">        ----------</span>
</span><span id="PretrainMLM-243"><a href="#PretrainMLM-243"><span class="linenos">243</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="PretrainMLM-244"><a href="#PretrainMLM-244"><span class="linenos">244</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainMLM-245"><a href="#PretrainMLM-245"><span class="linenos">245</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM-246"><a href="#PretrainMLM-246"><span class="linenos">246</span></a>
</span><span id="PretrainMLM-247"><a href="#PretrainMLM-247"><span class="linenos">247</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="PretrainMLM-248"><a href="#PretrainMLM-248"><span class="linenos">248</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span><span id="PretrainMLM-249"><a href="#PretrainMLM-249"><span class="linenos">249</span></a>
</span><span id="PretrainMLM-250"><a href="#PretrainMLM-250"><span class="linenos">250</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainMLM-251"><a href="#PretrainMLM-251"><span class="linenos">251</span></a>
</span><span id="PretrainMLM-252"><a href="#PretrainMLM-252"><span class="linenos">252</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM-253"><a href="#PretrainMLM-253"><span class="linenos">253</span></a><span class="sd">        Loads and configures the Electra model for masked language modeling.</span>
</span><span id="PretrainMLM-254"><a href="#PretrainMLM-254"><span class="linenos">254</span></a>
</span><span id="PretrainMLM-255"><a href="#PretrainMLM-255"><span class="linenos">255</span></a><span class="sd">        This method initializes the Electra model using the configuration settings, </span>
</span><span id="PretrainMLM-256"><a href="#PretrainMLM-256"><span class="linenos">256</span></a><span class="sd">        including vocabulary size, embedding size, hidden size, and other model parameters. </span>
</span><span id="PretrainMLM-257"><a href="#PretrainMLM-257"><span class="linenos">257</span></a><span class="sd">        The model is then moved to the appropriate device (CPU or GPU).</span>
</span><span id="PretrainMLM-258"><a href="#PretrainMLM-258"><span class="linenos">258</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM-259"><a href="#PretrainMLM-259"><span class="linenos">259</span></a>            
</span><span id="PretrainMLM-260"><a href="#PretrainMLM-260"><span class="linenos">260</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="PretrainMLM-261"><a href="#PretrainMLM-261"><span class="linenos">261</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainMLM-262"><a href="#PretrainMLM-262"><span class="linenos">262</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="PretrainMLM-263"><a href="#PretrainMLM-263"><span class="linenos">263</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="PretrainMLM-264"><a href="#PretrainMLM-264"><span class="linenos">264</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="PretrainMLM-265"><a href="#PretrainMLM-265"><span class="linenos">265</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span>
</span><span id="PretrainMLM-266"><a href="#PretrainMLM-266"><span class="linenos">266</span></a>            <span class="n">intermediate_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">intermediate_size</span>
</span><span id="PretrainMLM-267"><a href="#PretrainMLM-267"><span class="linenos">267</span></a>        <span class="p">)</span>
</span><span id="PretrainMLM-268"><a href="#PretrainMLM-268"><span class="linenos">268</span></a>
</span><span id="PretrainMLM-269"><a href="#PretrainMLM-269"><span class="linenos">269</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ElectraForMaskedLM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
</span><span id="PretrainMLM-270"><a href="#PretrainMLM-270"><span class="linenos">270</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainMLM-271"><a href="#PretrainMLM-271"><span class="linenos">271</span></a>
</span><span id="PretrainMLM-272"><a href="#PretrainMLM-272"><span class="linenos">272</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainMLM-273"><a href="#PretrainMLM-273"><span class="linenos">273</span></a>
</span><span id="PretrainMLM-274"><a href="#PretrainMLM-274"><span class="linenos">274</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM-275"><a href="#PretrainMLM-275"><span class="linenos">275</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainMLM-276"><a href="#PretrainMLM-276"><span class="linenos">276</span></a>
</span><span id="PretrainMLM-277"><a href="#PretrainMLM-277"><span class="linenos">277</span></a><span class="sd">        This method calculates the total number of training steps, initializes the AdamW optimizer, </span>
</span><span id="PretrainMLM-278"><a href="#PretrainMLM-278"><span class="linenos">278</span></a><span class="sd">        and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="PretrainMLM-279"><a href="#PretrainMLM-279"><span class="linenos">279</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM-280"><a href="#PretrainMLM-280"><span class="linenos">280</span></a>
</span><span id="PretrainMLM-281"><a href="#PretrainMLM-281"><span class="linenos">281</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="PretrainMLM-282"><a href="#PretrainMLM-282"><span class="linenos">282</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="PretrainMLM-283"><a href="#PretrainMLM-283"><span class="linenos">283</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="PretrainMLM-284"><a href="#PretrainMLM-284"><span class="linenos">284</span></a>
</span><span id="PretrainMLM-285"><a href="#PretrainMLM-285"><span class="linenos">285</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="PretrainMLM-286"><a href="#PretrainMLM-286"><span class="linenos">286</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span>  
</span><span id="PretrainMLM-287"><a href="#PretrainMLM-287"><span class="linenos">287</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="PretrainMLM-288"><a href="#PretrainMLM-288"><span class="linenos">288</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span><span id="PretrainMLM-289"><a href="#PretrainMLM-289"><span class="linenos">289</span></a>
</span><span id="PretrainMLM-290"><a href="#PretrainMLM-290"><span class="linenos">290</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainMLM-291"><a href="#PretrainMLM-291"><span class="linenos">291</span></a>
</span><span id="PretrainMLM-292"><a href="#PretrainMLM-292"><span class="linenos">292</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM-293"><a href="#PretrainMLM-293"><span class="linenos">293</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="PretrainMLM-294"><a href="#PretrainMLM-294"><span class="linenos">294</span></a>
</span><span id="PretrainMLM-295"><a href="#PretrainMLM-295"><span class="linenos">295</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the model, </span>
</span><span id="PretrainMLM-296"><a href="#PretrainMLM-296"><span class="linenos">296</span></a><span class="sd">        and set up the optimizer and learning rate scheduler.</span>
</span><span id="PretrainMLM-297"><a href="#PretrainMLM-297"><span class="linenos">297</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM-298"><a href="#PretrainMLM-298"><span class="linenos">298</span></a>            
</span><span id="PretrainMLM-299"><a href="#PretrainMLM-299"><span class="linenos">299</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="PretrainMLM-300"><a href="#PretrainMLM-300"><span class="linenos">300</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="PretrainMLM-301"><a href="#PretrainMLM-301"><span class="linenos">301</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span><span id="PretrainMLM-302"><a href="#PretrainMLM-302"><span class="linenos">302</span></a>
</span><span id="PretrainMLM-303"><a href="#PretrainMLM-303"><span class="linenos">303</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainMLM-304"><a href="#PretrainMLM-304"><span class="linenos">304</span></a>
</span><span id="PretrainMLM-305"><a href="#PretrainMLM-305"><span class="linenos">305</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM-306"><a href="#PretrainMLM-306"><span class="linenos">306</span></a><span class="sd">        Trains the masked language model and saves the results and model.</span>
</span><span id="PretrainMLM-307"><a href="#PretrainMLM-307"><span class="linenos">307</span></a>
</span><span id="PretrainMLM-308"><a href="#PretrainMLM-308"><span class="linenos">308</span></a><span class="sd">        This method handles the training loop, including masking input tokens, calculating </span>
</span><span id="PretrainMLM-309"><a href="#PretrainMLM-309"><span class="linenos">309</span></a><span class="sd">        the MLM loss, updating model parameters, and logging training metrics. After training </span>
</span><span id="PretrainMLM-310"><a href="#PretrainMLM-310"><span class="linenos">310</span></a><span class="sd">        is complete, it saves the model, training metrics, and plots of the loss and accuracy.</span>
</span><span id="PretrainMLM-311"><a href="#PretrainMLM-311"><span class="linenos">311</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM-312"><a href="#PretrainMLM-312"><span class="linenos">312</span></a>
</span><span id="PretrainMLM-313"><a href="#PretrainMLM-313"><span class="linenos">313</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-314"><a href="#PretrainMLM-314"><span class="linenos">314</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="PretrainMLM-315"><a href="#PretrainMLM-315"><span class="linenos">315</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainMLM-316"><a href="#PretrainMLM-316"><span class="linenos">316</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainMLM-317"><a href="#PretrainMLM-317"><span class="linenos">317</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainMLM-318"><a href="#PretrainMLM-318"><span class="linenos">318</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainMLM-319"><a href="#PretrainMLM-319"><span class="linenos">319</span></a>
</span><span id="PretrainMLM-320"><a href="#PretrainMLM-320"><span class="linenos">320</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="PretrainMLM-321"><a href="#PretrainMLM-321"><span class="linenos">321</span></a>
</span><span id="PretrainMLM-322"><a href="#PretrainMLM-322"><span class="linenos">322</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="PretrainMLM-323"><a href="#PretrainMLM-323"><span class="linenos">323</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="PretrainMLM-324"><a href="#PretrainMLM-324"><span class="linenos">324</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="PretrainMLM-325"><a href="#PretrainMLM-325"><span class="linenos">325</span></a>
</span><span id="PretrainMLM-326"><a href="#PretrainMLM-326"><span class="linenos">326</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="PretrainMLM-327"><a href="#PretrainMLM-327"><span class="linenos">327</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainMLM-328"><a href="#PretrainMLM-328"><span class="linenos">328</span></a>
</span><span id="PretrainMLM-329"><a href="#PretrainMLM-329"><span class="linenos">329</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="PretrainMLM-330"><a href="#PretrainMLM-330"><span class="linenos">330</span></a>                    <span class="n">inputs</span><span class="p">,</span>
</span><span id="PretrainMLM-331"><a href="#PretrainMLM-331"><span class="linenos">331</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="PretrainMLM-332"><a href="#PretrainMLM-332"><span class="linenos">332</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainMLM-333"><a href="#PretrainMLM-333"><span class="linenos">333</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="PretrainMLM-334"><a href="#PretrainMLM-334"><span class="linenos">334</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span><span id="PretrainMLM-335"><a href="#PretrainMLM-335"><span class="linenos">335</span></a>
</span><span id="PretrainMLM-336"><a href="#PretrainMLM-336"><span class="linenos">336</span></a>                <span class="n">mlm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="PretrainMLM-337"><a href="#PretrainMLM-337"><span class="linenos">337</span></a>                <span class="n">mlm_loss</span><span class="p">,</span> <span class="n">mlm_logits</span> <span class="o">=</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="PretrainMLM-338"><a href="#PretrainMLM-338"><span class="linenos">338</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainMLM-339"><a href="#PretrainMLM-339"><span class="linenos">339</span></a>
</span><span id="PretrainMLM-340"><a href="#PretrainMLM-340"><span class="linenos">340</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="PretrainMLM-341"><a href="#PretrainMLM-341"><span class="linenos">341</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="PretrainMLM-342"><a href="#PretrainMLM-342"><span class="linenos">342</span></a>
</span><span id="PretrainMLM-343"><a href="#PretrainMLM-343"><span class="linenos">343</span></a>                <span class="c1"># determine gradients</span>
</span><span id="PretrainMLM-344"><a href="#PretrainMLM-344"><span class="linenos">344</span></a>                <span class="n">mlm_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="PretrainMLM-345"><a href="#PretrainMLM-345"><span class="linenos">345</span></a>
</span><span id="PretrainMLM-346"><a href="#PretrainMLM-346"><span class="linenos">346</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="PretrainMLM-347"><a href="#PretrainMLM-347"><span class="linenos">347</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="PretrainMLM-348"><a href="#PretrainMLM-348"><span class="linenos">348</span></a>
</span><span id="PretrainMLM-349"><a href="#PretrainMLM-349"><span class="linenos">349</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="PretrainMLM-350"><a href="#PretrainMLM-350"><span class="linenos">350</span></a>                <span class="n">mlm_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
</span><span id="PretrainMLM-351"><a href="#PretrainMLM-351"><span class="linenos">351</span></a>                <span class="n">mlm_grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">mlm_grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="PretrainMLM-352"><a href="#PretrainMLM-352"><span class="linenos">352</span></a>
</span><span id="PretrainMLM-353"><a href="#PretrainMLM-353"><span class="linenos">353</span></a>                <span class="c1"># update parameters        </span>
</span><span id="PretrainMLM-354"><a href="#PretrainMLM-354"><span class="linenos">354</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainMLM-355"><a href="#PretrainMLM-355"><span class="linenos">355</span></a>                <span class="c1"># update learning rate</span>
</span><span id="PretrainMLM-356"><a href="#PretrainMLM-356"><span class="linenos">356</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainMLM-357"><a href="#PretrainMLM-357"><span class="linenos">357</span></a>
</span><span id="PretrainMLM-358"><a href="#PretrainMLM-358"><span class="linenos">358</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="PretrainMLM-359"><a href="#PretrainMLM-359"><span class="linenos">359</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="PretrainMLM-360"><a href="#PretrainMLM-360"><span class="linenos">360</span></a>                    <span class="c1"># mask to identify ids which have been masked before</span>
</span><span id="PretrainMLM-361"><a href="#PretrainMLM-361"><span class="linenos">361</span></a>                    <span class="n">masked_ids_mask</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span>
</span><span id="PretrainMLM-362"><a href="#PretrainMLM-362"><span class="linenos">362</span></a>                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PretrainMLM-363"><a href="#PretrainMLM-363"><span class="linenos">363</span></a>                    <span class="n">mlm_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">]</span> <span class="o">==</span> <span class="n">labels</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="PretrainMLM-364"><a href="#PretrainMLM-364"><span class="linenos">364</span></a>
</span><span id="PretrainMLM-365"><a href="#PretrainMLM-365"><span class="linenos">365</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainMLM-366"><a href="#PretrainMLM-366"><span class="linenos">366</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainMLM-367"><a href="#PretrainMLM-367"><span class="linenos">367</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="PretrainMLM-368"><a href="#PretrainMLM-368"><span class="linenos">368</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="PretrainMLM-369"><a href="#PretrainMLM-369"><span class="linenos">369</span></a>
</span><span id="PretrainMLM-370"><a href="#PretrainMLM-370"><span class="linenos">370</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="PretrainMLM-371"><a href="#PretrainMLM-371"><span class="linenos">371</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-372"><a href="#PretrainMLM-372"><span class="linenos">372</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MLM loss: </span><span class="si">{</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-373"><a href="#PretrainMLM-373"><span class="linenos">373</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">mlm_grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-374"><a href="#PretrainMLM-374"><span class="linenos">374</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-375"><a href="#PretrainMLM-375"><span class="linenos">375</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for masking task: </span><span class="si">{</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-376"><a href="#PretrainMLM-376"><span class="linenos">376</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="PretrainMLM-377"><a href="#PretrainMLM-377"><span class="linenos">377</span></a>
</span><span id="PretrainMLM-378"><a href="#PretrainMLM-378"><span class="linenos">378</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-379"><a href="#PretrainMLM-379"><span class="linenos">379</span></a>
</span><span id="PretrainMLM-380"><a href="#PretrainMLM-380"><span class="linenos">380</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;mlm&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-381"><a href="#PretrainMLM-381"><span class="linenos">381</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="PretrainMLM-382"><a href="#PretrainMLM-382"><span class="linenos">382</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="PretrainMLM-383"><a href="#PretrainMLM-383"><span class="linenos">383</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="PretrainMLM-384"><a href="#PretrainMLM-384"><span class="linenos">384</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-385"><a href="#PretrainMLM-385"><span class="linenos">385</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="PretrainMLM-386"><a href="#PretrainMLM-386"><span class="linenos">386</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-387"><a href="#PretrainMLM-387"><span class="linenos">387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;mlm_model&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-388"><a href="#PretrainMLM-388"><span class="linenos">388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM-389"><a href="#PretrainMLM-389"><span class="linenos">389</span></a>
</span><span id="PretrainMLM-390"><a href="#PretrainMLM-390"><span class="linenos">390</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class for pretraining a Masked Language Model (MLM) using the FinLM framework.</p>

<p>This class inherits from <code><a href="#PretrainLM">PretrainLM</a></code> and provides specific implementations for 
preparing data, loading the model, and training the Masked Language Model (MLM). </p>

<h2 id="attributes">Attributes</h2>

<p>config : FinLMConfig
    Configuration object containing dataset, model, and optimization configurations.
dataset : FinLMDataset
    The dataset prepared for MLM training.
model : ElectraForMaskedLM
    The Electra model configured for masked language modeling.
optimizer : torch.optim.Optimizer
    The optimizer used for training.
scheduler : torch.optim.lr_scheduler.LambdaLR
    The learning rate scheduler used during training.
iteration_steps_per_epoch : int
    Number of iteration steps per training epoch.
logger : logging.Logger
    Logger instance for logging messages related to training.
device : torch.device
    Device on which computations will be performed (CPU or CUDA).</p>

<h2 id="methods">Methods</h2>

<p>load_model() -> None
    Loads and configures the Electra model for masked language modeling.
load_optimization() -> None
    Sets up the optimizer and learning rate scheduler based on the optimization configuration.
prepare_data_model_optimizer() -> None
    Prepares the dataset, model, and optimizer for training.
train() -> None
    Trains the masked language model and saves the results and model.</p>
</div>


                            <div id="PretrainMLM.__init__" class="classattr">
                                        <input id="PretrainMLM.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">PretrainMLM</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="PretrainMLM.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainMLM.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainMLM.__init__-236"><a href="#PretrainMLM.__init__-236"><span class="linenos">236</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="PretrainMLM.__init__-237"><a href="#PretrainMLM.__init__-237"><span class="linenos">237</span></a>
</span><span id="PretrainMLM.__init__-238"><a href="#PretrainMLM.__init__-238"><span class="linenos">238</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM.__init__-239"><a href="#PretrainMLM.__init__-239"><span class="linenos">239</span></a><span class="sd">        Initializes the PretrainMLM class with the given configuration.</span>
</span><span id="PretrainMLM.__init__-240"><a href="#PretrainMLM.__init__-240"><span class="linenos">240</span></a>
</span><span id="PretrainMLM.__init__-241"><a href="#PretrainMLM.__init__-241"><span class="linenos">241</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainMLM.__init__-242"><a href="#PretrainMLM.__init__-242"><span class="linenos">242</span></a><span class="sd">        ----------</span>
</span><span id="PretrainMLM.__init__-243"><a href="#PretrainMLM.__init__-243"><span class="linenos">243</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="PretrainMLM.__init__-244"><a href="#PretrainMLM.__init__-244"><span class="linenos">244</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainMLM.__init__-245"><a href="#PretrainMLM.__init__-245"><span class="linenos">245</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM.__init__-246"><a href="#PretrainMLM.__init__-246"><span class="linenos">246</span></a>
</span><span id="PretrainMLM.__init__-247"><a href="#PretrainMLM.__init__-247"><span class="linenos">247</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="PretrainMLM.__init__-248"><a href="#PretrainMLM.__init__-248"><span class="linenos">248</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the PretrainMLM class with the given configuration.</p>

<h2 id="parameters">Parameters</h2>

<p>config : FinLMConfig
    Configuration object containing dataset, model, and optimization configurations.</p>
</div>


                            </div>
                            <div id="PretrainMLM.load_model" class="classattr">
                                        <input id="PretrainMLM.load_model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_model</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainMLM.load_model-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainMLM.load_model"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainMLM.load_model-250"><a href="#PretrainMLM.load_model-250"><span class="linenos">250</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainMLM.load_model-251"><a href="#PretrainMLM.load_model-251"><span class="linenos">251</span></a>
</span><span id="PretrainMLM.load_model-252"><a href="#PretrainMLM.load_model-252"><span class="linenos">252</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM.load_model-253"><a href="#PretrainMLM.load_model-253"><span class="linenos">253</span></a><span class="sd">        Loads and configures the Electra model for masked language modeling.</span>
</span><span id="PretrainMLM.load_model-254"><a href="#PretrainMLM.load_model-254"><span class="linenos">254</span></a>
</span><span id="PretrainMLM.load_model-255"><a href="#PretrainMLM.load_model-255"><span class="linenos">255</span></a><span class="sd">        This method initializes the Electra model using the configuration settings, </span>
</span><span id="PretrainMLM.load_model-256"><a href="#PretrainMLM.load_model-256"><span class="linenos">256</span></a><span class="sd">        including vocabulary size, embedding size, hidden size, and other model parameters. </span>
</span><span id="PretrainMLM.load_model-257"><a href="#PretrainMLM.load_model-257"><span class="linenos">257</span></a><span class="sd">        The model is then moved to the appropriate device (CPU or GPU).</span>
</span><span id="PretrainMLM.load_model-258"><a href="#PretrainMLM.load_model-258"><span class="linenos">258</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM.load_model-259"><a href="#PretrainMLM.load_model-259"><span class="linenos">259</span></a>            
</span><span id="PretrainMLM.load_model-260"><a href="#PretrainMLM.load_model-260"><span class="linenos">260</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="PretrainMLM.load_model-261"><a href="#PretrainMLM.load_model-261"><span class="linenos">261</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainMLM.load_model-262"><a href="#PretrainMLM.load_model-262"><span class="linenos">262</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="PretrainMLM.load_model-263"><a href="#PretrainMLM.load_model-263"><span class="linenos">263</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="PretrainMLM.load_model-264"><a href="#PretrainMLM.load_model-264"><span class="linenos">264</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="PretrainMLM.load_model-265"><a href="#PretrainMLM.load_model-265"><span class="linenos">265</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span>
</span><span id="PretrainMLM.load_model-266"><a href="#PretrainMLM.load_model-266"><span class="linenos">266</span></a>            <span class="n">intermediate_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">intermediate_size</span>
</span><span id="PretrainMLM.load_model-267"><a href="#PretrainMLM.load_model-267"><span class="linenos">267</span></a>        <span class="p">)</span>
</span><span id="PretrainMLM.load_model-268"><a href="#PretrainMLM.load_model-268"><span class="linenos">268</span></a>
</span><span id="PretrainMLM.load_model-269"><a href="#PretrainMLM.load_model-269"><span class="linenos">269</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ElectraForMaskedLM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
</span><span id="PretrainMLM.load_model-270"><a href="#PretrainMLM.load_model-270"><span class="linenos">270</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Loads and configures the Electra model for masked language modeling.</p>

<p>This method initializes the Electra model using the configuration settings, 
including vocabulary size, embedding size, hidden size, and other model parameters. 
The model is then moved to the appropriate device (CPU or GPU).</p>
</div>


                            </div>
                            <div id="PretrainMLM.load_optimization" class="classattr">
                                        <input id="PretrainMLM.load_optimization-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_optimization</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainMLM.load_optimization-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainMLM.load_optimization"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainMLM.load_optimization-272"><a href="#PretrainMLM.load_optimization-272"><span class="linenos">272</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainMLM.load_optimization-273"><a href="#PretrainMLM.load_optimization-273"><span class="linenos">273</span></a>
</span><span id="PretrainMLM.load_optimization-274"><a href="#PretrainMLM.load_optimization-274"><span class="linenos">274</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM.load_optimization-275"><a href="#PretrainMLM.load_optimization-275"><span class="linenos">275</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainMLM.load_optimization-276"><a href="#PretrainMLM.load_optimization-276"><span class="linenos">276</span></a>
</span><span id="PretrainMLM.load_optimization-277"><a href="#PretrainMLM.load_optimization-277"><span class="linenos">277</span></a><span class="sd">        This method calculates the total number of training steps, initializes the AdamW optimizer, </span>
</span><span id="PretrainMLM.load_optimization-278"><a href="#PretrainMLM.load_optimization-278"><span class="linenos">278</span></a><span class="sd">        and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="PretrainMLM.load_optimization-279"><a href="#PretrainMLM.load_optimization-279"><span class="linenos">279</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM.load_optimization-280"><a href="#PretrainMLM.load_optimization-280"><span class="linenos">280</span></a>
</span><span id="PretrainMLM.load_optimization-281"><a href="#PretrainMLM.load_optimization-281"><span class="linenos">281</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="PretrainMLM.load_optimization-282"><a href="#PretrainMLM.load_optimization-282"><span class="linenos">282</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="PretrainMLM.load_optimization-283"><a href="#PretrainMLM.load_optimization-283"><span class="linenos">283</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="PretrainMLM.load_optimization-284"><a href="#PretrainMLM.load_optimization-284"><span class="linenos">284</span></a>
</span><span id="PretrainMLM.load_optimization-285"><a href="#PretrainMLM.load_optimization-285"><span class="linenos">285</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="PretrainMLM.load_optimization-286"><a href="#PretrainMLM.load_optimization-286"><span class="linenos">286</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span>  
</span><span id="PretrainMLM.load_optimization-287"><a href="#PretrainMLM.load_optimization-287"><span class="linenos">287</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="PretrainMLM.load_optimization-288"><a href="#PretrainMLM.load_optimization-288"><span class="linenos">288</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Sets up the optimizer and learning rate scheduler based on the optimization configuration.</p>

<p>This method calculates the total number of training steps, initializes the AdamW optimizer, 
and configures a linear learning rate scheduler with warm-up steps.</p>
</div>


                            </div>
                            <div id="PretrainMLM.prepare_data_model_optimizer" class="classattr">
                                        <input id="PretrainMLM.prepare_data_model_optimizer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">prepare_data_model_optimizer</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainMLM.prepare_data_model_optimizer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainMLM.prepare_data_model_optimizer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainMLM.prepare_data_model_optimizer-290"><a href="#PretrainMLM.prepare_data_model_optimizer-290"><span class="linenos">290</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainMLM.prepare_data_model_optimizer-291"><a href="#PretrainMLM.prepare_data_model_optimizer-291"><span class="linenos">291</span></a>
</span><span id="PretrainMLM.prepare_data_model_optimizer-292"><a href="#PretrainMLM.prepare_data_model_optimizer-292"><span class="linenos">292</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM.prepare_data_model_optimizer-293"><a href="#PretrainMLM.prepare_data_model_optimizer-293"><span class="linenos">293</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="PretrainMLM.prepare_data_model_optimizer-294"><a href="#PretrainMLM.prepare_data_model_optimizer-294"><span class="linenos">294</span></a>
</span><span id="PretrainMLM.prepare_data_model_optimizer-295"><a href="#PretrainMLM.prepare_data_model_optimizer-295"><span class="linenos">295</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the model, </span>
</span><span id="PretrainMLM.prepare_data_model_optimizer-296"><a href="#PretrainMLM.prepare_data_model_optimizer-296"><span class="linenos">296</span></a><span class="sd">        and set up the optimizer and learning rate scheduler.</span>
</span><span id="PretrainMLM.prepare_data_model_optimizer-297"><a href="#PretrainMLM.prepare_data_model_optimizer-297"><span class="linenos">297</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM.prepare_data_model_optimizer-298"><a href="#PretrainMLM.prepare_data_model_optimizer-298"><span class="linenos">298</span></a>            
</span><span id="PretrainMLM.prepare_data_model_optimizer-299"><a href="#PretrainMLM.prepare_data_model_optimizer-299"><span class="linenos">299</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="PretrainMLM.prepare_data_model_optimizer-300"><a href="#PretrainMLM.prepare_data_model_optimizer-300"><span class="linenos">300</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="PretrainMLM.prepare_data_model_optimizer-301"><a href="#PretrainMLM.prepare_data_model_optimizer-301"><span class="linenos">301</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Prepares the dataset, model, and optimizer for training.</p>

<p>This method calls the appropriate methods to load the dataset, load the model, 
and set up the optimizer and learning rate scheduler.</p>
</div>


                            </div>
                            <div id="PretrainMLM.train" class="classattr">
                                        <input id="PretrainMLM.train-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">train</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainMLM.train-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainMLM.train"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainMLM.train-303"><a href="#PretrainMLM.train-303"><span class="linenos">303</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainMLM.train-304"><a href="#PretrainMLM.train-304"><span class="linenos">304</span></a>
</span><span id="PretrainMLM.train-305"><a href="#PretrainMLM.train-305"><span class="linenos">305</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainMLM.train-306"><a href="#PretrainMLM.train-306"><span class="linenos">306</span></a><span class="sd">        Trains the masked language model and saves the results and model.</span>
</span><span id="PretrainMLM.train-307"><a href="#PretrainMLM.train-307"><span class="linenos">307</span></a>
</span><span id="PretrainMLM.train-308"><a href="#PretrainMLM.train-308"><span class="linenos">308</span></a><span class="sd">        This method handles the training loop, including masking input tokens, calculating </span>
</span><span id="PretrainMLM.train-309"><a href="#PretrainMLM.train-309"><span class="linenos">309</span></a><span class="sd">        the MLM loss, updating model parameters, and logging training metrics. After training </span>
</span><span id="PretrainMLM.train-310"><a href="#PretrainMLM.train-310"><span class="linenos">310</span></a><span class="sd">        is complete, it saves the model, training metrics, and plots of the loss and accuracy.</span>
</span><span id="PretrainMLM.train-311"><a href="#PretrainMLM.train-311"><span class="linenos">311</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainMLM.train-312"><a href="#PretrainMLM.train-312"><span class="linenos">312</span></a>
</span><span id="PretrainMLM.train-313"><a href="#PretrainMLM.train-313"><span class="linenos">313</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-314"><a href="#PretrainMLM.train-314"><span class="linenos">314</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="PretrainMLM.train-315"><a href="#PretrainMLM.train-315"><span class="linenos">315</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainMLM.train-316"><a href="#PretrainMLM.train-316"><span class="linenos">316</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainMLM.train-317"><a href="#PretrainMLM.train-317"><span class="linenos">317</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainMLM.train-318"><a href="#PretrainMLM.train-318"><span class="linenos">318</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainMLM.train-319"><a href="#PretrainMLM.train-319"><span class="linenos">319</span></a>
</span><span id="PretrainMLM.train-320"><a href="#PretrainMLM.train-320"><span class="linenos">320</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="PretrainMLM.train-321"><a href="#PretrainMLM.train-321"><span class="linenos">321</span></a>
</span><span id="PretrainMLM.train-322"><a href="#PretrainMLM.train-322"><span class="linenos">322</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="PretrainMLM.train-323"><a href="#PretrainMLM.train-323"><span class="linenos">323</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="PretrainMLM.train-324"><a href="#PretrainMLM.train-324"><span class="linenos">324</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="PretrainMLM.train-325"><a href="#PretrainMLM.train-325"><span class="linenos">325</span></a>
</span><span id="PretrainMLM.train-326"><a href="#PretrainMLM.train-326"><span class="linenos">326</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="PretrainMLM.train-327"><a href="#PretrainMLM.train-327"><span class="linenos">327</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainMLM.train-328"><a href="#PretrainMLM.train-328"><span class="linenos">328</span></a>
</span><span id="PretrainMLM.train-329"><a href="#PretrainMLM.train-329"><span class="linenos">329</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="PretrainMLM.train-330"><a href="#PretrainMLM.train-330"><span class="linenos">330</span></a>                    <span class="n">inputs</span><span class="p">,</span>
</span><span id="PretrainMLM.train-331"><a href="#PretrainMLM.train-331"><span class="linenos">331</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="PretrainMLM.train-332"><a href="#PretrainMLM.train-332"><span class="linenos">332</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainMLM.train-333"><a href="#PretrainMLM.train-333"><span class="linenos">333</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="PretrainMLM.train-334"><a href="#PretrainMLM.train-334"><span class="linenos">334</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span><span id="PretrainMLM.train-335"><a href="#PretrainMLM.train-335"><span class="linenos">335</span></a>
</span><span id="PretrainMLM.train-336"><a href="#PretrainMLM.train-336"><span class="linenos">336</span></a>                <span class="n">mlm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="PretrainMLM.train-337"><a href="#PretrainMLM.train-337"><span class="linenos">337</span></a>                <span class="n">mlm_loss</span><span class="p">,</span> <span class="n">mlm_logits</span> <span class="o">=</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="PretrainMLM.train-338"><a href="#PretrainMLM.train-338"><span class="linenos">338</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainMLM.train-339"><a href="#PretrainMLM.train-339"><span class="linenos">339</span></a>
</span><span id="PretrainMLM.train-340"><a href="#PretrainMLM.train-340"><span class="linenos">340</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="PretrainMLM.train-341"><a href="#PretrainMLM.train-341"><span class="linenos">341</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="PretrainMLM.train-342"><a href="#PretrainMLM.train-342"><span class="linenos">342</span></a>
</span><span id="PretrainMLM.train-343"><a href="#PretrainMLM.train-343"><span class="linenos">343</span></a>                <span class="c1"># determine gradients</span>
</span><span id="PretrainMLM.train-344"><a href="#PretrainMLM.train-344"><span class="linenos">344</span></a>                <span class="n">mlm_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="PretrainMLM.train-345"><a href="#PretrainMLM.train-345"><span class="linenos">345</span></a>
</span><span id="PretrainMLM.train-346"><a href="#PretrainMLM.train-346"><span class="linenos">346</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="PretrainMLM.train-347"><a href="#PretrainMLM.train-347"><span class="linenos">347</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="PretrainMLM.train-348"><a href="#PretrainMLM.train-348"><span class="linenos">348</span></a>
</span><span id="PretrainMLM.train-349"><a href="#PretrainMLM.train-349"><span class="linenos">349</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="PretrainMLM.train-350"><a href="#PretrainMLM.train-350"><span class="linenos">350</span></a>                <span class="n">mlm_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
</span><span id="PretrainMLM.train-351"><a href="#PretrainMLM.train-351"><span class="linenos">351</span></a>                <span class="n">mlm_grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">mlm_grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="PretrainMLM.train-352"><a href="#PretrainMLM.train-352"><span class="linenos">352</span></a>
</span><span id="PretrainMLM.train-353"><a href="#PretrainMLM.train-353"><span class="linenos">353</span></a>                <span class="c1"># update parameters        </span>
</span><span id="PretrainMLM.train-354"><a href="#PretrainMLM.train-354"><span class="linenos">354</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainMLM.train-355"><a href="#PretrainMLM.train-355"><span class="linenos">355</span></a>                <span class="c1"># update learning rate</span>
</span><span id="PretrainMLM.train-356"><a href="#PretrainMLM.train-356"><span class="linenos">356</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainMLM.train-357"><a href="#PretrainMLM.train-357"><span class="linenos">357</span></a>
</span><span id="PretrainMLM.train-358"><a href="#PretrainMLM.train-358"><span class="linenos">358</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="PretrainMLM.train-359"><a href="#PretrainMLM.train-359"><span class="linenos">359</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="PretrainMLM.train-360"><a href="#PretrainMLM.train-360"><span class="linenos">360</span></a>                    <span class="c1"># mask to identify ids which have been masked before</span>
</span><span id="PretrainMLM.train-361"><a href="#PretrainMLM.train-361"><span class="linenos">361</span></a>                    <span class="n">masked_ids_mask</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span>
</span><span id="PretrainMLM.train-362"><a href="#PretrainMLM.train-362"><span class="linenos">362</span></a>                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PretrainMLM.train-363"><a href="#PretrainMLM.train-363"><span class="linenos">363</span></a>                    <span class="n">mlm_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">]</span> <span class="o">==</span> <span class="n">labels</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="PretrainMLM.train-364"><a href="#PretrainMLM.train-364"><span class="linenos">364</span></a>
</span><span id="PretrainMLM.train-365"><a href="#PretrainMLM.train-365"><span class="linenos">365</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainMLM.train-366"><a href="#PretrainMLM.train-366"><span class="linenos">366</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainMLM.train-367"><a href="#PretrainMLM.train-367"><span class="linenos">367</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="PretrainMLM.train-368"><a href="#PretrainMLM.train-368"><span class="linenos">368</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="PretrainMLM.train-369"><a href="#PretrainMLM.train-369"><span class="linenos">369</span></a>
</span><span id="PretrainMLM.train-370"><a href="#PretrainMLM.train-370"><span class="linenos">370</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="PretrainMLM.train-371"><a href="#PretrainMLM.train-371"><span class="linenos">371</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-372"><a href="#PretrainMLM.train-372"><span class="linenos">372</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MLM loss: </span><span class="si">{</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-373"><a href="#PretrainMLM.train-373"><span class="linenos">373</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">mlm_grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-374"><a href="#PretrainMLM.train-374"><span class="linenos">374</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-375"><a href="#PretrainMLM.train-375"><span class="linenos">375</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for masking task: </span><span class="si">{</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-376"><a href="#PretrainMLM.train-376"><span class="linenos">376</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="PretrainMLM.train-377"><a href="#PretrainMLM.train-377"><span class="linenos">377</span></a>
</span><span id="PretrainMLM.train-378"><a href="#PretrainMLM.train-378"><span class="linenos">378</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-379"><a href="#PretrainMLM.train-379"><span class="linenos">379</span></a>
</span><span id="PretrainMLM.train-380"><a href="#PretrainMLM.train-380"><span class="linenos">380</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;mlm&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-381"><a href="#PretrainMLM.train-381"><span class="linenos">381</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="PretrainMLM.train-382"><a href="#PretrainMLM.train-382"><span class="linenos">382</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="PretrainMLM.train-383"><a href="#PretrainMLM.train-383"><span class="linenos">383</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="PretrainMLM.train-384"><a href="#PretrainMLM.train-384"><span class="linenos">384</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-385"><a href="#PretrainMLM.train-385"><span class="linenos">385</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="PretrainMLM.train-386"><a href="#PretrainMLM.train-386"><span class="linenos">386</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-387"><a href="#PretrainMLM.train-387"><span class="linenos">387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;mlm_model&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-388"><a href="#PretrainMLM.train-388"><span class="linenos">388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="PretrainMLM.train-389"><a href="#PretrainMLM.train-389"><span class="linenos">389</span></a>
</span><span id="PretrainMLM.train-390"><a href="#PretrainMLM.train-390"><span class="linenos">390</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Trains the masked language model and saves the results and model.</p>

<p>This method handles the training loop, including masking input tokens, calculating 
the MLM loss, updating model parameters, and logging training metrics. After training 
is complete, it saves the model, training metrics, and plots of the loss and accuracy.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PretrainLM">PretrainLM</a></dt>
                                <dd id="PretrainMLM.config" class="variable"><a href="#PretrainLM.config">config</a></dd>
                <dd id="PretrainMLM.dataset_config" class="variable"><a href="#PretrainLM.dataset_config">dataset_config</a></dd>
                <dd id="PretrainMLM.model_config" class="variable"><a href="#PretrainLM.model_config">model_config</a></dd>
                <dd id="PretrainMLM.optimization_config" class="variable"><a href="#PretrainLM.optimization_config">optimization_config</a></dd>
                <dd id="PretrainMLM.save_root_path" class="variable"><a href="#PretrainLM.save_root_path">save_root_path</a></dd>
                <dd id="PretrainMLM.logger" class="variable"><a href="#PretrainLM.logger">logger</a></dd>
                <dd id="PretrainMLM.load_dataset" class="function"><a href="#PretrainLM.load_dataset">load_dataset</a></dd>
                <dd id="PretrainMLM.mask_tokens" class="function"><a href="#PretrainLM.mask_tokens">mask_tokens</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="PretrainDiscriminator">
                            <input id="PretrainDiscriminator-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PretrainDiscriminator</span><wbr>(<span class="base"><a href="#PretrainLM">PretrainLM</a></span>):

                <label class="view-source-button" for="PretrainDiscriminator-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainDiscriminator"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainDiscriminator-393"><a href="#PretrainDiscriminator-393"><span class="linenos">393</span></a><span class="k">class</span> <span class="nc">PretrainDiscriminator</span><span class="p">(</span><span class="n">PretrainLM</span><span class="p">):</span>
</span><span id="PretrainDiscriminator-394"><a href="#PretrainDiscriminator-394"><span class="linenos">394</span></a>
</span><span id="PretrainDiscriminator-395"><a href="#PretrainDiscriminator-395"><span class="linenos">395</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-396"><a href="#PretrainDiscriminator-396"><span class="linenos">396</span></a><span class="sd">    A class for pretraining a discriminator model in the Electra framework using the FinLM setup.</span>
</span><span id="PretrainDiscriminator-397"><a href="#PretrainDiscriminator-397"><span class="linenos">397</span></a>
</span><span id="PretrainDiscriminator-398"><a href="#PretrainDiscriminator-398"><span class="linenos">398</span></a><span class="sd">    This class inherits from `PretrainLM` and provides specific implementations for </span>
</span><span id="PretrainDiscriminator-399"><a href="#PretrainDiscriminator-399"><span class="linenos">399</span></a><span class="sd">    preparing data, loading the discriminator model, and training the model.</span>
</span><span id="PretrainDiscriminator-400"><a href="#PretrainDiscriminator-400"><span class="linenos">400</span></a>
</span><span id="PretrainDiscriminator-401"><a href="#PretrainDiscriminator-401"><span class="linenos">401</span></a><span class="sd">    Attributes</span>
</span><span id="PretrainDiscriminator-402"><a href="#PretrainDiscriminator-402"><span class="linenos">402</span></a><span class="sd">    ----------</span>
</span><span id="PretrainDiscriminator-403"><a href="#PretrainDiscriminator-403"><span class="linenos">403</span></a><span class="sd">    config : FinLMConfig</span>
</span><span id="PretrainDiscriminator-404"><a href="#PretrainDiscriminator-404"><span class="linenos">404</span></a><span class="sd">        Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainDiscriminator-405"><a href="#PretrainDiscriminator-405"><span class="linenos">405</span></a><span class="sd">    dataset : FinLMDataset</span>
</span><span id="PretrainDiscriminator-406"><a href="#PretrainDiscriminator-406"><span class="linenos">406</span></a><span class="sd">        The dataset prepared for discriminator training.</span>
</span><span id="PretrainDiscriminator-407"><a href="#PretrainDiscriminator-407"><span class="linenos">407</span></a><span class="sd">    model : ElectraForPreTraining</span>
</span><span id="PretrainDiscriminator-408"><a href="#PretrainDiscriminator-408"><span class="linenos">408</span></a><span class="sd">        The Electra model configured for discriminator pretraining.</span>
</span><span id="PretrainDiscriminator-409"><a href="#PretrainDiscriminator-409"><span class="linenos">409</span></a><span class="sd">    optimizer : torch.optim.Optimizer</span>
</span><span id="PretrainDiscriminator-410"><a href="#PretrainDiscriminator-410"><span class="linenos">410</span></a><span class="sd">        The optimizer used for training.</span>
</span><span id="PretrainDiscriminator-411"><a href="#PretrainDiscriminator-411"><span class="linenos">411</span></a><span class="sd">    scheduler : torch.optim.lr_scheduler.LambdaLR</span>
</span><span id="PretrainDiscriminator-412"><a href="#PretrainDiscriminator-412"><span class="linenos">412</span></a><span class="sd">        The learning rate scheduler used during training.</span>
</span><span id="PretrainDiscriminator-413"><a href="#PretrainDiscriminator-413"><span class="linenos">413</span></a><span class="sd">    iteration_steps_per_epoch : int</span>
</span><span id="PretrainDiscriminator-414"><a href="#PretrainDiscriminator-414"><span class="linenos">414</span></a><span class="sd">        Number of iteration steps per training epoch.</span>
</span><span id="PretrainDiscriminator-415"><a href="#PretrainDiscriminator-415"><span class="linenos">415</span></a><span class="sd">    logger : logging.Logger</span>
</span><span id="PretrainDiscriminator-416"><a href="#PretrainDiscriminator-416"><span class="linenos">416</span></a><span class="sd">        Logger instance for logging messages related to training.</span>
</span><span id="PretrainDiscriminator-417"><a href="#PretrainDiscriminator-417"><span class="linenos">417</span></a><span class="sd">    device : torch.device</span>
</span><span id="PretrainDiscriminator-418"><a href="#PretrainDiscriminator-418"><span class="linenos">418</span></a><span class="sd">        Device on which computations will be performed (CPU or CUDA).</span>
</span><span id="PretrainDiscriminator-419"><a href="#PretrainDiscriminator-419"><span class="linenos">419</span></a>
</span><span id="PretrainDiscriminator-420"><a href="#PretrainDiscriminator-420"><span class="linenos">420</span></a><span class="sd">    Methods</span>
</span><span id="PretrainDiscriminator-421"><a href="#PretrainDiscriminator-421"><span class="linenos">421</span></a><span class="sd">    -------</span>
</span><span id="PretrainDiscriminator-422"><a href="#PretrainDiscriminator-422"><span class="linenos">422</span></a><span class="sd">    load_model() -&gt; None</span>
</span><span id="PretrainDiscriminator-423"><a href="#PretrainDiscriminator-423"><span class="linenos">423</span></a><span class="sd">        Loads and configures the Electra discriminator model.</span>
</span><span id="PretrainDiscriminator-424"><a href="#PretrainDiscriminator-424"><span class="linenos">424</span></a><span class="sd">    load_optimization() -&gt; None</span>
</span><span id="PretrainDiscriminator-425"><a href="#PretrainDiscriminator-425"><span class="linenos">425</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainDiscriminator-426"><a href="#PretrainDiscriminator-426"><span class="linenos">426</span></a><span class="sd">    prepare_data_model_optimizer() -&gt; None</span>
</span><span id="PretrainDiscriminator-427"><a href="#PretrainDiscriminator-427"><span class="linenos">427</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="PretrainDiscriminator-428"><a href="#PretrainDiscriminator-428"><span class="linenos">428</span></a><span class="sd">    replace_masked_tokens_randomly(inputs: torch.Tensor, mlm_probability: float, mask_token_id: int, special_token_ids: list[int], n_tokens: int, hard_masking: bool = True) -&gt; Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainDiscriminator-429"><a href="#PretrainDiscriminator-429"><span class="linenos">429</span></a><span class="sd">        Replaces masked tokens with random tokens and generates labels for discriminator training.</span>
</span><span id="PretrainDiscriminator-430"><a href="#PretrainDiscriminator-430"><span class="linenos">430</span></a><span class="sd">    train() -&gt; None</span>
</span><span id="PretrainDiscriminator-431"><a href="#PretrainDiscriminator-431"><span class="linenos">431</span></a><span class="sd">        Trains the discriminator model and saves the results and model.</span>
</span><span id="PretrainDiscriminator-432"><a href="#PretrainDiscriminator-432"><span class="linenos">432</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-433"><a href="#PretrainDiscriminator-433"><span class="linenos">433</span></a>
</span><span id="PretrainDiscriminator-434"><a href="#PretrainDiscriminator-434"><span class="linenos">434</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="PretrainDiscriminator-435"><a href="#PretrainDiscriminator-435"><span class="linenos">435</span></a>
</span><span id="PretrainDiscriminator-436"><a href="#PretrainDiscriminator-436"><span class="linenos">436</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-437"><a href="#PretrainDiscriminator-437"><span class="linenos">437</span></a><span class="sd">        Initializes the PretrainDiscriminator class with the given configuration.</span>
</span><span id="PretrainDiscriminator-438"><a href="#PretrainDiscriminator-438"><span class="linenos">438</span></a>
</span><span id="PretrainDiscriminator-439"><a href="#PretrainDiscriminator-439"><span class="linenos">439</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainDiscriminator-440"><a href="#PretrainDiscriminator-440"><span class="linenos">440</span></a><span class="sd">        ----------</span>
</span><span id="PretrainDiscriminator-441"><a href="#PretrainDiscriminator-441"><span class="linenos">441</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="PretrainDiscriminator-442"><a href="#PretrainDiscriminator-442"><span class="linenos">442</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainDiscriminator-443"><a href="#PretrainDiscriminator-443"><span class="linenos">443</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-444"><a href="#PretrainDiscriminator-444"><span class="linenos">444</span></a>
</span><span id="PretrainDiscriminator-445"><a href="#PretrainDiscriminator-445"><span class="linenos">445</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-446"><a href="#PretrainDiscriminator-446"><span class="linenos">446</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-447"><a href="#PretrainDiscriminator-447"><span class="linenos">447</span></a>
</span><span id="PretrainDiscriminator-448"><a href="#PretrainDiscriminator-448"><span class="linenos">448</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainDiscriminator-449"><a href="#PretrainDiscriminator-449"><span class="linenos">449</span></a>
</span><span id="PretrainDiscriminator-450"><a href="#PretrainDiscriminator-450"><span class="linenos">450</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-451"><a href="#PretrainDiscriminator-451"><span class="linenos">451</span></a><span class="sd">        Loads and configures the Electra discriminator model.</span>
</span><span id="PretrainDiscriminator-452"><a href="#PretrainDiscriminator-452"><span class="linenos">452</span></a>
</span><span id="PretrainDiscriminator-453"><a href="#PretrainDiscriminator-453"><span class="linenos">453</span></a><span class="sd">        This method initializes the Electra model for discriminator pretraining using the configuration settings, </span>
</span><span id="PretrainDiscriminator-454"><a href="#PretrainDiscriminator-454"><span class="linenos">454</span></a><span class="sd">        including vocabulary size, embedding size, hidden size, and other model parameters. The model is then moved </span>
</span><span id="PretrainDiscriminator-455"><a href="#PretrainDiscriminator-455"><span class="linenos">455</span></a><span class="sd">        to the appropriate device (CPU or GPU).</span>
</span><span id="PretrainDiscriminator-456"><a href="#PretrainDiscriminator-456"><span class="linenos">456</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-457"><a href="#PretrainDiscriminator-457"><span class="linenos">457</span></a>        
</span><span id="PretrainDiscriminator-458"><a href="#PretrainDiscriminator-458"><span class="linenos">458</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="PretrainDiscriminator-459"><a href="#PretrainDiscriminator-459"><span class="linenos">459</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-460"><a href="#PretrainDiscriminator-460"><span class="linenos">460</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-461"><a href="#PretrainDiscriminator-461"><span class="linenos">461</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="PretrainDiscriminator-462"><a href="#PretrainDiscriminator-462"><span class="linenos">462</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-463"><a href="#PretrainDiscriminator-463"><span class="linenos">463</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span>
</span><span id="PretrainDiscriminator-464"><a href="#PretrainDiscriminator-464"><span class="linenos">464</span></a>        <span class="p">)</span>
</span><span id="PretrainDiscriminator-465"><a href="#PretrainDiscriminator-465"><span class="linenos">465</span></a>
</span><span id="PretrainDiscriminator-466"><a href="#PretrainDiscriminator-466"><span class="linenos">466</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ElectraForPreTraining</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-467"><a href="#PretrainDiscriminator-467"><span class="linenos">467</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-468"><a href="#PretrainDiscriminator-468"><span class="linenos">468</span></a>
</span><span id="PretrainDiscriminator-469"><a href="#PretrainDiscriminator-469"><span class="linenos">469</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainDiscriminator-470"><a href="#PretrainDiscriminator-470"><span class="linenos">470</span></a>
</span><span id="PretrainDiscriminator-471"><a href="#PretrainDiscriminator-471"><span class="linenos">471</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-472"><a href="#PretrainDiscriminator-472"><span class="linenos">472</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainDiscriminator-473"><a href="#PretrainDiscriminator-473"><span class="linenos">473</span></a>
</span><span id="PretrainDiscriminator-474"><a href="#PretrainDiscriminator-474"><span class="linenos">474</span></a><span class="sd">        This method calculates the total number of training steps, initializes the AdamW optimizer, </span>
</span><span id="PretrainDiscriminator-475"><a href="#PretrainDiscriminator-475"><span class="linenos">475</span></a><span class="sd">        and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="PretrainDiscriminator-476"><a href="#PretrainDiscriminator-476"><span class="linenos">476</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-477"><a href="#PretrainDiscriminator-477"><span class="linenos">477</span></a>
</span><span id="PretrainDiscriminator-478"><a href="#PretrainDiscriminator-478"><span class="linenos">478</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="PretrainDiscriminator-479"><a href="#PretrainDiscriminator-479"><span class="linenos">479</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="PretrainDiscriminator-480"><a href="#PretrainDiscriminator-480"><span class="linenos">480</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="PretrainDiscriminator-481"><a href="#PretrainDiscriminator-481"><span class="linenos">481</span></a>
</span><span id="PretrainDiscriminator-482"><a href="#PretrainDiscriminator-482"><span class="linenos">482</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="PretrainDiscriminator-483"><a href="#PretrainDiscriminator-483"><span class="linenos">483</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span>  
</span><span id="PretrainDiscriminator-484"><a href="#PretrainDiscriminator-484"><span class="linenos">484</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="PretrainDiscriminator-485"><a href="#PretrainDiscriminator-485"><span class="linenos">485</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-486"><a href="#PretrainDiscriminator-486"><span class="linenos">486</span></a>
</span><span id="PretrainDiscriminator-487"><a href="#PretrainDiscriminator-487"><span class="linenos">487</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainDiscriminator-488"><a href="#PretrainDiscriminator-488"><span class="linenos">488</span></a>
</span><span id="PretrainDiscriminator-489"><a href="#PretrainDiscriminator-489"><span class="linenos">489</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-490"><a href="#PretrainDiscriminator-490"><span class="linenos">490</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="PretrainDiscriminator-491"><a href="#PretrainDiscriminator-491"><span class="linenos">491</span></a>
</span><span id="PretrainDiscriminator-492"><a href="#PretrainDiscriminator-492"><span class="linenos">492</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the model, </span>
</span><span id="PretrainDiscriminator-493"><a href="#PretrainDiscriminator-493"><span class="linenos">493</span></a><span class="sd">        and set up the optimizer and learning rate scheduler.</span>
</span><span id="PretrainDiscriminator-494"><a href="#PretrainDiscriminator-494"><span class="linenos">494</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-495"><a href="#PretrainDiscriminator-495"><span class="linenos">495</span></a>        
</span><span id="PretrainDiscriminator-496"><a href="#PretrainDiscriminator-496"><span class="linenos">496</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-497"><a href="#PretrainDiscriminator-497"><span class="linenos">497</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-498"><a href="#PretrainDiscriminator-498"><span class="linenos">498</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-499"><a href="#PretrainDiscriminator-499"><span class="linenos">499</span></a>
</span><span id="PretrainDiscriminator-500"><a href="#PretrainDiscriminator-500"><span class="linenos">500</span></a>
</span><span id="PretrainDiscriminator-501"><a href="#PretrainDiscriminator-501"><span class="linenos">501</span></a>    <span class="k">def</span> <span class="nf">replace_masked_tokens_randomly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="n">special_token_ids</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="PretrainDiscriminator-502"><a href="#PretrainDiscriminator-502"><span class="linenos">502</span></a>
</span><span id="PretrainDiscriminator-503"><a href="#PretrainDiscriminator-503"><span class="linenos">503</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-504"><a href="#PretrainDiscriminator-504"><span class="linenos">504</span></a><span class="sd">        Replaces masked tokens with random tokens and generates labels for discriminator training.</span>
</span><span id="PretrainDiscriminator-505"><a href="#PretrainDiscriminator-505"><span class="linenos">505</span></a>
</span><span id="PretrainDiscriminator-506"><a href="#PretrainDiscriminator-506"><span class="linenos">506</span></a><span class="sd">        This method first applies masked language modeling (MLM) to the input tokens. It then replaces </span>
</span><span id="PretrainDiscriminator-507"><a href="#PretrainDiscriminator-507"><span class="linenos">507</span></a><span class="sd">        the masked tokens with random tokens and generates labels indicating whether a token has been </span>
</span><span id="PretrainDiscriminator-508"><a href="#PretrainDiscriminator-508"><span class="linenos">508</span></a><span class="sd">        replaced (1) or not (0).</span>
</span><span id="PretrainDiscriminator-509"><a href="#PretrainDiscriminator-509"><span class="linenos">509</span></a>
</span><span id="PretrainDiscriminator-510"><a href="#PretrainDiscriminator-510"><span class="linenos">510</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainDiscriminator-511"><a href="#PretrainDiscriminator-511"><span class="linenos">511</span></a><span class="sd">        ----------</span>
</span><span id="PretrainDiscriminator-512"><a href="#PretrainDiscriminator-512"><span class="linenos">512</span></a><span class="sd">        inputs : torch.Tensor</span>
</span><span id="PretrainDiscriminator-513"><a href="#PretrainDiscriminator-513"><span class="linenos">513</span></a><span class="sd">            Tensor containing the input token IDs.</span>
</span><span id="PretrainDiscriminator-514"><a href="#PretrainDiscriminator-514"><span class="linenos">514</span></a><span class="sd">        mlm_probability : float</span>
</span><span id="PretrainDiscriminator-515"><a href="#PretrainDiscriminator-515"><span class="linenos">515</span></a><span class="sd">            Probability of masking a token for MLM.</span>
</span><span id="PretrainDiscriminator-516"><a href="#PretrainDiscriminator-516"><span class="linenos">516</span></a><span class="sd">        mask_token_id : int</span>
</span><span id="PretrainDiscriminator-517"><a href="#PretrainDiscriminator-517"><span class="linenos">517</span></a><span class="sd">            The token ID to use for masking (typically the ID for the [MASK] token).</span>
</span><span id="PretrainDiscriminator-518"><a href="#PretrainDiscriminator-518"><span class="linenos">518</span></a><span class="sd">        special_token_ids : list[int]</span>
</span><span id="PretrainDiscriminator-519"><a href="#PretrainDiscriminator-519"><span class="linenos">519</span></a><span class="sd">            List of token IDs that should not be masked (e.g., special tokens like [CLS], [SEP]).</span>
</span><span id="PretrainDiscriminator-520"><a href="#PretrainDiscriminator-520"><span class="linenos">520</span></a><span class="sd">        n_tokens : int</span>
</span><span id="PretrainDiscriminator-521"><a href="#PretrainDiscriminator-521"><span class="linenos">521</span></a><span class="sd">            The total number of tokens in the vocabulary (used for selecting random tokens).</span>
</span><span id="PretrainDiscriminator-522"><a href="#PretrainDiscriminator-522"><span class="linenos">522</span></a><span class="sd">        hard_masking : bool, optional</span>
</span><span id="PretrainDiscriminator-523"><a href="#PretrainDiscriminator-523"><span class="linenos">523</span></a><span class="sd">            If True, all masked tokens are replaced by the mask token; otherwise, some tokens may be </span>
</span><span id="PretrainDiscriminator-524"><a href="#PretrainDiscriminator-524"><span class="linenos">524</span></a><span class="sd">            replaced by random tokens or left unchanged (default is True).</span>
</span><span id="PretrainDiscriminator-525"><a href="#PretrainDiscriminator-525"><span class="linenos">525</span></a>
</span><span id="PretrainDiscriminator-526"><a href="#PretrainDiscriminator-526"><span class="linenos">526</span></a><span class="sd">        Returns</span>
</span><span id="PretrainDiscriminator-527"><a href="#PretrainDiscriminator-527"><span class="linenos">527</span></a><span class="sd">        -------</span>
</span><span id="PretrainDiscriminator-528"><a href="#PretrainDiscriminator-528"><span class="linenos">528</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainDiscriminator-529"><a href="#PretrainDiscriminator-529"><span class="linenos">529</span></a><span class="sd">            A tuple containing the corrupted input tensor and the corresponding labels tensor.</span>
</span><span id="PretrainDiscriminator-530"><a href="#PretrainDiscriminator-530"><span class="linenos">530</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-531"><a href="#PretrainDiscriminator-531"><span class="linenos">531</span></a>         
</span><span id="PretrainDiscriminator-532"><a href="#PretrainDiscriminator-532"><span class="linenos">532</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="PretrainDiscriminator-533"><a href="#PretrainDiscriminator-533"><span class="linenos">533</span></a>        <span class="n">masked_inputs</span><span class="p">,</span> <span class="n">original_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="PretrainDiscriminator-534"><a href="#PretrainDiscriminator-534"><span class="linenos">534</span></a>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-535"><a href="#PretrainDiscriminator-535"><span class="linenos">535</span></a>            <span class="n">mlm_probability</span> <span class="o">=</span> <span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-536"><a href="#PretrainDiscriminator-536"><span class="linenos">536</span></a>            <span class="n">mask_token_id</span> <span class="o">=</span> <span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-537"><a href="#PretrainDiscriminator-537"><span class="linenos">537</span></a>            <span class="n">special_token_ids</span> <span class="o">=</span> <span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-538"><a href="#PretrainDiscriminator-538"><span class="linenos">538</span></a>            <span class="n">n_tokens</span> <span class="o">=</span> <span class="n">n_tokens</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-539"><a href="#PretrainDiscriminator-539"><span class="linenos">539</span></a>            <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-540"><a href="#PretrainDiscriminator-540"><span class="linenos">540</span></a>            <span class="n">hard_masking</span> <span class="o">=</span> <span class="n">hard_masking</span>
</span><span id="PretrainDiscriminator-541"><a href="#PretrainDiscriminator-541"><span class="linenos">541</span></a>            <span class="p">)</span>
</span><span id="PretrainDiscriminator-542"><a href="#PretrainDiscriminator-542"><span class="linenos">542</span></a>        
</span><span id="PretrainDiscriminator-543"><a href="#PretrainDiscriminator-543"><span class="linenos">543</span></a>        <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">masked_inputs</span> <span class="o">==</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-544"><a href="#PretrainDiscriminator-544"><span class="linenos">544</span></a>        <span class="n">random_words</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_tokens</span><span class="p">,</span> <span class="n">original_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-545"><a href="#PretrainDiscriminator-545"><span class="linenos">545</span></a>        <span class="n">corrupted_inputs</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-546"><a href="#PretrainDiscriminator-546"><span class="linenos">546</span></a>        <span class="n">corrupted_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_words</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span>
</span><span id="PretrainDiscriminator-547"><a href="#PretrainDiscriminator-547"><span class="linenos">547</span></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">corrupted_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-548"><a href="#PretrainDiscriminator-548"><span class="linenos">548</span></a>        <span class="n">labels</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">!=</span> <span class="n">corrupted_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span>
</span><span id="PretrainDiscriminator-549"><a href="#PretrainDiscriminator-549"><span class="linenos">549</span></a>
</span><span id="PretrainDiscriminator-550"><a href="#PretrainDiscriminator-550"><span class="linenos">550</span></a>        <span class="k">return</span> <span class="n">corrupted_inputs</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-551"><a href="#PretrainDiscriminator-551"><span class="linenos">551</span></a>
</span><span id="PretrainDiscriminator-552"><a href="#PretrainDiscriminator-552"><span class="linenos">552</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainDiscriminator-553"><a href="#PretrainDiscriminator-553"><span class="linenos">553</span></a>
</span><span id="PretrainDiscriminator-554"><a href="#PretrainDiscriminator-554"><span class="linenos">554</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-555"><a href="#PretrainDiscriminator-555"><span class="linenos">555</span></a><span class="sd">        Trains the discriminator model and saves the results and model.</span>
</span><span id="PretrainDiscriminator-556"><a href="#PretrainDiscriminator-556"><span class="linenos">556</span></a>
</span><span id="PretrainDiscriminator-557"><a href="#PretrainDiscriminator-557"><span class="linenos">557</span></a><span class="sd">        This method handles the training loop, including replacing masked tokens, calculating </span>
</span><span id="PretrainDiscriminator-558"><a href="#PretrainDiscriminator-558"><span class="linenos">558</span></a><span class="sd">        the discriminator loss, updating model parameters, and logging training metrics. After </span>
</span><span id="PretrainDiscriminator-559"><a href="#PretrainDiscriminator-559"><span class="linenos">559</span></a><span class="sd">        training is complete, it saves the model, training metrics, and plots of the loss, accuracy, </span>
</span><span id="PretrainDiscriminator-560"><a href="#PretrainDiscriminator-560"><span class="linenos">560</span></a><span class="sd">        precision, and recall.</span>
</span><span id="PretrainDiscriminator-561"><a href="#PretrainDiscriminator-561"><span class="linenos">561</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator-562"><a href="#PretrainDiscriminator-562"><span class="linenos">562</span></a>        
</span><span id="PretrainDiscriminator-563"><a href="#PretrainDiscriminator-563"><span class="linenos">563</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-564"><a href="#PretrainDiscriminator-564"><span class="linenos">564</span></a>
</span><span id="PretrainDiscriminator-565"><a href="#PretrainDiscriminator-565"><span class="linenos">565</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="PretrainDiscriminator-566"><a href="#PretrainDiscriminator-566"><span class="linenos">566</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator-567"><a href="#PretrainDiscriminator-567"><span class="linenos">567</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator-568"><a href="#PretrainDiscriminator-568"><span class="linenos">568</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator-569"><a href="#PretrainDiscriminator-569"><span class="linenos">569</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator-570"><a href="#PretrainDiscriminator-570"><span class="linenos">570</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator-571"><a href="#PretrainDiscriminator-571"><span class="linenos">571</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator-572"><a href="#PretrainDiscriminator-572"><span class="linenos">572</span></a>
</span><span id="PretrainDiscriminator-573"><a href="#PretrainDiscriminator-573"><span class="linenos">573</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="PretrainDiscriminator-574"><a href="#PretrainDiscriminator-574"><span class="linenos">574</span></a>
</span><span id="PretrainDiscriminator-575"><a href="#PretrainDiscriminator-575"><span class="linenos">575</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="PretrainDiscriminator-576"><a href="#PretrainDiscriminator-576"><span class="linenos">576</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-577"><a href="#PretrainDiscriminator-577"><span class="linenos">577</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-578"><a href="#PretrainDiscriminator-578"><span class="linenos">578</span></a>
</span><span id="PretrainDiscriminator-579"><a href="#PretrainDiscriminator-579"><span class="linenos">579</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="PretrainDiscriminator-580"><a href="#PretrainDiscriminator-580"><span class="linenos">580</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-581"><a href="#PretrainDiscriminator-581"><span class="linenos">581</span></a>
</span><span id="PretrainDiscriminator-582"><a href="#PretrainDiscriminator-582"><span class="linenos">582</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_masked_tokens_randomly</span><span class="p">(</span>
</span><span id="PretrainDiscriminator-583"><a href="#PretrainDiscriminator-583"><span class="linenos">583</span></a>                    <span class="n">inputs</span><span class="p">,</span> 
</span><span id="PretrainDiscriminator-584"><a href="#PretrainDiscriminator-584"><span class="linenos">584</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-585"><a href="#PretrainDiscriminator-585"><span class="linenos">585</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-586"><a href="#PretrainDiscriminator-586"><span class="linenos">586</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-587"><a href="#PretrainDiscriminator-587"><span class="linenos">587</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainDiscriminator-588"><a href="#PretrainDiscriminator-588"><span class="linenos">588</span></a>                    <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="PretrainDiscriminator-589"><a href="#PretrainDiscriminator-589"><span class="linenos">589</span></a>                <span class="p">)</span>
</span><span id="PretrainDiscriminator-590"><a href="#PretrainDiscriminator-590"><span class="linenos">590</span></a>
</span><span id="PretrainDiscriminator-591"><a href="#PretrainDiscriminator-591"><span class="linenos">591</span></a>                <span class="n">discriminator_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-592"><a href="#PretrainDiscriminator-592"><span class="linenos">592</span></a>                <span class="n">discriminator_loss</span><span class="p">,</span> <span class="n">discriminator_logits</span> <span class="o">=</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="PretrainDiscriminator-593"><a href="#PretrainDiscriminator-593"><span class="linenos">593</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator-594"><a href="#PretrainDiscriminator-594"><span class="linenos">594</span></a>
</span><span id="PretrainDiscriminator-595"><a href="#PretrainDiscriminator-595"><span class="linenos">595</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="PretrainDiscriminator-596"><a href="#PretrainDiscriminator-596"><span class="linenos">596</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-597"><a href="#PretrainDiscriminator-597"><span class="linenos">597</span></a>
</span><span id="PretrainDiscriminator-598"><a href="#PretrainDiscriminator-598"><span class="linenos">598</span></a>                <span class="c1"># determine gradients</span>
</span><span id="PretrainDiscriminator-599"><a href="#PretrainDiscriminator-599"><span class="linenos">599</span></a>                <span class="n">discriminator_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-600"><a href="#PretrainDiscriminator-600"><span class="linenos">600</span></a>
</span><span id="PretrainDiscriminator-601"><a href="#PretrainDiscriminator-601"><span class="linenos">601</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="PretrainDiscriminator-602"><a href="#PretrainDiscriminator-602"><span class="linenos">602</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-603"><a href="#PretrainDiscriminator-603"><span class="linenos">603</span></a>
</span><span id="PretrainDiscriminator-604"><a href="#PretrainDiscriminator-604"><span class="linenos">604</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="PretrainDiscriminator-605"><a href="#PretrainDiscriminator-605"><span class="linenos">605</span></a>                <span class="n">discriminator_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
</span><span id="PretrainDiscriminator-606"><a href="#PretrainDiscriminator-606"><span class="linenos">606</span></a>                <span class="n">discriminator_grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">discriminator_grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-607"><a href="#PretrainDiscriminator-607"><span class="linenos">607</span></a>
</span><span id="PretrainDiscriminator-608"><a href="#PretrainDiscriminator-608"><span class="linenos">608</span></a>                <span class="c1"># update parameters        </span>
</span><span id="PretrainDiscriminator-609"><a href="#PretrainDiscriminator-609"><span class="linenos">609</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-610"><a href="#PretrainDiscriminator-610"><span class="linenos">610</span></a>                <span class="c1"># update learning rate</span>
</span><span id="PretrainDiscriminator-611"><a href="#PretrainDiscriminator-611"><span class="linenos">611</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-612"><a href="#PretrainDiscriminator-612"><span class="linenos">612</span></a>
</span><span id="PretrainDiscriminator-613"><a href="#PretrainDiscriminator-613"><span class="linenos">613</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="PretrainDiscriminator-614"><a href="#PretrainDiscriminator-614"><span class="linenos">614</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="PretrainDiscriminator-615"><a href="#PretrainDiscriminator-615"><span class="linenos">615</span></a>                    <span class="n">active_loss</span> <span class="o">=</span> <span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="PretrainDiscriminator-616"><a href="#PretrainDiscriminator-616"><span class="linenos">616</span></a>                    <span class="n">active_logits</span> <span class="o">=</span> <span class="n">discriminator_logits</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="PretrainDiscriminator-617"><a href="#PretrainDiscriminator-617"><span class="linenos">617</span></a>                    <span class="n">active_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">active_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
</span><span id="PretrainDiscriminator-618"><a href="#PretrainDiscriminator-618"><span class="linenos">618</span></a>                    <span class="n">active_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="PretrainDiscriminator-619"><a href="#PretrainDiscriminator-619"><span class="linenos">619</span></a>
</span><span id="PretrainDiscriminator-620"><a href="#PretrainDiscriminator-620"><span class="linenos">620</span></a>                    <span class="n">discriminator_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">active_predictions</span> <span class="o">==</span> <span class="n">active_labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-621"><a href="#PretrainDiscriminator-621"><span class="linenos">621</span></a>                    <span class="n">discriminator_precision</span> <span class="o">=</span> <span class="n">binary_precision</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="PretrainDiscriminator-622"><a href="#PretrainDiscriminator-622"><span class="linenos">622</span></a>                    <span class="n">discriminator_recall</span> <span class="o">=</span> <span class="n">binary_recall</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="PretrainDiscriminator-623"><a href="#PretrainDiscriminator-623"><span class="linenos">623</span></a>
</span><span id="PretrainDiscriminator-624"><a href="#PretrainDiscriminator-624"><span class="linenos">624</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator-625"><a href="#PretrainDiscriminator-625"><span class="linenos">625</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator-626"><a href="#PretrainDiscriminator-626"><span class="linenos">626</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator-627"><a href="#PretrainDiscriminator-627"><span class="linenos">627</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator-628"><a href="#PretrainDiscriminator-628"><span class="linenos">628</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="PretrainDiscriminator-629"><a href="#PretrainDiscriminator-629"><span class="linenos">629</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-630"><a href="#PretrainDiscriminator-630"><span class="linenos">630</span></a>
</span><span id="PretrainDiscriminator-631"><a href="#PretrainDiscriminator-631"><span class="linenos">631</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="PretrainDiscriminator-632"><a href="#PretrainDiscriminator-632"><span class="linenos">632</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-633"><a href="#PretrainDiscriminator-633"><span class="linenos">633</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Discriminator loss: </span><span class="si">{</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-634"><a href="#PretrainDiscriminator-634"><span class="linenos">634</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">discriminator_grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-635"><a href="#PretrainDiscriminator-635"><span class="linenos">635</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-636"><a href="#PretrainDiscriminator-636"><span class="linenos">636</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for replacement task: </span><span class="si">{</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-637"><a href="#PretrainDiscriminator-637"><span class="linenos">637</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision for replacement task: </span><span class="si">{</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-638"><a href="#PretrainDiscriminator-638"><span class="linenos">638</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall for replacement task: </span><span class="si">{</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-639"><a href="#PretrainDiscriminator-639"><span class="linenos">639</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="PretrainDiscriminator-640"><a href="#PretrainDiscriminator-640"><span class="linenos">640</span></a>
</span><span id="PretrainDiscriminator-641"><a href="#PretrainDiscriminator-641"><span class="linenos">641</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-642"><a href="#PretrainDiscriminator-642"><span class="linenos">642</span></a>        
</span><span id="PretrainDiscriminator-643"><a href="#PretrainDiscriminator-643"><span class="linenos">643</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;discriminator&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-644"><a href="#PretrainDiscriminator-644"><span class="linenos">644</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-645"><a href="#PretrainDiscriminator-645"><span class="linenos">645</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-646"><a href="#PretrainDiscriminator-646"><span class="linenos">646</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="PretrainDiscriminator-647"><a href="#PretrainDiscriminator-647"><span class="linenos">647</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-648"><a href="#PretrainDiscriminator-648"><span class="linenos">648</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-649"><a href="#PretrainDiscriminator-649"><span class="linenos">649</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-650"><a href="#PretrainDiscriminator-650"><span class="linenos">650</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;discriminator_model&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-651"><a href="#PretrainDiscriminator-651"><span class="linenos">651</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator-652"><a href="#PretrainDiscriminator-652"><span class="linenos">652</span></a>
</span><span id="PretrainDiscriminator-653"><a href="#PretrainDiscriminator-653"><span class="linenos">653</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class for pretraining a discriminator model in the Electra framework using the FinLM setup.</p>

<p>This class inherits from <code><a href="#PretrainLM">PretrainLM</a></code> and provides specific implementations for 
preparing data, loading the discriminator model, and training the model.</p>

<h2 id="attributes">Attributes</h2>

<p>config : FinLMConfig
    Configuration object containing dataset, model, and optimization configurations.
dataset : FinLMDataset
    The dataset prepared for discriminator training.
model : ElectraForPreTraining
    The Electra model configured for discriminator pretraining.
optimizer : torch.optim.Optimizer
    The optimizer used for training.
scheduler : torch.optim.lr_scheduler.LambdaLR
    The learning rate scheduler used during training.
iteration_steps_per_epoch : int
    Number of iteration steps per training epoch.
logger : logging.Logger
    Logger instance for logging messages related to training.
device : torch.device
    Device on which computations will be performed (CPU or CUDA).</p>

<h2 id="methods">Methods</h2>

<p>load_model() -> None
    Loads and configures the Electra discriminator model.
load_optimization() -> None
    Sets up the optimizer and learning rate scheduler based on the optimization configuration.
prepare_data_model_optimizer() -> None
    Prepares the dataset, model, and optimizer for training.
replace_masked_tokens_randomly(inputs: torch.Tensor, mlm_probability: float, mask_token_id: int, special_token_ids: list[int], n_tokens: int, hard_masking: bool = True) -> Tuple[torch.Tensor, torch.Tensor]
    Replaces masked tokens with random tokens and generates labels for discriminator training.
train() -> None
    Trains the discriminator model and saves the results and model.</p>
</div>


                            <div id="PretrainDiscriminator.__init__" class="classattr">
                                        <input id="PretrainDiscriminator.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">PretrainDiscriminator</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="PretrainDiscriminator.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainDiscriminator.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainDiscriminator.__init__-434"><a href="#PretrainDiscriminator.__init__-434"><span class="linenos">434</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="PretrainDiscriminator.__init__-435"><a href="#PretrainDiscriminator.__init__-435"><span class="linenos">435</span></a>
</span><span id="PretrainDiscriminator.__init__-436"><a href="#PretrainDiscriminator.__init__-436"><span class="linenos">436</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.__init__-437"><a href="#PretrainDiscriminator.__init__-437"><span class="linenos">437</span></a><span class="sd">        Initializes the PretrainDiscriminator class with the given configuration.</span>
</span><span id="PretrainDiscriminator.__init__-438"><a href="#PretrainDiscriminator.__init__-438"><span class="linenos">438</span></a>
</span><span id="PretrainDiscriminator.__init__-439"><a href="#PretrainDiscriminator.__init__-439"><span class="linenos">439</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainDiscriminator.__init__-440"><a href="#PretrainDiscriminator.__init__-440"><span class="linenos">440</span></a><span class="sd">        ----------</span>
</span><span id="PretrainDiscriminator.__init__-441"><a href="#PretrainDiscriminator.__init__-441"><span class="linenos">441</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="PretrainDiscriminator.__init__-442"><a href="#PretrainDiscriminator.__init__-442"><span class="linenos">442</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainDiscriminator.__init__-443"><a href="#PretrainDiscriminator.__init__-443"><span class="linenos">443</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.__init__-444"><a href="#PretrainDiscriminator.__init__-444"><span class="linenos">444</span></a>
</span><span id="PretrainDiscriminator.__init__-445"><a href="#PretrainDiscriminator.__init__-445"><span class="linenos">445</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.__init__-446"><a href="#PretrainDiscriminator.__init__-446"><span class="linenos">446</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the PretrainDiscriminator class with the given configuration.</p>

<h2 id="parameters">Parameters</h2>

<p>config : FinLMConfig
    Configuration object containing dataset, model, and optimization configurations.</p>
</div>


                            </div>
                            <div id="PretrainDiscriminator.load_model" class="classattr">
                                        <input id="PretrainDiscriminator.load_model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_model</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainDiscriminator.load_model-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainDiscriminator.load_model"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainDiscriminator.load_model-448"><a href="#PretrainDiscriminator.load_model-448"><span class="linenos">448</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainDiscriminator.load_model-449"><a href="#PretrainDiscriminator.load_model-449"><span class="linenos">449</span></a>
</span><span id="PretrainDiscriminator.load_model-450"><a href="#PretrainDiscriminator.load_model-450"><span class="linenos">450</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.load_model-451"><a href="#PretrainDiscriminator.load_model-451"><span class="linenos">451</span></a><span class="sd">        Loads and configures the Electra discriminator model.</span>
</span><span id="PretrainDiscriminator.load_model-452"><a href="#PretrainDiscriminator.load_model-452"><span class="linenos">452</span></a>
</span><span id="PretrainDiscriminator.load_model-453"><a href="#PretrainDiscriminator.load_model-453"><span class="linenos">453</span></a><span class="sd">        This method initializes the Electra model for discriminator pretraining using the configuration settings, </span>
</span><span id="PretrainDiscriminator.load_model-454"><a href="#PretrainDiscriminator.load_model-454"><span class="linenos">454</span></a><span class="sd">        including vocabulary size, embedding size, hidden size, and other model parameters. The model is then moved </span>
</span><span id="PretrainDiscriminator.load_model-455"><a href="#PretrainDiscriminator.load_model-455"><span class="linenos">455</span></a><span class="sd">        to the appropriate device (CPU or GPU).</span>
</span><span id="PretrainDiscriminator.load_model-456"><a href="#PretrainDiscriminator.load_model-456"><span class="linenos">456</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.load_model-457"><a href="#PretrainDiscriminator.load_model-457"><span class="linenos">457</span></a>        
</span><span id="PretrainDiscriminator.load_model-458"><a href="#PretrainDiscriminator.load_model-458"><span class="linenos">458</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="PretrainDiscriminator.load_model-459"><a href="#PretrainDiscriminator.load_model-459"><span class="linenos">459</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.load_model-460"><a href="#PretrainDiscriminator.load_model-460"><span class="linenos">460</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.load_model-461"><a href="#PretrainDiscriminator.load_model-461"><span class="linenos">461</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="PretrainDiscriminator.load_model-462"><a href="#PretrainDiscriminator.load_model-462"><span class="linenos">462</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.load_model-463"><a href="#PretrainDiscriminator.load_model-463"><span class="linenos">463</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span>
</span><span id="PretrainDiscriminator.load_model-464"><a href="#PretrainDiscriminator.load_model-464"><span class="linenos">464</span></a>        <span class="p">)</span>
</span><span id="PretrainDiscriminator.load_model-465"><a href="#PretrainDiscriminator.load_model-465"><span class="linenos">465</span></a>
</span><span id="PretrainDiscriminator.load_model-466"><a href="#PretrainDiscriminator.load_model-466"><span class="linenos">466</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ElectraForPreTraining</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.load_model-467"><a href="#PretrainDiscriminator.load_model-467"><span class="linenos">467</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Loads and configures the Electra discriminator model.</p>

<p>This method initializes the Electra model for discriminator pretraining using the configuration settings, 
including vocabulary size, embedding size, hidden size, and other model parameters. The model is then moved 
to the appropriate device (CPU or GPU).</p>
</div>


                            </div>
                            <div id="PretrainDiscriminator.load_optimization" class="classattr">
                                        <input id="PretrainDiscriminator.load_optimization-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_optimization</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainDiscriminator.load_optimization-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainDiscriminator.load_optimization"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainDiscriminator.load_optimization-469"><a href="#PretrainDiscriminator.load_optimization-469"><span class="linenos">469</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainDiscriminator.load_optimization-470"><a href="#PretrainDiscriminator.load_optimization-470"><span class="linenos">470</span></a>
</span><span id="PretrainDiscriminator.load_optimization-471"><a href="#PretrainDiscriminator.load_optimization-471"><span class="linenos">471</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.load_optimization-472"><a href="#PretrainDiscriminator.load_optimization-472"><span class="linenos">472</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainDiscriminator.load_optimization-473"><a href="#PretrainDiscriminator.load_optimization-473"><span class="linenos">473</span></a>
</span><span id="PretrainDiscriminator.load_optimization-474"><a href="#PretrainDiscriminator.load_optimization-474"><span class="linenos">474</span></a><span class="sd">        This method calculates the total number of training steps, initializes the AdamW optimizer, </span>
</span><span id="PretrainDiscriminator.load_optimization-475"><a href="#PretrainDiscriminator.load_optimization-475"><span class="linenos">475</span></a><span class="sd">        and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="PretrainDiscriminator.load_optimization-476"><a href="#PretrainDiscriminator.load_optimization-476"><span class="linenos">476</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.load_optimization-477"><a href="#PretrainDiscriminator.load_optimization-477"><span class="linenos">477</span></a>
</span><span id="PretrainDiscriminator.load_optimization-478"><a href="#PretrainDiscriminator.load_optimization-478"><span class="linenos">478</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="PretrainDiscriminator.load_optimization-479"><a href="#PretrainDiscriminator.load_optimization-479"><span class="linenos">479</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="PretrainDiscriminator.load_optimization-480"><a href="#PretrainDiscriminator.load_optimization-480"><span class="linenos">480</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="PretrainDiscriminator.load_optimization-481"><a href="#PretrainDiscriminator.load_optimization-481"><span class="linenos">481</span></a>
</span><span id="PretrainDiscriminator.load_optimization-482"><a href="#PretrainDiscriminator.load_optimization-482"><span class="linenos">482</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="PretrainDiscriminator.load_optimization-483"><a href="#PretrainDiscriminator.load_optimization-483"><span class="linenos">483</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span>  
</span><span id="PretrainDiscriminator.load_optimization-484"><a href="#PretrainDiscriminator.load_optimization-484"><span class="linenos">484</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="PretrainDiscriminator.load_optimization-485"><a href="#PretrainDiscriminator.load_optimization-485"><span class="linenos">485</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Sets up the optimizer and learning rate scheduler based on the optimization configuration.</p>

<p>This method calculates the total number of training steps, initializes the AdamW optimizer, 
and configures a linear learning rate scheduler with warm-up steps.</p>
</div>


                            </div>
                            <div id="PretrainDiscriminator.prepare_data_model_optimizer" class="classattr">
                                        <input id="PretrainDiscriminator.prepare_data_model_optimizer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">prepare_data_model_optimizer</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainDiscriminator.prepare_data_model_optimizer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainDiscriminator.prepare_data_model_optimizer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainDiscriminator.prepare_data_model_optimizer-487"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-487"><span class="linenos">487</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-488"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-488"><span class="linenos">488</span></a>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-489"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-489"><span class="linenos">489</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-490"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-490"><span class="linenos">490</span></a><span class="sd">        Prepares the dataset, model, and optimizer for training.</span>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-491"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-491"><span class="linenos">491</span></a>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-492"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-492"><span class="linenos">492</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the model, </span>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-493"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-493"><span class="linenos">493</span></a><span class="sd">        and set up the optimizer and learning rate scheduler.</span>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-494"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-494"><span class="linenos">494</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-495"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-495"><span class="linenos">495</span></a>        
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-496"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-496"><span class="linenos">496</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-497"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-497"><span class="linenos">497</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.prepare_data_model_optimizer-498"><a href="#PretrainDiscriminator.prepare_data_model_optimizer-498"><span class="linenos">498</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Prepares the dataset, model, and optimizer for training.</p>

<p>This method calls the appropriate methods to load the dataset, load the model, 
and set up the optimizer and learning rate scheduler.</p>
</div>


                            </div>
                            <div id="PretrainDiscriminator.replace_masked_tokens_randomly" class="classattr">
                                        <input id="PretrainDiscriminator.replace_masked_tokens_randomly-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">replace_masked_tokens_randomly</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">inputs</span>,</span><span class="param">	<span class="n">mlm_probability</span>,</span><span class="param">	<span class="n">mask_token_id</span>,</span><span class="param">	<span class="n">special_token_ids</span>,</span><span class="param">	<span class="n">n_tokens</span>,</span><span class="param">	<span class="n">hard_masking</span><span class="o">=</span><span class="kc">True</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainDiscriminator.replace_masked_tokens_randomly-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainDiscriminator.replace_masked_tokens_randomly"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-501"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-501"><span class="linenos">501</span></a>    <span class="k">def</span> <span class="nf">replace_masked_tokens_randomly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">,</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="n">special_token_ids</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-502"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-502"><span class="linenos">502</span></a>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-503"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-503"><span class="linenos">503</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-504"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-504"><span class="linenos">504</span></a><span class="sd">        Replaces masked tokens with random tokens and generates labels for discriminator training.</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-505"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-505"><span class="linenos">505</span></a>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-506"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-506"><span class="linenos">506</span></a><span class="sd">        This method first applies masked language modeling (MLM) to the input tokens. It then replaces </span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-507"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-507"><span class="linenos">507</span></a><span class="sd">        the masked tokens with random tokens and generates labels indicating whether a token has been </span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-508"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-508"><span class="linenos">508</span></a><span class="sd">        replaced (1) or not (0).</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-509"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-509"><span class="linenos">509</span></a>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-510"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-510"><span class="linenos">510</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-511"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-511"><span class="linenos">511</span></a><span class="sd">        ----------</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-512"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-512"><span class="linenos">512</span></a><span class="sd">        inputs : torch.Tensor</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-513"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-513"><span class="linenos">513</span></a><span class="sd">            Tensor containing the input token IDs.</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-514"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-514"><span class="linenos">514</span></a><span class="sd">        mlm_probability : float</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-515"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-515"><span class="linenos">515</span></a><span class="sd">            Probability of masking a token for MLM.</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-516"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-516"><span class="linenos">516</span></a><span class="sd">        mask_token_id : int</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-517"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-517"><span class="linenos">517</span></a><span class="sd">            The token ID to use for masking (typically the ID for the [MASK] token).</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-518"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-518"><span class="linenos">518</span></a><span class="sd">        special_token_ids : list[int]</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-519"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-519"><span class="linenos">519</span></a><span class="sd">            List of token IDs that should not be masked (e.g., special tokens like [CLS], [SEP]).</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-520"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-520"><span class="linenos">520</span></a><span class="sd">        n_tokens : int</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-521"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-521"><span class="linenos">521</span></a><span class="sd">            The total number of tokens in the vocabulary (used for selecting random tokens).</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-522"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-522"><span class="linenos">522</span></a><span class="sd">        hard_masking : bool, optional</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-523"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-523"><span class="linenos">523</span></a><span class="sd">            If True, all masked tokens are replaced by the mask token; otherwise, some tokens may be </span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-524"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-524"><span class="linenos">524</span></a><span class="sd">            replaced by random tokens or left unchanged (default is True).</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-525"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-525"><span class="linenos">525</span></a>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-526"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-526"><span class="linenos">526</span></a><span class="sd">        Returns</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-527"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-527"><span class="linenos">527</span></a><span class="sd">        -------</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-528"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-528"><span class="linenos">528</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-529"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-529"><span class="linenos">529</span></a><span class="sd">            A tuple containing the corrupted input tensor and the corresponding labels tensor.</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-530"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-530"><span class="linenos">530</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-531"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-531"><span class="linenos">531</span></a>         
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-532"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-532"><span class="linenos">532</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-533"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-533"><span class="linenos">533</span></a>        <span class="n">masked_inputs</span><span class="p">,</span> <span class="n">original_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-534"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-534"><span class="linenos">534</span></a>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-535"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-535"><span class="linenos">535</span></a>            <span class="n">mlm_probability</span> <span class="o">=</span> <span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-536"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-536"><span class="linenos">536</span></a>            <span class="n">mask_token_id</span> <span class="o">=</span> <span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-537"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-537"><span class="linenos">537</span></a>            <span class="n">special_token_ids</span> <span class="o">=</span> <span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-538"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-538"><span class="linenos">538</span></a>            <span class="n">n_tokens</span> <span class="o">=</span> <span class="n">n_tokens</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-539"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-539"><span class="linenos">539</span></a>            <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-540"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-540"><span class="linenos">540</span></a>            <span class="n">hard_masking</span> <span class="o">=</span> <span class="n">hard_masking</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-541"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-541"><span class="linenos">541</span></a>            <span class="p">)</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-542"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-542"><span class="linenos">542</span></a>        
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-543"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-543"><span class="linenos">543</span></a>        <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">masked_inputs</span> <span class="o">==</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-544"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-544"><span class="linenos">544</span></a>        <span class="n">random_words</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_tokens</span><span class="p">,</span> <span class="n">original_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-545"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-545"><span class="linenos">545</span></a>        <span class="n">corrupted_inputs</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-546"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-546"><span class="linenos">546</span></a>        <span class="n">corrupted_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_words</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-547"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-547"><span class="linenos">547</span></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">corrupted_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-548"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-548"><span class="linenos">548</span></a>        <span class="n">labels</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span> <span class="o">!=</span> <span class="n">corrupted_inputs</span><span class="p">[</span><span class="n">masked_indices</span><span class="p">]</span>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-549"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-549"><span class="linenos">549</span></a>
</span><span id="PretrainDiscriminator.replace_masked_tokens_randomly-550"><a href="#PretrainDiscriminator.replace_masked_tokens_randomly-550"><span class="linenos">550</span></a>        <span class="k">return</span> <span class="n">corrupted_inputs</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Replaces masked tokens with random tokens and generates labels for discriminator training.</p>

<p>This method first applies masked language modeling (MLM) to the input tokens. It then replaces 
the masked tokens with random tokens and generates labels indicating whether a token has been 
replaced (1) or not (0).</p>

<h2 id="parameters">Parameters</h2>

<p>inputs : torch.Tensor
    Tensor containing the input token IDs.
mlm_probability : float
    Probability of masking a token for MLM.
mask_token_id : int
    The token ID to use for masking (typically the ID for the [MASK] token).
special_token_ids : list[int]
    List of token IDs that should not be masked (e.g., special tokens like [CLS], [SEP]).
n_tokens : int
    The total number of tokens in the vocabulary (used for selecting random tokens).
hard_masking : bool, optional
    If True, all masked tokens are replaced by the mask token; otherwise, some tokens may be 
    replaced by random tokens or left unchanged (default is True).</p>

<h2 id="returns">Returns</h2>

<p>Tuple[torch.Tensor, torch.Tensor]
    A tuple containing the corrupted input tensor and the corresponding labels tensor.</p>
</div>


                            </div>
                            <div id="PretrainDiscriminator.train" class="classattr">
                                        <input id="PretrainDiscriminator.train-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">train</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainDiscriminator.train-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainDiscriminator.train"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainDiscriminator.train-552"><a href="#PretrainDiscriminator.train-552"><span class="linenos">552</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainDiscriminator.train-553"><a href="#PretrainDiscriminator.train-553"><span class="linenos">553</span></a>
</span><span id="PretrainDiscriminator.train-554"><a href="#PretrainDiscriminator.train-554"><span class="linenos">554</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.train-555"><a href="#PretrainDiscriminator.train-555"><span class="linenos">555</span></a><span class="sd">        Trains the discriminator model and saves the results and model.</span>
</span><span id="PretrainDiscriminator.train-556"><a href="#PretrainDiscriminator.train-556"><span class="linenos">556</span></a>
</span><span id="PretrainDiscriminator.train-557"><a href="#PretrainDiscriminator.train-557"><span class="linenos">557</span></a><span class="sd">        This method handles the training loop, including replacing masked tokens, calculating </span>
</span><span id="PretrainDiscriminator.train-558"><a href="#PretrainDiscriminator.train-558"><span class="linenos">558</span></a><span class="sd">        the discriminator loss, updating model parameters, and logging training metrics. After </span>
</span><span id="PretrainDiscriminator.train-559"><a href="#PretrainDiscriminator.train-559"><span class="linenos">559</span></a><span class="sd">        training is complete, it saves the model, training metrics, and plots of the loss, accuracy, </span>
</span><span id="PretrainDiscriminator.train-560"><a href="#PretrainDiscriminator.train-560"><span class="linenos">560</span></a><span class="sd">        precision, and recall.</span>
</span><span id="PretrainDiscriminator.train-561"><a href="#PretrainDiscriminator.train-561"><span class="linenos">561</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainDiscriminator.train-562"><a href="#PretrainDiscriminator.train-562"><span class="linenos">562</span></a>        
</span><span id="PretrainDiscriminator.train-563"><a href="#PretrainDiscriminator.train-563"><span class="linenos">563</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-564"><a href="#PretrainDiscriminator.train-564"><span class="linenos">564</span></a>
</span><span id="PretrainDiscriminator.train-565"><a href="#PretrainDiscriminator.train-565"><span class="linenos">565</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="PretrainDiscriminator.train-566"><a href="#PretrainDiscriminator.train-566"><span class="linenos">566</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator.train-567"><a href="#PretrainDiscriminator.train-567"><span class="linenos">567</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator.train-568"><a href="#PretrainDiscriminator.train-568"><span class="linenos">568</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator.train-569"><a href="#PretrainDiscriminator.train-569"><span class="linenos">569</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator.train-570"><a href="#PretrainDiscriminator.train-570"><span class="linenos">570</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator.train-571"><a href="#PretrainDiscriminator.train-571"><span class="linenos">571</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainDiscriminator.train-572"><a href="#PretrainDiscriminator.train-572"><span class="linenos">572</span></a>
</span><span id="PretrainDiscriminator.train-573"><a href="#PretrainDiscriminator.train-573"><span class="linenos">573</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="PretrainDiscriminator.train-574"><a href="#PretrainDiscriminator.train-574"><span class="linenos">574</span></a>
</span><span id="PretrainDiscriminator.train-575"><a href="#PretrainDiscriminator.train-575"><span class="linenos">575</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="PretrainDiscriminator.train-576"><a href="#PretrainDiscriminator.train-576"><span class="linenos">576</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-577"><a href="#PretrainDiscriminator.train-577"><span class="linenos">577</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.train-578"><a href="#PretrainDiscriminator.train-578"><span class="linenos">578</span></a>
</span><span id="PretrainDiscriminator.train-579"><a href="#PretrainDiscriminator.train-579"><span class="linenos">579</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="PretrainDiscriminator.train-580"><a href="#PretrainDiscriminator.train-580"><span class="linenos">580</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-581"><a href="#PretrainDiscriminator.train-581"><span class="linenos">581</span></a>
</span><span id="PretrainDiscriminator.train-582"><a href="#PretrainDiscriminator.train-582"><span class="linenos">582</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_masked_tokens_randomly</span><span class="p">(</span>
</span><span id="PretrainDiscriminator.train-583"><a href="#PretrainDiscriminator.train-583"><span class="linenos">583</span></a>                    <span class="n">inputs</span><span class="p">,</span> 
</span><span id="PretrainDiscriminator.train-584"><a href="#PretrainDiscriminator.train-584"><span class="linenos">584</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.train-585"><a href="#PretrainDiscriminator.train-585"><span class="linenos">585</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.train-586"><a href="#PretrainDiscriminator.train-586"><span class="linenos">586</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.train-587"><a href="#PretrainDiscriminator.train-587"><span class="linenos">587</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainDiscriminator.train-588"><a href="#PretrainDiscriminator.train-588"><span class="linenos">588</span></a>                    <span class="n">hard_masking</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="PretrainDiscriminator.train-589"><a href="#PretrainDiscriminator.train-589"><span class="linenos">589</span></a>                <span class="p">)</span>
</span><span id="PretrainDiscriminator.train-590"><a href="#PretrainDiscriminator.train-590"><span class="linenos">590</span></a>
</span><span id="PretrainDiscriminator.train-591"><a href="#PretrainDiscriminator.train-591"><span class="linenos">591</span></a>                <span class="n">discriminator_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-592"><a href="#PretrainDiscriminator.train-592"><span class="linenos">592</span></a>                <span class="n">discriminator_loss</span><span class="p">,</span> <span class="n">discriminator_logits</span> <span class="o">=</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="PretrainDiscriminator.train-593"><a href="#PretrainDiscriminator.train-593"><span class="linenos">593</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator.train-594"><a href="#PretrainDiscriminator.train-594"><span class="linenos">594</span></a>
</span><span id="PretrainDiscriminator.train-595"><a href="#PretrainDiscriminator.train-595"><span class="linenos">595</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="PretrainDiscriminator.train-596"><a href="#PretrainDiscriminator.train-596"><span class="linenos">596</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.train-597"><a href="#PretrainDiscriminator.train-597"><span class="linenos">597</span></a>
</span><span id="PretrainDiscriminator.train-598"><a href="#PretrainDiscriminator.train-598"><span class="linenos">598</span></a>                <span class="c1"># determine gradients</span>
</span><span id="PretrainDiscriminator.train-599"><a href="#PretrainDiscriminator.train-599"><span class="linenos">599</span></a>                <span class="n">discriminator_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.train-600"><a href="#PretrainDiscriminator.train-600"><span class="linenos">600</span></a>
</span><span id="PretrainDiscriminator.train-601"><a href="#PretrainDiscriminator.train-601"><span class="linenos">601</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="PretrainDiscriminator.train-602"><a href="#PretrainDiscriminator.train-602"><span class="linenos">602</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-603"><a href="#PretrainDiscriminator.train-603"><span class="linenos">603</span></a>
</span><span id="PretrainDiscriminator.train-604"><a href="#PretrainDiscriminator.train-604"><span class="linenos">604</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="PretrainDiscriminator.train-605"><a href="#PretrainDiscriminator.train-605"><span class="linenos">605</span></a>                <span class="n">discriminator_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
</span><span id="PretrainDiscriminator.train-606"><a href="#PretrainDiscriminator.train-606"><span class="linenos">606</span></a>                <span class="n">discriminator_grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">discriminator_grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.train-607"><a href="#PretrainDiscriminator.train-607"><span class="linenos">607</span></a>
</span><span id="PretrainDiscriminator.train-608"><a href="#PretrainDiscriminator.train-608"><span class="linenos">608</span></a>                <span class="c1"># update parameters        </span>
</span><span id="PretrainDiscriminator.train-609"><a href="#PretrainDiscriminator.train-609"><span class="linenos">609</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.train-610"><a href="#PretrainDiscriminator.train-610"><span class="linenos">610</span></a>                <span class="c1"># update learning rate</span>
</span><span id="PretrainDiscriminator.train-611"><a href="#PretrainDiscriminator.train-611"><span class="linenos">611</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.train-612"><a href="#PretrainDiscriminator.train-612"><span class="linenos">612</span></a>
</span><span id="PretrainDiscriminator.train-613"><a href="#PretrainDiscriminator.train-613"><span class="linenos">613</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="PretrainDiscriminator.train-614"><a href="#PretrainDiscriminator.train-614"><span class="linenos">614</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="PretrainDiscriminator.train-615"><a href="#PretrainDiscriminator.train-615"><span class="linenos">615</span></a>                    <span class="n">active_loss</span> <span class="o">=</span> <span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="PretrainDiscriminator.train-616"><a href="#PretrainDiscriminator.train-616"><span class="linenos">616</span></a>                    <span class="n">active_logits</span> <span class="o">=</span> <span class="n">discriminator_logits</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="PretrainDiscriminator.train-617"><a href="#PretrainDiscriminator.train-617"><span class="linenos">617</span></a>                    <span class="n">active_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">active_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
</span><span id="PretrainDiscriminator.train-618"><a href="#PretrainDiscriminator.train-618"><span class="linenos">618</span></a>                    <span class="n">active_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="PretrainDiscriminator.train-619"><a href="#PretrainDiscriminator.train-619"><span class="linenos">619</span></a>
</span><span id="PretrainDiscriminator.train-620"><a href="#PretrainDiscriminator.train-620"><span class="linenos">620</span></a>                    <span class="n">discriminator_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">active_predictions</span> <span class="o">==</span> <span class="n">active_labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.train-621"><a href="#PretrainDiscriminator.train-621"><span class="linenos">621</span></a>                    <span class="n">discriminator_precision</span> <span class="o">=</span> <span class="n">binary_precision</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="PretrainDiscriminator.train-622"><a href="#PretrainDiscriminator.train-622"><span class="linenos">622</span></a>                    <span class="n">discriminator_recall</span> <span class="o">=</span> <span class="n">binary_recall</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="PretrainDiscriminator.train-623"><a href="#PretrainDiscriminator.train-623"><span class="linenos">623</span></a>
</span><span id="PretrainDiscriminator.train-624"><a href="#PretrainDiscriminator.train-624"><span class="linenos">624</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator.train-625"><a href="#PretrainDiscriminator.train-625"><span class="linenos">625</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator.train-626"><a href="#PretrainDiscriminator.train-626"><span class="linenos">626</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator.train-627"><a href="#PretrainDiscriminator.train-627"><span class="linenos">627</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainDiscriminator.train-628"><a href="#PretrainDiscriminator.train-628"><span class="linenos">628</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="PretrainDiscriminator.train-629"><a href="#PretrainDiscriminator.train-629"><span class="linenos">629</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-630"><a href="#PretrainDiscriminator.train-630"><span class="linenos">630</span></a>
</span><span id="PretrainDiscriminator.train-631"><a href="#PretrainDiscriminator.train-631"><span class="linenos">631</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="PretrainDiscriminator.train-632"><a href="#PretrainDiscriminator.train-632"><span class="linenos">632</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-633"><a href="#PretrainDiscriminator.train-633"><span class="linenos">633</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Discriminator loss: </span><span class="si">{</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-634"><a href="#PretrainDiscriminator.train-634"><span class="linenos">634</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">discriminator_grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-635"><a href="#PretrainDiscriminator.train-635"><span class="linenos">635</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-636"><a href="#PretrainDiscriminator.train-636"><span class="linenos">636</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for replacement task: </span><span class="si">{</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-637"><a href="#PretrainDiscriminator.train-637"><span class="linenos">637</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision for replacement task: </span><span class="si">{</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-638"><a href="#PretrainDiscriminator.train-638"><span class="linenos">638</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall for replacement task: </span><span class="si">{</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-639"><a href="#PretrainDiscriminator.train-639"><span class="linenos">639</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="PretrainDiscriminator.train-640"><a href="#PretrainDiscriminator.train-640"><span class="linenos">640</span></a>
</span><span id="PretrainDiscriminator.train-641"><a href="#PretrainDiscriminator.train-641"><span class="linenos">641</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-642"><a href="#PretrainDiscriminator.train-642"><span class="linenos">642</span></a>        
</span><span id="PretrainDiscriminator.train-643"><a href="#PretrainDiscriminator.train-643"><span class="linenos">643</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;discriminator&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-644"><a href="#PretrainDiscriminator.train-644"><span class="linenos">644</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-645"><a href="#PretrainDiscriminator.train-645"><span class="linenos">645</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-646"><a href="#PretrainDiscriminator.train-646"><span class="linenos">646</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</span><span id="PretrainDiscriminator.train-647"><a href="#PretrainDiscriminator.train-647"><span class="linenos">647</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-648"><a href="#PretrainDiscriminator.train-648"><span class="linenos">648</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-649"><a href="#PretrainDiscriminator.train-649"><span class="linenos">649</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-650"><a href="#PretrainDiscriminator.train-650"><span class="linenos">650</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;discriminator_model&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-651"><a href="#PretrainDiscriminator.train-651"><span class="linenos">651</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="PretrainDiscriminator.train-652"><a href="#PretrainDiscriminator.train-652"><span class="linenos">652</span></a>
</span><span id="PretrainDiscriminator.train-653"><a href="#PretrainDiscriminator.train-653"><span class="linenos">653</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Trains the discriminator model and saves the results and model.</p>

<p>This method handles the training loop, including replacing masked tokens, calculating 
the discriminator loss, updating model parameters, and logging training metrics. After 
training is complete, it saves the model, training metrics, and plots of the loss, accuracy, 
precision, and recall.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PretrainLM">PretrainLM</a></dt>
                                <dd id="PretrainDiscriminator.config" class="variable"><a href="#PretrainLM.config">config</a></dd>
                <dd id="PretrainDiscriminator.dataset_config" class="variable"><a href="#PretrainLM.dataset_config">dataset_config</a></dd>
                <dd id="PretrainDiscriminator.model_config" class="variable"><a href="#PretrainLM.model_config">model_config</a></dd>
                <dd id="PretrainDiscriminator.optimization_config" class="variable"><a href="#PretrainLM.optimization_config">optimization_config</a></dd>
                <dd id="PretrainDiscriminator.save_root_path" class="variable"><a href="#PretrainLM.save_root_path">save_root_path</a></dd>
                <dd id="PretrainDiscriminator.logger" class="variable"><a href="#PretrainLM.logger">logger</a></dd>
                <dd id="PretrainDiscriminator.load_dataset" class="function"><a href="#PretrainLM.load_dataset">load_dataset</a></dd>
                <dd id="PretrainDiscriminator.mask_tokens" class="function"><a href="#PretrainLM.mask_tokens">mask_tokens</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="PretrainElectra">
                            <input id="PretrainElectra-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PretrainElectra</span><wbr>(<span class="base"><a href="#PretrainLM">PretrainLM</a></span>):

                <label class="view-source-button" for="PretrainElectra-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainElectra"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainElectra-656"><a href="#PretrainElectra-656"><span class="linenos">656</span></a><span class="k">class</span> <span class="nc">PretrainElectra</span><span class="p">(</span><span class="n">PretrainLM</span><span class="p">):</span>
</span><span id="PretrainElectra-657"><a href="#PretrainElectra-657"><span class="linenos">657</span></a>
</span><span id="PretrainElectra-658"><a href="#PretrainElectra-658"><span class="linenos">658</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra-659"><a href="#PretrainElectra-659"><span class="linenos">659</span></a><span class="sd">    A class for pretraining the Electra model using the FinLM setup.</span>
</span><span id="PretrainElectra-660"><a href="#PretrainElectra-660"><span class="linenos">660</span></a>
</span><span id="PretrainElectra-661"><a href="#PretrainElectra-661"><span class="linenos">661</span></a><span class="sd">    This class inherits from `PretrainLM` and provides specific implementations for </span>
</span><span id="PretrainElectra-662"><a href="#PretrainElectra-662"><span class="linenos">662</span></a><span class="sd">    preparing data, loading both the generator and discriminator models, and training </span>
</span><span id="PretrainElectra-663"><a href="#PretrainElectra-663"><span class="linenos">663</span></a><span class="sd">    the Electra model, which includes both components.</span>
</span><span id="PretrainElectra-664"><a href="#PretrainElectra-664"><span class="linenos">664</span></a>
</span><span id="PretrainElectra-665"><a href="#PretrainElectra-665"><span class="linenos">665</span></a><span class="sd">    Attributes</span>
</span><span id="PretrainElectra-666"><a href="#PretrainElectra-666"><span class="linenos">666</span></a><span class="sd">    ----------</span>
</span><span id="PretrainElectra-667"><a href="#PretrainElectra-667"><span class="linenos">667</span></a><span class="sd">    config : FinLMConfig</span>
</span><span id="PretrainElectra-668"><a href="#PretrainElectra-668"><span class="linenos">668</span></a><span class="sd">        Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainElectra-669"><a href="#PretrainElectra-669"><span class="linenos">669</span></a><span class="sd">    dataset : FinLMDataset</span>
</span><span id="PretrainElectra-670"><a href="#PretrainElectra-670"><span class="linenos">670</span></a><span class="sd">        The dataset prepared for Electra model training.</span>
</span><span id="PretrainElectra-671"><a href="#PretrainElectra-671"><span class="linenos">671</span></a><span class="sd">    generator : ElectraForMaskedLM</span>
</span><span id="PretrainElectra-672"><a href="#PretrainElectra-672"><span class="linenos">672</span></a><span class="sd">        The generator model in the Electra framework configured for masked language modeling.</span>
</span><span id="PretrainElectra-673"><a href="#PretrainElectra-673"><span class="linenos">673</span></a><span class="sd">    discriminator : ElectraForPreTraining</span>
</span><span id="PretrainElectra-674"><a href="#PretrainElectra-674"><span class="linenos">674</span></a><span class="sd">        The discriminator model in the Electra framework configured for identifying replaced tokens.</span>
</span><span id="PretrainElectra-675"><a href="#PretrainElectra-675"><span class="linenos">675</span></a><span class="sd">    optimizer : torch.optim.Optimizer</span>
</span><span id="PretrainElectra-676"><a href="#PretrainElectra-676"><span class="linenos">676</span></a><span class="sd">        The optimizer used for training.</span>
</span><span id="PretrainElectra-677"><a href="#PretrainElectra-677"><span class="linenos">677</span></a><span class="sd">    scheduler : torch.optim.lr_scheduler.LambdaLR</span>
</span><span id="PretrainElectra-678"><a href="#PretrainElectra-678"><span class="linenos">678</span></a><span class="sd">        The learning rate scheduler used during training.</span>
</span><span id="PretrainElectra-679"><a href="#PretrainElectra-679"><span class="linenos">679</span></a><span class="sd">    iteration_steps_per_epoch : int</span>
</span><span id="PretrainElectra-680"><a href="#PretrainElectra-680"><span class="linenos">680</span></a><span class="sd">        Number of iteration steps per training epoch.</span>
</span><span id="PretrainElectra-681"><a href="#PretrainElectra-681"><span class="linenos">681</span></a><span class="sd">    logger : logging.Logger</span>
</span><span id="PretrainElectra-682"><a href="#PretrainElectra-682"><span class="linenos">682</span></a><span class="sd">        Logger instance for logging messages related to training.</span>
</span><span id="PretrainElectra-683"><a href="#PretrainElectra-683"><span class="linenos">683</span></a><span class="sd">    device : torch.device</span>
</span><span id="PretrainElectra-684"><a href="#PretrainElectra-684"><span class="linenos">684</span></a><span class="sd">        Device on which computations will be performed (CPU or CUDA).</span>
</span><span id="PretrainElectra-685"><a href="#PretrainElectra-685"><span class="linenos">685</span></a>
</span><span id="PretrainElectra-686"><a href="#PretrainElectra-686"><span class="linenos">686</span></a><span class="sd">    Methods</span>
</span><span id="PretrainElectra-687"><a href="#PretrainElectra-687"><span class="linenos">687</span></a><span class="sd">    -------</span>
</span><span id="PretrainElectra-688"><a href="#PretrainElectra-688"><span class="linenos">688</span></a><span class="sd">    load_model() -&gt; None</span>
</span><span id="PretrainElectra-689"><a href="#PretrainElectra-689"><span class="linenos">689</span></a><span class="sd">        Loads and configures the Electra generator and discriminator models.</span>
</span><span id="PretrainElectra-690"><a href="#PretrainElectra-690"><span class="linenos">690</span></a><span class="sd">    load_optimization() -&gt; None</span>
</span><span id="PretrainElectra-691"><a href="#PretrainElectra-691"><span class="linenos">691</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainElectra-692"><a href="#PretrainElectra-692"><span class="linenos">692</span></a><span class="sd">    prepare_data_model_optimizer() -&gt; None</span>
</span><span id="PretrainElectra-693"><a href="#PretrainElectra-693"><span class="linenos">693</span></a><span class="sd">        Prepares the dataset, models, and optimizer for training.</span>
</span><span id="PretrainElectra-694"><a href="#PretrainElectra-694"><span class="linenos">694</span></a><span class="sd">    replace_masked_tokens_from_generator(masked_inputs: torch.Tensor, original_inputs: torch.Tensor, logits: torch.Tensor, special_mask_id: int, discriminator_sampling: str = &quot;multinomial&quot;) -&gt; Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainElectra-695"><a href="#PretrainElectra-695"><span class="linenos">695</span></a><span class="sd">        Replaces masked tokens with tokens sampled from the generator and generates labels for discriminator training.</span>
</span><span id="PretrainElectra-696"><a href="#PretrainElectra-696"><span class="linenos">696</span></a><span class="sd">    train() -&gt; None</span>
</span><span id="PretrainElectra-697"><a href="#PretrainElectra-697"><span class="linenos">697</span></a><span class="sd">        Trains the Electra model, which includes both the generator and discriminator, and saves the results and models.</span>
</span><span id="PretrainElectra-698"><a href="#PretrainElectra-698"><span class="linenos">698</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PretrainElectra-699"><a href="#PretrainElectra-699"><span class="linenos">699</span></a>
</span><span id="PretrainElectra-700"><a href="#PretrainElectra-700"><span class="linenos">700</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="PretrainElectra-701"><a href="#PretrainElectra-701"><span class="linenos">701</span></a>
</span><span id="PretrainElectra-702"><a href="#PretrainElectra-702"><span class="linenos">702</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra-703"><a href="#PretrainElectra-703"><span class="linenos">703</span></a><span class="sd">        Initializes the PretrainElectra class with the given configuration.</span>
</span><span id="PretrainElectra-704"><a href="#PretrainElectra-704"><span class="linenos">704</span></a>
</span><span id="PretrainElectra-705"><a href="#PretrainElectra-705"><span class="linenos">705</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainElectra-706"><a href="#PretrainElectra-706"><span class="linenos">706</span></a><span class="sd">        ----------</span>
</span><span id="PretrainElectra-707"><a href="#PretrainElectra-707"><span class="linenos">707</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="PretrainElectra-708"><a href="#PretrainElectra-708"><span class="linenos">708</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainElectra-709"><a href="#PretrainElectra-709"><span class="linenos">709</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra-710"><a href="#PretrainElectra-710"><span class="linenos">710</span></a>
</span><span id="PretrainElectra-711"><a href="#PretrainElectra-711"><span class="linenos">711</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="PretrainElectra-712"><a href="#PretrainElectra-712"><span class="linenos">712</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span><span id="PretrainElectra-713"><a href="#PretrainElectra-713"><span class="linenos">713</span></a>
</span><span id="PretrainElectra-714"><a href="#PretrainElectra-714"><span class="linenos">714</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainElectra-715"><a href="#PretrainElectra-715"><span class="linenos">715</span></a>
</span><span id="PretrainElectra-716"><a href="#PretrainElectra-716"><span class="linenos">716</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra-717"><a href="#PretrainElectra-717"><span class="linenos">717</span></a><span class="sd">        Loads and configures the Electra generator and discriminator models.</span>
</span><span id="PretrainElectra-718"><a href="#PretrainElectra-718"><span class="linenos">718</span></a>
</span><span id="PretrainElectra-719"><a href="#PretrainElectra-719"><span class="linenos">719</span></a><span class="sd">        This method initializes the Electra generator and discriminator models using the </span>
</span><span id="PretrainElectra-720"><a href="#PretrainElectra-720"><span class="linenos">720</span></a><span class="sd">        configuration settings, including vocabulary size, embedding size, hidden size, </span>
</span><span id="PretrainElectra-721"><a href="#PretrainElectra-721"><span class="linenos">721</span></a><span class="sd">        and other model parameters. The models are then moved to the appropriate device (CPU or GPU).</span>
</span><span id="PretrainElectra-722"><a href="#PretrainElectra-722"><span class="linenos">722</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra-723"><a href="#PretrainElectra-723"><span class="linenos">723</span></a>            
</span><span id="PretrainElectra-724"><a href="#PretrainElectra-724"><span class="linenos">724</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator_model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="PretrainElectra-725"><a href="#PretrainElectra-725"><span class="linenos">725</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainElectra-726"><a href="#PretrainElectra-726"><span class="linenos">726</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="PretrainElectra-727"><a href="#PretrainElectra-727"><span class="linenos">727</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">),</span> 
</span><span id="PretrainElectra-728"><a href="#PretrainElectra-728"><span class="linenos">728</span></a>            <span class="n">intermediate_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">),</span>
</span><span id="PretrainElectra-729"><a href="#PretrainElectra-729"><span class="linenos">729</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_layer_size</span><span class="p">),</span>
</span><span id="PretrainElectra-730"><a href="#PretrainElectra-730"><span class="linenos">730</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">)</span>
</span><span id="PretrainElectra-731"><a href="#PretrainElectra-731"><span class="linenos">731</span></a>        <span class="p">)</span>
</span><span id="PretrainElectra-732"><a href="#PretrainElectra-732"><span class="linenos">732</span></a>
</span><span id="PretrainElectra-733"><a href="#PretrainElectra-733"><span class="linenos">733</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator_model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="PretrainElectra-734"><a href="#PretrainElectra-734"><span class="linenos">734</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainElectra-735"><a href="#PretrainElectra-735"><span class="linenos">735</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="PretrainElectra-736"><a href="#PretrainElectra-736"><span class="linenos">736</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="PretrainElectra-737"><a href="#PretrainElectra-737"><span class="linenos">737</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="PretrainElectra-738"><a href="#PretrainElectra-738"><span class="linenos">738</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span>
</span><span id="PretrainElectra-739"><a href="#PretrainElectra-739"><span class="linenos">739</span></a>        <span class="p">)</span>
</span><span id="PretrainElectra-740"><a href="#PretrainElectra-740"><span class="linenos">740</span></a>
</span><span id="PretrainElectra-741"><a href="#PretrainElectra-741"><span class="linenos">741</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">ElectraForMaskedLM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">generator_model_config</span><span class="p">)</span>
</span><span id="PretrainElectra-742"><a href="#PretrainElectra-742"><span class="linenos">742</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">ElectraForPreTraining</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">discriminator_model_config</span><span class="p">)</span>
</span><span id="PretrainElectra-743"><a href="#PretrainElectra-743"><span class="linenos">743</span></a>        <span class="c1"># tie word and position embeddings</span>
</span><span id="PretrainElectra-744"><a href="#PretrainElectra-744"><span class="linenos">744</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span>
</span><span id="PretrainElectra-745"><a href="#PretrainElectra-745"><span class="linenos">745</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">position_embeddings</span>
</span><span id="PretrainElectra-746"><a href="#PretrainElectra-746"><span class="linenos">746</span></a>        <span class="c1"># add to device</span>
</span><span id="PretrainElectra-747"><a href="#PretrainElectra-747"><span class="linenos">747</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainElectra-748"><a href="#PretrainElectra-748"><span class="linenos">748</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainElectra-749"><a href="#PretrainElectra-749"><span class="linenos">749</span></a>
</span><span id="PretrainElectra-750"><a href="#PretrainElectra-750"><span class="linenos">750</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainElectra-751"><a href="#PretrainElectra-751"><span class="linenos">751</span></a>
</span><span id="PretrainElectra-752"><a href="#PretrainElectra-752"><span class="linenos">752</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra-753"><a href="#PretrainElectra-753"><span class="linenos">753</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainElectra-754"><a href="#PretrainElectra-754"><span class="linenos">754</span></a>
</span><span id="PretrainElectra-755"><a href="#PretrainElectra-755"><span class="linenos">755</span></a><span class="sd">        This method identifies the trainable parameters, ensuring that the word and position embeddings </span>
</span><span id="PretrainElectra-756"><a href="#PretrainElectra-756"><span class="linenos">756</span></a><span class="sd">        are not duplicated. It then calculates the total number of training steps, initializes the AdamW </span>
</span><span id="PretrainElectra-757"><a href="#PretrainElectra-757"><span class="linenos">757</span></a><span class="sd">        optimizer, and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="PretrainElectra-758"><a href="#PretrainElectra-758"><span class="linenos">758</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra-759"><a href="#PretrainElectra-759"><span class="linenos">759</span></a>        
</span><span id="PretrainElectra-760"><a href="#PretrainElectra-760"><span class="linenos">760</span></a>        <span class="c1"># identify trainable parameters without duplicating the embedding and position parameters</span>
</span><span id="PretrainElectra-761"><a href="#PretrainElectra-761"><span class="linenos">761</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-762"><a href="#PretrainElectra-762"><span class="linenos">762</span></a>        <span class="c1"># generator</span>
</span><span id="PretrainElectra-763"><a href="#PretrainElectra-763"><span class="linenos">763</span></a>        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="PretrainElectra-764"><a href="#PretrainElectra-764"><span class="linenos">764</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span><span id="PretrainElectra-765"><a href="#PretrainElectra-765"><span class="linenos">765</span></a>        <span class="c1"># discriminator</span>
</span><span id="PretrainElectra-766"><a href="#PretrainElectra-766"><span class="linenos">766</span></a>        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="PretrainElectra-767"><a href="#PretrainElectra-767"><span class="linenos">767</span></a>            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;word_embeddings.weight&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;position_embeddings.weight&quot;</span><span class="p">):</span>
</span><span id="PretrainElectra-768"><a href="#PretrainElectra-768"><span class="linenos">768</span></a>                <span class="k">continue</span>
</span><span id="PretrainElectra-769"><a href="#PretrainElectra-769"><span class="linenos">769</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PretrainElectra-770"><a href="#PretrainElectra-770"><span class="linenos">770</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span><span id="PretrainElectra-771"><a href="#PretrainElectra-771"><span class="linenos">771</span></a>        
</span><span id="PretrainElectra-772"><a href="#PretrainElectra-772"><span class="linenos">772</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="PretrainElectra-773"><a href="#PretrainElectra-773"><span class="linenos">773</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="PretrainElectra-774"><a href="#PretrainElectra-774"><span class="linenos">774</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="PretrainElectra-775"><a href="#PretrainElectra-775"><span class="linenos">775</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="PretrainElectra-776"><a href="#PretrainElectra-776"><span class="linenos">776</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span> 
</span><span id="PretrainElectra-777"><a href="#PretrainElectra-777"><span class="linenos">777</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="PretrainElectra-778"><a href="#PretrainElectra-778"><span class="linenos">778</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span><span id="PretrainElectra-779"><a href="#PretrainElectra-779"><span class="linenos">779</span></a>
</span><span id="PretrainElectra-780"><a href="#PretrainElectra-780"><span class="linenos">780</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainElectra-781"><a href="#PretrainElectra-781"><span class="linenos">781</span></a>
</span><span id="PretrainElectra-782"><a href="#PretrainElectra-782"><span class="linenos">782</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra-783"><a href="#PretrainElectra-783"><span class="linenos">783</span></a><span class="sd">        Prepares the dataset, models, and optimizer for training.</span>
</span><span id="PretrainElectra-784"><a href="#PretrainElectra-784"><span class="linenos">784</span></a>
</span><span id="PretrainElectra-785"><a href="#PretrainElectra-785"><span class="linenos">785</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the generator and </span>
</span><span id="PretrainElectra-786"><a href="#PretrainElectra-786"><span class="linenos">786</span></a><span class="sd">        discriminator models, and set up the optimizer and learning rate scheduler.</span>
</span><span id="PretrainElectra-787"><a href="#PretrainElectra-787"><span class="linenos">787</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra-788"><a href="#PretrainElectra-788"><span class="linenos">788</span></a>
</span><span id="PretrainElectra-789"><a href="#PretrainElectra-789"><span class="linenos">789</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="PretrainElectra-790"><a href="#PretrainElectra-790"><span class="linenos">790</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="PretrainElectra-791"><a href="#PretrainElectra-791"><span class="linenos">791</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span><span id="PretrainElectra-792"><a href="#PretrainElectra-792"><span class="linenos">792</span></a>
</span><span id="PretrainElectra-793"><a href="#PretrainElectra-793"><span class="linenos">793</span></a>    <span class="nd">@staticmethod</span>
</span><span id="PretrainElectra-794"><a href="#PretrainElectra-794"><span class="linenos">794</span></a>    <span class="k">def</span> <span class="nf">replace_masked_tokens_from_generator</span><span class="p">(</span><span class="n">masked_inputs</span><span class="p">,</span> <span class="n">original_inputs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">special_mask_id</span><span class="p">,</span> <span class="n">discriminator_sampling</span> <span class="o">=</span> <span class="s2">&quot;gumbel_softmax&quot;</span><span class="p">):</span>
</span><span id="PretrainElectra-795"><a href="#PretrainElectra-795"><span class="linenos">795</span></a><span class="w">    </span>
</span><span id="PretrainElectra-796"><a href="#PretrainElectra-796"><span class="linenos">796</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra-797"><a href="#PretrainElectra-797"><span class="linenos">797</span></a><span class="sd">        Replaces masked tokens with tokens sampled from the generator and generates labels for discriminator training.</span>
</span><span id="PretrainElectra-798"><a href="#PretrainElectra-798"><span class="linenos">798</span></a>
</span><span id="PretrainElectra-799"><a href="#PretrainElectra-799"><span class="linenos">799</span></a><span class="sd">        This method uses the generator&#39;s output logits to replace masked tokens in the input. It generates labels </span>
</span><span id="PretrainElectra-800"><a href="#PretrainElectra-800"><span class="linenos">800</span></a><span class="sd">        indicating whether a token has been replaced and whether the replacement matches the original token.</span>
</span><span id="PretrainElectra-801"><a href="#PretrainElectra-801"><span class="linenos">801</span></a>
</span><span id="PretrainElectra-802"><a href="#PretrainElectra-802"><span class="linenos">802</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainElectra-803"><a href="#PretrainElectra-803"><span class="linenos">803</span></a><span class="sd">        ----------</span>
</span><span id="PretrainElectra-804"><a href="#PretrainElectra-804"><span class="linenos">804</span></a><span class="sd">        masked_inputs : torch.Tensor</span>
</span><span id="PretrainElectra-805"><a href="#PretrainElectra-805"><span class="linenos">805</span></a><span class="sd">            Tensor containing the masked input token IDs.</span>
</span><span id="PretrainElectra-806"><a href="#PretrainElectra-806"><span class="linenos">806</span></a><span class="sd">        original_inputs : torch.Tensor</span>
</span><span id="PretrainElectra-807"><a href="#PretrainElectra-807"><span class="linenos">807</span></a><span class="sd">            Tensor containing the original input token IDs before masking.</span>
</span><span id="PretrainElectra-808"><a href="#PretrainElectra-808"><span class="linenos">808</span></a><span class="sd">        logits : torch.Tensor</span>
</span><span id="PretrainElectra-809"><a href="#PretrainElectra-809"><span class="linenos">809</span></a><span class="sd">            Logits output by the generator model.</span>
</span><span id="PretrainElectra-810"><a href="#PretrainElectra-810"><span class="linenos">810</span></a><span class="sd">        special_mask_id : int</span>
</span><span id="PretrainElectra-811"><a href="#PretrainElectra-811"><span class="linenos">811</span></a><span class="sd">            The token ID used for masking (typically the ID for the [MASK] token).</span>
</span><span id="PretrainElectra-812"><a href="#PretrainElectra-812"><span class="linenos">812</span></a><span class="sd">        discriminator_sampling : str, optional</span>
</span><span id="PretrainElectra-813"><a href="#PretrainElectra-813"><span class="linenos">813</span></a><span class="sd">            The sampling strategy for selecting replacement tokens, either &quot;multinomial&quot; or another strategy like &quot;aggressive&quot; or &quot;gumbel_softmax&quot; (default is &quot;gumbel_softmax&quot;).</span>
</span><span id="PretrainElectra-814"><a href="#PretrainElectra-814"><span class="linenos">814</span></a>
</span><span id="PretrainElectra-815"><a href="#PretrainElectra-815"><span class="linenos">815</span></a><span class="sd">        Returns</span>
</span><span id="PretrainElectra-816"><a href="#PretrainElectra-816"><span class="linenos">816</span></a><span class="sd">        -------</span>
</span><span id="PretrainElectra-817"><a href="#PretrainElectra-817"><span class="linenos">817</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainElectra-818"><a href="#PretrainElectra-818"><span class="linenos">818</span></a><span class="sd">            A tuple containing the discriminator inputs (with replaced tokens) and the corresponding labels tensor.</span>
</span><span id="PretrainElectra-819"><a href="#PretrainElectra-819"><span class="linenos">819</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra-820"><a href="#PretrainElectra-820"><span class="linenos">820</span></a>            
</span><span id="PretrainElectra-821"><a href="#PretrainElectra-821"><span class="linenos">821</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="PretrainElectra-822"><a href="#PretrainElectra-822"><span class="linenos">822</span></a>        <span class="n">discriminator_inputs</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="PretrainElectra-823"><a href="#PretrainElectra-823"><span class="linenos">823</span></a>        <span class="n">mask_indices</span> <span class="o">=</span> <span class="n">masked_inputs</span> <span class="o">==</span> <span class="n">special_mask_id</span>
</span><span id="PretrainElectra-824"><a href="#PretrainElectra-824"><span class="linenos">824</span></a>
</span><span id="PretrainElectra-825"><a href="#PretrainElectra-825"><span class="linenos">825</span></a>        <span class="k">if</span> <span class="n">discriminator_sampling</span> <span class="o">==</span> <span class="s2">&quot;aggressive&quot;</span><span class="p">:</span>
</span><span id="PretrainElectra-826"><a href="#PretrainElectra-826"><span class="linenos">826</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PretrainElectra-827"><a href="#PretrainElectra-827"><span class="linenos">827</span></a>        <span class="k">elif</span> <span class="n">discriminator_sampling</span> <span class="o">==</span> <span class="s2">&quot;gumbel_softmax&quot;</span><span class="p">:</span>
</span><span id="PretrainElectra-828"><a href="#PretrainElectra-828"><span class="linenos">828</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gumbel_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">],</span> <span class="n">hard</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PretrainElectra-829"><a href="#PretrainElectra-829"><span class="linenos">829</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="PretrainElectra-830"><a href="#PretrainElectra-830"><span class="linenos">830</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">],</span> <span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</span><span id="PretrainElectra-831"><a href="#PretrainElectra-831"><span class="linenos">831</span></a>
</span><span id="PretrainElectra-832"><a href="#PretrainElectra-832"><span class="linenos">832</span></a>        <span class="n">discriminator_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">sampled_ids</span>
</span><span id="PretrainElectra-833"><a href="#PretrainElectra-833"><span class="linenos">833</span></a>        <span class="c1"># initialize discriminator labels with False</span>
</span><span id="PretrainElectra-834"><a href="#PretrainElectra-834"><span class="linenos">834</span></a>        <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">masked_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainElectra-835"><a href="#PretrainElectra-835"><span class="linenos">835</span></a>        <span class="c1"># replace False with True if an id is sampled and not the same as the original one</span>
</span><span id="PretrainElectra-836"><a href="#PretrainElectra-836"><span class="linenos">836</span></a>        <span class="n">discriminator_labels</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">discriminator_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">!=</span> <span class="n">original_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span>
</span><span id="PretrainElectra-837"><a href="#PretrainElectra-837"><span class="linenos">837</span></a>        <span class="c1"># convert to float </span>
</span><span id="PretrainElectra-838"><a href="#PretrainElectra-838"><span class="linenos">838</span></a>        <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="PretrainElectra-839"><a href="#PretrainElectra-839"><span class="linenos">839</span></a>
</span><span id="PretrainElectra-840"><a href="#PretrainElectra-840"><span class="linenos">840</span></a>        <span class="k">return</span> <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">discriminator_labels</span>
</span><span id="PretrainElectra-841"><a href="#PretrainElectra-841"><span class="linenos">841</span></a>
</span><span id="PretrainElectra-842"><a href="#PretrainElectra-842"><span class="linenos">842</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainElectra-843"><a href="#PretrainElectra-843"><span class="linenos">843</span></a>
</span><span id="PretrainElectra-844"><a href="#PretrainElectra-844"><span class="linenos">844</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra-845"><a href="#PretrainElectra-845"><span class="linenos">845</span></a><span class="sd">        Trains the Electra model, which includes both the generator and discriminator, and saves the results and models.</span>
</span><span id="PretrainElectra-846"><a href="#PretrainElectra-846"><span class="linenos">846</span></a>
</span><span id="PretrainElectra-847"><a href="#PretrainElectra-847"><span class="linenos">847</span></a><span class="sd">        This method handles the training loop, including masking input tokens, generating replacements using the generator, </span>
</span><span id="PretrainElectra-848"><a href="#PretrainElectra-848"><span class="linenos">848</span></a><span class="sd">        training the discriminator on identifying the replaced tokens, calculating losses, updating model parameters, and </span>
</span><span id="PretrainElectra-849"><a href="#PretrainElectra-849"><span class="linenos">849</span></a><span class="sd">        logging training metrics. After training is complete, it saves the models, training metrics, and plots of the loss, </span>
</span><span id="PretrainElectra-850"><a href="#PretrainElectra-850"><span class="linenos">850</span></a><span class="sd">        accuracy, precision, and recall.</span>
</span><span id="PretrainElectra-851"><a href="#PretrainElectra-851"><span class="linenos">851</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra-852"><a href="#PretrainElectra-852"><span class="linenos">852</span></a>
</span><span id="PretrainElectra-853"><a href="#PretrainElectra-853"><span class="linenos">853</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-854"><a href="#PretrainElectra-854"><span class="linenos">854</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="PretrainElectra-855"><a href="#PretrainElectra-855"><span class="linenos">855</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-856"><a href="#PretrainElectra-856"><span class="linenos">856</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-857"><a href="#PretrainElectra-857"><span class="linenos">857</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-858"><a href="#PretrainElectra-858"><span class="linenos">858</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-859"><a href="#PretrainElectra-859"><span class="linenos">859</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-860"><a href="#PretrainElectra-860"><span class="linenos">860</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_precision&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-861"><a href="#PretrainElectra-861"><span class="linenos">861</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-862"><a href="#PretrainElectra-862"><span class="linenos">862</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-863"><a href="#PretrainElectra-863"><span class="linenos">863</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra-864"><a href="#PretrainElectra-864"><span class="linenos">864</span></a>
</span><span id="PretrainElectra-865"><a href="#PretrainElectra-865"><span class="linenos">865</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="PretrainElectra-866"><a href="#PretrainElectra-866"><span class="linenos">866</span></a>            
</span><span id="PretrainElectra-867"><a href="#PretrainElectra-867"><span class="linenos">867</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="PretrainElectra-868"><a href="#PretrainElectra-868"><span class="linenos">868</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="PretrainElectra-869"><a href="#PretrainElectra-869"><span class="linenos">869</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="PretrainElectra-870"><a href="#PretrainElectra-870"><span class="linenos">870</span></a>
</span><span id="PretrainElectra-871"><a href="#PretrainElectra-871"><span class="linenos">871</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="PretrainElectra-872"><a href="#PretrainElectra-872"><span class="linenos">872</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainElectra-873"><a href="#PretrainElectra-873"><span class="linenos">873</span></a>
</span><span id="PretrainElectra-874"><a href="#PretrainElectra-874"><span class="linenos">874</span></a>                <span class="n">original_inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="PretrainElectra-875"><a href="#PretrainElectra-875"><span class="linenos">875</span></a>                <span class="n">generator_inputs</span><span class="p">,</span> <span class="n">generator_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="PretrainElectra-876"><a href="#PretrainElectra-876"><span class="linenos">876</span></a>                    <span class="n">inputs</span><span class="p">,</span>
</span><span id="PretrainElectra-877"><a href="#PretrainElectra-877"><span class="linenos">877</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="PretrainElectra-878"><a href="#PretrainElectra-878"><span class="linenos">878</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainElectra-879"><a href="#PretrainElectra-879"><span class="linenos">879</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="PretrainElectra-880"><a href="#PretrainElectra-880"><span class="linenos">880</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span><span id="PretrainElectra-881"><a href="#PretrainElectra-881"><span class="linenos">881</span></a>
</span><span id="PretrainElectra-882"><a href="#PretrainElectra-882"><span class="linenos">882</span></a>                <span class="n">mlm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">generator_inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">generator_labels</span><span class="p">)</span>
</span><span id="PretrainElectra-883"><a href="#PretrainElectra-883"><span class="linenos">883</span></a>                <span class="n">mlm_loss</span><span class="p">,</span> <span class="n">mlm_logits</span> <span class="o">=</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="PretrainElectra-884"><a href="#PretrainElectra-884"><span class="linenos">884</span></a>
</span><span id="PretrainElectra-885"><a href="#PretrainElectra-885"><span class="linenos">885</span></a>                <span class="n">sampling_logits</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span><span id="PretrainElectra-886"><a href="#PretrainElectra-886"><span class="linenos">886</span></a>                <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_masked_tokens_from_generator</span><span class="p">(</span>
</span><span id="PretrainElectra-887"><a href="#PretrainElectra-887"><span class="linenos">887</span></a>                    <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">generator_inputs</span><span class="p">,</span>
</span><span id="PretrainElectra-888"><a href="#PretrainElectra-888"><span class="linenos">888</span></a>                    <span class="n">original_inputs</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="p">,</span>
</span><span id="PretrainElectra-889"><a href="#PretrainElectra-889"><span class="linenos">889</span></a>                    <span class="n">logits</span> <span class="o">=</span> <span class="n">sampling_logits</span><span class="p">,</span>
</span><span id="PretrainElectra-890"><a href="#PretrainElectra-890"><span class="linenos">890</span></a>                    <span class="n">special_mask_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainElectra-891"><a href="#PretrainElectra-891"><span class="linenos">891</span></a>                    <span class="n">discriminator_sampling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">discriminator_sampling</span>
</span><span id="PretrainElectra-892"><a href="#PretrainElectra-892"><span class="linenos">892</span></a>                    <span class="p">)</span>
</span><span id="PretrainElectra-893"><a href="#PretrainElectra-893"><span class="linenos">893</span></a>                
</span><span id="PretrainElectra-894"><a href="#PretrainElectra-894"><span class="linenos">894</span></a>                <span class="n">discriminator_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="p">)</span>
</span><span id="PretrainElectra-895"><a href="#PretrainElectra-895"><span class="linenos">895</span></a>                <span class="n">discriminator_loss</span><span class="p">,</span> <span class="n">discriminator_logits</span> <span class="o">=</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="PretrainElectra-896"><a href="#PretrainElectra-896"><span class="linenos">896</span></a>
</span><span id="PretrainElectra-897"><a href="#PretrainElectra-897"><span class="linenos">897</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">mlm_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">discriminator_weight</span> <span class="o">*</span> <span class="n">discriminator_loss</span>
</span><span id="PretrainElectra-898"><a href="#PretrainElectra-898"><span class="linenos">898</span></a>
</span><span id="PretrainElectra-899"><a href="#PretrainElectra-899"><span class="linenos">899</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra-900"><a href="#PretrainElectra-900"><span class="linenos">900</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra-901"><a href="#PretrainElectra-901"><span class="linenos">901</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra-902"><a href="#PretrainElectra-902"><span class="linenos">902</span></a>
</span><span id="PretrainElectra-903"><a href="#PretrainElectra-903"><span class="linenos">903</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="PretrainElectra-904"><a href="#PretrainElectra-904"><span class="linenos">904</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="PretrainElectra-905"><a href="#PretrainElectra-905"><span class="linenos">905</span></a>
</span><span id="PretrainElectra-906"><a href="#PretrainElectra-906"><span class="linenos">906</span></a>                <span class="c1"># determine gradients</span>
</span><span id="PretrainElectra-907"><a href="#PretrainElectra-907"><span class="linenos">907</span></a>                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="PretrainElectra-908"><a href="#PretrainElectra-908"><span class="linenos">908</span></a>
</span><span id="PretrainElectra-909"><a href="#PretrainElectra-909"><span class="linenos">909</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="PretrainElectra-910"><a href="#PretrainElectra-910"><span class="linenos">910</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">,</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="PretrainElectra-911"><a href="#PretrainElectra-911"><span class="linenos">911</span></a>
</span><span id="PretrainElectra-912"><a href="#PretrainElectra-912"><span class="linenos">912</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="PretrainElectra-913"><a href="#PretrainElectra-913"><span class="linenos">913</span></a>                <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">]</span>
</span><span id="PretrainElectra-914"><a href="#PretrainElectra-914"><span class="linenos">914</span></a>                <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="PretrainElectra-915"><a href="#PretrainElectra-915"><span class="linenos">915</span></a>
</span><span id="PretrainElectra-916"><a href="#PretrainElectra-916"><span class="linenos">916</span></a>
</span><span id="PretrainElectra-917"><a href="#PretrainElectra-917"><span class="linenos">917</span></a>                <span class="c1"># update parameters        </span>
</span><span id="PretrainElectra-918"><a href="#PretrainElectra-918"><span class="linenos">918</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainElectra-919"><a href="#PretrainElectra-919"><span class="linenos">919</span></a>                <span class="c1"># update learning rate</span>
</span><span id="PretrainElectra-920"><a href="#PretrainElectra-920"><span class="linenos">920</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainElectra-921"><a href="#PretrainElectra-921"><span class="linenos">921</span></a>
</span><span id="PretrainElectra-922"><a href="#PretrainElectra-922"><span class="linenos">922</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="PretrainElectra-923"><a href="#PretrainElectra-923"><span class="linenos">923</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="PretrainElectra-924"><a href="#PretrainElectra-924"><span class="linenos">924</span></a>                    <span class="c1"># mask to identify ids which have been masked before</span>
</span><span id="PretrainElectra-925"><a href="#PretrainElectra-925"><span class="linenos">925</span></a>                    <span class="n">masked_ids_mask</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span>
</span><span id="PretrainElectra-926"><a href="#PretrainElectra-926"><span class="linenos">926</span></a>                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PretrainElectra-927"><a href="#PretrainElectra-927"><span class="linenos">927</span></a>                    <span class="n">mlm_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">]</span> <span class="o">==</span> <span class="n">generator_labels</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="PretrainElectra-928"><a href="#PretrainElectra-928"><span class="linenos">928</span></a>                    <span class="n">active_loss</span> <span class="o">=</span> <span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="PretrainElectra-929"><a href="#PretrainElectra-929"><span class="linenos">929</span></a>                    <span class="n">active_logits</span> <span class="o">=</span> <span class="n">discriminator_logits</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="PretrainElectra-930"><a href="#PretrainElectra-930"><span class="linenos">930</span></a>                    <span class="n">active_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">active_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
</span><span id="PretrainElectra-931"><a href="#PretrainElectra-931"><span class="linenos">931</span></a>                    <span class="n">active_labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="PretrainElectra-932"><a href="#PretrainElectra-932"><span class="linenos">932</span></a>                    <span class="n">discriminator_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">active_predictions</span> <span class="o">==</span> <span class="n">active_labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="PretrainElectra-933"><a href="#PretrainElectra-933"><span class="linenos">933</span></a>                    <span class="n">discriminator_precision</span> <span class="o">=</span> <span class="n">binary_precision</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="PretrainElectra-934"><a href="#PretrainElectra-934"><span class="linenos">934</span></a>                    <span class="n">discriminator_recall</span> <span class="o">=</span> <span class="n">binary_recall</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="PretrainElectra-935"><a href="#PretrainElectra-935"><span class="linenos">935</span></a>
</span><span id="PretrainElectra-936"><a href="#PretrainElectra-936"><span class="linenos">936</span></a>
</span><span id="PretrainElectra-937"><a href="#PretrainElectra-937"><span class="linenos">937</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra-938"><a href="#PretrainElectra-938"><span class="linenos">938</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra-939"><a href="#PretrainElectra-939"><span class="linenos">939</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra-940"><a href="#PretrainElectra-940"><span class="linenos">940</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra-941"><a href="#PretrainElectra-941"><span class="linenos">941</span></a>
</span><span id="PretrainElectra-942"><a href="#PretrainElectra-942"><span class="linenos">942</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="PretrainElectra-943"><a href="#PretrainElectra-943"><span class="linenos">943</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="PretrainElectra-944"><a href="#PretrainElectra-944"><span class="linenos">944</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="PretrainElectra-945"><a href="#PretrainElectra-945"><span class="linenos">945</span></a>
</span><span id="PretrainElectra-946"><a href="#PretrainElectra-946"><span class="linenos">946</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="PretrainElectra-947"><a href="#PretrainElectra-947"><span class="linenos">947</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-948"><a href="#PretrainElectra-948"><span class="linenos">948</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-949"><a href="#PretrainElectra-949"><span class="linenos">949</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MLM Loss: </span><span class="si">{</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-950"><a href="#PretrainElectra-950"><span class="linenos">950</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Discriminator Loss: </span><span class="si">{</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-951"><a href="#PretrainElectra-951"><span class="linenos">951</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-952"><a href="#PretrainElectra-952"><span class="linenos">952</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-953"><a href="#PretrainElectra-953"><span class="linenos">953</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for masking task: </span><span class="si">{</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-954"><a href="#PretrainElectra-954"><span class="linenos">954</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for replacement task: </span><span class="si">{</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-955"><a href="#PretrainElectra-955"><span class="linenos">955</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision for replacement task: </span><span class="si">{</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-956"><a href="#PretrainElectra-956"><span class="linenos">956</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall for replacement task: </span><span class="si">{</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-957"><a href="#PretrainElectra-957"><span class="linenos">957</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="PretrainElectra-958"><a href="#PretrainElectra-958"><span class="linenos">958</span></a>
</span><span id="PretrainElectra-959"><a href="#PretrainElectra-959"><span class="linenos">959</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-960"><a href="#PretrainElectra-960"><span class="linenos">960</span></a>
</span><span id="PretrainElectra-961"><a href="#PretrainElectra-961"><span class="linenos">961</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="PretrainElectra-962"><a href="#PretrainElectra-962"><span class="linenos">962</span></a>        
</span><span id="PretrainElectra-963"><a href="#PretrainElectra-963"><span class="linenos">963</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;electra&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-964"><a href="#PretrainElectra-964"><span class="linenos">964</span></a>        <span class="c1"># create a function for making an output directory which creates it and saves the csv and model</span>
</span><span id="PretrainElectra-965"><a href="#PretrainElectra-965"><span class="linenos">965</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="PretrainElectra-966"><a href="#PretrainElectra-966"><span class="linenos">966</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;mlm_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="PretrainElectra-967"><a href="#PretrainElectra-967"><span class="linenos">967</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-968"><a href="#PretrainElectra-968"><span class="linenos">968</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_precision&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="PretrainElectra-969"><a href="#PretrainElectra-969"><span class="linenos">969</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-970"><a href="#PretrainElectra-970"><span class="linenos">970</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;mlm_model&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-971"><a href="#PretrainElectra-971"><span class="linenos">971</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;discriminator_model&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-972"><a href="#PretrainElectra-972"><span class="linenos">972</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra-973"><a href="#PretrainElectra-973"><span class="linenos">973</span></a>
</span><span id="PretrainElectra-974"><a href="#PretrainElectra-974"><span class="linenos">974</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class for pretraining the Electra model using the FinLM setup.</p>

<p>This class inherits from <code><a href="#PretrainLM">PretrainLM</a></code> and provides specific implementations for 
preparing data, loading both the generator and discriminator models, and training 
the Electra model, which includes both components.</p>

<h2 id="attributes">Attributes</h2>

<p>config : FinLMConfig
    Configuration object containing dataset, model, and optimization configurations.
dataset : FinLMDataset
    The dataset prepared for Electra model training.
generator : ElectraForMaskedLM
    The generator model in the Electra framework configured for masked language modeling.
discriminator : ElectraForPreTraining
    The discriminator model in the Electra framework configured for identifying replaced tokens.
optimizer : torch.optim.Optimizer
    The optimizer used for training.
scheduler : torch.optim.lr_scheduler.LambdaLR
    The learning rate scheduler used during training.
iteration_steps_per_epoch : int
    Number of iteration steps per training epoch.
logger : logging.Logger
    Logger instance for logging messages related to training.
device : torch.device
    Device on which computations will be performed (CPU or CUDA).</p>

<h2 id="methods">Methods</h2>

<p>load_model() -> None
    Loads and configures the Electra generator and discriminator models.
load_optimization() -> None
    Sets up the optimizer and learning rate scheduler based on the optimization configuration.
prepare_data_model_optimizer() -> None
    Prepares the dataset, models, and optimizer for training.
replace_masked_tokens_from_generator(masked_inputs: torch.Tensor, original_inputs: torch.Tensor, logits: torch.Tensor, special_mask_id: int, discriminator_sampling: str = "multinomial") -> Tuple[torch.Tensor, torch.Tensor]
    Replaces masked tokens with tokens sampled from the generator and generates labels for discriminator training.
train() -> None
    Trains the Electra model, which includes both the generator and discriminator, and saves the results and models.</p>
</div>


                            <div id="PretrainElectra.__init__" class="classattr">
                                        <input id="PretrainElectra.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">PretrainElectra</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="PretrainElectra.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainElectra.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainElectra.__init__-700"><a href="#PretrainElectra.__init__-700"><span class="linenos">700</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="PretrainElectra.__init__-701"><a href="#PretrainElectra.__init__-701"><span class="linenos">701</span></a>
</span><span id="PretrainElectra.__init__-702"><a href="#PretrainElectra.__init__-702"><span class="linenos">702</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra.__init__-703"><a href="#PretrainElectra.__init__-703"><span class="linenos">703</span></a><span class="sd">        Initializes the PretrainElectra class with the given configuration.</span>
</span><span id="PretrainElectra.__init__-704"><a href="#PretrainElectra.__init__-704"><span class="linenos">704</span></a>
</span><span id="PretrainElectra.__init__-705"><a href="#PretrainElectra.__init__-705"><span class="linenos">705</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainElectra.__init__-706"><a href="#PretrainElectra.__init__-706"><span class="linenos">706</span></a><span class="sd">        ----------</span>
</span><span id="PretrainElectra.__init__-707"><a href="#PretrainElectra.__init__-707"><span class="linenos">707</span></a><span class="sd">        config : FinLMConfig</span>
</span><span id="PretrainElectra.__init__-708"><a href="#PretrainElectra.__init__-708"><span class="linenos">708</span></a><span class="sd">            Configuration object containing dataset, model, and optimization configurations.</span>
</span><span id="PretrainElectra.__init__-709"><a href="#PretrainElectra.__init__-709"><span class="linenos">709</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra.__init__-710"><a href="#PretrainElectra.__init__-710"><span class="linenos">710</span></a>
</span><span id="PretrainElectra.__init__-711"><a href="#PretrainElectra.__init__-711"><span class="linenos">711</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="PretrainElectra.__init__-712"><a href="#PretrainElectra.__init__-712"><span class="linenos">712</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_model_optimizer</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the PretrainElectra class with the given configuration.</p>

<h2 id="parameters">Parameters</h2>

<p>config : FinLMConfig
    Configuration object containing dataset, model, and optimization configurations.</p>
</div>


                            </div>
                            <div id="PretrainElectra.load_model" class="classattr">
                                        <input id="PretrainElectra.load_model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_model</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainElectra.load_model-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainElectra.load_model"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainElectra.load_model-714"><a href="#PretrainElectra.load_model-714"><span class="linenos">714</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainElectra.load_model-715"><a href="#PretrainElectra.load_model-715"><span class="linenos">715</span></a>
</span><span id="PretrainElectra.load_model-716"><a href="#PretrainElectra.load_model-716"><span class="linenos">716</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra.load_model-717"><a href="#PretrainElectra.load_model-717"><span class="linenos">717</span></a><span class="sd">        Loads and configures the Electra generator and discriminator models.</span>
</span><span id="PretrainElectra.load_model-718"><a href="#PretrainElectra.load_model-718"><span class="linenos">718</span></a>
</span><span id="PretrainElectra.load_model-719"><a href="#PretrainElectra.load_model-719"><span class="linenos">719</span></a><span class="sd">        This method initializes the Electra generator and discriminator models using the </span>
</span><span id="PretrainElectra.load_model-720"><a href="#PretrainElectra.load_model-720"><span class="linenos">720</span></a><span class="sd">        configuration settings, including vocabulary size, embedding size, hidden size, </span>
</span><span id="PretrainElectra.load_model-721"><a href="#PretrainElectra.load_model-721"><span class="linenos">721</span></a><span class="sd">        and other model parameters. The models are then moved to the appropriate device (CPU or GPU).</span>
</span><span id="PretrainElectra.load_model-722"><a href="#PretrainElectra.load_model-722"><span class="linenos">722</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra.load_model-723"><a href="#PretrainElectra.load_model-723"><span class="linenos">723</span></a>            
</span><span id="PretrainElectra.load_model-724"><a href="#PretrainElectra.load_model-724"><span class="linenos">724</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator_model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="PretrainElectra.load_model-725"><a href="#PretrainElectra.load_model-725"><span class="linenos">725</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainElectra.load_model-726"><a href="#PretrainElectra.load_model-726"><span class="linenos">726</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="PretrainElectra.load_model-727"><a href="#PretrainElectra.load_model-727"><span class="linenos">727</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">),</span> 
</span><span id="PretrainElectra.load_model-728"><a href="#PretrainElectra.load_model-728"><span class="linenos">728</span></a>            <span class="n">intermediate_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">),</span>
</span><span id="PretrainElectra.load_model-729"><a href="#PretrainElectra.load_model-729"><span class="linenos">729</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_layer_size</span><span class="p">),</span>
</span><span id="PretrainElectra.load_model-730"><a href="#PretrainElectra.load_model-730"><span class="linenos">730</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">generator_size</span><span class="p">)</span>
</span><span id="PretrainElectra.load_model-731"><a href="#PretrainElectra.load_model-731"><span class="linenos">731</span></a>        <span class="p">)</span>
</span><span id="PretrainElectra.load_model-732"><a href="#PretrainElectra.load_model-732"><span class="linenos">732</span></a>
</span><span id="PretrainElectra.load_model-733"><a href="#PretrainElectra.load_model-733"><span class="linenos">733</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator_model_config</span> <span class="o">=</span> <span class="n">ElectraConfig</span><span class="p">(</span>
</span><span id="PretrainElectra.load_model-734"><a href="#PretrainElectra.load_model-734"><span class="linenos">734</span></a>            <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
</span><span id="PretrainElectra.load_model-735"><a href="#PretrainElectra.load_model-735"><span class="linenos">735</span></a>            <span class="n">embedding_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
</span><span id="PretrainElectra.load_model-736"><a href="#PretrainElectra.load_model-736"><span class="linenos">736</span></a>            <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
</span><span id="PretrainElectra.load_model-737"><a href="#PretrainElectra.load_model-737"><span class="linenos">737</span></a>            <span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">,</span>
</span><span id="PretrainElectra.load_model-738"><a href="#PretrainElectra.load_model-738"><span class="linenos">738</span></a>            <span class="n">num_attention_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_attention_heads</span>
</span><span id="PretrainElectra.load_model-739"><a href="#PretrainElectra.load_model-739"><span class="linenos">739</span></a>        <span class="p">)</span>
</span><span id="PretrainElectra.load_model-740"><a href="#PretrainElectra.load_model-740"><span class="linenos">740</span></a>
</span><span id="PretrainElectra.load_model-741"><a href="#PretrainElectra.load_model-741"><span class="linenos">741</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">ElectraForMaskedLM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">generator_model_config</span><span class="p">)</span>
</span><span id="PretrainElectra.load_model-742"><a href="#PretrainElectra.load_model-742"><span class="linenos">742</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">ElectraForPreTraining</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">discriminator_model_config</span><span class="p">)</span>
</span><span id="PretrainElectra.load_model-743"><a href="#PretrainElectra.load_model-743"><span class="linenos">743</span></a>        <span class="c1"># tie word and position embeddings</span>
</span><span id="PretrainElectra.load_model-744"><a href="#PretrainElectra.load_model-744"><span class="linenos">744</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span>
</span><span id="PretrainElectra.load_model-745"><a href="#PretrainElectra.load_model-745"><span class="linenos">745</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">electra</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">position_embeddings</span>
</span><span id="PretrainElectra.load_model-746"><a href="#PretrainElectra.load_model-746"><span class="linenos">746</span></a>        <span class="c1"># add to device</span>
</span><span id="PretrainElectra.load_model-747"><a href="#PretrainElectra.load_model-747"><span class="linenos">747</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainElectra.load_model-748"><a href="#PretrainElectra.load_model-748"><span class="linenos">748</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Loads and configures the Electra generator and discriminator models.</p>

<p>This method initializes the Electra generator and discriminator models using the 
configuration settings, including vocabulary size, embedding size, hidden size, 
and other model parameters. The models are then moved to the appropriate device (CPU or GPU).</p>
</div>


                            </div>
                            <div id="PretrainElectra.load_optimization" class="classattr">
                                        <input id="PretrainElectra.load_optimization-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_optimization</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainElectra.load_optimization-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainElectra.load_optimization"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainElectra.load_optimization-750"><a href="#PretrainElectra.load_optimization-750"><span class="linenos">750</span></a>    <span class="k">def</span> <span class="nf">load_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainElectra.load_optimization-751"><a href="#PretrainElectra.load_optimization-751"><span class="linenos">751</span></a>
</span><span id="PretrainElectra.load_optimization-752"><a href="#PretrainElectra.load_optimization-752"><span class="linenos">752</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra.load_optimization-753"><a href="#PretrainElectra.load_optimization-753"><span class="linenos">753</span></a><span class="sd">        Sets up the optimizer and learning rate scheduler based on the optimization configuration.</span>
</span><span id="PretrainElectra.load_optimization-754"><a href="#PretrainElectra.load_optimization-754"><span class="linenos">754</span></a>
</span><span id="PretrainElectra.load_optimization-755"><a href="#PretrainElectra.load_optimization-755"><span class="linenos">755</span></a><span class="sd">        This method identifies the trainable parameters, ensuring that the word and position embeddings </span>
</span><span id="PretrainElectra.load_optimization-756"><a href="#PretrainElectra.load_optimization-756"><span class="linenos">756</span></a><span class="sd">        are not duplicated. It then calculates the total number of training steps, initializes the AdamW </span>
</span><span id="PretrainElectra.load_optimization-757"><a href="#PretrainElectra.load_optimization-757"><span class="linenos">757</span></a><span class="sd">        optimizer, and configures a linear learning rate scheduler with warm-up steps.</span>
</span><span id="PretrainElectra.load_optimization-758"><a href="#PretrainElectra.load_optimization-758"><span class="linenos">758</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra.load_optimization-759"><a href="#PretrainElectra.load_optimization-759"><span class="linenos">759</span></a>        
</span><span id="PretrainElectra.load_optimization-760"><a href="#PretrainElectra.load_optimization-760"><span class="linenos">760</span></a>        <span class="c1"># identify trainable parameters without duplicating the embedding and position parameters</span>
</span><span id="PretrainElectra.load_optimization-761"><a href="#PretrainElectra.load_optimization-761"><span class="linenos">761</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.load_optimization-762"><a href="#PretrainElectra.load_optimization-762"><span class="linenos">762</span></a>        <span class="c1"># generator</span>
</span><span id="PretrainElectra.load_optimization-763"><a href="#PretrainElectra.load_optimization-763"><span class="linenos">763</span></a>        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="PretrainElectra.load_optimization-764"><a href="#PretrainElectra.load_optimization-764"><span class="linenos">764</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span><span id="PretrainElectra.load_optimization-765"><a href="#PretrainElectra.load_optimization-765"><span class="linenos">765</span></a>        <span class="c1"># discriminator</span>
</span><span id="PretrainElectra.load_optimization-766"><a href="#PretrainElectra.load_optimization-766"><span class="linenos">766</span></a>        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="PretrainElectra.load_optimization-767"><a href="#PretrainElectra.load_optimization-767"><span class="linenos">767</span></a>            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;word_embeddings.weight&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;position_embeddings.weight&quot;</span><span class="p">):</span>
</span><span id="PretrainElectra.load_optimization-768"><a href="#PretrainElectra.load_optimization-768"><span class="linenos">768</span></a>                <span class="k">continue</span>
</span><span id="PretrainElectra.load_optimization-769"><a href="#PretrainElectra.load_optimization-769"><span class="linenos">769</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PretrainElectra.load_optimization-770"><a href="#PretrainElectra.load_optimization-770"><span class="linenos">770</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span><span id="PretrainElectra.load_optimization-771"><a href="#PretrainElectra.load_optimization-771"><span class="linenos">771</span></a>        
</span><span id="PretrainElectra.load_optimization-772"><a href="#PretrainElectra.load_optimization-772"><span class="linenos">772</span></a>        <span class="n">n_sequences</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="PretrainElectra.load_optimization-773"><a href="#PretrainElectra.load_optimization-773"><span class="linenos">773</span></a>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="PretrainElectra.load_optimization-774"><a href="#PretrainElectra.load_optimization-774"><span class="linenos">774</span></a>            <span class="n">n_sequences</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">database_retrieval</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;limit&quot;</span><span class="p">]</span>
</span><span id="PretrainElectra.load_optimization-775"><a href="#PretrainElectra.load_optimization-775"><span class="linenos">775</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_sequences</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
</span><span id="PretrainElectra.load_optimization-776"><a href="#PretrainElectra.load_optimization-776"><span class="linenos">776</span></a>        <span class="n">total_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span> 
</span><span id="PretrainElectra.load_optimization-777"><a href="#PretrainElectra.load_optimization-777"><span class="linenos">777</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> 
</span><span id="PretrainElectra.load_optimization-778"><a href="#PretrainElectra.load_optimization-778"><span class="linenos">778</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">lr_scheduler_warm_up_steps</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Sets up the optimizer and learning rate scheduler based on the optimization configuration.</p>

<p>This method identifies the trainable parameters, ensuring that the word and position embeddings 
are not duplicated. It then calculates the total number of training steps, initializes the AdamW 
optimizer, and configures a linear learning rate scheduler with warm-up steps.</p>
</div>


                            </div>
                            <div id="PretrainElectra.prepare_data_model_optimizer" class="classattr">
                                        <input id="PretrainElectra.prepare_data_model_optimizer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">prepare_data_model_optimizer</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainElectra.prepare_data_model_optimizer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainElectra.prepare_data_model_optimizer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainElectra.prepare_data_model_optimizer-780"><a href="#PretrainElectra.prepare_data_model_optimizer-780"><span class="linenos">780</span></a>    <span class="k">def</span> <span class="nf">prepare_data_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainElectra.prepare_data_model_optimizer-781"><a href="#PretrainElectra.prepare_data_model_optimizer-781"><span class="linenos">781</span></a>
</span><span id="PretrainElectra.prepare_data_model_optimizer-782"><a href="#PretrainElectra.prepare_data_model_optimizer-782"><span class="linenos">782</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra.prepare_data_model_optimizer-783"><a href="#PretrainElectra.prepare_data_model_optimizer-783"><span class="linenos">783</span></a><span class="sd">        Prepares the dataset, models, and optimizer for training.</span>
</span><span id="PretrainElectra.prepare_data_model_optimizer-784"><a href="#PretrainElectra.prepare_data_model_optimizer-784"><span class="linenos">784</span></a>
</span><span id="PretrainElectra.prepare_data_model_optimizer-785"><a href="#PretrainElectra.prepare_data_model_optimizer-785"><span class="linenos">785</span></a><span class="sd">        This method calls the appropriate methods to load the dataset, load the generator and </span>
</span><span id="PretrainElectra.prepare_data_model_optimizer-786"><a href="#PretrainElectra.prepare_data_model_optimizer-786"><span class="linenos">786</span></a><span class="sd">        discriminator models, and set up the optimizer and learning rate scheduler.</span>
</span><span id="PretrainElectra.prepare_data_model_optimizer-787"><a href="#PretrainElectra.prepare_data_model_optimizer-787"><span class="linenos">787</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra.prepare_data_model_optimizer-788"><a href="#PretrainElectra.prepare_data_model_optimizer-788"><span class="linenos">788</span></a>
</span><span id="PretrainElectra.prepare_data_model_optimizer-789"><a href="#PretrainElectra.prepare_data_model_optimizer-789"><span class="linenos">789</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
</span><span id="PretrainElectra.prepare_data_model_optimizer-790"><a href="#PretrainElectra.prepare_data_model_optimizer-790"><span class="linenos">790</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span><span id="PretrainElectra.prepare_data_model_optimizer-791"><a href="#PretrainElectra.prepare_data_model_optimizer-791"><span class="linenos">791</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_optimization</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Prepares the dataset, models, and optimizer for training.</p>

<p>This method calls the appropriate methods to load the dataset, load the generator and 
discriminator models, and set up the optimizer and learning rate scheduler.</p>
</div>


                            </div>
                            <div id="PretrainElectra.replace_masked_tokens_from_generator" class="classattr">
                                        <input id="PretrainElectra.replace_masked_tokens_from_generator-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@staticmethod</div>

        <span class="def">def</span>
        <span class="name">replace_masked_tokens_from_generator</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">masked_inputs</span>,</span><span class="param">	<span class="n">original_inputs</span>,</span><span class="param">	<span class="n">logits</span>,</span><span class="param">	<span class="n">special_mask_id</span>,</span><span class="param">	<span class="n">discriminator_sampling</span><span class="o">=</span><span class="s1">&#39;gumbel_softmax&#39;</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainElectra.replace_masked_tokens_from_generator-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainElectra.replace_masked_tokens_from_generator"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainElectra.replace_masked_tokens_from_generator-793"><a href="#PretrainElectra.replace_masked_tokens_from_generator-793"><span class="linenos">793</span></a>    <span class="nd">@staticmethod</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-794"><a href="#PretrainElectra.replace_masked_tokens_from_generator-794"><span class="linenos">794</span></a>    <span class="k">def</span> <span class="nf">replace_masked_tokens_from_generator</span><span class="p">(</span><span class="n">masked_inputs</span><span class="p">,</span> <span class="n">original_inputs</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">special_mask_id</span><span class="p">,</span> <span class="n">discriminator_sampling</span> <span class="o">=</span> <span class="s2">&quot;gumbel_softmax&quot;</span><span class="p">):</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-795"><a href="#PretrainElectra.replace_masked_tokens_from_generator-795"><span class="linenos">795</span></a><span class="w">    </span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-796"><a href="#PretrainElectra.replace_masked_tokens_from_generator-796"><span class="linenos">796</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-797"><a href="#PretrainElectra.replace_masked_tokens_from_generator-797"><span class="linenos">797</span></a><span class="sd">        Replaces masked tokens with tokens sampled from the generator and generates labels for discriminator training.</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-798"><a href="#PretrainElectra.replace_masked_tokens_from_generator-798"><span class="linenos">798</span></a>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-799"><a href="#PretrainElectra.replace_masked_tokens_from_generator-799"><span class="linenos">799</span></a><span class="sd">        This method uses the generator&#39;s output logits to replace masked tokens in the input. It generates labels </span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-800"><a href="#PretrainElectra.replace_masked_tokens_from_generator-800"><span class="linenos">800</span></a><span class="sd">        indicating whether a token has been replaced and whether the replacement matches the original token.</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-801"><a href="#PretrainElectra.replace_masked_tokens_from_generator-801"><span class="linenos">801</span></a>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-802"><a href="#PretrainElectra.replace_masked_tokens_from_generator-802"><span class="linenos">802</span></a><span class="sd">        Parameters</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-803"><a href="#PretrainElectra.replace_masked_tokens_from_generator-803"><span class="linenos">803</span></a><span class="sd">        ----------</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-804"><a href="#PretrainElectra.replace_masked_tokens_from_generator-804"><span class="linenos">804</span></a><span class="sd">        masked_inputs : torch.Tensor</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-805"><a href="#PretrainElectra.replace_masked_tokens_from_generator-805"><span class="linenos">805</span></a><span class="sd">            Tensor containing the masked input token IDs.</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-806"><a href="#PretrainElectra.replace_masked_tokens_from_generator-806"><span class="linenos">806</span></a><span class="sd">        original_inputs : torch.Tensor</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-807"><a href="#PretrainElectra.replace_masked_tokens_from_generator-807"><span class="linenos">807</span></a><span class="sd">            Tensor containing the original input token IDs before masking.</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-808"><a href="#PretrainElectra.replace_masked_tokens_from_generator-808"><span class="linenos">808</span></a><span class="sd">        logits : torch.Tensor</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-809"><a href="#PretrainElectra.replace_masked_tokens_from_generator-809"><span class="linenos">809</span></a><span class="sd">            Logits output by the generator model.</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-810"><a href="#PretrainElectra.replace_masked_tokens_from_generator-810"><span class="linenos">810</span></a><span class="sd">        special_mask_id : int</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-811"><a href="#PretrainElectra.replace_masked_tokens_from_generator-811"><span class="linenos">811</span></a><span class="sd">            The token ID used for masking (typically the ID for the [MASK] token).</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-812"><a href="#PretrainElectra.replace_masked_tokens_from_generator-812"><span class="linenos">812</span></a><span class="sd">        discriminator_sampling : str, optional</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-813"><a href="#PretrainElectra.replace_masked_tokens_from_generator-813"><span class="linenos">813</span></a><span class="sd">            The sampling strategy for selecting replacement tokens, either &quot;multinomial&quot; or another strategy like &quot;aggressive&quot; or &quot;gumbel_softmax&quot; (default is &quot;gumbel_softmax&quot;).</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-814"><a href="#PretrainElectra.replace_masked_tokens_from_generator-814"><span class="linenos">814</span></a>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-815"><a href="#PretrainElectra.replace_masked_tokens_from_generator-815"><span class="linenos">815</span></a><span class="sd">        Returns</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-816"><a href="#PretrainElectra.replace_masked_tokens_from_generator-816"><span class="linenos">816</span></a><span class="sd">        -------</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-817"><a href="#PretrainElectra.replace_masked_tokens_from_generator-817"><span class="linenos">817</span></a><span class="sd">        Tuple[torch.Tensor, torch.Tensor]</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-818"><a href="#PretrainElectra.replace_masked_tokens_from_generator-818"><span class="linenos">818</span></a><span class="sd">            A tuple containing the discriminator inputs (with replaced tokens) and the corresponding labels tensor.</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-819"><a href="#PretrainElectra.replace_masked_tokens_from_generator-819"><span class="linenos">819</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-820"><a href="#PretrainElectra.replace_masked_tokens_from_generator-820"><span class="linenos">820</span></a>            
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-821"><a href="#PretrainElectra.replace_masked_tokens_from_generator-821"><span class="linenos">821</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">device</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-822"><a href="#PretrainElectra.replace_masked_tokens_from_generator-822"><span class="linenos">822</span></a>        <span class="n">discriminator_inputs</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-823"><a href="#PretrainElectra.replace_masked_tokens_from_generator-823"><span class="linenos">823</span></a>        <span class="n">mask_indices</span> <span class="o">=</span> <span class="n">masked_inputs</span> <span class="o">==</span> <span class="n">special_mask_id</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-824"><a href="#PretrainElectra.replace_masked_tokens_from_generator-824"><span class="linenos">824</span></a>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-825"><a href="#PretrainElectra.replace_masked_tokens_from_generator-825"><span class="linenos">825</span></a>        <span class="k">if</span> <span class="n">discriminator_sampling</span> <span class="o">==</span> <span class="s2">&quot;aggressive&quot;</span><span class="p">:</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-826"><a href="#PretrainElectra.replace_masked_tokens_from_generator-826"><span class="linenos">826</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-827"><a href="#PretrainElectra.replace_masked_tokens_from_generator-827"><span class="linenos">827</span></a>        <span class="k">elif</span> <span class="n">discriminator_sampling</span> <span class="o">==</span> <span class="s2">&quot;gumbel_softmax&quot;</span><span class="p">:</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-828"><a href="#PretrainElectra.replace_masked_tokens_from_generator-828"><span class="linenos">828</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gumbel_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">],</span> <span class="n">hard</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-829"><a href="#PretrainElectra.replace_masked_tokens_from_generator-829"><span class="linenos">829</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-830"><a href="#PretrainElectra.replace_masked_tokens_from_generator-830"><span class="linenos">830</span></a>            <span class="n">sampled_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">],</span> <span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-831"><a href="#PretrainElectra.replace_masked_tokens_from_generator-831"><span class="linenos">831</span></a>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-832"><a href="#PretrainElectra.replace_masked_tokens_from_generator-832"><span class="linenos">832</span></a>        <span class="n">discriminator_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">sampled_ids</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-833"><a href="#PretrainElectra.replace_masked_tokens_from_generator-833"><span class="linenos">833</span></a>        <span class="c1"># initialize discriminator labels with False</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-834"><a href="#PretrainElectra.replace_masked_tokens_from_generator-834"><span class="linenos">834</span></a>        <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">masked_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-835"><a href="#PretrainElectra.replace_masked_tokens_from_generator-835"><span class="linenos">835</span></a>        <span class="c1"># replace False with True if an id is sampled and not the same as the original one</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-836"><a href="#PretrainElectra.replace_masked_tokens_from_generator-836"><span class="linenos">836</span></a>        <span class="n">discriminator_labels</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">discriminator_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span> <span class="o">!=</span> <span class="n">original_inputs</span><span class="p">[</span><span class="n">mask_indices</span><span class="p">]</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-837"><a href="#PretrainElectra.replace_masked_tokens_from_generator-837"><span class="linenos">837</span></a>        <span class="c1"># convert to float </span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-838"><a href="#PretrainElectra.replace_masked_tokens_from_generator-838"><span class="linenos">838</span></a>        <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-839"><a href="#PretrainElectra.replace_masked_tokens_from_generator-839"><span class="linenos">839</span></a>
</span><span id="PretrainElectra.replace_masked_tokens_from_generator-840"><a href="#PretrainElectra.replace_masked_tokens_from_generator-840"><span class="linenos">840</span></a>        <span class="k">return</span> <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">discriminator_labels</span>
</span></pre></div>


            <div class="docstring"><p>Replaces masked tokens with tokens sampled from the generator and generates labels for discriminator training.</p>

<p>This method uses the generator's output logits to replace masked tokens in the input. It generates labels 
indicating whether a token has been replaced and whether the replacement matches the original token.</p>

<h2 id="parameters">Parameters</h2>

<p>masked_inputs : torch.Tensor
    Tensor containing the masked input token IDs.
original_inputs : torch.Tensor
    Tensor containing the original input token IDs before masking.
logits : torch.Tensor
    Logits output by the generator model.
special_mask_id : int
    The token ID used for masking (typically the ID for the [MASK] token).
discriminator_sampling : str, optional
    The sampling strategy for selecting replacement tokens, either "multinomial" or another strategy like "aggressive" or "gumbel_softmax" (default is "gumbel_softmax").</p>

<h2 id="returns">Returns</h2>

<p>Tuple[torch.Tensor, torch.Tensor]
    A tuple containing the discriminator inputs (with replaced tokens) and the corresponding labels tensor.</p>
</div>


                            </div>
                            <div id="PretrainElectra.train" class="classattr">
                                        <input id="PretrainElectra.train-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">train</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="PretrainElectra.train-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PretrainElectra.train"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PretrainElectra.train-842"><a href="#PretrainElectra.train-842"><span class="linenos">842</span></a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PretrainElectra.train-843"><a href="#PretrainElectra.train-843"><span class="linenos">843</span></a>
</span><span id="PretrainElectra.train-844"><a href="#PretrainElectra.train-844"><span class="linenos">844</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PretrainElectra.train-845"><a href="#PretrainElectra.train-845"><span class="linenos">845</span></a><span class="sd">        Trains the Electra model, which includes both the generator and discriminator, and saves the results and models.</span>
</span><span id="PretrainElectra.train-846"><a href="#PretrainElectra.train-846"><span class="linenos">846</span></a>
</span><span id="PretrainElectra.train-847"><a href="#PretrainElectra.train-847"><span class="linenos">847</span></a><span class="sd">        This method handles the training loop, including masking input tokens, generating replacements using the generator, </span>
</span><span id="PretrainElectra.train-848"><a href="#PretrainElectra.train-848"><span class="linenos">848</span></a><span class="sd">        training the discriminator on identifying the replaced tokens, calculating losses, updating model parameters, and </span>
</span><span id="PretrainElectra.train-849"><a href="#PretrainElectra.train-849"><span class="linenos">849</span></a><span class="sd">        logging training metrics. After training is complete, it saves the models, training metrics, and plots of the loss, </span>
</span><span id="PretrainElectra.train-850"><a href="#PretrainElectra.train-850"><span class="linenos">850</span></a><span class="sd">        accuracy, precision, and recall.</span>
</span><span id="PretrainElectra.train-851"><a href="#PretrainElectra.train-851"><span class="linenos">851</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PretrainElectra.train-852"><a href="#PretrainElectra.train-852"><span class="linenos">852</span></a>
</span><span id="PretrainElectra.train-853"><a href="#PretrainElectra.train-853"><span class="linenos">853</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting with training...&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-854"><a href="#PretrainElectra.train-854"><span class="linenos">854</span></a>        <span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="PretrainElectra.train-855"><a href="#PretrainElectra.train-855"><span class="linenos">855</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-856"><a href="#PretrainElectra.train-856"><span class="linenos">856</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-857"><a href="#PretrainElectra.train-857"><span class="linenos">857</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-858"><a href="#PretrainElectra.train-858"><span class="linenos">858</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-859"><a href="#PretrainElectra.train-859"><span class="linenos">859</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-860"><a href="#PretrainElectra.train-860"><span class="linenos">860</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_precision&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-861"><a href="#PretrainElectra.train-861"><span class="linenos">861</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-862"><a href="#PretrainElectra.train-862"><span class="linenos">862</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-863"><a href="#PretrainElectra.train-863"><span class="linenos">863</span></a>        <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PretrainElectra.train-864"><a href="#PretrainElectra.train-864"><span class="linenos">864</span></a>
</span><span id="PretrainElectra.train-865"><a href="#PretrainElectra.train-865"><span class="linenos">865</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span> 
</span><span id="PretrainElectra.train-866"><a href="#PretrainElectra.train-866"><span class="linenos">866</span></a>            
</span><span id="PretrainElectra.train-867"><a href="#PretrainElectra.train-867"><span class="linenos">867</span></a>            <span class="c1"># update the offset for database retrieval, epoch = 0 -&gt; offset = 0, epoch = 1 -&gt; offset = 1 * limit, epoch = 2 -&gt; offset = 2 * limit, ...    </span>
</span><span id="PretrainElectra.train-868"><a href="#PretrainElectra.train-868"><span class="linenos">868</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dataset_offsets</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span><span id="PretrainElectra.train-869"><a href="#PretrainElectra.train-869"><span class="linenos">869</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">prepare_data_loader</span><span class="p">()</span>
</span><span id="PretrainElectra.train-870"><a href="#PretrainElectra.train-870"><span class="linenos">870</span></a>
</span><span id="PretrainElectra.train-871"><a href="#PretrainElectra.train-871"><span class="linenos">871</span></a>            <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="PretrainElectra.train-872"><a href="#PretrainElectra.train-872"><span class="linenos">872</span></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="PretrainElectra.train-873"><a href="#PretrainElectra.train-873"><span class="linenos">873</span></a>
</span><span id="PretrainElectra.train-874"><a href="#PretrainElectra.train-874"><span class="linenos">874</span></a>                <span class="n">original_inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="PretrainElectra.train-875"><a href="#PretrainElectra.train-875"><span class="linenos">875</span></a>                <span class="n">generator_inputs</span><span class="p">,</span> <span class="n">generator_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="p">(</span>
</span><span id="PretrainElectra.train-876"><a href="#PretrainElectra.train-876"><span class="linenos">876</span></a>                    <span class="n">inputs</span><span class="p">,</span>
</span><span id="PretrainElectra.train-877"><a href="#PretrainElectra.train-877"><span class="linenos">877</span></a>                    <span class="n">mlm_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span>
</span><span id="PretrainElectra.train-878"><a href="#PretrainElectra.train-878"><span class="linenos">878</span></a>                    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainElectra.train-879"><a href="#PretrainElectra.train-879"><span class="linenos">879</span></a>                    <span class="n">special_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">special_token_ids</span><span class="p">,</span>
</span><span id="PretrainElectra.train-880"><a href="#PretrainElectra.train-880"><span class="linenos">880</span></a>                    <span class="n">n_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span><span id="PretrainElectra.train-881"><a href="#PretrainElectra.train-881"><span class="linenos">881</span></a>
</span><span id="PretrainElectra.train-882"><a href="#PretrainElectra.train-882"><span class="linenos">882</span></a>                <span class="n">mlm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">generator_inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">generator_labels</span><span class="p">)</span>
</span><span id="PretrainElectra.train-883"><a href="#PretrainElectra.train-883"><span class="linenos">883</span></a>                <span class="n">mlm_loss</span><span class="p">,</span> <span class="n">mlm_logits</span> <span class="o">=</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">mlm_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="PretrainElectra.train-884"><a href="#PretrainElectra.train-884"><span class="linenos">884</span></a>
</span><span id="PretrainElectra.train-885"><a href="#PretrainElectra.train-885"><span class="linenos">885</span></a>                <span class="n">sampling_logits</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span><span id="PretrainElectra.train-886"><a href="#PretrainElectra.train-886"><span class="linenos">886</span></a>                <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replace_masked_tokens_from_generator</span><span class="p">(</span>
</span><span id="PretrainElectra.train-887"><a href="#PretrainElectra.train-887"><span class="linenos">887</span></a>                    <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">generator_inputs</span><span class="p">,</span>
</span><span id="PretrainElectra.train-888"><a href="#PretrainElectra.train-888"><span class="linenos">888</span></a>                    <span class="n">original_inputs</span> <span class="o">=</span> <span class="n">original_inputs</span><span class="p">,</span>
</span><span id="PretrainElectra.train-889"><a href="#PretrainElectra.train-889"><span class="linenos">889</span></a>                    <span class="n">logits</span> <span class="o">=</span> <span class="n">sampling_logits</span><span class="p">,</span>
</span><span id="PretrainElectra.train-890"><a href="#PretrainElectra.train-890"><span class="linenos">890</span></a>                    <span class="n">special_mask_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">,</span>
</span><span id="PretrainElectra.train-891"><a href="#PretrainElectra.train-891"><span class="linenos">891</span></a>                    <span class="n">discriminator_sampling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">discriminator_sampling</span>
</span><span id="PretrainElectra.train-892"><a href="#PretrainElectra.train-892"><span class="linenos">892</span></a>                    <span class="p">)</span>
</span><span id="PretrainElectra.train-893"><a href="#PretrainElectra.train-893"><span class="linenos">893</span></a>                
</span><span id="PretrainElectra.train-894"><a href="#PretrainElectra.train-894"><span class="linenos">894</span></a>                <span class="n">discriminator_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">discriminator_inputs</span><span class="p">,</span> <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="p">)</span>
</span><span id="PretrainElectra.train-895"><a href="#PretrainElectra.train-895"><span class="linenos">895</span></a>                <span class="n">discriminator_loss</span><span class="p">,</span> <span class="n">discriminator_logits</span> <span class="o">=</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">discriminator_output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="PretrainElectra.train-896"><a href="#PretrainElectra.train-896"><span class="linenos">896</span></a>
</span><span id="PretrainElectra.train-897"><a href="#PretrainElectra.train-897"><span class="linenos">897</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">mlm_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">discriminator_weight</span> <span class="o">*</span> <span class="n">discriminator_loss</span>
</span><span id="PretrainElectra.train-898"><a href="#PretrainElectra.train-898"><span class="linenos">898</span></a>
</span><span id="PretrainElectra.train-899"><a href="#PretrainElectra.train-899"><span class="linenos">899</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra.train-900"><a href="#PretrainElectra.train-900"><span class="linenos">900</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra.train-901"><a href="#PretrainElectra.train-901"><span class="linenos">901</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra.train-902"><a href="#PretrainElectra.train-902"><span class="linenos">902</span></a>
</span><span id="PretrainElectra.train-903"><a href="#PretrainElectra.train-903"><span class="linenos">903</span></a>                <span class="c1"># gradient determination and update</span>
</span><span id="PretrainElectra.train-904"><a href="#PretrainElectra.train-904"><span class="linenos">904</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="PretrainElectra.train-905"><a href="#PretrainElectra.train-905"><span class="linenos">905</span></a>
</span><span id="PretrainElectra.train-906"><a href="#PretrainElectra.train-906"><span class="linenos">906</span></a>                <span class="c1"># determine gradients</span>
</span><span id="PretrainElectra.train-907"><a href="#PretrainElectra.train-907"><span class="linenos">907</span></a>                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="PretrainElectra.train-908"><a href="#PretrainElectra.train-908"><span class="linenos">908</span></a>
</span><span id="PretrainElectra.train-909"><a href="#PretrainElectra.train-909"><span class="linenos">909</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_config</span><span class="o">.</span><span class="n">use_gradient_clipping</span><span class="p">:</span>
</span><span id="PretrainElectra.train-910"><a href="#PretrainElectra.train-910"><span class="linenos">910</span></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">,</span> <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="PretrainElectra.train-911"><a href="#PretrainElectra.train-911"><span class="linenos">911</span></a>
</span><span id="PretrainElectra.train-912"><a href="#PretrainElectra.train-912"><span class="linenos">912</span></a>                <span class="c1"># determine gradient norms, equal to one if use_gradient_clipping is set to True</span>
</span><span id="PretrainElectra.train-913"><a href="#PretrainElectra.train-913"><span class="linenos">913</span></a>                <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_parameters</span><span class="p">]</span>
</span><span id="PretrainElectra.train-914"><a href="#PretrainElectra.train-914"><span class="linenos">914</span></a>                <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="PretrainElectra.train-915"><a href="#PretrainElectra.train-915"><span class="linenos">915</span></a>
</span><span id="PretrainElectra.train-916"><a href="#PretrainElectra.train-916"><span class="linenos">916</span></a>
</span><span id="PretrainElectra.train-917"><a href="#PretrainElectra.train-917"><span class="linenos">917</span></a>                <span class="c1"># update parameters        </span>
</span><span id="PretrainElectra.train-918"><a href="#PretrainElectra.train-918"><span class="linenos">918</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainElectra.train-919"><a href="#PretrainElectra.train-919"><span class="linenos">919</span></a>                <span class="c1"># update learning rate</span>
</span><span id="PretrainElectra.train-920"><a href="#PretrainElectra.train-920"><span class="linenos">920</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="PretrainElectra.train-921"><a href="#PretrainElectra.train-921"><span class="linenos">921</span></a>
</span><span id="PretrainElectra.train-922"><a href="#PretrainElectra.train-922"><span class="linenos">922</span></a>                <span class="c1"># determine accuracy metrics, (maybe check for correctness later, has been implemented quickly;))</span>
</span><span id="PretrainElectra.train-923"><a href="#PretrainElectra.train-923"><span class="linenos">923</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="PretrainElectra.train-924"><a href="#PretrainElectra.train-924"><span class="linenos">924</span></a>                    <span class="c1"># mask to identify ids which have been masked before</span>
</span><span id="PretrainElectra.train-925"><a href="#PretrainElectra.train-925"><span class="linenos">925</span></a>                    <span class="n">masked_ids_mask</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span>
</span><span id="PretrainElectra.train-926"><a href="#PretrainElectra.train-926"><span class="linenos">926</span></a>                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mlm_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PretrainElectra.train-927"><a href="#PretrainElectra.train-927"><span class="linenos">927</span></a>                    <span class="n">mlm_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">]</span> <span class="o">==</span> <span class="n">generator_labels</span><span class="p">[</span><span class="n">masked_ids_mask</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="PretrainElectra.train-928"><a href="#PretrainElectra.train-928"><span class="linenos">928</span></a>                    <span class="n">active_loss</span> <span class="o">=</span> <span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="PretrainElectra.train-929"><a href="#PretrainElectra.train-929"><span class="linenos">929</span></a>                    <span class="n">active_logits</span> <span class="o">=</span> <span class="n">discriminator_logits</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="PretrainElectra.train-930"><a href="#PretrainElectra.train-930"><span class="linenos">930</span></a>                    <span class="n">active_predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">active_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
</span><span id="PretrainElectra.train-931"><a href="#PretrainElectra.train-931"><span class="linenos">931</span></a>                    <span class="n">active_labels</span> <span class="o">=</span> <span class="n">discriminator_labels</span><span class="p">[</span><span class="n">active_loss</span><span class="p">]</span>
</span><span id="PretrainElectra.train-932"><a href="#PretrainElectra.train-932"><span class="linenos">932</span></a>                    <span class="n">discriminator_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">active_predictions</span> <span class="o">==</span> <span class="n">active_labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="PretrainElectra.train-933"><a href="#PretrainElectra.train-933"><span class="linenos">933</span></a>                    <span class="n">discriminator_precision</span> <span class="o">=</span> <span class="n">binary_precision</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="PretrainElectra.train-934"><a href="#PretrainElectra.train-934"><span class="linenos">934</span></a>                    <span class="n">discriminator_recall</span> <span class="o">=</span> <span class="n">binary_recall</span><span class="p">(</span><span class="n">active_predictions</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">active_labels</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span id="PretrainElectra.train-935"><a href="#PretrainElectra.train-935"><span class="linenos">935</span></a>
</span><span id="PretrainElectra.train-936"><a href="#PretrainElectra.train-936"><span class="linenos">936</span></a>
</span><span id="PretrainElectra.train-937"><a href="#PretrainElectra.train-937"><span class="linenos">937</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra.train-938"><a href="#PretrainElectra.train-938"><span class="linenos">938</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra.train-939"><a href="#PretrainElectra.train-939"><span class="linenos">939</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra.train-940"><a href="#PretrainElectra.train-940"><span class="linenos">940</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="PretrainElectra.train-941"><a href="#PretrainElectra.train-941"><span class="linenos">941</span></a>
</span><span id="PretrainElectra.train-942"><a href="#PretrainElectra.train-942"><span class="linenos">942</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;gradient_norm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="PretrainElectra.train-943"><a href="#PretrainElectra.train-943"><span class="linenos">943</span></a>                <span class="n">current_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="PretrainElectra.train-944"><a href="#PretrainElectra.train-944"><span class="linenos">944</span></a>                <span class="n">training_metrics</span><span class="p">[</span><span class="s2">&quot;learning_rates&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_lr</span><span class="p">)</span>
</span><span id="PretrainElectra.train-945"><a href="#PretrainElectra.train-945"><span class="linenos">945</span></a>
</span><span id="PretrainElectra.train-946"><a href="#PretrainElectra.train-946"><span class="linenos">946</span></a>                <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="PretrainElectra.train-947"><a href="#PretrainElectra.train-947"><span class="linenos">947</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Results after </span><span class="si">{</span><span class="n">batch_id</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration_steps_per_epoch</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> iterations of epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-948"><a href="#PretrainElectra.train-948"><span class="linenos">948</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-949"><a href="#PretrainElectra.train-949"><span class="linenos">949</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MLM Loss: </span><span class="si">{</span><span class="n">mlm_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-950"><a href="#PretrainElectra.train-950"><span class="linenos">950</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Discriminator Loss: </span><span class="si">{</span><span class="n">discriminator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-951"><a href="#PretrainElectra.train-951"><span class="linenos">951</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-952"><a href="#PretrainElectra.train-952"><span class="linenos">952</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-953"><a href="#PretrainElectra.train-953"><span class="linenos">953</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for masking task: </span><span class="si">{</span><span class="n">mlm_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-954"><a href="#PretrainElectra.train-954"><span class="linenos">954</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy for replacement task: </span><span class="si">{</span><span class="n">discriminator_accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-955"><a href="#PretrainElectra.train-955"><span class="linenos">955</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision for replacement task: </span><span class="si">{</span><span class="n">discriminator_precision</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-956"><a href="#PretrainElectra.train-956"><span class="linenos">956</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall for replacement task: </span><span class="si">{</span><span class="n">discriminator_recall</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-957"><a href="#PretrainElectra.train-957"><span class="linenos">957</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>   
</span><span id="PretrainElectra.train-958"><a href="#PretrainElectra.train-958"><span class="linenos">958</span></a>
</span><span id="PretrainElectra.train-959"><a href="#PretrainElectra.train-959"><span class="linenos">959</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;...training is finished, saving results and model.&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-960"><a href="#PretrainElectra.train-960"><span class="linenos">960</span></a>
</span><span id="PretrainElectra.train-961"><a href="#PretrainElectra.train-961"><span class="linenos">961</span></a>        <span class="n">training_metrics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_metrics</span><span class="p">)</span>
</span><span id="PretrainElectra.train-962"><a href="#PretrainElectra.train-962"><span class="linenos">962</span></a>        
</span><span id="PretrainElectra.train-963"><a href="#PretrainElectra.train-963"><span class="linenos">963</span></a>        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_directory_and_return_save_path</span><span class="p">(</span><span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;electra&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-964"><a href="#PretrainElectra.train-964"><span class="linenos">964</span></a>        <span class="c1"># create a function for making an output directory which creates it and saves the csv and model</span>
</span><span id="PretrainElectra.train-965"><a href="#PretrainElectra.train-965"><span class="linenos">965</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;training_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="PretrainElectra.train-966"><a href="#PretrainElectra.train-966"><span class="linenos">966</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;mlm_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="PretrainElectra.train-967"><a href="#PretrainElectra.train-967"><span class="linenos">967</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;loss.png&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-968"><a href="#PretrainElectra.train-968"><span class="linenos">968</span></a>        <span class="n">training_metrics_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;mlm_accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_precision&quot;</span><span class="p">,</span> <span class="s2">&quot;discriminator_recall&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="PretrainElectra.train-969"><a href="#PretrainElectra.train-969"><span class="linenos">969</span></a>        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;accuracy.png&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-970"><a href="#PretrainElectra.train-970"><span class="linenos">970</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;mlm_model&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-971"><a href="#PretrainElectra.train-971"><span class="linenos">971</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;discriminator_model&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-972"><a href="#PretrainElectra.train-972"><span class="linenos">972</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">save_path</span> <span class="o">+</span> <span class="s2">&quot;model_config.json&quot;</span><span class="p">)</span>
</span><span id="PretrainElectra.train-973"><a href="#PretrainElectra.train-973"><span class="linenos">973</span></a>
</span><span id="PretrainElectra.train-974"><a href="#PretrainElectra.train-974"><span class="linenos">974</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results and model are saved.&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Trains the Electra model, which includes both the generator and discriminator, and saves the results and models.</p>

<p>This method handles the training loop, including masking input tokens, generating replacements using the generator, 
training the discriminator on identifying the replaced tokens, calculating losses, updating model parameters, and 
logging training metrics. After training is complete, it saves the models, training metrics, and plots of the loss, 
accuracy, precision, and recall.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PretrainLM">PretrainLM</a></dt>
                                <dd id="PretrainElectra.config" class="variable"><a href="#PretrainLM.config">config</a></dd>
                <dd id="PretrainElectra.dataset_config" class="variable"><a href="#PretrainLM.dataset_config">dataset_config</a></dd>
                <dd id="PretrainElectra.model_config" class="variable"><a href="#PretrainLM.model_config">model_config</a></dd>
                <dd id="PretrainElectra.optimization_config" class="variable"><a href="#PretrainLM.optimization_config">optimization_config</a></dd>
                <dd id="PretrainElectra.save_root_path" class="variable"><a href="#PretrainLM.save_root_path">save_root_path</a></dd>
                <dd id="PretrainElectra.logger" class="variable"><a href="#PretrainLM.logger">logger</a></dd>
                <dd id="PretrainElectra.load_dataset" class="function"><a href="#PretrainLM.load_dataset">load_dataset</a></dd>
                <dd id="PretrainElectra.mask_tokens" class="function"><a href="#PretrainLM.mask_tokens">mask_tokens</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ElectraSimpleAttention">
                            <input id="ElectraSimpleAttention-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ElectraSimpleAttention</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="ElectraSimpleAttention-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttention"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttention-981"><a href="#ElectraSimpleAttention-981"><span class="linenos"> 981</span></a><span class="k">class</span> <span class="nc">ElectraSimpleAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="ElectraSimpleAttention-982"><a href="#ElectraSimpleAttention-982"><span class="linenos"> 982</span></a><span class="w">    </span>
</span><span id="ElectraSimpleAttention-983"><a href="#ElectraSimpleAttention-983"><span class="linenos"> 983</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention-984"><a href="#ElectraSimpleAttention-984"><span class="linenos"> 984</span></a><span class="sd">    A single-head attention layer for use in the Electra model.</span>
</span><span id="ElectraSimpleAttention-985"><a href="#ElectraSimpleAttention-985"><span class="linenos"> 985</span></a>
</span><span id="ElectraSimpleAttention-986"><a href="#ElectraSimpleAttention-986"><span class="linenos"> 986</span></a><span class="sd">    This class implements a simple attention mechanism, where attention scores are computed </span>
</span><span id="ElectraSimpleAttention-987"><a href="#ElectraSimpleAttention-987"><span class="linenos"> 987</span></a><span class="sd">    using a single attention head. The attention layer includes dropout and can optionally </span>
</span><span id="ElectraSimpleAttention-988"><a href="#ElectraSimpleAttention-988"><span class="linenos"> 988</span></a><span class="sd">    return attention probabilities.</span>
</span><span id="ElectraSimpleAttention-989"><a href="#ElectraSimpleAttention-989"><span class="linenos"> 989</span></a>
</span><span id="ElectraSimpleAttention-990"><a href="#ElectraSimpleAttention-990"><span class="linenos"> 990</span></a><span class="sd">    Attributes</span>
</span><span id="ElectraSimpleAttention-991"><a href="#ElectraSimpleAttention-991"><span class="linenos"> 991</span></a><span class="sd">    ----------</span>
</span><span id="ElectraSimpleAttention-992"><a href="#ElectraSimpleAttention-992"><span class="linenos"> 992</span></a><span class="sd">    hidden_size : int</span>
</span><span id="ElectraSimpleAttention-993"><a href="#ElectraSimpleAttention-993"><span class="linenos"> 993</span></a><span class="sd">        The size of the hidden layer in the attention mechanism.</span>
</span><span id="ElectraSimpleAttention-994"><a href="#ElectraSimpleAttention-994"><span class="linenos"> 994</span></a><span class="sd">    query : nn.Linear</span>
</span><span id="ElectraSimpleAttention-995"><a href="#ElectraSimpleAttention-995"><span class="linenos"> 995</span></a><span class="sd">        The linear layer that projects the input to the query space.</span>
</span><span id="ElectraSimpleAttention-996"><a href="#ElectraSimpleAttention-996"><span class="linenos"> 996</span></a><span class="sd">    key : nn.Linear</span>
</span><span id="ElectraSimpleAttention-997"><a href="#ElectraSimpleAttention-997"><span class="linenos"> 997</span></a><span class="sd">        The linear layer that projects the input to the key space.</span>
</span><span id="ElectraSimpleAttention-998"><a href="#ElectraSimpleAttention-998"><span class="linenos"> 998</span></a><span class="sd">    value : nn.Linear</span>
</span><span id="ElectraSimpleAttention-999"><a href="#ElectraSimpleAttention-999"><span class="linenos"> 999</span></a><span class="sd">        The linear layer that projects the input to the value space.</span>
</span><span id="ElectraSimpleAttention-1000"><a href="#ElectraSimpleAttention-1000"><span class="linenos">1000</span></a><span class="sd">    dropout : nn.Dropout</span>
</span><span id="ElectraSimpleAttention-1001"><a href="#ElectraSimpleAttention-1001"><span class="linenos">1001</span></a><span class="sd">        Dropout applied to the attention probabilities.</span>
</span><span id="ElectraSimpleAttention-1002"><a href="#ElectraSimpleAttention-1002"><span class="linenos">1002</span></a>
</span><span id="ElectraSimpleAttention-1003"><a href="#ElectraSimpleAttention-1003"><span class="linenos">1003</span></a><span class="sd">    Methods</span>
</span><span id="ElectraSimpleAttention-1004"><a href="#ElectraSimpleAttention-1004"><span class="linenos">1004</span></a><span class="sd">    -------</span>
</span><span id="ElectraSimpleAttention-1005"><a href="#ElectraSimpleAttention-1005"><span class="linenos">1005</span></a><span class="sd">    forward(sequence_embeddings: torch.Tensor, return_attention: bool = True) -&gt; Tuple[torch.Tensor, ...]</span>
</span><span id="ElectraSimpleAttention-1006"><a href="#ElectraSimpleAttention-1006"><span class="linenos">1006</span></a><span class="sd">        Performs the forward pass, calculating the attention output and optionally returning the attention probabilities.</span>
</span><span id="ElectraSimpleAttention-1007"><a href="#ElectraSimpleAttention-1007"><span class="linenos">1007</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention-1008"><a href="#ElectraSimpleAttention-1008"><span class="linenos">1008</span></a>
</span><span id="ElectraSimpleAttention-1009"><a href="#ElectraSimpleAttention-1009"><span class="linenos">1009</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraSimpleAttention-1010"><a href="#ElectraSimpleAttention-1010"><span class="linenos">1010</span></a>
</span><span id="ElectraSimpleAttention-1011"><a href="#ElectraSimpleAttention-1011"><span class="linenos">1011</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention-1012"><a href="#ElectraSimpleAttention-1012"><span class="linenos">1012</span></a><span class="sd">        Initializes the ElectraSimpleAttention layer with the provided configuration.</span>
</span><span id="ElectraSimpleAttention-1013"><a href="#ElectraSimpleAttention-1013"><span class="linenos">1013</span></a>
</span><span id="ElectraSimpleAttention-1014"><a href="#ElectraSimpleAttention-1014"><span class="linenos">1014</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttention-1015"><a href="#ElectraSimpleAttention-1015"><span class="linenos">1015</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttention-1016"><a href="#ElectraSimpleAttention-1016"><span class="linenos">1016</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraSimpleAttention-1017"><a href="#ElectraSimpleAttention-1017"><span class="linenos">1017</span></a><span class="sd">            The configuration object containing the hidden size and dropout probability.</span>
</span><span id="ElectraSimpleAttention-1018"><a href="#ElectraSimpleAttention-1018"><span class="linenos">1018</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention-1019"><a href="#ElectraSimpleAttention-1019"><span class="linenos">1019</span></a>
</span><span id="ElectraSimpleAttention-1020"><a href="#ElectraSimpleAttention-1020"><span class="linenos">1020</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ElectraSimpleAttention-1021"><a href="#ElectraSimpleAttention-1021"><span class="linenos">1021</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
</span><span id="ElectraSimpleAttention-1022"><a href="#ElectraSimpleAttention-1022"><span class="linenos">1022</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1023"><a href="#ElectraSimpleAttention-1023"><span class="linenos">1023</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1024"><a href="#ElectraSimpleAttention-1024"><span class="linenos">1024</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1025"><a href="#ElectraSimpleAttention-1025"><span class="linenos">1025</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1026"><a href="#ElectraSimpleAttention-1026"><span class="linenos">1026</span></a>
</span><span id="ElectraSimpleAttention-1027"><a href="#ElectraSimpleAttention-1027"><span class="linenos">1027</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="ElectraSimpleAttention-1028"><a href="#ElectraSimpleAttention-1028"><span class="linenos">1028</span></a>
</span><span id="ElectraSimpleAttention-1029"><a href="#ElectraSimpleAttention-1029"><span class="linenos">1029</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention-1030"><a href="#ElectraSimpleAttention-1030"><span class="linenos">1030</span></a><span class="sd">        Performs the forward pass of the attention layer.</span>
</span><span id="ElectraSimpleAttention-1031"><a href="#ElectraSimpleAttention-1031"><span class="linenos">1031</span></a>
</span><span id="ElectraSimpleAttention-1032"><a href="#ElectraSimpleAttention-1032"><span class="linenos">1032</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttention-1033"><a href="#ElectraSimpleAttention-1033"><span class="linenos">1033</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttention-1034"><a href="#ElectraSimpleAttention-1034"><span class="linenos">1034</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="ElectraSimpleAttention-1035"><a href="#ElectraSimpleAttention-1035"><span class="linenos">1035</span></a><span class="sd">            The input sequence embeddings of shape (number of sequences over all batched documents, hidden_size).</span>
</span><span id="ElectraSimpleAttention-1036"><a href="#ElectraSimpleAttention-1036"><span class="linenos">1036</span></a><span class="sd">            Before this mechanism is applied the nested document sequences are flattened and sequence embeddings are extracted.</span>
</span><span id="ElectraSimpleAttention-1037"><a href="#ElectraSimpleAttention-1037"><span class="linenos">1037</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="ElectraSimpleAttention-1038"><a href="#ElectraSimpleAttention-1038"><span class="linenos">1038</span></a><span class="sd">            If True, returns the attention probabilities along with the context layer (default is True).</span>
</span><span id="ElectraSimpleAttention-1039"><a href="#ElectraSimpleAttention-1039"><span class="linenos">1039</span></a>
</span><span id="ElectraSimpleAttention-1040"><a href="#ElectraSimpleAttention-1040"><span class="linenos">1040</span></a><span class="sd">        Returns</span>
</span><span id="ElectraSimpleAttention-1041"><a href="#ElectraSimpleAttention-1041"><span class="linenos">1041</span></a><span class="sd">        -------</span>
</span><span id="ElectraSimpleAttention-1042"><a href="#ElectraSimpleAttention-1042"><span class="linenos">1042</span></a><span class="sd">        Tuple[torch.Tensor, ...]</span>
</span><span id="ElectraSimpleAttention-1043"><a href="#ElectraSimpleAttention-1043"><span class="linenos">1043</span></a><span class="sd">            The context layer and, optionally, the attention probabilities.</span>
</span><span id="ElectraSimpleAttention-1044"><a href="#ElectraSimpleAttention-1044"><span class="linenos">1044</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention-1045"><a href="#ElectraSimpleAttention-1045"><span class="linenos">1045</span></a>
</span><span id="ElectraSimpleAttention-1046"><a href="#ElectraSimpleAttention-1046"><span class="linenos">1046</span></a>        <span class="n">query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1047"><a href="#ElectraSimpleAttention-1047"><span class="linenos">1047</span></a>        <span class="n">key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1048"><a href="#ElectraSimpleAttention-1048"><span class="linenos">1048</span></a>        <span class="n">value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1049"><a href="#ElectraSimpleAttention-1049"><span class="linenos">1049</span></a>
</span><span id="ElectraSimpleAttention-1050"><a href="#ElectraSimpleAttention-1050"><span class="linenos">1050</span></a>        <span class="c1"># determine attention scores and weights</span>
</span><span id="ElectraSimpleAttention-1051"><a href="#ElectraSimpleAttention-1051"><span class="linenos">1051</span></a>        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query_layer</span><span class="p">,</span> <span class="n">key_layer</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="ElectraSimpleAttention-1052"><a href="#ElectraSimpleAttention-1052"><span class="linenos">1052</span></a>        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1053"><a href="#ElectraSimpleAttention-1053"><span class="linenos">1053</span></a>
</span><span id="ElectraSimpleAttention-1054"><a href="#ElectraSimpleAttention-1054"><span class="linenos">1054</span></a>        <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1055"><a href="#ElectraSimpleAttention-1055"><span class="linenos">1055</span></a>        <span class="n">attention_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention-1056"><a href="#ElectraSimpleAttention-1056"><span class="linenos">1056</span></a>
</span><span id="ElectraSimpleAttention-1057"><a href="#ElectraSimpleAttention-1057"><span class="linenos">1057</span></a>        <span class="n">context_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">,</span> <span class="n">value_layer</span><span class="p">)</span> 
</span><span id="ElectraSimpleAttention-1058"><a href="#ElectraSimpleAttention-1058"><span class="linenos">1058</span></a>
</span><span id="ElectraSimpleAttention-1059"><a href="#ElectraSimpleAttention-1059"><span class="linenos">1059</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">context_layer</span><span class="p">,</span> <span class="n">attention_probs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">context_layer</span><span class="p">,</span> <span class="p">)</span>
</span><span id="ElectraSimpleAttention-1060"><a href="#ElectraSimpleAttention-1060"><span class="linenos">1060</span></a>
</span><span id="ElectraSimpleAttention-1061"><a href="#ElectraSimpleAttention-1061"><span class="linenos">1061</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


            <div class="docstring"><p>A single-head attention layer for use in the Electra model.</p>

<p>This class implements a simple attention mechanism, where attention scores are computed 
using a single attention head. The attention layer includes dropout and can optionally 
return attention probabilities.</p>

<h2 id="attributes">Attributes</h2>

<p>hidden_size : int
    The size of the hidden layer in the attention mechanism.
query : nn.Linear
    The linear layer that projects the input to the query space.
key : nn.Linear
    The linear layer that projects the input to the key space.
value : nn.Linear
    The linear layer that projects the input to the value space.
dropout : nn.Dropout
    Dropout applied to the attention probabilities.</p>

<h2 id="methods">Methods</h2>

<p>forward(sequence_embeddings: torch.Tensor, return_attention: bool = True) -> Tuple[torch.Tensor, ...]
    Performs the forward pass, calculating the attention output and optionally returning the attention probabilities.</p>
</div>


                            <div id="ElectraSimpleAttention.__init__" class="classattr">
                                        <input id="ElectraSimpleAttention.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ElectraSimpleAttention</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ElectraSimpleAttention.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttention.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttention.__init__-1009"><a href="#ElectraSimpleAttention.__init__-1009"><span class="linenos">1009</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraSimpleAttention.__init__-1010"><a href="#ElectraSimpleAttention.__init__-1010"><span class="linenos">1010</span></a>
</span><span id="ElectraSimpleAttention.__init__-1011"><a href="#ElectraSimpleAttention.__init__-1011"><span class="linenos">1011</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention.__init__-1012"><a href="#ElectraSimpleAttention.__init__-1012"><span class="linenos">1012</span></a><span class="sd">        Initializes the ElectraSimpleAttention layer with the provided configuration.</span>
</span><span id="ElectraSimpleAttention.__init__-1013"><a href="#ElectraSimpleAttention.__init__-1013"><span class="linenos">1013</span></a>
</span><span id="ElectraSimpleAttention.__init__-1014"><a href="#ElectraSimpleAttention.__init__-1014"><span class="linenos">1014</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttention.__init__-1015"><a href="#ElectraSimpleAttention.__init__-1015"><span class="linenos">1015</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttention.__init__-1016"><a href="#ElectraSimpleAttention.__init__-1016"><span class="linenos">1016</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraSimpleAttention.__init__-1017"><a href="#ElectraSimpleAttention.__init__-1017"><span class="linenos">1017</span></a><span class="sd">            The configuration object containing the hidden size and dropout probability.</span>
</span><span id="ElectraSimpleAttention.__init__-1018"><a href="#ElectraSimpleAttention.__init__-1018"><span class="linenos">1018</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention.__init__-1019"><a href="#ElectraSimpleAttention.__init__-1019"><span class="linenos">1019</span></a>
</span><span id="ElectraSimpleAttention.__init__-1020"><a href="#ElectraSimpleAttention.__init__-1020"><span class="linenos">1020</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ElectraSimpleAttention.__init__-1021"><a href="#ElectraSimpleAttention.__init__-1021"><span class="linenos">1021</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
</span><span id="ElectraSimpleAttention.__init__-1022"><a href="#ElectraSimpleAttention.__init__-1022"><span class="linenos">1022</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.__init__-1023"><a href="#ElectraSimpleAttention.__init__-1023"><span class="linenos">1023</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.__init__-1024"><a href="#ElectraSimpleAttention.__init__-1024"><span class="linenos">1024</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.__init__-1025"><a href="#ElectraSimpleAttention.__init__-1025"><span class="linenos">1025</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the ElectraSimpleAttention layer with the provided configuration.</p>

<h2 id="parameters">Parameters</h2>

<p>config : ElectraConfig
    The configuration object containing the hidden size and dropout probability.</p>
</div>


                            </div>
                            <div id="ElectraSimpleAttention.hidden_size" class="classattr">
                                <div class="attr variable">
            <span class="name">hidden_size</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttention.hidden_size"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttention.query" class="classattr">
                                <div class="attr variable">
            <span class="name">query</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttention.query"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttention.key" class="classattr">
                                <div class="attr variable">
            <span class="name">key</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttention.key"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttention.value" class="classattr">
                                <div class="attr variable">
            <span class="name">value</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttention.value"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttention.dropout" class="classattr">
                                <div class="attr variable">
            <span class="name">dropout</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttention.dropout"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttention.forward" class="classattr">
                                        <input id="ElectraSimpleAttention.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">sequence_embeddings</span>, </span><span class="param"><span class="n">return_attention</span><span class="o">=</span><span class="kc">True</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ElectraSimpleAttention.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttention.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttention.forward-1027"><a href="#ElectraSimpleAttention.forward-1027"><span class="linenos">1027</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="ElectraSimpleAttention.forward-1028"><a href="#ElectraSimpleAttention.forward-1028"><span class="linenos">1028</span></a>
</span><span id="ElectraSimpleAttention.forward-1029"><a href="#ElectraSimpleAttention.forward-1029"><span class="linenos">1029</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention.forward-1030"><a href="#ElectraSimpleAttention.forward-1030"><span class="linenos">1030</span></a><span class="sd">        Performs the forward pass of the attention layer.</span>
</span><span id="ElectraSimpleAttention.forward-1031"><a href="#ElectraSimpleAttention.forward-1031"><span class="linenos">1031</span></a>
</span><span id="ElectraSimpleAttention.forward-1032"><a href="#ElectraSimpleAttention.forward-1032"><span class="linenos">1032</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttention.forward-1033"><a href="#ElectraSimpleAttention.forward-1033"><span class="linenos">1033</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttention.forward-1034"><a href="#ElectraSimpleAttention.forward-1034"><span class="linenos">1034</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="ElectraSimpleAttention.forward-1035"><a href="#ElectraSimpleAttention.forward-1035"><span class="linenos">1035</span></a><span class="sd">            The input sequence embeddings of shape (number of sequences over all batched documents, hidden_size).</span>
</span><span id="ElectraSimpleAttention.forward-1036"><a href="#ElectraSimpleAttention.forward-1036"><span class="linenos">1036</span></a><span class="sd">            Before this mechanism is applied the nested document sequences are flattened and sequence embeddings are extracted.</span>
</span><span id="ElectraSimpleAttention.forward-1037"><a href="#ElectraSimpleAttention.forward-1037"><span class="linenos">1037</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="ElectraSimpleAttention.forward-1038"><a href="#ElectraSimpleAttention.forward-1038"><span class="linenos">1038</span></a><span class="sd">            If True, returns the attention probabilities along with the context layer (default is True).</span>
</span><span id="ElectraSimpleAttention.forward-1039"><a href="#ElectraSimpleAttention.forward-1039"><span class="linenos">1039</span></a>
</span><span id="ElectraSimpleAttention.forward-1040"><a href="#ElectraSimpleAttention.forward-1040"><span class="linenos">1040</span></a><span class="sd">        Returns</span>
</span><span id="ElectraSimpleAttention.forward-1041"><a href="#ElectraSimpleAttention.forward-1041"><span class="linenos">1041</span></a><span class="sd">        -------</span>
</span><span id="ElectraSimpleAttention.forward-1042"><a href="#ElectraSimpleAttention.forward-1042"><span class="linenos">1042</span></a><span class="sd">        Tuple[torch.Tensor, ...]</span>
</span><span id="ElectraSimpleAttention.forward-1043"><a href="#ElectraSimpleAttention.forward-1043"><span class="linenos">1043</span></a><span class="sd">            The context layer and, optionally, the attention probabilities.</span>
</span><span id="ElectraSimpleAttention.forward-1044"><a href="#ElectraSimpleAttention.forward-1044"><span class="linenos">1044</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttention.forward-1045"><a href="#ElectraSimpleAttention.forward-1045"><span class="linenos">1045</span></a>
</span><span id="ElectraSimpleAttention.forward-1046"><a href="#ElectraSimpleAttention.forward-1046"><span class="linenos">1046</span></a>        <span class="n">query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.forward-1047"><a href="#ElectraSimpleAttention.forward-1047"><span class="linenos">1047</span></a>        <span class="n">key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.forward-1048"><a href="#ElectraSimpleAttention.forward-1048"><span class="linenos">1048</span></a>        <span class="n">value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.forward-1049"><a href="#ElectraSimpleAttention.forward-1049"><span class="linenos">1049</span></a>
</span><span id="ElectraSimpleAttention.forward-1050"><a href="#ElectraSimpleAttention.forward-1050"><span class="linenos">1050</span></a>        <span class="c1"># determine attention scores and weights</span>
</span><span id="ElectraSimpleAttention.forward-1051"><a href="#ElectraSimpleAttention.forward-1051"><span class="linenos">1051</span></a>        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query_layer</span><span class="p">,</span> <span class="n">key_layer</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="ElectraSimpleAttention.forward-1052"><a href="#ElectraSimpleAttention.forward-1052"><span class="linenos">1052</span></a>        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.forward-1053"><a href="#ElectraSimpleAttention.forward-1053"><span class="linenos">1053</span></a>
</span><span id="ElectraSimpleAttention.forward-1054"><a href="#ElectraSimpleAttention.forward-1054"><span class="linenos">1054</span></a>        <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.forward-1055"><a href="#ElectraSimpleAttention.forward-1055"><span class="linenos">1055</span></a>        <span class="n">attention_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">)</span>
</span><span id="ElectraSimpleAttention.forward-1056"><a href="#ElectraSimpleAttention.forward-1056"><span class="linenos">1056</span></a>
</span><span id="ElectraSimpleAttention.forward-1057"><a href="#ElectraSimpleAttention.forward-1057"><span class="linenos">1057</span></a>        <span class="n">context_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">,</span> <span class="n">value_layer</span><span class="p">)</span> 
</span><span id="ElectraSimpleAttention.forward-1058"><a href="#ElectraSimpleAttention.forward-1058"><span class="linenos">1058</span></a>
</span><span id="ElectraSimpleAttention.forward-1059"><a href="#ElectraSimpleAttention.forward-1059"><span class="linenos">1059</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">context_layer</span><span class="p">,</span> <span class="n">attention_probs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">context_layer</span><span class="p">,</span> <span class="p">)</span>
</span><span id="ElectraSimpleAttention.forward-1060"><a href="#ElectraSimpleAttention.forward-1060"><span class="linenos">1060</span></a>
</span><span id="ElectraSimpleAttention.forward-1061"><a href="#ElectraSimpleAttention.forward-1061"><span class="linenos">1061</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


            <div class="docstring"><p>Performs the forward pass of the attention layer.</p>

<h2 id="parameters">Parameters</h2>

<p>sequence_embeddings : torch.Tensor
    The input sequence embeddings of shape (number of sequences over all batched documents, hidden_size).
    Before this mechanism is applied the nested document sequences are flattened and sequence embeddings are extracted.
return_attention : bool, optional
    If True, returns the attention probabilities along with the context layer (default is True).</p>

<h2 id="returns">Returns</h2>

<p>Tuple[torch.Tensor, ...]
    The context layer and, optionally, the attention probabilities.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ElectraSimpleAttention.dump_patches" class="variable">dump_patches</dd>
                <dd id="ElectraSimpleAttention.training" class="variable">training</dd>
                <dd id="ElectraSimpleAttention.call_super_init" class="variable">call_super_init</dd>
                <dd id="ElectraSimpleAttention.register_buffer" class="function">register_buffer</dd>
                <dd id="ElectraSimpleAttention.register_parameter" class="function">register_parameter</dd>
                <dd id="ElectraSimpleAttention.add_module" class="function">add_module</dd>
                <dd id="ElectraSimpleAttention.register_module" class="function">register_module</dd>
                <dd id="ElectraSimpleAttention.get_submodule" class="function">get_submodule</dd>
                <dd id="ElectraSimpleAttention.get_parameter" class="function">get_parameter</dd>
                <dd id="ElectraSimpleAttention.get_buffer" class="function">get_buffer</dd>
                <dd id="ElectraSimpleAttention.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ElectraSimpleAttention.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ElectraSimpleAttention.apply" class="function">apply</dd>
                <dd id="ElectraSimpleAttention.cuda" class="function">cuda</dd>
                <dd id="ElectraSimpleAttention.ipu" class="function">ipu</dd>
                <dd id="ElectraSimpleAttention.xpu" class="function">xpu</dd>
                <dd id="ElectraSimpleAttention.cpu" class="function">cpu</dd>
                <dd id="ElectraSimpleAttention.type" class="function">type</dd>
                <dd id="ElectraSimpleAttention.float" class="function">float</dd>
                <dd id="ElectraSimpleAttention.double" class="function">double</dd>
                <dd id="ElectraSimpleAttention.half" class="function">half</dd>
                <dd id="ElectraSimpleAttention.bfloat16" class="function">bfloat16</dd>
                <dd id="ElectraSimpleAttention.to_empty" class="function">to_empty</dd>
                <dd id="ElectraSimpleAttention.to" class="function">to</dd>
                <dd id="ElectraSimpleAttention.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ElectraSimpleAttention.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ElectraSimpleAttention.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ElectraSimpleAttention.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ElectraSimpleAttention.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ElectraSimpleAttention.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ElectraSimpleAttention.state_dict" class="function">state_dict</dd>
                <dd id="ElectraSimpleAttention.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ElectraSimpleAttention.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ElectraSimpleAttention.parameters" class="function">parameters</dd>
                <dd id="ElectraSimpleAttention.named_parameters" class="function">named_parameters</dd>
                <dd id="ElectraSimpleAttention.buffers" class="function">buffers</dd>
                <dd id="ElectraSimpleAttention.named_buffers" class="function">named_buffers</dd>
                <dd id="ElectraSimpleAttention.children" class="function">children</dd>
                <dd id="ElectraSimpleAttention.named_children" class="function">named_children</dd>
                <dd id="ElectraSimpleAttention.modules" class="function">modules</dd>
                <dd id="ElectraSimpleAttention.named_modules" class="function">named_modules</dd>
                <dd id="ElectraSimpleAttention.train" class="function">train</dd>
                <dd id="ElectraSimpleAttention.eval" class="function">eval</dd>
                <dd id="ElectraSimpleAttention.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ElectraSimpleAttention.zero_grad" class="function">zero_grad</dd>
                <dd id="ElectraSimpleAttention.share_memory" class="function">share_memory</dd>
                <dd id="ElectraSimpleAttention.extra_repr" class="function">extra_repr</dd>
                <dd id="ElectraSimpleAttention.compile" class="function">compile</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ElectraSimpleAttentionOutput">
                            <input id="ElectraSimpleAttentionOutput-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ElectraSimpleAttentionOutput</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="ElectraSimpleAttentionOutput-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionOutput"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttentionOutput-1063"><a href="#ElectraSimpleAttentionOutput-1063"><span class="linenos">1063</span></a><span class="k">class</span> <span class="nc">ElectraSimpleAttentionOutput</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionOutput-1064"><a href="#ElectraSimpleAttentionOutput-1064"><span class="linenos">1064</span></a><span class="w">    </span>
</span><span id="ElectraSimpleAttentionOutput-1065"><a href="#ElectraSimpleAttentionOutput-1065"><span class="linenos">1065</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput-1066"><a href="#ElectraSimpleAttentionOutput-1066"><span class="linenos">1066</span></a><span class="sd">    Outputs from the ElectraSimpleAttention layer, with residual connections and aggregation.</span>
</span><span id="ElectraSimpleAttentionOutput-1067"><a href="#ElectraSimpleAttentionOutput-1067"><span class="linenos">1067</span></a>
</span><span id="ElectraSimpleAttentionOutput-1068"><a href="#ElectraSimpleAttentionOutput-1068"><span class="linenos">1068</span></a><span class="sd">    This class applies a dense layer, dropout, and LayerNorm to the sequence attention embeddings.</span>
</span><span id="ElectraSimpleAttentionOutput-1069"><a href="#ElectraSimpleAttentionOutput-1069"><span class="linenos">1069</span></a><span class="sd">    It also aggregates sequence embeddings by averaging and applies a residual connection.</span>
</span><span id="ElectraSimpleAttentionOutput-1070"><a href="#ElectraSimpleAttentionOutput-1070"><span class="linenos">1070</span></a>
</span><span id="ElectraSimpleAttentionOutput-1071"><a href="#ElectraSimpleAttentionOutput-1071"><span class="linenos">1071</span></a><span class="sd">    Attributes</span>
</span><span id="ElectraSimpleAttentionOutput-1072"><a href="#ElectraSimpleAttentionOutput-1072"><span class="linenos">1072</span></a><span class="sd">    ----------</span>
</span><span id="ElectraSimpleAttentionOutput-1073"><a href="#ElectraSimpleAttentionOutput-1073"><span class="linenos">1073</span></a><span class="sd">    dense : nn.Linear</span>
</span><span id="ElectraSimpleAttentionOutput-1074"><a href="#ElectraSimpleAttentionOutput-1074"><span class="linenos">1074</span></a><span class="sd">        A linear layer applied to the attention output.</span>
</span><span id="ElectraSimpleAttentionOutput-1075"><a href="#ElectraSimpleAttentionOutput-1075"><span class="linenos">1075</span></a><span class="sd">    dropout : nn.Dropout</span>
</span><span id="ElectraSimpleAttentionOutput-1076"><a href="#ElectraSimpleAttentionOutput-1076"><span class="linenos">1076</span></a><span class="sd">        Dropout applied to the attention output.</span>
</span><span id="ElectraSimpleAttentionOutput-1077"><a href="#ElectraSimpleAttentionOutput-1077"><span class="linenos">1077</span></a><span class="sd">    LayerNorm : nn.LayerNorm</span>
</span><span id="ElectraSimpleAttentionOutput-1078"><a href="#ElectraSimpleAttentionOutput-1078"><span class="linenos">1078</span></a><span class="sd">        Layer normalization applied after adding the residual connection.</span>
</span><span id="ElectraSimpleAttentionOutput-1079"><a href="#ElectraSimpleAttentionOutput-1079"><span class="linenos">1079</span></a><span class="sd">    out_projection : nn.Linear</span>
</span><span id="ElectraSimpleAttentionOutput-1080"><a href="#ElectraSimpleAttentionOutput-1080"><span class="linenos">1080</span></a><span class="sd">        A linear layer that projects the aggregated embeddings to the number of labels.</span>
</span><span id="ElectraSimpleAttentionOutput-1081"><a href="#ElectraSimpleAttentionOutput-1081"><span class="linenos">1081</span></a>
</span><span id="ElectraSimpleAttentionOutput-1082"><a href="#ElectraSimpleAttentionOutput-1082"><span class="linenos">1082</span></a><span class="sd">    Methods</span>
</span><span id="ElectraSimpleAttentionOutput-1083"><a href="#ElectraSimpleAttentionOutput-1083"><span class="linenos">1083</span></a><span class="sd">    -------</span>
</span><span id="ElectraSimpleAttentionOutput-1084"><a href="#ElectraSimpleAttentionOutput-1084"><span class="linenos">1084</span></a><span class="sd">    forward(sequence_attention_embeddings: torch.Tensor, sequence_embeddings: torch.Tensor, original_shapes: List[int]) -&gt; torch.Tensor</span>
</span><span id="ElectraSimpleAttentionOutput-1085"><a href="#ElectraSimpleAttentionOutput-1085"><span class="linenos">1085</span></a><span class="sd">        Performs the forward pass, applying the dense layer, residual connection, and aggregation.</span>
</span><span id="ElectraSimpleAttentionOutput-1086"><a href="#ElectraSimpleAttentionOutput-1086"><span class="linenos">1086</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput-1087"><a href="#ElectraSimpleAttentionOutput-1087"><span class="linenos">1087</span></a>
</span><span id="ElectraSimpleAttentionOutput-1088"><a href="#ElectraSimpleAttentionOutput-1088"><span class="linenos">1088</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionOutput-1089"><a href="#ElectraSimpleAttentionOutput-1089"><span class="linenos">1089</span></a>
</span><span id="ElectraSimpleAttentionOutput-1090"><a href="#ElectraSimpleAttentionOutput-1090"><span class="linenos">1090</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput-1091"><a href="#ElectraSimpleAttentionOutput-1091"><span class="linenos">1091</span></a><span class="sd">        Initializes the ElectraSimpleAttentionOutput layer with the provided configuration.</span>
</span><span id="ElectraSimpleAttentionOutput-1092"><a href="#ElectraSimpleAttentionOutput-1092"><span class="linenos">1092</span></a>
</span><span id="ElectraSimpleAttentionOutput-1093"><a href="#ElectraSimpleAttentionOutput-1093"><span class="linenos">1093</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttentionOutput-1094"><a href="#ElectraSimpleAttentionOutput-1094"><span class="linenos">1094</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttentionOutput-1095"><a href="#ElectraSimpleAttentionOutput-1095"><span class="linenos">1095</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraSimpleAttentionOutput-1096"><a href="#ElectraSimpleAttentionOutput-1096"><span class="linenos">1096</span></a><span class="sd">            The configuration object containing the hidden size, dropout probability, and number of labels.</span>
</span><span id="ElectraSimpleAttentionOutput-1097"><a href="#ElectraSimpleAttentionOutput-1097"><span class="linenos">1097</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput-1098"><a href="#ElectraSimpleAttentionOutput-1098"><span class="linenos">1098</span></a>
</span><span id="ElectraSimpleAttentionOutput-1099"><a href="#ElectraSimpleAttentionOutput-1099"><span class="linenos">1099</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ElectraSimpleAttentionOutput-1100"><a href="#ElectraSimpleAttentionOutput-1100"><span class="linenos">1100</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1101"><a href="#ElectraSimpleAttentionOutput-1101"><span class="linenos">1101</span></a>        <span class="c1"># dropout</span>
</span><span id="ElectraSimpleAttentionOutput-1102"><a href="#ElectraSimpleAttentionOutput-1102"><span class="linenos">1102</span></a>        <span class="n">aggregation_head_dropout</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="ElectraSimpleAttentionOutput-1103"><a href="#ElectraSimpleAttentionOutput-1103"><span class="linenos">1103</span></a>            <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span>
</span><span id="ElectraSimpleAttentionOutput-1104"><a href="#ElectraSimpleAttentionOutput-1104"><span class="linenos">1104</span></a>        <span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1105"><a href="#ElectraSimpleAttentionOutput-1105"><span class="linenos">1105</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">aggregation_head_dropout</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1106"><a href="#ElectraSimpleAttentionOutput-1106"><span class="linenos">1106</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1107"><a href="#ElectraSimpleAttentionOutput-1107"><span class="linenos">1107</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1108"><a href="#ElectraSimpleAttentionOutput-1108"><span class="linenos">1108</span></a>
</span><span id="ElectraSimpleAttentionOutput-1109"><a href="#ElectraSimpleAttentionOutput-1109"><span class="linenos">1109</span></a>
</span><span id="ElectraSimpleAttentionOutput-1110"><a href="#ElectraSimpleAttentionOutput-1110"><span class="linenos">1110</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionOutput-1111"><a href="#ElectraSimpleAttentionOutput-1111"><span class="linenos">1111</span></a><span class="w">        </span>
</span><span id="ElectraSimpleAttentionOutput-1112"><a href="#ElectraSimpleAttentionOutput-1112"><span class="linenos">1112</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput-1113"><a href="#ElectraSimpleAttentionOutput-1113"><span class="linenos">1113</span></a><span class="sd">        Performs the forward pass of the attention output layer.</span>
</span><span id="ElectraSimpleAttentionOutput-1114"><a href="#ElectraSimpleAttentionOutput-1114"><span class="linenos">1114</span></a>
</span><span id="ElectraSimpleAttentionOutput-1115"><a href="#ElectraSimpleAttentionOutput-1115"><span class="linenos">1115</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttentionOutput-1116"><a href="#ElectraSimpleAttentionOutput-1116"><span class="linenos">1116</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttentionOutput-1117"><a href="#ElectraSimpleAttentionOutput-1117"><span class="linenos">1117</span></a><span class="sd">        sequence_attention_embeddings : torch.Tensor</span>
</span><span id="ElectraSimpleAttentionOutput-1118"><a href="#ElectraSimpleAttentionOutput-1118"><span class="linenos">1118</span></a><span class="sd">            The embeddings output from the attention layer.</span>
</span><span id="ElectraSimpleAttentionOutput-1119"><a href="#ElectraSimpleAttentionOutput-1119"><span class="linenos">1119</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="ElectraSimpleAttentionOutput-1120"><a href="#ElectraSimpleAttentionOutput-1120"><span class="linenos">1120</span></a><span class="sd">            The original sequence embeddings for the residual connection.</span>
</span><span id="ElectraSimpleAttentionOutput-1121"><a href="#ElectraSimpleAttentionOutput-1121"><span class="linenos">1121</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="ElectraSimpleAttentionOutput-1122"><a href="#ElectraSimpleAttentionOutput-1122"><span class="linenos">1122</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="ElectraSimpleAttentionOutput-1123"><a href="#ElectraSimpleAttentionOutput-1123"><span class="linenos">1123</span></a>
</span><span id="ElectraSimpleAttentionOutput-1124"><a href="#ElectraSimpleAttentionOutput-1124"><span class="linenos">1124</span></a><span class="sd">        Returns</span>
</span><span id="ElectraSimpleAttentionOutput-1125"><a href="#ElectraSimpleAttentionOutput-1125"><span class="linenos">1125</span></a><span class="sd">        -------</span>
</span><span id="ElectraSimpleAttentionOutput-1126"><a href="#ElectraSimpleAttentionOutput-1126"><span class="linenos">1126</span></a><span class="sd">        torch.Tensor</span>
</span><span id="ElectraSimpleAttentionOutput-1127"><a href="#ElectraSimpleAttentionOutput-1127"><span class="linenos">1127</span></a><span class="sd">            The logits for each aggregated sequence.</span>
</span><span id="ElectraSimpleAttentionOutput-1128"><a href="#ElectraSimpleAttentionOutput-1128"><span class="linenos">1128</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput-1129"><a href="#ElectraSimpleAttentionOutput-1129"><span class="linenos">1129</span></a>
</span><span id="ElectraSimpleAttentionOutput-1130"><a href="#ElectraSimpleAttentionOutput-1130"><span class="linenos">1130</span></a>        <span class="c1"># sequence attention embeddings are the ones coming from the simple attention layer</span>
</span><span id="ElectraSimpleAttentionOutput-1131"><a href="#ElectraSimpleAttentionOutput-1131"><span class="linenos">1131</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1132"><a href="#ElectraSimpleAttentionOutput-1132"><span class="linenos">1132</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1133"><a href="#ElectraSimpleAttentionOutput-1133"><span class="linenos">1133</span></a>        <span class="c1"># residual connection with the original sequence embeddings</span>
</span><span id="ElectraSimpleAttentionOutput-1134"><a href="#ElectraSimpleAttentionOutput-1134"><span class="linenos">1134</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span> <span class="o">+</span> <span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1135"><a href="#ElectraSimpleAttentionOutput-1135"><span class="linenos">1135</span></a>        <span class="n">sequence_attention_embeddings_original_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1136"><a href="#ElectraSimpleAttentionOutput-1136"><span class="linenos">1136</span></a>        <span class="n">sequence_attention_embeddings_aggregated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch_tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">torch_tensor</span> <span class="ow">in</span> <span class="n">sequence_attention_embeddings_original_shapes</span><span class="p">])</span>
</span><span id="ElectraSimpleAttentionOutput-1137"><a href="#ElectraSimpleAttentionOutput-1137"><span class="linenos">1137</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">sequence_attention_embeddings_aggregated</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput-1138"><a href="#ElectraSimpleAttentionOutput-1138"><span class="linenos">1138</span></a> 
</span><span id="ElectraSimpleAttentionOutput-1139"><a href="#ElectraSimpleAttentionOutput-1139"><span class="linenos">1139</span></a>        <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Outputs from the ElectraSimpleAttention layer, with residual connections and aggregation.</p>

<p>This class applies a dense layer, dropout, and LayerNorm to the sequence attention embeddings.
It also aggregates sequence embeddings by averaging and applies a residual connection.</p>

<h2 id="attributes">Attributes</h2>

<p>dense : nn.Linear
    A linear layer applied to the attention output.
dropout : nn.Dropout
    Dropout applied to the attention output.
LayerNorm : nn.LayerNorm
    Layer normalization applied after adding the residual connection.
out_projection : nn.Linear
    A linear layer that projects the aggregated embeddings to the number of labels.</p>

<h2 id="methods">Methods</h2>

<p>forward(sequence_attention_embeddings: torch.Tensor, sequence_embeddings: torch.Tensor, original_shapes: List[int]) -> torch.Tensor
    Performs the forward pass, applying the dense layer, residual connection, and aggregation.</p>
</div>


                            <div id="ElectraSimpleAttentionOutput.__init__" class="classattr">
                                        <input id="ElectraSimpleAttentionOutput.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ElectraSimpleAttentionOutput</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ElectraSimpleAttentionOutput.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionOutput.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttentionOutput.__init__-1088"><a href="#ElectraSimpleAttentionOutput.__init__-1088"><span class="linenos">1088</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1089"><a href="#ElectraSimpleAttentionOutput.__init__-1089"><span class="linenos">1089</span></a>
</span><span id="ElectraSimpleAttentionOutput.__init__-1090"><a href="#ElectraSimpleAttentionOutput.__init__-1090"><span class="linenos">1090</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1091"><a href="#ElectraSimpleAttentionOutput.__init__-1091"><span class="linenos">1091</span></a><span class="sd">        Initializes the ElectraSimpleAttentionOutput layer with the provided configuration.</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1092"><a href="#ElectraSimpleAttentionOutput.__init__-1092"><span class="linenos">1092</span></a>
</span><span id="ElectraSimpleAttentionOutput.__init__-1093"><a href="#ElectraSimpleAttentionOutput.__init__-1093"><span class="linenos">1093</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1094"><a href="#ElectraSimpleAttentionOutput.__init__-1094"><span class="linenos">1094</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1095"><a href="#ElectraSimpleAttentionOutput.__init__-1095"><span class="linenos">1095</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1096"><a href="#ElectraSimpleAttentionOutput.__init__-1096"><span class="linenos">1096</span></a><span class="sd">            The configuration object containing the hidden size, dropout probability, and number of labels.</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1097"><a href="#ElectraSimpleAttentionOutput.__init__-1097"><span class="linenos">1097</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1098"><a href="#ElectraSimpleAttentionOutput.__init__-1098"><span class="linenos">1098</span></a>
</span><span id="ElectraSimpleAttentionOutput.__init__-1099"><a href="#ElectraSimpleAttentionOutput.__init__-1099"><span class="linenos">1099</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1100"><a href="#ElectraSimpleAttentionOutput.__init__-1100"><span class="linenos">1100</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1101"><a href="#ElectraSimpleAttentionOutput.__init__-1101"><span class="linenos">1101</span></a>        <span class="c1"># dropout</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1102"><a href="#ElectraSimpleAttentionOutput.__init__-1102"><span class="linenos">1102</span></a>        <span class="n">aggregation_head_dropout</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1103"><a href="#ElectraSimpleAttentionOutput.__init__-1103"><span class="linenos">1103</span></a>            <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1104"><a href="#ElectraSimpleAttentionOutput.__init__-1104"><span class="linenos">1104</span></a>        <span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1105"><a href="#ElectraSimpleAttentionOutput.__init__-1105"><span class="linenos">1105</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">aggregation_head_dropout</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1106"><a href="#ElectraSimpleAttentionOutput.__init__-1106"><span class="linenos">1106</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.__init__-1107"><a href="#ElectraSimpleAttentionOutput.__init__-1107"><span class="linenos">1107</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the ElectraSimpleAttentionOutput layer with the provided configuration.</p>

<h2 id="parameters">Parameters</h2>

<p>config : ElectraConfig
    The configuration object containing the hidden size, dropout probability, and number of labels.</p>
</div>


                            </div>
                            <div id="ElectraSimpleAttentionOutput.dense" class="classattr">
                                <div class="attr variable">
            <span class="name">dense</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionOutput.dense"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttentionOutput.dropout" class="classattr">
                                <div class="attr variable">
            <span class="name">dropout</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionOutput.dropout"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttentionOutput.LayerNorm" class="classattr">
                                <div class="attr variable">
            <span class="name">LayerNorm</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionOutput.LayerNorm"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttentionOutput.out_projection" class="classattr">
                                <div class="attr variable">
            <span class="name">out_projection</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionOutput.out_projection"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttentionOutput.forward" class="classattr">
                                        <input id="ElectraSimpleAttentionOutput.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">sequence_attention_embeddings</span>,</span><span class="param">	<span class="n">sequence_embeddings</span>,</span><span class="param">	<span class="n">original_shapes</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ElectraSimpleAttentionOutput.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionOutput.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttentionOutput.forward-1110"><a href="#ElectraSimpleAttentionOutput.forward-1110"><span class="linenos">1110</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1111"><a href="#ElectraSimpleAttentionOutput.forward-1111"><span class="linenos">1111</span></a><span class="w">        </span>
</span><span id="ElectraSimpleAttentionOutput.forward-1112"><a href="#ElectraSimpleAttentionOutput.forward-1112"><span class="linenos">1112</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1113"><a href="#ElectraSimpleAttentionOutput.forward-1113"><span class="linenos">1113</span></a><span class="sd">        Performs the forward pass of the attention output layer.</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1114"><a href="#ElectraSimpleAttentionOutput.forward-1114"><span class="linenos">1114</span></a>
</span><span id="ElectraSimpleAttentionOutput.forward-1115"><a href="#ElectraSimpleAttentionOutput.forward-1115"><span class="linenos">1115</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1116"><a href="#ElectraSimpleAttentionOutput.forward-1116"><span class="linenos">1116</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1117"><a href="#ElectraSimpleAttentionOutput.forward-1117"><span class="linenos">1117</span></a><span class="sd">        sequence_attention_embeddings : torch.Tensor</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1118"><a href="#ElectraSimpleAttentionOutput.forward-1118"><span class="linenos">1118</span></a><span class="sd">            The embeddings output from the attention layer.</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1119"><a href="#ElectraSimpleAttentionOutput.forward-1119"><span class="linenos">1119</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1120"><a href="#ElectraSimpleAttentionOutput.forward-1120"><span class="linenos">1120</span></a><span class="sd">            The original sequence embeddings for the residual connection.</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1121"><a href="#ElectraSimpleAttentionOutput.forward-1121"><span class="linenos">1121</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1122"><a href="#ElectraSimpleAttentionOutput.forward-1122"><span class="linenos">1122</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1123"><a href="#ElectraSimpleAttentionOutput.forward-1123"><span class="linenos">1123</span></a>
</span><span id="ElectraSimpleAttentionOutput.forward-1124"><a href="#ElectraSimpleAttentionOutput.forward-1124"><span class="linenos">1124</span></a><span class="sd">        Returns</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1125"><a href="#ElectraSimpleAttentionOutput.forward-1125"><span class="linenos">1125</span></a><span class="sd">        -------</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1126"><a href="#ElectraSimpleAttentionOutput.forward-1126"><span class="linenos">1126</span></a><span class="sd">        torch.Tensor</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1127"><a href="#ElectraSimpleAttentionOutput.forward-1127"><span class="linenos">1127</span></a><span class="sd">            The logits for each aggregated sequence.</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1128"><a href="#ElectraSimpleAttentionOutput.forward-1128"><span class="linenos">1128</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1129"><a href="#ElectraSimpleAttentionOutput.forward-1129"><span class="linenos">1129</span></a>
</span><span id="ElectraSimpleAttentionOutput.forward-1130"><a href="#ElectraSimpleAttentionOutput.forward-1130"><span class="linenos">1130</span></a>        <span class="c1"># sequence attention embeddings are the ones coming from the simple attention layer</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1131"><a href="#ElectraSimpleAttentionOutput.forward-1131"><span class="linenos">1131</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1132"><a href="#ElectraSimpleAttentionOutput.forward-1132"><span class="linenos">1132</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1133"><a href="#ElectraSimpleAttentionOutput.forward-1133"><span class="linenos">1133</span></a>        <span class="c1"># residual connection with the original sequence embeddings</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1134"><a href="#ElectraSimpleAttentionOutput.forward-1134"><span class="linenos">1134</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span> <span class="o">+</span> <span class="n">sequence_embeddings</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1135"><a href="#ElectraSimpleAttentionOutput.forward-1135"><span class="linenos">1135</span></a>        <span class="n">sequence_attention_embeddings_original_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1136"><a href="#ElectraSimpleAttentionOutput.forward-1136"><span class="linenos">1136</span></a>        <span class="n">sequence_attention_embeddings_aggregated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch_tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">torch_tensor</span> <span class="ow">in</span> <span class="n">sequence_attention_embeddings_original_shapes</span><span class="p">])</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1137"><a href="#ElectraSimpleAttentionOutput.forward-1137"><span class="linenos">1137</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">sequence_attention_embeddings_aggregated</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionOutput.forward-1138"><a href="#ElectraSimpleAttentionOutput.forward-1138"><span class="linenos">1138</span></a> 
</span><span id="ElectraSimpleAttentionOutput.forward-1139"><a href="#ElectraSimpleAttentionOutput.forward-1139"><span class="linenos">1139</span></a>        <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Performs the forward pass of the attention output layer.</p>

<h2 id="parameters">Parameters</h2>

<p>sequence_attention_embeddings : torch.Tensor
    The embeddings output from the attention layer.
sequence_embeddings : torch.Tensor
    The original sequence embeddings for the residual connection.
original_shapes : List[int]
    The original shapes of the sequences before flattening.</p>

<h2 id="returns">Returns</h2>

<p>torch.Tensor
    The logits for each aggregated sequence.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ElectraSimpleAttentionOutput.dump_patches" class="variable">dump_patches</dd>
                <dd id="ElectraSimpleAttentionOutput.training" class="variable">training</dd>
                <dd id="ElectraSimpleAttentionOutput.call_super_init" class="variable">call_super_init</dd>
                <dd id="ElectraSimpleAttentionOutput.register_buffer" class="function">register_buffer</dd>
                <dd id="ElectraSimpleAttentionOutput.register_parameter" class="function">register_parameter</dd>
                <dd id="ElectraSimpleAttentionOutput.add_module" class="function">add_module</dd>
                <dd id="ElectraSimpleAttentionOutput.register_module" class="function">register_module</dd>
                <dd id="ElectraSimpleAttentionOutput.get_submodule" class="function">get_submodule</dd>
                <dd id="ElectraSimpleAttentionOutput.get_parameter" class="function">get_parameter</dd>
                <dd id="ElectraSimpleAttentionOutput.get_buffer" class="function">get_buffer</dd>
                <dd id="ElectraSimpleAttentionOutput.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ElectraSimpleAttentionOutput.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ElectraSimpleAttentionOutput.apply" class="function">apply</dd>
                <dd id="ElectraSimpleAttentionOutput.cuda" class="function">cuda</dd>
                <dd id="ElectraSimpleAttentionOutput.ipu" class="function">ipu</dd>
                <dd id="ElectraSimpleAttentionOutput.xpu" class="function">xpu</dd>
                <dd id="ElectraSimpleAttentionOutput.cpu" class="function">cpu</dd>
                <dd id="ElectraSimpleAttentionOutput.type" class="function">type</dd>
                <dd id="ElectraSimpleAttentionOutput.float" class="function">float</dd>
                <dd id="ElectraSimpleAttentionOutput.double" class="function">double</dd>
                <dd id="ElectraSimpleAttentionOutput.half" class="function">half</dd>
                <dd id="ElectraSimpleAttentionOutput.bfloat16" class="function">bfloat16</dd>
                <dd id="ElectraSimpleAttentionOutput.to_empty" class="function">to_empty</dd>
                <dd id="ElectraSimpleAttentionOutput.to" class="function">to</dd>
                <dd id="ElectraSimpleAttentionOutput.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ElectraSimpleAttentionOutput.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ElectraSimpleAttentionOutput.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ElectraSimpleAttentionOutput.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ElectraSimpleAttentionOutput.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ElectraSimpleAttentionOutput.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ElectraSimpleAttentionOutput.state_dict" class="function">state_dict</dd>
                <dd id="ElectraSimpleAttentionOutput.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ElectraSimpleAttentionOutput.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ElectraSimpleAttentionOutput.parameters" class="function">parameters</dd>
                <dd id="ElectraSimpleAttentionOutput.named_parameters" class="function">named_parameters</dd>
                <dd id="ElectraSimpleAttentionOutput.buffers" class="function">buffers</dd>
                <dd id="ElectraSimpleAttentionOutput.named_buffers" class="function">named_buffers</dd>
                <dd id="ElectraSimpleAttentionOutput.children" class="function">children</dd>
                <dd id="ElectraSimpleAttentionOutput.named_children" class="function">named_children</dd>
                <dd id="ElectraSimpleAttentionOutput.modules" class="function">modules</dd>
                <dd id="ElectraSimpleAttentionOutput.named_modules" class="function">named_modules</dd>
                <dd id="ElectraSimpleAttentionOutput.train" class="function">train</dd>
                <dd id="ElectraSimpleAttentionOutput.eval" class="function">eval</dd>
                <dd id="ElectraSimpleAttentionOutput.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ElectraSimpleAttentionOutput.zero_grad" class="function">zero_grad</dd>
                <dd id="ElectraSimpleAttentionOutput.share_memory" class="function">share_memory</dd>
                <dd id="ElectraSimpleAttentionOutput.extra_repr" class="function">extra_repr</dd>
                <dd id="ElectraSimpleAttentionOutput.compile" class="function">compile</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ElectraSimpleAttentionHead">
                            <input id="ElectraSimpleAttentionHead-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ElectraSimpleAttentionHead</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="ElectraSimpleAttentionHead-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionHead"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttentionHead-1142"><a href="#ElectraSimpleAttentionHead-1142"><span class="linenos">1142</span></a><span class="k">class</span> <span class="nc">ElectraSimpleAttentionHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionHead-1143"><a href="#ElectraSimpleAttentionHead-1143"><span class="linenos">1143</span></a><span class="w">    </span>
</span><span id="ElectraSimpleAttentionHead-1144"><a href="#ElectraSimpleAttentionHead-1144"><span class="linenos">1144</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead-1145"><a href="#ElectraSimpleAttentionHead-1145"><span class="linenos">1145</span></a><span class="sd">    A combination of simple attention and output layers with aggregation.</span>
</span><span id="ElectraSimpleAttentionHead-1146"><a href="#ElectraSimpleAttentionHead-1146"><span class="linenos">1146</span></a>
</span><span id="ElectraSimpleAttentionHead-1147"><a href="#ElectraSimpleAttentionHead-1147"><span class="linenos">1147</span></a><span class="sd">    This class combines the ElectraSimpleAttention and ElectraSimpleAttentionOutput layers </span>
</span><span id="ElectraSimpleAttentionHead-1148"><a href="#ElectraSimpleAttentionHead-1148"><span class="linenos">1148</span></a><span class="sd">    to produce a final prediction for a sequence, with optional attention probability output.</span>
</span><span id="ElectraSimpleAttentionHead-1149"><a href="#ElectraSimpleAttentionHead-1149"><span class="linenos">1149</span></a>
</span><span id="ElectraSimpleAttentionHead-1150"><a href="#ElectraSimpleAttentionHead-1150"><span class="linenos">1150</span></a><span class="sd">    Attributes</span>
</span><span id="ElectraSimpleAttentionHead-1151"><a href="#ElectraSimpleAttentionHead-1151"><span class="linenos">1151</span></a><span class="sd">    ----------</span>
</span><span id="ElectraSimpleAttentionHead-1152"><a href="#ElectraSimpleAttentionHead-1152"><span class="linenos">1152</span></a><span class="sd">    simple_attention : ElectraSimpleAttention</span>
</span><span id="ElectraSimpleAttentionHead-1153"><a href="#ElectraSimpleAttentionHead-1153"><span class="linenos">1153</span></a><span class="sd">        The simple attention layer.</span>
</span><span id="ElectraSimpleAttentionHead-1154"><a href="#ElectraSimpleAttentionHead-1154"><span class="linenos">1154</span></a><span class="sd">    attention_output : ElectraSimpleAttentionOutput</span>
</span><span id="ElectraSimpleAttentionHead-1155"><a href="#ElectraSimpleAttentionHead-1155"><span class="linenos">1155</span></a><span class="sd">        The output layer that processes and aggregates the attention embeddings.</span>
</span><span id="ElectraSimpleAttentionHead-1156"><a href="#ElectraSimpleAttentionHead-1156"><span class="linenos">1156</span></a>
</span><span id="ElectraSimpleAttentionHead-1157"><a href="#ElectraSimpleAttentionHead-1157"><span class="linenos">1157</span></a><span class="sd">    Methods</span>
</span><span id="ElectraSimpleAttentionHead-1158"><a href="#ElectraSimpleAttentionHead-1158"><span class="linenos">1158</span></a><span class="sd">    -------</span>
</span><span id="ElectraSimpleAttentionHead-1159"><a href="#ElectraSimpleAttentionHead-1159"><span class="linenos">1159</span></a><span class="sd">    forward(sequence_embeddings: torch.Tensor, original_shapes: List[int], return_attention: bool = True) -&gt; Tuple[torch.Tensor, ...]</span>
</span><span id="ElectraSimpleAttentionHead-1160"><a href="#ElectraSimpleAttentionHead-1160"><span class="linenos">1160</span></a><span class="sd">        Performs the forward pass through the attention and output layers.</span>
</span><span id="ElectraSimpleAttentionHead-1161"><a href="#ElectraSimpleAttentionHead-1161"><span class="linenos">1161</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead-1162"><a href="#ElectraSimpleAttentionHead-1162"><span class="linenos">1162</span></a>
</span><span id="ElectraSimpleAttentionHead-1163"><a href="#ElectraSimpleAttentionHead-1163"><span class="linenos">1163</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionHead-1164"><a href="#ElectraSimpleAttentionHead-1164"><span class="linenos">1164</span></a>
</span><span id="ElectraSimpleAttentionHead-1165"><a href="#ElectraSimpleAttentionHead-1165"><span class="linenos">1165</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead-1166"><a href="#ElectraSimpleAttentionHead-1166"><span class="linenos">1166</span></a><span class="sd">        Initializes the ElectraSimpleAttentionHead with the provided configuration.</span>
</span><span id="ElectraSimpleAttentionHead-1167"><a href="#ElectraSimpleAttentionHead-1167"><span class="linenos">1167</span></a>
</span><span id="ElectraSimpleAttentionHead-1168"><a href="#ElectraSimpleAttentionHead-1168"><span class="linenos">1168</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttentionHead-1169"><a href="#ElectraSimpleAttentionHead-1169"><span class="linenos">1169</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttentionHead-1170"><a href="#ElectraSimpleAttentionHead-1170"><span class="linenos">1170</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraSimpleAttentionHead-1171"><a href="#ElectraSimpleAttentionHead-1171"><span class="linenos">1171</span></a><span class="sd">            The configuration object containing the necessary model parameters.</span>
</span><span id="ElectraSimpleAttentionHead-1172"><a href="#ElectraSimpleAttentionHead-1172"><span class="linenos">1172</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead-1173"><a href="#ElectraSimpleAttentionHead-1173"><span class="linenos">1173</span></a>
</span><span id="ElectraSimpleAttentionHead-1174"><a href="#ElectraSimpleAttentionHead-1174"><span class="linenos">1174</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ElectraSimpleAttentionHead-1175"><a href="#ElectraSimpleAttentionHead-1175"><span class="linenos">1175</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">simple_attention</span> <span class="o">=</span> <span class="n">ElectraSimpleAttention</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionHead-1176"><a href="#ElectraSimpleAttentionHead-1176"><span class="linenos">1176</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_output</span> <span class="o">=</span> <span class="n">ElectraSimpleAttentionOutput</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionHead-1177"><a href="#ElectraSimpleAttentionHead-1177"><span class="linenos">1177</span></a>
</span><span id="ElectraSimpleAttentionHead-1178"><a href="#ElectraSimpleAttentionHead-1178"><span class="linenos">1178</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionHead-1179"><a href="#ElectraSimpleAttentionHead-1179"><span class="linenos">1179</span></a>
</span><span id="ElectraSimpleAttentionHead-1180"><a href="#ElectraSimpleAttentionHead-1180"><span class="linenos">1180</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead-1181"><a href="#ElectraSimpleAttentionHead-1181"><span class="linenos">1181</span></a><span class="sd">        Performs the forward pass through the attention and output layers.</span>
</span><span id="ElectraSimpleAttentionHead-1182"><a href="#ElectraSimpleAttentionHead-1182"><span class="linenos">1182</span></a>
</span><span id="ElectraSimpleAttentionHead-1183"><a href="#ElectraSimpleAttentionHead-1183"><span class="linenos">1183</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttentionHead-1184"><a href="#ElectraSimpleAttentionHead-1184"><span class="linenos">1184</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttentionHead-1185"><a href="#ElectraSimpleAttentionHead-1185"><span class="linenos">1185</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="ElectraSimpleAttentionHead-1186"><a href="#ElectraSimpleAttentionHead-1186"><span class="linenos">1186</span></a><span class="sd">            The flattened input sequence embeddings of shape (number of sequences over all batched documents, hidden_size).</span>
</span><span id="ElectraSimpleAttentionHead-1187"><a href="#ElectraSimpleAttentionHead-1187"><span class="linenos">1187</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="ElectraSimpleAttentionHead-1188"><a href="#ElectraSimpleAttentionHead-1188"><span class="linenos">1188</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="ElectraSimpleAttentionHead-1189"><a href="#ElectraSimpleAttentionHead-1189"><span class="linenos">1189</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="ElectraSimpleAttentionHead-1190"><a href="#ElectraSimpleAttentionHead-1190"><span class="linenos">1190</span></a><span class="sd">            If True, returns the attention probabilities along with the logits (default is True).</span>
</span><span id="ElectraSimpleAttentionHead-1191"><a href="#ElectraSimpleAttentionHead-1191"><span class="linenos">1191</span></a>
</span><span id="ElectraSimpleAttentionHead-1192"><a href="#ElectraSimpleAttentionHead-1192"><span class="linenos">1192</span></a><span class="sd">        Returns</span>
</span><span id="ElectraSimpleAttentionHead-1193"><a href="#ElectraSimpleAttentionHead-1193"><span class="linenos">1193</span></a><span class="sd">        -------</span>
</span><span id="ElectraSimpleAttentionHead-1194"><a href="#ElectraSimpleAttentionHead-1194"><span class="linenos">1194</span></a><span class="sd">        Tuple[torch.Tensor, ...]</span>
</span><span id="ElectraSimpleAttentionHead-1195"><a href="#ElectraSimpleAttentionHead-1195"><span class="linenos">1195</span></a><span class="sd">            The logits for each sequence and, optionally, the attention probabilities.</span>
</span><span id="ElectraSimpleAttentionHead-1196"><a href="#ElectraSimpleAttentionHead-1196"><span class="linenos">1196</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead-1197"><a href="#ElectraSimpleAttentionHead-1197"><span class="linenos">1197</span></a>
</span><span id="ElectraSimpleAttentionHead-1198"><a href="#ElectraSimpleAttentionHead-1198"><span class="linenos">1198</span></a>
</span><span id="ElectraSimpleAttentionHead-1199"><a href="#ElectraSimpleAttentionHead-1199"><span class="linenos">1199</span></a>        <span class="c1"># determine simple attention output and attention probabilities (if return_attention is set to True)</span>
</span><span id="ElectraSimpleAttentionHead-1200"><a href="#ElectraSimpleAttentionHead-1200"><span class="linenos">1200</span></a>        <span class="n">simple_attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">simple_attention</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="n">return_attention</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionHead-1201"><a href="#ElectraSimpleAttentionHead-1201"><span class="linenos">1201</span></a>
</span><span id="ElectraSimpleAttentionHead-1202"><a href="#ElectraSimpleAttentionHead-1202"><span class="linenos">1202</span></a>        <span class="c1"># get sequence attention embeddings after simple attention layer</span>
</span><span id="ElectraSimpleAttentionHead-1203"><a href="#ElectraSimpleAttentionHead-1203"><span class="linenos">1203</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="n">simple_attention_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ElectraSimpleAttentionHead-1204"><a href="#ElectraSimpleAttentionHead-1204"><span class="linenos">1204</span></a>
</span><span id="ElectraSimpleAttentionHead-1205"><a href="#ElectraSimpleAttentionHead-1205"><span class="linenos">1205</span></a>        <span class="k">if</span> <span class="n">return_attention</span><span class="p">:</span>
</span><span id="ElectraSimpleAttentionHead-1206"><a href="#ElectraSimpleAttentionHead-1206"><span class="linenos">1206</span></a>            <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">simple_attention_output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ElectraSimpleAttentionHead-1207"><a href="#ElectraSimpleAttentionHead-1207"><span class="linenos">1207</span></a>
</span><span id="ElectraSimpleAttentionHead-1208"><a href="#ElectraSimpleAttentionHead-1208"><span class="linenos">1208</span></a>        <span class="c1"># process sequence attention embeddings through a dense layer and create a residual connection with the original sequence embeddings</span>
</span><span id="ElectraSimpleAttentionHead-1209"><a href="#ElectraSimpleAttentionHead-1209"><span class="linenos">1209</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_output</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionHead-1210"><a href="#ElectraSimpleAttentionHead-1210"><span class="linenos">1210</span></a>        
</span><span id="ElectraSimpleAttentionHead-1211"><a href="#ElectraSimpleAttentionHead-1211"><span class="linenos">1211</span></a>        <span class="c1"># output prediction and optionally the attention probabilities</span>
</span><span id="ElectraSimpleAttentionHead-1212"><a href="#ElectraSimpleAttentionHead-1212"><span class="linenos">1212</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">attention_probs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">logits</span><span class="p">,)</span>
</span><span id="ElectraSimpleAttentionHead-1213"><a href="#ElectraSimpleAttentionHead-1213"><span class="linenos">1213</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


            <div class="docstring"><p>A combination of simple attention and output layers with aggregation.</p>

<p>This class combines the ElectraSimpleAttention and ElectraSimpleAttentionOutput layers 
to produce a final prediction for a sequence, with optional attention probability output.</p>

<h2 id="attributes">Attributes</h2>

<p>simple_attention : ElectraSimpleAttention
    The simple attention layer.
attention_output : ElectraSimpleAttentionOutput
    The output layer that processes and aggregates the attention embeddings.</p>

<h2 id="methods">Methods</h2>

<p>forward(sequence_embeddings: torch.Tensor, original_shapes: List[int], return_attention: bool = True) -> Tuple[torch.Tensor, ...]
    Performs the forward pass through the attention and output layers.</p>
</div>


                            <div id="ElectraSimpleAttentionHead.__init__" class="classattr">
                                        <input id="ElectraSimpleAttentionHead.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ElectraSimpleAttentionHead</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ElectraSimpleAttentionHead.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionHead.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttentionHead.__init__-1163"><a href="#ElectraSimpleAttentionHead.__init__-1163"><span class="linenos">1163</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1164"><a href="#ElectraSimpleAttentionHead.__init__-1164"><span class="linenos">1164</span></a>
</span><span id="ElectraSimpleAttentionHead.__init__-1165"><a href="#ElectraSimpleAttentionHead.__init__-1165"><span class="linenos">1165</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1166"><a href="#ElectraSimpleAttentionHead.__init__-1166"><span class="linenos">1166</span></a><span class="sd">        Initializes the ElectraSimpleAttentionHead with the provided configuration.</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1167"><a href="#ElectraSimpleAttentionHead.__init__-1167"><span class="linenos">1167</span></a>
</span><span id="ElectraSimpleAttentionHead.__init__-1168"><a href="#ElectraSimpleAttentionHead.__init__-1168"><span class="linenos">1168</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1169"><a href="#ElectraSimpleAttentionHead.__init__-1169"><span class="linenos">1169</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1170"><a href="#ElectraSimpleAttentionHead.__init__-1170"><span class="linenos">1170</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1171"><a href="#ElectraSimpleAttentionHead.__init__-1171"><span class="linenos">1171</span></a><span class="sd">            The configuration object containing the necessary model parameters.</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1172"><a href="#ElectraSimpleAttentionHead.__init__-1172"><span class="linenos">1172</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1173"><a href="#ElectraSimpleAttentionHead.__init__-1173"><span class="linenos">1173</span></a>
</span><span id="ElectraSimpleAttentionHead.__init__-1174"><a href="#ElectraSimpleAttentionHead.__init__-1174"><span class="linenos">1174</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1175"><a href="#ElectraSimpleAttentionHead.__init__-1175"><span class="linenos">1175</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">simple_attention</span> <span class="o">=</span> <span class="n">ElectraSimpleAttention</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionHead.__init__-1176"><a href="#ElectraSimpleAttentionHead.__init__-1176"><span class="linenos">1176</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_output</span> <span class="o">=</span> <span class="n">ElectraSimpleAttentionOutput</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the ElectraSimpleAttentionHead with the provided configuration.</p>

<h2 id="parameters">Parameters</h2>

<p>config : ElectraConfig
    The configuration object containing the necessary model parameters.</p>
</div>


                            </div>
                            <div id="ElectraSimpleAttentionHead.simple_attention" class="classattr">
                                <div class="attr variable">
            <span class="name">simple_attention</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionHead.simple_attention"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttentionHead.attention_output" class="classattr">
                                <div class="attr variable">
            <span class="name">attention_output</span>

        
    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionHead.attention_output"></a>
    
    

                            </div>
                            <div id="ElectraSimpleAttentionHead.forward" class="classattr">
                                        <input id="ElectraSimpleAttentionHead.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">sequence_embeddings</span>, </span><span class="param"><span class="n">original_shapes</span>, </span><span class="param"><span class="n">return_attention</span><span class="o">=</span><span class="kc">True</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ElectraSimpleAttentionHead.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraSimpleAttentionHead.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraSimpleAttentionHead.forward-1178"><a href="#ElectraSimpleAttentionHead.forward-1178"><span class="linenos">1178</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="ElectraSimpleAttentionHead.forward-1179"><a href="#ElectraSimpleAttentionHead.forward-1179"><span class="linenos">1179</span></a>
</span><span id="ElectraSimpleAttentionHead.forward-1180"><a href="#ElectraSimpleAttentionHead.forward-1180"><span class="linenos">1180</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead.forward-1181"><a href="#ElectraSimpleAttentionHead.forward-1181"><span class="linenos">1181</span></a><span class="sd">        Performs the forward pass through the attention and output layers.</span>
</span><span id="ElectraSimpleAttentionHead.forward-1182"><a href="#ElectraSimpleAttentionHead.forward-1182"><span class="linenos">1182</span></a>
</span><span id="ElectraSimpleAttentionHead.forward-1183"><a href="#ElectraSimpleAttentionHead.forward-1183"><span class="linenos">1183</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraSimpleAttentionHead.forward-1184"><a href="#ElectraSimpleAttentionHead.forward-1184"><span class="linenos">1184</span></a><span class="sd">        ----------</span>
</span><span id="ElectraSimpleAttentionHead.forward-1185"><a href="#ElectraSimpleAttentionHead.forward-1185"><span class="linenos">1185</span></a><span class="sd">        sequence_embeddings : torch.Tensor</span>
</span><span id="ElectraSimpleAttentionHead.forward-1186"><a href="#ElectraSimpleAttentionHead.forward-1186"><span class="linenos">1186</span></a><span class="sd">            The flattened input sequence embeddings of shape (number of sequences over all batched documents, hidden_size).</span>
</span><span id="ElectraSimpleAttentionHead.forward-1187"><a href="#ElectraSimpleAttentionHead.forward-1187"><span class="linenos">1187</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="ElectraSimpleAttentionHead.forward-1188"><a href="#ElectraSimpleAttentionHead.forward-1188"><span class="linenos">1188</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="ElectraSimpleAttentionHead.forward-1189"><a href="#ElectraSimpleAttentionHead.forward-1189"><span class="linenos">1189</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="ElectraSimpleAttentionHead.forward-1190"><a href="#ElectraSimpleAttentionHead.forward-1190"><span class="linenos">1190</span></a><span class="sd">            If True, returns the attention probabilities along with the logits (default is True).</span>
</span><span id="ElectraSimpleAttentionHead.forward-1191"><a href="#ElectraSimpleAttentionHead.forward-1191"><span class="linenos">1191</span></a>
</span><span id="ElectraSimpleAttentionHead.forward-1192"><a href="#ElectraSimpleAttentionHead.forward-1192"><span class="linenos">1192</span></a><span class="sd">        Returns</span>
</span><span id="ElectraSimpleAttentionHead.forward-1193"><a href="#ElectraSimpleAttentionHead.forward-1193"><span class="linenos">1193</span></a><span class="sd">        -------</span>
</span><span id="ElectraSimpleAttentionHead.forward-1194"><a href="#ElectraSimpleAttentionHead.forward-1194"><span class="linenos">1194</span></a><span class="sd">        Tuple[torch.Tensor, ...]</span>
</span><span id="ElectraSimpleAttentionHead.forward-1195"><a href="#ElectraSimpleAttentionHead.forward-1195"><span class="linenos">1195</span></a><span class="sd">            The logits for each sequence and, optionally, the attention probabilities.</span>
</span><span id="ElectraSimpleAttentionHead.forward-1196"><a href="#ElectraSimpleAttentionHead.forward-1196"><span class="linenos">1196</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraSimpleAttentionHead.forward-1197"><a href="#ElectraSimpleAttentionHead.forward-1197"><span class="linenos">1197</span></a>
</span><span id="ElectraSimpleAttentionHead.forward-1198"><a href="#ElectraSimpleAttentionHead.forward-1198"><span class="linenos">1198</span></a>
</span><span id="ElectraSimpleAttentionHead.forward-1199"><a href="#ElectraSimpleAttentionHead.forward-1199"><span class="linenos">1199</span></a>        <span class="c1"># determine simple attention output and attention probabilities (if return_attention is set to True)</span>
</span><span id="ElectraSimpleAttentionHead.forward-1200"><a href="#ElectraSimpleAttentionHead.forward-1200"><span class="linenos">1200</span></a>        <span class="n">simple_attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">simple_attention</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="n">return_attention</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionHead.forward-1201"><a href="#ElectraSimpleAttentionHead.forward-1201"><span class="linenos">1201</span></a>
</span><span id="ElectraSimpleAttentionHead.forward-1202"><a href="#ElectraSimpleAttentionHead.forward-1202"><span class="linenos">1202</span></a>        <span class="c1"># get sequence attention embeddings after simple attention layer</span>
</span><span id="ElectraSimpleAttentionHead.forward-1203"><a href="#ElectraSimpleAttentionHead.forward-1203"><span class="linenos">1203</span></a>        <span class="n">sequence_attention_embeddings</span> <span class="o">=</span> <span class="n">simple_attention_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ElectraSimpleAttentionHead.forward-1204"><a href="#ElectraSimpleAttentionHead.forward-1204"><span class="linenos">1204</span></a>
</span><span id="ElectraSimpleAttentionHead.forward-1205"><a href="#ElectraSimpleAttentionHead.forward-1205"><span class="linenos">1205</span></a>        <span class="k">if</span> <span class="n">return_attention</span><span class="p">:</span>
</span><span id="ElectraSimpleAttentionHead.forward-1206"><a href="#ElectraSimpleAttentionHead.forward-1206"><span class="linenos">1206</span></a>            <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">simple_attention_output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ElectraSimpleAttentionHead.forward-1207"><a href="#ElectraSimpleAttentionHead.forward-1207"><span class="linenos">1207</span></a>
</span><span id="ElectraSimpleAttentionHead.forward-1208"><a href="#ElectraSimpleAttentionHead.forward-1208"><span class="linenos">1208</span></a>        <span class="c1"># process sequence attention embeddings through a dense layer and create a residual connection with the original sequence embeddings</span>
</span><span id="ElectraSimpleAttentionHead.forward-1209"><a href="#ElectraSimpleAttentionHead.forward-1209"><span class="linenos">1209</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_output</span><span class="p">(</span><span class="n">sequence_attention_embeddings</span><span class="p">,</span> <span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">)</span>
</span><span id="ElectraSimpleAttentionHead.forward-1210"><a href="#ElectraSimpleAttentionHead.forward-1210"><span class="linenos">1210</span></a>        
</span><span id="ElectraSimpleAttentionHead.forward-1211"><a href="#ElectraSimpleAttentionHead.forward-1211"><span class="linenos">1211</span></a>        <span class="c1"># output prediction and optionally the attention probabilities</span>
</span><span id="ElectraSimpleAttentionHead.forward-1212"><a href="#ElectraSimpleAttentionHead.forward-1212"><span class="linenos">1212</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">attention_probs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">logits</span><span class="p">,)</span>
</span><span id="ElectraSimpleAttentionHead.forward-1213"><a href="#ElectraSimpleAttentionHead.forward-1213"><span class="linenos">1213</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


            <div class="docstring"><p>Performs the forward pass through the attention and output layers.</p>

<h2 id="parameters">Parameters</h2>

<p>sequence_embeddings : torch.Tensor
    The flattened input sequence embeddings of shape (number of sequences over all batched documents, hidden_size).
original_shapes : List[int]
    The original shapes of the sequences before flattening.
return_attention : bool, optional
    If True, returns the attention probabilities along with the logits (default is True).</p>

<h2 id="returns">Returns</h2>

<p>Tuple[torch.Tensor, ...]
    The logits for each sequence and, optionally, the attention probabilities.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ElectraSimpleAttentionHead.dump_patches" class="variable">dump_patches</dd>
                <dd id="ElectraSimpleAttentionHead.training" class="variable">training</dd>
                <dd id="ElectraSimpleAttentionHead.call_super_init" class="variable">call_super_init</dd>
                <dd id="ElectraSimpleAttentionHead.register_buffer" class="function">register_buffer</dd>
                <dd id="ElectraSimpleAttentionHead.register_parameter" class="function">register_parameter</dd>
                <dd id="ElectraSimpleAttentionHead.add_module" class="function">add_module</dd>
                <dd id="ElectraSimpleAttentionHead.register_module" class="function">register_module</dd>
                <dd id="ElectraSimpleAttentionHead.get_submodule" class="function">get_submodule</dd>
                <dd id="ElectraSimpleAttentionHead.get_parameter" class="function">get_parameter</dd>
                <dd id="ElectraSimpleAttentionHead.get_buffer" class="function">get_buffer</dd>
                <dd id="ElectraSimpleAttentionHead.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ElectraSimpleAttentionHead.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ElectraSimpleAttentionHead.apply" class="function">apply</dd>
                <dd id="ElectraSimpleAttentionHead.cuda" class="function">cuda</dd>
                <dd id="ElectraSimpleAttentionHead.ipu" class="function">ipu</dd>
                <dd id="ElectraSimpleAttentionHead.xpu" class="function">xpu</dd>
                <dd id="ElectraSimpleAttentionHead.cpu" class="function">cpu</dd>
                <dd id="ElectraSimpleAttentionHead.type" class="function">type</dd>
                <dd id="ElectraSimpleAttentionHead.float" class="function">float</dd>
                <dd id="ElectraSimpleAttentionHead.double" class="function">double</dd>
                <dd id="ElectraSimpleAttentionHead.half" class="function">half</dd>
                <dd id="ElectraSimpleAttentionHead.bfloat16" class="function">bfloat16</dd>
                <dd id="ElectraSimpleAttentionHead.to_empty" class="function">to_empty</dd>
                <dd id="ElectraSimpleAttentionHead.to" class="function">to</dd>
                <dd id="ElectraSimpleAttentionHead.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ElectraSimpleAttentionHead.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ElectraSimpleAttentionHead.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ElectraSimpleAttentionHead.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ElectraSimpleAttentionHead.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ElectraSimpleAttentionHead.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ElectraSimpleAttentionHead.state_dict" class="function">state_dict</dd>
                <dd id="ElectraSimpleAttentionHead.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ElectraSimpleAttentionHead.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ElectraSimpleAttentionHead.parameters" class="function">parameters</dd>
                <dd id="ElectraSimpleAttentionHead.named_parameters" class="function">named_parameters</dd>
                <dd id="ElectraSimpleAttentionHead.buffers" class="function">buffers</dd>
                <dd id="ElectraSimpleAttentionHead.named_buffers" class="function">named_buffers</dd>
                <dd id="ElectraSimpleAttentionHead.children" class="function">children</dd>
                <dd id="ElectraSimpleAttentionHead.named_children" class="function">named_children</dd>
                <dd id="ElectraSimpleAttentionHead.modules" class="function">modules</dd>
                <dd id="ElectraSimpleAttentionHead.named_modules" class="function">named_modules</dd>
                <dd id="ElectraSimpleAttentionHead.train" class="function">train</dd>
                <dd id="ElectraSimpleAttentionHead.eval" class="function">eval</dd>
                <dd id="ElectraSimpleAttentionHead.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ElectraSimpleAttentionHead.zero_grad" class="function">zero_grad</dd>
                <dd id="ElectraSimpleAttentionHead.share_memory" class="function">share_memory</dd>
                <dd id="ElectraSimpleAttentionHead.extra_repr" class="function">extra_repr</dd>
                <dd id="ElectraSimpleAttentionHead.compile" class="function">compile</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ElectraForAggregatePredictionWithAttention">
                            <input id="ElectraForAggregatePredictionWithAttention-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ElectraForAggregatePredictionWithAttention</span><wbr>(<span class="base">transformers.models.electra.modeling_electra.ElectraPreTrainedModel</span>):

                <label class="view-source-button" for="ElectraForAggregatePredictionWithAttention-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraForAggregatePredictionWithAttention"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraForAggregatePredictionWithAttention-1216"><a href="#ElectraForAggregatePredictionWithAttention-1216"><span class="linenos">1216</span></a><span class="k">class</span> <span class="nc">ElectraForAggregatePredictionWithAttention</span><span class="p">(</span><span class="n">ElectraPreTrainedModel</span><span class="p">):</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1217"><a href="#ElectraForAggregatePredictionWithAttention-1217"><span class="linenos">1217</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1218"><a href="#ElectraForAggregatePredictionWithAttention-1218"><span class="linenos">1218</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1219"><a href="#ElectraForAggregatePredictionWithAttention-1219"><span class="linenos">1219</span></a><span class="sd">    An Electra model with aggregate prediction using attention mechanisms.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1220"><a href="#ElectraForAggregatePredictionWithAttention-1220"><span class="linenos">1220</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1221"><a href="#ElectraForAggregatePredictionWithAttention-1221"><span class="linenos">1221</span></a><span class="sd">    This class extends the Electra model by adding a custom head for aggregate prediction.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1222"><a href="#ElectraForAggregatePredictionWithAttention-1222"><span class="linenos">1222</span></a><span class="sd">    It combines token embeddings into sequence embeddings, applies attention, and makes </span>
</span><span id="ElectraForAggregatePredictionWithAttention-1223"><a href="#ElectraForAggregatePredictionWithAttention-1223"><span class="linenos">1223</span></a><span class="sd">    predictions for entire documents which consist of sequences.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1224"><a href="#ElectraForAggregatePredictionWithAttention-1224"><span class="linenos">1224</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1225"><a href="#ElectraForAggregatePredictionWithAttention-1225"><span class="linenos">1225</span></a><span class="sd">    Attributes</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1226"><a href="#ElectraForAggregatePredictionWithAttention-1226"><span class="linenos">1226</span></a><span class="sd">    ----------</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1227"><a href="#ElectraForAggregatePredictionWithAttention-1227"><span class="linenos">1227</span></a><span class="sd">    config : ElectraConfig</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1228"><a href="#ElectraForAggregatePredictionWithAttention-1228"><span class="linenos">1228</span></a><span class="sd">        The configuration object for the Electra model.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1229"><a href="#ElectraForAggregatePredictionWithAttention-1229"><span class="linenos">1229</span></a><span class="sd">    num_labels : int</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1230"><a href="#ElectraForAggregatePredictionWithAttention-1230"><span class="linenos">1230</span></a><span class="sd">        The number of labels for classification tasks.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1231"><a href="#ElectraForAggregatePredictionWithAttention-1231"><span class="linenos">1231</span></a><span class="sd">    electra : ElectraModel</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1232"><a href="#ElectraForAggregatePredictionWithAttention-1232"><span class="linenos">1232</span></a><span class="sd">        The Electra encoder model for generating token embeddings.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1233"><a href="#ElectraForAggregatePredictionWithAttention-1233"><span class="linenos">1233</span></a><span class="sd">    head : ElectraSimpleAttentionHead</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1234"><a href="#ElectraForAggregatePredictionWithAttention-1234"><span class="linenos">1234</span></a><span class="sd">        The custom head for making aggregate predictions with attention.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1235"><a href="#ElectraForAggregatePredictionWithAttention-1235"><span class="linenos">1235</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1236"><a href="#ElectraForAggregatePredictionWithAttention-1236"><span class="linenos">1236</span></a><span class="sd">    Methods</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1237"><a href="#ElectraForAggregatePredictionWithAttention-1237"><span class="linenos">1237</span></a><span class="sd">    -------</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1238"><a href="#ElectraForAggregatePredictionWithAttention-1238"><span class="linenos">1238</span></a><span class="sd">    forward(input_ids: List[List[Tensor]], attention_mask: List[List[Tensor]], labels: Optional[torch.Tensor] = None, return_attention: bool = True) -&gt; Any</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1239"><a href="#ElectraForAggregatePredictionWithAttention-1239"><span class="linenos">1239</span></a><span class="sd">        Performs the forward pass, generating sequence embeddings and making predictions.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1240"><a href="#ElectraForAggregatePredictionWithAttention-1240"><span class="linenos">1240</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1241"><a href="#ElectraForAggregatePredictionWithAttention-1241"><span class="linenos">1241</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1242"><a href="#ElectraForAggregatePredictionWithAttention-1242"><span class="linenos">1242</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1243"><a href="#ElectraForAggregatePredictionWithAttention-1243"><span class="linenos">1243</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1244"><a href="#ElectraForAggregatePredictionWithAttention-1244"><span class="linenos">1244</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1245"><a href="#ElectraForAggregatePredictionWithAttention-1245"><span class="linenos">1245</span></a><span class="sd">        Initializes the ElectraForAggregatePredictionWithAttention model.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1246"><a href="#ElectraForAggregatePredictionWithAttention-1246"><span class="linenos">1246</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1247"><a href="#ElectraForAggregatePredictionWithAttention-1247"><span class="linenos">1247</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1248"><a href="#ElectraForAggregatePredictionWithAttention-1248"><span class="linenos">1248</span></a><span class="sd">        ----------</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1249"><a href="#ElectraForAggregatePredictionWithAttention-1249"><span class="linenos">1249</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1250"><a href="#ElectraForAggregatePredictionWithAttention-1250"><span class="linenos">1250</span></a><span class="sd">            The configuration object for the Electra model.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1251"><a href="#ElectraForAggregatePredictionWithAttention-1251"><span class="linenos">1251</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1252"><a href="#ElectraForAggregatePredictionWithAttention-1252"><span class="linenos">1252</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1253"><a href="#ElectraForAggregatePredictionWithAttention-1253"><span class="linenos">1253</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1254"><a href="#ElectraForAggregatePredictionWithAttention-1254"><span class="linenos">1254</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1255"><a href="#ElectraForAggregatePredictionWithAttention-1255"><span class="linenos">1255</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1256"><a href="#ElectraForAggregatePredictionWithAttention-1256"><span class="linenos">1256</span></a>        <span class="c1"># the encoder for creating token embeddings</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1257"><a href="#ElectraForAggregatePredictionWithAttention-1257"><span class="linenos">1257</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">electra</span> <span class="o">=</span> <span class="n">ElectraModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1258"><a href="#ElectraForAggregatePredictionWithAttention-1258"><span class="linenos">1258</span></a>        <span class="c1"># the head for creating a single prediction for a batch of embeddings, in our case a batch of sequence embeddings</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1259"><a href="#ElectraForAggregatePredictionWithAttention-1259"><span class="linenos">1259</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">ElectraSimpleAttentionHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1260"><a href="#ElectraForAggregatePredictionWithAttention-1260"><span class="linenos">1260</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1261"><a href="#ElectraForAggregatePredictionWithAttention-1261"><span class="linenos">1261</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1262"><a href="#ElectraForAggregatePredictionWithAttention-1262"><span class="linenos">1262</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1263"><a href="#ElectraForAggregatePredictionWithAttention-1263"><span class="linenos">1263</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1264"><a href="#ElectraForAggregatePredictionWithAttention-1264"><span class="linenos">1264</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="ElectraForAggregatePredictionWithAttention-1265"><a href="#ElectraForAggregatePredictionWithAttention-1265"><span class="linenos">1265</span></a>        <span class="n">input_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1266"><a href="#ElectraForAggregatePredictionWithAttention-1266"><span class="linenos">1266</span></a>        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1267"><a href="#ElectraForAggregatePredictionWithAttention-1267"><span class="linenos">1267</span></a>        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1268"><a href="#ElectraForAggregatePredictionWithAttention-1268"><span class="linenos">1268</span></a>        <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1269"><a href="#ElectraForAggregatePredictionWithAttention-1269"><span class="linenos">1269</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1270"><a href="#ElectraForAggregatePredictionWithAttention-1270"><span class="linenos">1270</span></a><span class="w">        </span>
</span><span id="ElectraForAggregatePredictionWithAttention-1271"><a href="#ElectraForAggregatePredictionWithAttention-1271"><span class="linenos">1271</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1272"><a href="#ElectraForAggregatePredictionWithAttention-1272"><span class="linenos">1272</span></a><span class="sd">        Performs the forward pass of the Electra model with aggregate prediction.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1273"><a href="#ElectraForAggregatePredictionWithAttention-1273"><span class="linenos">1273</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1274"><a href="#ElectraForAggregatePredictionWithAttention-1274"><span class="linenos">1274</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1275"><a href="#ElectraForAggregatePredictionWithAttention-1275"><span class="linenos">1275</span></a><span class="sd">        ----------</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1276"><a href="#ElectraForAggregatePredictionWithAttention-1276"><span class="linenos">1276</span></a><span class="sd">        input_ids : List[List[Tensor]]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1277"><a href="#ElectraForAggregatePredictionWithAttention-1277"><span class="linenos">1277</span></a><span class="sd">            A batch of input token IDs.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1278"><a href="#ElectraForAggregatePredictionWithAttention-1278"><span class="linenos">1278</span></a><span class="sd">        attention_mask : List[List[Tensor]]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1279"><a href="#ElectraForAggregatePredictionWithAttention-1279"><span class="linenos">1279</span></a><span class="sd">            A batch of attention masks corresponding to the input IDs.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1280"><a href="#ElectraForAggregatePredictionWithAttention-1280"><span class="linenos">1280</span></a><span class="sd">        labels : Optional[torch.Tensor], optional</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1281"><a href="#ElectraForAggregatePredictionWithAttention-1281"><span class="linenos">1281</span></a><span class="sd">            Ground truth labels for the input sequences (default is None).</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1282"><a href="#ElectraForAggregatePredictionWithAttention-1282"><span class="linenos">1282</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1283"><a href="#ElectraForAggregatePredictionWithAttention-1283"><span class="linenos">1283</span></a><span class="sd">            If True, returns attention probabilities along with the logits (default is True).</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1284"><a href="#ElectraForAggregatePredictionWithAttention-1284"><span class="linenos">1284</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1285"><a href="#ElectraForAggregatePredictionWithAttention-1285"><span class="linenos">1285</span></a><span class="sd">        Returns</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1286"><a href="#ElectraForAggregatePredictionWithAttention-1286"><span class="linenos">1286</span></a><span class="sd">        -------</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1287"><a href="#ElectraForAggregatePredictionWithAttention-1287"><span class="linenos">1287</span></a><span class="sd">        Any</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1288"><a href="#ElectraForAggregatePredictionWithAttention-1288"><span class="linenos">1288</span></a><span class="sd">            The loss (if labels are provided), logits, and optionally the attention probabilities.</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1289"><a href="#ElectraForAggregatePredictionWithAttention-1289"><span class="linenos">1289</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1290"><a href="#ElectraForAggregatePredictionWithAttention-1290"><span class="linenos">1290</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1291"><a href="#ElectraForAggregatePredictionWithAttention-1291"><span class="linenos">1291</span></a>       
</span><span id="ElectraForAggregatePredictionWithAttention-1292"><a href="#ElectraForAggregatePredictionWithAttention-1292"><span class="linenos">1292</span></a>        <span class="n">input_id_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_input_ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_input_ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1293"><a href="#ElectraForAggregatePredictionWithAttention-1293"><span class="linenos">1293</span></a>        <span class="n">attention_mask_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_attention_mask</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_attention_mask</span> <span class="ow">in</span> <span class="n">attention_mask</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1294"><a href="#ElectraForAggregatePredictionWithAttention-1294"><span class="linenos">1294</span></a>        <span class="c1"># Store the original shapes</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1295"><a href="#ElectraForAggregatePredictionWithAttention-1295"><span class="linenos">1295</span></a>        <span class="n">original_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_ids_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">input_ids_tensor</span> <span class="ow">in</span> <span class="n">input_id_tensors</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1296"><a href="#ElectraForAggregatePredictionWithAttention-1296"><span class="linenos">1296</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1297"><a href="#ElectraForAggregatePredictionWithAttention-1297"><span class="linenos">1297</span></a>        <span class="c1"># Step 2: Concatenate the tensors along the first dimension</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1298"><a href="#ElectraForAggregatePredictionWithAttention-1298"><span class="linenos">1298</span></a>        <span class="n">flattened_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_id_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1299"><a href="#ElectraForAggregatePredictionWithAttention-1299"><span class="linenos">1299</span></a>        <span class="n">flattened_attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attention_mask_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1300"><a href="#ElectraForAggregatePredictionWithAttention-1300"><span class="linenos">1300</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1301"><a href="#ElectraForAggregatePredictionWithAttention-1301"><span class="linenos">1301</span></a>        <span class="n">discriminator_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">electra</span><span class="p">(</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1302"><a href="#ElectraForAggregatePredictionWithAttention-1302"><span class="linenos">1302</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">flattened_input_ids</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1303"><a href="#ElectraForAggregatePredictionWithAttention-1303"><span class="linenos">1303</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">flattened_attention_mask</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1304"><a href="#ElectraForAggregatePredictionWithAttention-1304"><span class="linenos">1304</span></a>        <span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1305"><a href="#ElectraForAggregatePredictionWithAttention-1305"><span class="linenos">1305</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1306"><a href="#ElectraForAggregatePredictionWithAttention-1306"><span class="linenos">1306</span></a>        <span class="c1"># collect all token embeddings </span>
</span><span id="ElectraForAggregatePredictionWithAttention-1307"><a href="#ElectraForAggregatePredictionWithAttention-1307"><span class="linenos">1307</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">discriminator_hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1308"><a href="#ElectraForAggregatePredictionWithAttention-1308"><span class="linenos">1308</span></a>        <span class="c1"># collect the sequence embeddings, only assuming the first token is a seq token</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1309"><a href="#ElectraForAggregatePredictionWithAttention-1309"><span class="linenos">1309</span></a>        <span class="n">sequence_embeddings</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1310"><a href="#ElectraForAggregatePredictionWithAttention-1310"><span class="linenos">1310</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1311"><a href="#ElectraForAggregatePredictionWithAttention-1311"><span class="linenos">1311</span></a>        <span class="c1"># logits is the real valued prediction</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1312"><a href="#ElectraForAggregatePredictionWithAttention-1312"><span class="linenos">1312</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="n">return_attention</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1313"><a href="#ElectraForAggregatePredictionWithAttention-1313"><span class="linenos">1313</span></a>    
</span><span id="ElectraForAggregatePredictionWithAttention-1314"><a href="#ElectraForAggregatePredictionWithAttention-1314"><span class="linenos">1314</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1315"><a href="#ElectraForAggregatePredictionWithAttention-1315"><span class="linenos">1315</span></a>    
</span><span id="ElectraForAggregatePredictionWithAttention-1316"><a href="#ElectraForAggregatePredictionWithAttention-1316"><span class="linenos">1316</span></a>        <span class="k">if</span> <span class="n">return_attention</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1317"><a href="#ElectraForAggregatePredictionWithAttention-1317"><span class="linenos">1317</span></a>            <span class="n">attention_probabilities</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1318"><a href="#ElectraForAggregatePredictionWithAttention-1318"><span class="linenos">1318</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1319"><a href="#ElectraForAggregatePredictionWithAttention-1319"><span class="linenos">1319</span></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1320"><a href="#ElectraForAggregatePredictionWithAttention-1320"><span class="linenos">1320</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1321"><a href="#ElectraForAggregatePredictionWithAttention-1321"><span class="linenos">1321</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1322"><a href="#ElectraForAggregatePredictionWithAttention-1322"><span class="linenos">1322</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1323"><a href="#ElectraForAggregatePredictionWithAttention-1323"><span class="linenos">1323</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;regression&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1324"><a href="#ElectraForAggregatePredictionWithAttention-1324"><span class="linenos">1324</span></a>                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span> <span class="ow">or</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">):</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1325"><a href="#ElectraForAggregatePredictionWithAttention-1325"><span class="linenos">1325</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;single_label_classification&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1326"><a href="#ElectraForAggregatePredictionWithAttention-1326"><span class="linenos">1326</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1327"><a href="#ElectraForAggregatePredictionWithAttention-1327"><span class="linenos">1327</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1328"><a href="#ElectraForAggregatePredictionWithAttention-1328"><span class="linenos">1328</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1329"><a href="#ElectraForAggregatePredictionWithAttention-1329"><span class="linenos">1329</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1330"><a href="#ElectraForAggregatePredictionWithAttention-1330"><span class="linenos">1330</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1331"><a href="#ElectraForAggregatePredictionWithAttention-1331"><span class="linenos">1331</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1332"><a href="#ElectraForAggregatePredictionWithAttention-1332"><span class="linenos">1332</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1333"><a href="#ElectraForAggregatePredictionWithAttention-1333"><span class="linenos">1333</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1334"><a href="#ElectraForAggregatePredictionWithAttention-1334"><span class="linenos">1334</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1335"><a href="#ElectraForAggregatePredictionWithAttention-1335"><span class="linenos">1335</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;single_label_classification&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1336"><a href="#ElectraForAggregatePredictionWithAttention-1336"><span class="linenos">1336</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1337"><a href="#ElectraForAggregatePredictionWithAttention-1337"><span class="linenos">1337</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1338"><a href="#ElectraForAggregatePredictionWithAttention-1338"><span class="linenos">1338</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;multi_label_classification&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1339"><a href="#ElectraForAggregatePredictionWithAttention-1339"><span class="linenos">1339</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1340"><a href="#ElectraForAggregatePredictionWithAttention-1340"><span class="linenos">1340</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1341"><a href="#ElectraForAggregatePredictionWithAttention-1341"><span class="linenos">1341</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1342"><a href="#ElectraForAggregatePredictionWithAttention-1342"><span class="linenos">1342</span></a>        <span class="n">full_output</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">attention_probabilities</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention-1343"><a href="#ElectraForAggregatePredictionWithAttention-1343"><span class="linenos">1343</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention-1344"><a href="#ElectraForAggregatePredictionWithAttention-1344"><span class="linenos">1344</span></a>        <span class="k">return</span> <span class="n">full_output</span>
</span></pre></div>


            <div class="docstring"><p>An Electra model with aggregate prediction using attention mechanisms.</p>

<p>This class extends the Electra model by adding a custom head for aggregate prediction.
It combines token embeddings into sequence embeddings, applies attention, and makes 
predictions for entire documents which consist of sequences.</p>

<h2 id="attributes">Attributes</h2>

<p>config : ElectraConfig
    The configuration object for the Electra model.
num_labels : int
    The number of labels for classification tasks.
electra : ElectraModel
    The Electra encoder model for generating token embeddings.
head : ElectraSimpleAttentionHead
    The custom head for making aggregate predictions with attention.</p>

<h2 id="methods">Methods</h2>

<p>forward(input_ids: List[List[Tensor]], attention_mask: List[List[Tensor]], labels: Optional[torch.Tensor] = None, return_attention: bool = True) -> Any
    Performs the forward pass, generating sequence embeddings and making predictions.</p>
</div>


                            <div id="ElectraForAggregatePredictionWithAttention.__init__" class="classattr">
                                        <input id="ElectraForAggregatePredictionWithAttention.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ElectraForAggregatePredictionWithAttention</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ElectraForAggregatePredictionWithAttention.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraForAggregatePredictionWithAttention.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraForAggregatePredictionWithAttention.__init__-1242"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1242"><span class="linenos">1242</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1243"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1243"><span class="linenos">1243</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1244"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1244"><span class="linenos">1244</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1245"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1245"><span class="linenos">1245</span></a><span class="sd">        Initializes the ElectraForAggregatePredictionWithAttention model.</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1246"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1246"><span class="linenos">1246</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1247"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1247"><span class="linenos">1247</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1248"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1248"><span class="linenos">1248</span></a><span class="sd">        ----------</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1249"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1249"><span class="linenos">1249</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1250"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1250"><span class="linenos">1250</span></a><span class="sd">            The configuration object for the Electra model.</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1251"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1251"><span class="linenos">1251</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1252"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1252"><span class="linenos">1252</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1253"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1253"><span class="linenos">1253</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1254"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1254"><span class="linenos">1254</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1255"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1255"><span class="linenos">1255</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1256"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1256"><span class="linenos">1256</span></a>        <span class="c1"># the encoder for creating token embeddings</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1257"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1257"><span class="linenos">1257</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">electra</span> <span class="o">=</span> <span class="n">ElectraModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1258"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1258"><span class="linenos">1258</span></a>        <span class="c1"># the head for creating a single prediction for a batch of embeddings, in our case a batch of sequence embeddings</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1259"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1259"><span class="linenos">1259</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">ElectraSimpleAttentionHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1260"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1260"><span class="linenos">1260</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.__init__-1261"><a href="#ElectraForAggregatePredictionWithAttention.__init__-1261"><span class="linenos">1261</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the ElectraForAggregatePredictionWithAttention model.</p>

<h2 id="parameters">Parameters</h2>

<p>config : ElectraConfig
    The configuration object for the Electra model.</p>
</div>


                            </div>
                            <div id="ElectraForAggregatePredictionWithAttention.config" class="classattr">
                                <div class="attr variable">
            <span class="name">config</span>

        
    </div>
    <a class="headerlink" href="#ElectraForAggregatePredictionWithAttention.config"></a>
    
    

                            </div>
                            <div id="ElectraForAggregatePredictionWithAttention.num_labels" class="classattr">
                                <div class="attr variable">
            <span class="name">num_labels</span>

        
    </div>
    <a class="headerlink" href="#ElectraForAggregatePredictionWithAttention.num_labels"></a>
    
    

                            </div>
                            <div id="ElectraForAggregatePredictionWithAttention.electra" class="classattr">
                                <div class="attr variable">
            <span class="name">electra</span>

        
    </div>
    <a class="headerlink" href="#ElectraForAggregatePredictionWithAttention.electra"></a>
    
    

                            </div>
                            <div id="ElectraForAggregatePredictionWithAttention.head" class="classattr">
                                <div class="attr variable">
            <span class="name">head</span>

        
    </div>
    <a class="headerlink" href="#ElectraForAggregatePredictionWithAttention.head"></a>
    
    

                            </div>
                            <div id="ElectraForAggregatePredictionWithAttention.forward" class="classattr">
                                        <input id="ElectraForAggregatePredictionWithAttention.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">return_attention</span><span class="o">=</span><span class="kc">True</span></span><span class="return-annotation">) -> <span class="n">Any</span>:</span></span>

                <label class="view-source-button" for="ElectraForAggregatePredictionWithAttention.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraForAggregatePredictionWithAttention.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraForAggregatePredictionWithAttention.forward-1263"><a href="#ElectraForAggregatePredictionWithAttention.forward-1263"><span class="linenos">1263</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1264"><a href="#ElectraForAggregatePredictionWithAttention.forward-1264"><span class="linenos">1264</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1265"><a href="#ElectraForAggregatePredictionWithAttention.forward-1265"><span class="linenos">1265</span></a>        <span class="n">input_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1266"><a href="#ElectraForAggregatePredictionWithAttention.forward-1266"><span class="linenos">1266</span></a>        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1267"><a href="#ElectraForAggregatePredictionWithAttention.forward-1267"><span class="linenos">1267</span></a>        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1268"><a href="#ElectraForAggregatePredictionWithAttention.forward-1268"><span class="linenos">1268</span></a>        <span class="n">return_attention</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1269"><a href="#ElectraForAggregatePredictionWithAttention.forward-1269"><span class="linenos">1269</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1270"><a href="#ElectraForAggregatePredictionWithAttention.forward-1270"><span class="linenos">1270</span></a><span class="w">        </span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1271"><a href="#ElectraForAggregatePredictionWithAttention.forward-1271"><span class="linenos">1271</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1272"><a href="#ElectraForAggregatePredictionWithAttention.forward-1272"><span class="linenos">1272</span></a><span class="sd">        Performs the forward pass of the Electra model with aggregate prediction.</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1273"><a href="#ElectraForAggregatePredictionWithAttention.forward-1273"><span class="linenos">1273</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1274"><a href="#ElectraForAggregatePredictionWithAttention.forward-1274"><span class="linenos">1274</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1275"><a href="#ElectraForAggregatePredictionWithAttention.forward-1275"><span class="linenos">1275</span></a><span class="sd">        ----------</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1276"><a href="#ElectraForAggregatePredictionWithAttention.forward-1276"><span class="linenos">1276</span></a><span class="sd">        input_ids : List[List[Tensor]]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1277"><a href="#ElectraForAggregatePredictionWithAttention.forward-1277"><span class="linenos">1277</span></a><span class="sd">            A batch of input token IDs.</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1278"><a href="#ElectraForAggregatePredictionWithAttention.forward-1278"><span class="linenos">1278</span></a><span class="sd">        attention_mask : List[List[Tensor]]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1279"><a href="#ElectraForAggregatePredictionWithAttention.forward-1279"><span class="linenos">1279</span></a><span class="sd">            A batch of attention masks corresponding to the input IDs.</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1280"><a href="#ElectraForAggregatePredictionWithAttention.forward-1280"><span class="linenos">1280</span></a><span class="sd">        labels : Optional[torch.Tensor], optional</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1281"><a href="#ElectraForAggregatePredictionWithAttention.forward-1281"><span class="linenos">1281</span></a><span class="sd">            Ground truth labels for the input sequences (default is None).</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1282"><a href="#ElectraForAggregatePredictionWithAttention.forward-1282"><span class="linenos">1282</span></a><span class="sd">        return_attention : bool, optional</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1283"><a href="#ElectraForAggregatePredictionWithAttention.forward-1283"><span class="linenos">1283</span></a><span class="sd">            If True, returns attention probabilities along with the logits (default is True).</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1284"><a href="#ElectraForAggregatePredictionWithAttention.forward-1284"><span class="linenos">1284</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1285"><a href="#ElectraForAggregatePredictionWithAttention.forward-1285"><span class="linenos">1285</span></a><span class="sd">        Returns</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1286"><a href="#ElectraForAggregatePredictionWithAttention.forward-1286"><span class="linenos">1286</span></a><span class="sd">        -------</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1287"><a href="#ElectraForAggregatePredictionWithAttention.forward-1287"><span class="linenos">1287</span></a><span class="sd">        Any</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1288"><a href="#ElectraForAggregatePredictionWithAttention.forward-1288"><span class="linenos">1288</span></a><span class="sd">            The loss (if labels are provided), logits, and optionally the attention probabilities.</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1289"><a href="#ElectraForAggregatePredictionWithAttention.forward-1289"><span class="linenos">1289</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1290"><a href="#ElectraForAggregatePredictionWithAttention.forward-1290"><span class="linenos">1290</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1291"><a href="#ElectraForAggregatePredictionWithAttention.forward-1291"><span class="linenos">1291</span></a>       
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1292"><a href="#ElectraForAggregatePredictionWithAttention.forward-1292"><span class="linenos">1292</span></a>        <span class="n">input_id_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_input_ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_input_ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1293"><a href="#ElectraForAggregatePredictionWithAttention.forward-1293"><span class="linenos">1293</span></a>        <span class="n">attention_mask_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_attention_mask</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_attention_mask</span> <span class="ow">in</span> <span class="n">attention_mask</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1294"><a href="#ElectraForAggregatePredictionWithAttention.forward-1294"><span class="linenos">1294</span></a>        <span class="c1"># Store the original shapes</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1295"><a href="#ElectraForAggregatePredictionWithAttention.forward-1295"><span class="linenos">1295</span></a>        <span class="n">original_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_ids_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">input_ids_tensor</span> <span class="ow">in</span> <span class="n">input_id_tensors</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1296"><a href="#ElectraForAggregatePredictionWithAttention.forward-1296"><span class="linenos">1296</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1297"><a href="#ElectraForAggregatePredictionWithAttention.forward-1297"><span class="linenos">1297</span></a>        <span class="c1"># Step 2: Concatenate the tensors along the first dimension</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1298"><a href="#ElectraForAggregatePredictionWithAttention.forward-1298"><span class="linenos">1298</span></a>        <span class="n">flattened_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_id_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1299"><a href="#ElectraForAggregatePredictionWithAttention.forward-1299"><span class="linenos">1299</span></a>        <span class="n">flattened_attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attention_mask_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1300"><a href="#ElectraForAggregatePredictionWithAttention.forward-1300"><span class="linenos">1300</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1301"><a href="#ElectraForAggregatePredictionWithAttention.forward-1301"><span class="linenos">1301</span></a>        <span class="n">discriminator_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">electra</span><span class="p">(</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1302"><a href="#ElectraForAggregatePredictionWithAttention.forward-1302"><span class="linenos">1302</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">flattened_input_ids</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1303"><a href="#ElectraForAggregatePredictionWithAttention.forward-1303"><span class="linenos">1303</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">flattened_attention_mask</span><span class="p">,</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1304"><a href="#ElectraForAggregatePredictionWithAttention.forward-1304"><span class="linenos">1304</span></a>        <span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1305"><a href="#ElectraForAggregatePredictionWithAttention.forward-1305"><span class="linenos">1305</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1306"><a href="#ElectraForAggregatePredictionWithAttention.forward-1306"><span class="linenos">1306</span></a>        <span class="c1"># collect all token embeddings </span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1307"><a href="#ElectraForAggregatePredictionWithAttention.forward-1307"><span class="linenos">1307</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">discriminator_hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1308"><a href="#ElectraForAggregatePredictionWithAttention.forward-1308"><span class="linenos">1308</span></a>        <span class="c1"># collect the sequence embeddings, only assuming the first token is a seq token</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1309"><a href="#ElectraForAggregatePredictionWithAttention.forward-1309"><span class="linenos">1309</span></a>        <span class="n">sequence_embeddings</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1310"><a href="#ElectraForAggregatePredictionWithAttention.forward-1310"><span class="linenos">1310</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1311"><a href="#ElectraForAggregatePredictionWithAttention.forward-1311"><span class="linenos">1311</span></a>        <span class="c1"># logits is the real valued prediction</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1312"><a href="#ElectraForAggregatePredictionWithAttention.forward-1312"><span class="linenos">1312</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">return_attention</span> <span class="o">=</span> <span class="n">return_attention</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1313"><a href="#ElectraForAggregatePredictionWithAttention.forward-1313"><span class="linenos">1313</span></a>    
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1314"><a href="#ElectraForAggregatePredictionWithAttention.forward-1314"><span class="linenos">1314</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1315"><a href="#ElectraForAggregatePredictionWithAttention.forward-1315"><span class="linenos">1315</span></a>    
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1316"><a href="#ElectraForAggregatePredictionWithAttention.forward-1316"><span class="linenos">1316</span></a>        <span class="k">if</span> <span class="n">return_attention</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1317"><a href="#ElectraForAggregatePredictionWithAttention.forward-1317"><span class="linenos">1317</span></a>            <span class="n">attention_probabilities</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1318"><a href="#ElectraForAggregatePredictionWithAttention.forward-1318"><span class="linenos">1318</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1319"><a href="#ElectraForAggregatePredictionWithAttention.forward-1319"><span class="linenos">1319</span></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1320"><a href="#ElectraForAggregatePredictionWithAttention.forward-1320"><span class="linenos">1320</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1321"><a href="#ElectraForAggregatePredictionWithAttention.forward-1321"><span class="linenos">1321</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1322"><a href="#ElectraForAggregatePredictionWithAttention.forward-1322"><span class="linenos">1322</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1323"><a href="#ElectraForAggregatePredictionWithAttention.forward-1323"><span class="linenos">1323</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;regression&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1324"><a href="#ElectraForAggregatePredictionWithAttention.forward-1324"><span class="linenos">1324</span></a>                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span> <span class="ow">or</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">):</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1325"><a href="#ElectraForAggregatePredictionWithAttention.forward-1325"><span class="linenos">1325</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;single_label_classification&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1326"><a href="#ElectraForAggregatePredictionWithAttention.forward-1326"><span class="linenos">1326</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1327"><a href="#ElectraForAggregatePredictionWithAttention.forward-1327"><span class="linenos">1327</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1328"><a href="#ElectraForAggregatePredictionWithAttention.forward-1328"><span class="linenos">1328</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1329"><a href="#ElectraForAggregatePredictionWithAttention.forward-1329"><span class="linenos">1329</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1330"><a href="#ElectraForAggregatePredictionWithAttention.forward-1330"><span class="linenos">1330</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1331"><a href="#ElectraForAggregatePredictionWithAttention.forward-1331"><span class="linenos">1331</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1332"><a href="#ElectraForAggregatePredictionWithAttention.forward-1332"><span class="linenos">1332</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1333"><a href="#ElectraForAggregatePredictionWithAttention.forward-1333"><span class="linenos">1333</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1334"><a href="#ElectraForAggregatePredictionWithAttention.forward-1334"><span class="linenos">1334</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1335"><a href="#ElectraForAggregatePredictionWithAttention.forward-1335"><span class="linenos">1335</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;single_label_classification&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1336"><a href="#ElectraForAggregatePredictionWithAttention.forward-1336"><span class="linenos">1336</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1337"><a href="#ElectraForAggregatePredictionWithAttention.forward-1337"><span class="linenos">1337</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1338"><a href="#ElectraForAggregatePredictionWithAttention.forward-1338"><span class="linenos">1338</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;multi_label_classification&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1339"><a href="#ElectraForAggregatePredictionWithAttention.forward-1339"><span class="linenos">1339</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1340"><a href="#ElectraForAggregatePredictionWithAttention.forward-1340"><span class="linenos">1340</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1341"><a href="#ElectraForAggregatePredictionWithAttention.forward-1341"><span class="linenos">1341</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1342"><a href="#ElectraForAggregatePredictionWithAttention.forward-1342"><span class="linenos">1342</span></a>        <span class="n">full_output</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">attention_probabilities</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_attention</span> <span class="k">else</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1343"><a href="#ElectraForAggregatePredictionWithAttention.forward-1343"><span class="linenos">1343</span></a>
</span><span id="ElectraForAggregatePredictionWithAttention.forward-1344"><a href="#ElectraForAggregatePredictionWithAttention.forward-1344"><span class="linenos">1344</span></a>        <span class="k">return</span> <span class="n">full_output</span>
</span></pre></div>


            <div class="docstring"><p>Performs the forward pass of the Electra model with aggregate prediction.</p>

<h2 id="parameters">Parameters</h2>

<p>input_ids : List[List[Tensor]]
    A batch of input token IDs.
attention_mask : List[List[Tensor]]
    A batch of attention masks corresponding to the input IDs.
labels : Optional[torch.Tensor], optional
    Ground truth labels for the input sequences (default is None).
return_attention : bool, optional
    If True, returns attention probabilities along with the logits (default is True).</p>

<h2 id="returns">Returns</h2>

<p>Any
    The loss (if labels are provided), logits, and optionally the attention probabilities.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>transformers.models.electra.modeling_electra.ElectraPreTrainedModel</dt>
                                <dd id="ElectraForAggregatePredictionWithAttention.config_class" class="variable">config_class</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.load_tf_weights" class="function">load_tf_weights</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.base_model_prefix" class="variable">base_model_prefix</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.supports_gradient_checkpointing" class="variable">supports_gradient_checkpointing</dd>

            </div>
            <div><dt>transformers.modeling_utils.PreTrainedModel</dt>
                                <dd id="ElectraForAggregatePredictionWithAttention.main_input_name" class="variable">main_input_name</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.model_tags" class="variable">model_tags</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.is_parallelizable" class="variable">is_parallelizable</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.dummy_inputs" class="variable">dummy_inputs</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.framework" class="variable">framework</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.name_or_path" class="variable">name_or_path</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.warnings_issued" class="variable">warnings_issued</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.generation_config" class="variable">generation_config</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.post_init" class="function">post_init</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.dequantize" class="function">dequantize</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.add_model_tags" class="function">add_model_tags</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.base_model" class="variable">base_model</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.can_generate" class="function">can_generate</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.enable_input_require_grads" class="function">enable_input_require_grads</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.disable_input_require_grads" class="function">disable_input_require_grads</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_input_embeddings" class="function">get_input_embeddings</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.set_input_embeddings" class="function">set_input_embeddings</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_output_embeddings" class="function">get_output_embeddings</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.tie_weights" class="function">tie_weights</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.resize_token_embeddings" class="function">resize_token_embeddings</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.resize_position_embeddings" class="function">resize_position_embeddings</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_position_embeddings" class="function">get_position_embeddings</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.init_weights" class="function">init_weights</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.prune_heads" class="function">prune_heads</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.gradient_checkpointing_enable" class="function">gradient_checkpointing_enable</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.gradient_checkpointing_disable" class="function">gradient_checkpointing_disable</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.is_gradient_checkpointing" class="variable">is_gradient_checkpointing</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.save_pretrained" class="function">save_pretrained</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.push_to_hub" class="function">push_to_hub</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_memory_footprint" class="function">get_memory_footprint</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.cuda" class="function">cuda</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.to" class="function">to</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.half" class="function">half</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.float" class="function">float</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.from_pretrained" class="function">from_pretrained</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.retrieve_modules_from_names" class="function">retrieve_modules_from_names</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_for_auto_class" class="function">register_for_auto_class</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.to_bettertransformer" class="function">to_bettertransformer</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.reverse_bettertransformer" class="function">reverse_bettertransformer</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.warn_if_padding_and_no_attention_mask" class="function">warn_if_padding_and_no_attention_mask</dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ElectraForAggregatePredictionWithAttention.dump_patches" class="variable">dump_patches</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.training" class="variable">training</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.call_super_init" class="variable">call_super_init</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_buffer" class="function">register_buffer</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_parameter" class="function">register_parameter</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.add_module" class="function">add_module</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_module" class="function">register_module</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_submodule" class="function">get_submodule</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_parameter" class="function">get_parameter</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_buffer" class="function">get_buffer</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.apply" class="function">apply</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.ipu" class="function">ipu</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.xpu" class="function">xpu</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.cpu" class="function">cpu</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.type" class="function">type</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.double" class="function">double</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.bfloat16" class="function">bfloat16</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.to_empty" class="function">to_empty</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.state_dict" class="function">state_dict</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.parameters" class="function">parameters</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.named_parameters" class="function">named_parameters</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.buffers" class="function">buffers</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.named_buffers" class="function">named_buffers</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.children" class="function">children</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.named_children" class="function">named_children</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.modules" class="function">modules</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.named_modules" class="function">named_modules</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.train" class="function">train</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.eval" class="function">eval</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.zero_grad" class="function">zero_grad</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.share_memory" class="function">share_memory</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.extra_repr" class="function">extra_repr</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.compile" class="function">compile</dd>

            </div>
            <div><dt>transformers.modeling_utils.ModuleUtilsMixin</dt>
                                <dd id="ElectraForAggregatePredictionWithAttention.add_memory_hooks" class="function">add_memory_hooks</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.reset_memory_hooks_state" class="function">reset_memory_hooks_state</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.device" class="variable">device</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.dtype" class="variable">dtype</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.invert_attention_mask" class="function">invert_attention_mask</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.create_extended_attention_mask_for_decoder" class="function">create_extended_attention_mask_for_decoder</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_extended_attention_mask" class="function">get_extended_attention_mask</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_head_mask" class="function">get_head_mask</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.num_parameters" class="function">num_parameters</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.estimate_tokens" class="function">estimate_tokens</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.floating_point_ops" class="function">floating_point_ops</dd>

            </div>
            <div><dt>transformers.generation.utils.GenerationMixin</dt>
                                <dd id="ElectraForAggregatePredictionWithAttention.prepare_inputs_for_generation" class="function">prepare_inputs_for_generation</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.compute_transition_scores" class="function">compute_transition_scores</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.generate" class="function">generate</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.heal_tokens" class="function">heal_tokens</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.contrastive_search" class="function">contrastive_search</dd>

            </div>
            <div><dt>transformers.integrations.peft.PeftAdapterMixin</dt>
                                <dd id="ElectraForAggregatePredictionWithAttention.load_adapter" class="function">load_adapter</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.add_adapter" class="function">add_adapter</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.set_adapter" class="function">set_adapter</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.disable_adapters" class="function">disable_adapters</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.enable_adapters" class="function">enable_adapters</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.active_adapters" class="function">active_adapters</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.active_adapter" class="function">active_adapter</dd>
                <dd id="ElectraForAggregatePredictionWithAttention.get_adapter_state_dict" class="function">get_adapter_state_dict</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ElectraAggregationHead">
                            <input id="ElectraAggregationHead-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ElectraAggregationHead</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="ElectraAggregationHead-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraAggregationHead"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraAggregationHead-1347"><a href="#ElectraAggregationHead-1347"><span class="linenos">1347</span></a><span class="k">class</span> <span class="nc">ElectraAggregationHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="ElectraAggregationHead-1348"><a href="#ElectraAggregationHead-1348"><span class="linenos">1348</span></a><span class="w">    </span>
</span><span id="ElectraAggregationHead-1349"><a href="#ElectraAggregationHead-1349"><span class="linenos">1349</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead-1350"><a href="#ElectraAggregationHead-1350"><span class="linenos">1350</span></a><span class="sd">    Head to aggregate sequence embeddings of a batch of documents with sequences into predictions for each document.</span>
</span><span id="ElectraAggregationHead-1351"><a href="#ElectraAggregationHead-1351"><span class="linenos">1351</span></a>
</span><span id="ElectraAggregationHead-1352"><a href="#ElectraAggregationHead-1352"><span class="linenos">1352</span></a><span class="sd">    This class takes sequence embeddings as input and aggregates them by averaging. </span>
</span><span id="ElectraAggregationHead-1353"><a href="#ElectraAggregationHead-1353"><span class="linenos">1353</span></a><span class="sd">    It then passes the aggregated embeddings through a dense layer, applies dropout </span>
</span><span id="ElectraAggregationHead-1354"><a href="#ElectraAggregationHead-1354"><span class="linenos">1354</span></a><span class="sd">    and activation, and finally projects the result to the number of output labels.</span>
</span><span id="ElectraAggregationHead-1355"><a href="#ElectraAggregationHead-1355"><span class="linenos">1355</span></a>
</span><span id="ElectraAggregationHead-1356"><a href="#ElectraAggregationHead-1356"><span class="linenos">1356</span></a><span class="sd">    Attributes</span>
</span><span id="ElectraAggregationHead-1357"><a href="#ElectraAggregationHead-1357"><span class="linenos">1357</span></a><span class="sd">    ----------</span>
</span><span id="ElectraAggregationHead-1358"><a href="#ElectraAggregationHead-1358"><span class="linenos">1358</span></a><span class="sd">    dense : nn.Linear</span>
</span><span id="ElectraAggregationHead-1359"><a href="#ElectraAggregationHead-1359"><span class="linenos">1359</span></a><span class="sd">        A linear layer that densely connects all sequence embeddings.</span>
</span><span id="ElectraAggregationHead-1360"><a href="#ElectraAggregationHead-1360"><span class="linenos">1360</span></a><span class="sd">    dropout : nn.Dropout</span>
</span><span id="ElectraAggregationHead-1361"><a href="#ElectraAggregationHead-1361"><span class="linenos">1361</span></a><span class="sd">        Dropout applied to the output of the dense layer.</span>
</span><span id="ElectraAggregationHead-1362"><a href="#ElectraAggregationHead-1362"><span class="linenos">1362</span></a><span class="sd">    activation : nn.GELU</span>
</span><span id="ElectraAggregationHead-1363"><a href="#ElectraAggregationHead-1363"><span class="linenos">1363</span></a><span class="sd">        Activation function applied after the dropout.</span>
</span><span id="ElectraAggregationHead-1364"><a href="#ElectraAggregationHead-1364"><span class="linenos">1364</span></a><span class="sd">    out_projection : nn.Linear</span>
</span><span id="ElectraAggregationHead-1365"><a href="#ElectraAggregationHead-1365"><span class="linenos">1365</span></a><span class="sd">        A linear layer that projects the aggregated embeddings to the number of labels.</span>
</span><span id="ElectraAggregationHead-1366"><a href="#ElectraAggregationHead-1366"><span class="linenos">1366</span></a>
</span><span id="ElectraAggregationHead-1367"><a href="#ElectraAggregationHead-1367"><span class="linenos">1367</span></a><span class="sd">    Methods</span>
</span><span id="ElectraAggregationHead-1368"><a href="#ElectraAggregationHead-1368"><span class="linenos">1368</span></a><span class="sd">    -------</span>
</span><span id="ElectraAggregationHead-1369"><a href="#ElectraAggregationHead-1369"><span class="linenos">1369</span></a><span class="sd">    forward(hidden_states: torch.Tensor, original_shapes: List[int]) -&gt; torch.Tensor</span>
</span><span id="ElectraAggregationHead-1370"><a href="#ElectraAggregationHead-1370"><span class="linenos">1370</span></a><span class="sd">        Performs the forward pass, aggregating the sequence embeddings and generating logits.</span>
</span><span id="ElectraAggregationHead-1371"><a href="#ElectraAggregationHead-1371"><span class="linenos">1371</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead-1372"><a href="#ElectraAggregationHead-1372"><span class="linenos">1372</span></a>
</span><span id="ElectraAggregationHead-1373"><a href="#ElectraAggregationHead-1373"><span class="linenos">1373</span></a>
</span><span id="ElectraAggregationHead-1374"><a href="#ElectraAggregationHead-1374"><span class="linenos">1374</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraAggregationHead-1375"><a href="#ElectraAggregationHead-1375"><span class="linenos">1375</span></a>
</span><span id="ElectraAggregationHead-1376"><a href="#ElectraAggregationHead-1376"><span class="linenos">1376</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead-1377"><a href="#ElectraAggregationHead-1377"><span class="linenos">1377</span></a><span class="sd">        Initializes the ElectraAggregationHead with the provided configuration.</span>
</span><span id="ElectraAggregationHead-1378"><a href="#ElectraAggregationHead-1378"><span class="linenos">1378</span></a>
</span><span id="ElectraAggregationHead-1379"><a href="#ElectraAggregationHead-1379"><span class="linenos">1379</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraAggregationHead-1380"><a href="#ElectraAggregationHead-1380"><span class="linenos">1380</span></a><span class="sd">        ----------</span>
</span><span id="ElectraAggregationHead-1381"><a href="#ElectraAggregationHead-1381"><span class="linenos">1381</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraAggregationHead-1382"><a href="#ElectraAggregationHead-1382"><span class="linenos">1382</span></a><span class="sd">            The configuration object containing the hidden size, dropout probability, </span>
</span><span id="ElectraAggregationHead-1383"><a href="#ElectraAggregationHead-1383"><span class="linenos">1383</span></a><span class="sd">            and number of labels.</span>
</span><span id="ElectraAggregationHead-1384"><a href="#ElectraAggregationHead-1384"><span class="linenos">1384</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead-1385"><a href="#ElectraAggregationHead-1385"><span class="linenos">1385</span></a>
</span><span id="ElectraAggregationHead-1386"><a href="#ElectraAggregationHead-1386"><span class="linenos">1386</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ElectraAggregationHead-1387"><a href="#ElectraAggregationHead-1387"><span class="linenos">1387</span></a>        <span class="c1"># densely connect all sequence embeddings</span>
</span><span id="ElectraAggregationHead-1388"><a href="#ElectraAggregationHead-1388"><span class="linenos">1388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraAggregationHead-1389"><a href="#ElectraAggregationHead-1389"><span class="linenos">1389</span></a>        <span class="c1"># dropout</span>
</span><span id="ElectraAggregationHead-1390"><a href="#ElectraAggregationHead-1390"><span class="linenos">1390</span></a>        <span class="n">aggregation_head_dropout</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="ElectraAggregationHead-1391"><a href="#ElectraAggregationHead-1391"><span class="linenos">1391</span></a>            <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span>
</span><span id="ElectraAggregationHead-1392"><a href="#ElectraAggregationHead-1392"><span class="linenos">1392</span></a>        <span class="p">)</span>
</span><span id="ElectraAggregationHead-1393"><a href="#ElectraAggregationHead-1393"><span class="linenos">1393</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">aggregation_head_dropout</span><span class="p">)</span>
</span><span id="ElectraAggregationHead-1394"><a href="#ElectraAggregationHead-1394"><span class="linenos">1394</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
</span><span id="ElectraAggregationHead-1395"><a href="#ElectraAggregationHead-1395"><span class="linenos">1395</span></a>        <span class="c1"># project the average aggregate of sequence embeddings after the dense layer</span>
</span><span id="ElectraAggregationHead-1396"><a href="#ElectraAggregationHead-1396"><span class="linenos">1396</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span><span id="ElectraAggregationHead-1397"><a href="#ElectraAggregationHead-1397"><span class="linenos">1397</span></a>
</span><span id="ElectraAggregationHead-1398"><a href="#ElectraAggregationHead-1398"><span class="linenos">1398</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">):</span>
</span><span id="ElectraAggregationHead-1399"><a href="#ElectraAggregationHead-1399"><span class="linenos">1399</span></a>
</span><span id="ElectraAggregationHead-1400"><a href="#ElectraAggregationHead-1400"><span class="linenos">1400</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead-1401"><a href="#ElectraAggregationHead-1401"><span class="linenos">1401</span></a><span class="sd">        Performs the forward pass, aggregating the sequence embeddings and generating logits.</span>
</span><span id="ElectraAggregationHead-1402"><a href="#ElectraAggregationHead-1402"><span class="linenos">1402</span></a>
</span><span id="ElectraAggregationHead-1403"><a href="#ElectraAggregationHead-1403"><span class="linenos">1403</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraAggregationHead-1404"><a href="#ElectraAggregationHead-1404"><span class="linenos">1404</span></a><span class="sd">        ----------</span>
</span><span id="ElectraAggregationHead-1405"><a href="#ElectraAggregationHead-1405"><span class="linenos">1405</span></a><span class="sd">        hidden_states : torch.Tensor</span>
</span><span id="ElectraAggregationHead-1406"><a href="#ElectraAggregationHead-1406"><span class="linenos">1406</span></a><span class="sd">            The input sequence embeddings of shape (batch_size, hidden_size).</span>
</span><span id="ElectraAggregationHead-1407"><a href="#ElectraAggregationHead-1407"><span class="linenos">1407</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="ElectraAggregationHead-1408"><a href="#ElectraAggregationHead-1408"><span class="linenos">1408</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="ElectraAggregationHead-1409"><a href="#ElectraAggregationHead-1409"><span class="linenos">1409</span></a>
</span><span id="ElectraAggregationHead-1410"><a href="#ElectraAggregationHead-1410"><span class="linenos">1410</span></a><span class="sd">        Returns</span>
</span><span id="ElectraAggregationHead-1411"><a href="#ElectraAggregationHead-1411"><span class="linenos">1411</span></a><span class="sd">        -------</span>
</span><span id="ElectraAggregationHead-1412"><a href="#ElectraAggregationHead-1412"><span class="linenos">1412</span></a><span class="sd">        torch.Tensor</span>
</span><span id="ElectraAggregationHead-1413"><a href="#ElectraAggregationHead-1413"><span class="linenos">1413</span></a><span class="sd">            The logits for each aggregated sequence.</span>
</span><span id="ElectraAggregationHead-1414"><a href="#ElectraAggregationHead-1414"><span class="linenos">1414</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead-1415"><a href="#ElectraAggregationHead-1415"><span class="linenos">1415</span></a>
</span><span id="ElectraAggregationHead-1416"><a href="#ElectraAggregationHead-1416"><span class="linenos">1416</span></a>        <span class="c1"># process flattened input embedding states through dense layer</span>
</span><span id="ElectraAggregationHead-1417"><a href="#ElectraAggregationHead-1417"><span class="linenos">1417</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
</span><span id="ElectraAggregationHead-1418"><a href="#ElectraAggregationHead-1418"><span class="linenos">1418</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ElectraAggregationHead-1419"><a href="#ElectraAggregationHead-1419"><span class="linenos">1419</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ElectraAggregationHead-1420"><a href="#ElectraAggregationHead-1420"><span class="linenos">1420</span></a>        <span class="n">x_original_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraAggregationHead-1421"><a href="#ElectraAggregationHead-1421"><span class="linenos">1421</span></a>        <span class="n">x_aggregated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch_tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">torch_tensor</span> <span class="ow">in</span> <span class="n">x_original_shapes</span><span class="p">])</span>
</span><span id="ElectraAggregationHead-1422"><a href="#ElectraAggregationHead-1422"><span class="linenos">1422</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">x_aggregated</span><span class="p">)</span>
</span><span id="ElectraAggregationHead-1423"><a href="#ElectraAggregationHead-1423"><span class="linenos">1423</span></a>        <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Head to aggregate sequence embeddings of a batch of documents with sequences into predictions for each document.</p>

<p>This class takes sequence embeddings as input and aggregates them by averaging. 
It then passes the aggregated embeddings through a dense layer, applies dropout 
and activation, and finally projects the result to the number of output labels.</p>

<h2 id="attributes">Attributes</h2>

<p>dense : nn.Linear
    A linear layer that densely connects all sequence embeddings.
dropout : nn.Dropout
    Dropout applied to the output of the dense layer.
activation : nn.GELU
    Activation function applied after the dropout.
out_projection : nn.Linear
    A linear layer that projects the aggregated embeddings to the number of labels.</p>

<h2 id="methods">Methods</h2>

<p>forward(hidden_states: torch.Tensor, original_shapes: List[int]) -> torch.Tensor
    Performs the forward pass, aggregating the sequence embeddings and generating logits.</p>
</div>


                            <div id="ElectraAggregationHead.__init__" class="classattr">
                                        <input id="ElectraAggregationHead.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ElectraAggregationHead</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ElectraAggregationHead.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraAggregationHead.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraAggregationHead.__init__-1374"><a href="#ElectraAggregationHead.__init__-1374"><span class="linenos">1374</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraAggregationHead.__init__-1375"><a href="#ElectraAggregationHead.__init__-1375"><span class="linenos">1375</span></a>
</span><span id="ElectraAggregationHead.__init__-1376"><a href="#ElectraAggregationHead.__init__-1376"><span class="linenos">1376</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead.__init__-1377"><a href="#ElectraAggregationHead.__init__-1377"><span class="linenos">1377</span></a><span class="sd">        Initializes the ElectraAggregationHead with the provided configuration.</span>
</span><span id="ElectraAggregationHead.__init__-1378"><a href="#ElectraAggregationHead.__init__-1378"><span class="linenos">1378</span></a>
</span><span id="ElectraAggregationHead.__init__-1379"><a href="#ElectraAggregationHead.__init__-1379"><span class="linenos">1379</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraAggregationHead.__init__-1380"><a href="#ElectraAggregationHead.__init__-1380"><span class="linenos">1380</span></a><span class="sd">        ----------</span>
</span><span id="ElectraAggregationHead.__init__-1381"><a href="#ElectraAggregationHead.__init__-1381"><span class="linenos">1381</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraAggregationHead.__init__-1382"><a href="#ElectraAggregationHead.__init__-1382"><span class="linenos">1382</span></a><span class="sd">            The configuration object containing the hidden size, dropout probability, </span>
</span><span id="ElectraAggregationHead.__init__-1383"><a href="#ElectraAggregationHead.__init__-1383"><span class="linenos">1383</span></a><span class="sd">            and number of labels.</span>
</span><span id="ElectraAggregationHead.__init__-1384"><a href="#ElectraAggregationHead.__init__-1384"><span class="linenos">1384</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead.__init__-1385"><a href="#ElectraAggregationHead.__init__-1385"><span class="linenos">1385</span></a>
</span><span id="ElectraAggregationHead.__init__-1386"><a href="#ElectraAggregationHead.__init__-1386"><span class="linenos">1386</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ElectraAggregationHead.__init__-1387"><a href="#ElectraAggregationHead.__init__-1387"><span class="linenos">1387</span></a>        <span class="c1"># densely connect all sequence embeddings</span>
</span><span id="ElectraAggregationHead.__init__-1388"><a href="#ElectraAggregationHead.__init__-1388"><span class="linenos">1388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ElectraAggregationHead.__init__-1389"><a href="#ElectraAggregationHead.__init__-1389"><span class="linenos">1389</span></a>        <span class="c1"># dropout</span>
</span><span id="ElectraAggregationHead.__init__-1390"><a href="#ElectraAggregationHead.__init__-1390"><span class="linenos">1390</span></a>        <span class="n">aggregation_head_dropout</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="ElectraAggregationHead.__init__-1391"><a href="#ElectraAggregationHead.__init__-1391"><span class="linenos">1391</span></a>            <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">classifier_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span>
</span><span id="ElectraAggregationHead.__init__-1392"><a href="#ElectraAggregationHead.__init__-1392"><span class="linenos">1392</span></a>        <span class="p">)</span>
</span><span id="ElectraAggregationHead.__init__-1393"><a href="#ElectraAggregationHead.__init__-1393"><span class="linenos">1393</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">aggregation_head_dropout</span><span class="p">)</span>
</span><span id="ElectraAggregationHead.__init__-1394"><a href="#ElectraAggregationHead.__init__-1394"><span class="linenos">1394</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
</span><span id="ElectraAggregationHead.__init__-1395"><a href="#ElectraAggregationHead.__init__-1395"><span class="linenos">1395</span></a>        <span class="c1"># project the average aggregate of sequence embeddings after the dense layer</span>
</span><span id="ElectraAggregationHead.__init__-1396"><a href="#ElectraAggregationHead.__init__-1396"><span class="linenos">1396</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the ElectraAggregationHead with the provided configuration.</p>

<h2 id="parameters">Parameters</h2>

<p>config : ElectraConfig
    The configuration object containing the hidden size, dropout probability, 
    and number of labels.</p>
</div>


                            </div>
                            <div id="ElectraAggregationHead.dense" class="classattr">
                                <div class="attr variable">
            <span class="name">dense</span>

        
    </div>
    <a class="headerlink" href="#ElectraAggregationHead.dense"></a>
    
    

                            </div>
                            <div id="ElectraAggregationHead.dropout" class="classattr">
                                <div class="attr variable">
            <span class="name">dropout</span>

        
    </div>
    <a class="headerlink" href="#ElectraAggregationHead.dropout"></a>
    
    

                            </div>
                            <div id="ElectraAggregationHead.activation" class="classattr">
                                <div class="attr variable">
            <span class="name">activation</span>

        
    </div>
    <a class="headerlink" href="#ElectraAggregationHead.activation"></a>
    
    

                            </div>
                            <div id="ElectraAggregationHead.out_projection" class="classattr">
                                <div class="attr variable">
            <span class="name">out_projection</span>

        
    </div>
    <a class="headerlink" href="#ElectraAggregationHead.out_projection"></a>
    
    

                            </div>
                            <div id="ElectraAggregationHead.forward" class="classattr">
                                        <input id="ElectraAggregationHead.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">hidden_states</span>, </span><span class="param"><span class="n">original_shapes</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ElectraAggregationHead.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraAggregationHead.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraAggregationHead.forward-1398"><a href="#ElectraAggregationHead.forward-1398"><span class="linenos">1398</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">):</span>
</span><span id="ElectraAggregationHead.forward-1399"><a href="#ElectraAggregationHead.forward-1399"><span class="linenos">1399</span></a>
</span><span id="ElectraAggregationHead.forward-1400"><a href="#ElectraAggregationHead.forward-1400"><span class="linenos">1400</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead.forward-1401"><a href="#ElectraAggregationHead.forward-1401"><span class="linenos">1401</span></a><span class="sd">        Performs the forward pass, aggregating the sequence embeddings and generating logits.</span>
</span><span id="ElectraAggregationHead.forward-1402"><a href="#ElectraAggregationHead.forward-1402"><span class="linenos">1402</span></a>
</span><span id="ElectraAggregationHead.forward-1403"><a href="#ElectraAggregationHead.forward-1403"><span class="linenos">1403</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraAggregationHead.forward-1404"><a href="#ElectraAggregationHead.forward-1404"><span class="linenos">1404</span></a><span class="sd">        ----------</span>
</span><span id="ElectraAggregationHead.forward-1405"><a href="#ElectraAggregationHead.forward-1405"><span class="linenos">1405</span></a><span class="sd">        hidden_states : torch.Tensor</span>
</span><span id="ElectraAggregationHead.forward-1406"><a href="#ElectraAggregationHead.forward-1406"><span class="linenos">1406</span></a><span class="sd">            The input sequence embeddings of shape (batch_size, hidden_size).</span>
</span><span id="ElectraAggregationHead.forward-1407"><a href="#ElectraAggregationHead.forward-1407"><span class="linenos">1407</span></a><span class="sd">        original_shapes : List[int]</span>
</span><span id="ElectraAggregationHead.forward-1408"><a href="#ElectraAggregationHead.forward-1408"><span class="linenos">1408</span></a><span class="sd">            The original shapes of the sequences before flattening.</span>
</span><span id="ElectraAggregationHead.forward-1409"><a href="#ElectraAggregationHead.forward-1409"><span class="linenos">1409</span></a>
</span><span id="ElectraAggregationHead.forward-1410"><a href="#ElectraAggregationHead.forward-1410"><span class="linenos">1410</span></a><span class="sd">        Returns</span>
</span><span id="ElectraAggregationHead.forward-1411"><a href="#ElectraAggregationHead.forward-1411"><span class="linenos">1411</span></a><span class="sd">        -------</span>
</span><span id="ElectraAggregationHead.forward-1412"><a href="#ElectraAggregationHead.forward-1412"><span class="linenos">1412</span></a><span class="sd">        torch.Tensor</span>
</span><span id="ElectraAggregationHead.forward-1413"><a href="#ElectraAggregationHead.forward-1413"><span class="linenos">1413</span></a><span class="sd">            The logits for each aggregated sequence.</span>
</span><span id="ElectraAggregationHead.forward-1414"><a href="#ElectraAggregationHead.forward-1414"><span class="linenos">1414</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraAggregationHead.forward-1415"><a href="#ElectraAggregationHead.forward-1415"><span class="linenos">1415</span></a>
</span><span id="ElectraAggregationHead.forward-1416"><a href="#ElectraAggregationHead.forward-1416"><span class="linenos">1416</span></a>        <span class="c1"># process flattened input embedding states through dense layer</span>
</span><span id="ElectraAggregationHead.forward-1417"><a href="#ElectraAggregationHead.forward-1417"><span class="linenos">1417</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
</span><span id="ElectraAggregationHead.forward-1418"><a href="#ElectraAggregationHead.forward-1418"><span class="linenos">1418</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ElectraAggregationHead.forward-1419"><a href="#ElectraAggregationHead.forward-1419"><span class="linenos">1419</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ElectraAggregationHead.forward-1420"><a href="#ElectraAggregationHead.forward-1420"><span class="linenos">1420</span></a>        <span class="n">x_original_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraAggregationHead.forward-1421"><a href="#ElectraAggregationHead.forward-1421"><span class="linenos">1421</span></a>        <span class="n">x_aggregated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch_tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">torch_tensor</span> <span class="ow">in</span> <span class="n">x_original_shapes</span><span class="p">])</span>
</span><span id="ElectraAggregationHead.forward-1422"><a href="#ElectraAggregationHead.forward-1422"><span class="linenos">1422</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">x_aggregated</span><span class="p">)</span>
</span><span id="ElectraAggregationHead.forward-1423"><a href="#ElectraAggregationHead.forward-1423"><span class="linenos">1423</span></a>        <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Performs the forward pass, aggregating the sequence embeddings and generating logits.</p>

<h2 id="parameters">Parameters</h2>

<p>hidden_states : torch.Tensor
    The input sequence embeddings of shape (batch_size, hidden_size).
original_shapes : List[int]
    The original shapes of the sequences before flattening.</p>

<h2 id="returns">Returns</h2>

<p>torch.Tensor
    The logits for each aggregated sequence.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ElectraAggregationHead.dump_patches" class="variable">dump_patches</dd>
                <dd id="ElectraAggregationHead.training" class="variable">training</dd>
                <dd id="ElectraAggregationHead.call_super_init" class="variable">call_super_init</dd>
                <dd id="ElectraAggregationHead.register_buffer" class="function">register_buffer</dd>
                <dd id="ElectraAggregationHead.register_parameter" class="function">register_parameter</dd>
                <dd id="ElectraAggregationHead.add_module" class="function">add_module</dd>
                <dd id="ElectraAggregationHead.register_module" class="function">register_module</dd>
                <dd id="ElectraAggregationHead.get_submodule" class="function">get_submodule</dd>
                <dd id="ElectraAggregationHead.get_parameter" class="function">get_parameter</dd>
                <dd id="ElectraAggregationHead.get_buffer" class="function">get_buffer</dd>
                <dd id="ElectraAggregationHead.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ElectraAggregationHead.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ElectraAggregationHead.apply" class="function">apply</dd>
                <dd id="ElectraAggregationHead.cuda" class="function">cuda</dd>
                <dd id="ElectraAggregationHead.ipu" class="function">ipu</dd>
                <dd id="ElectraAggregationHead.xpu" class="function">xpu</dd>
                <dd id="ElectraAggregationHead.cpu" class="function">cpu</dd>
                <dd id="ElectraAggregationHead.type" class="function">type</dd>
                <dd id="ElectraAggregationHead.float" class="function">float</dd>
                <dd id="ElectraAggregationHead.double" class="function">double</dd>
                <dd id="ElectraAggregationHead.half" class="function">half</dd>
                <dd id="ElectraAggregationHead.bfloat16" class="function">bfloat16</dd>
                <dd id="ElectraAggregationHead.to_empty" class="function">to_empty</dd>
                <dd id="ElectraAggregationHead.to" class="function">to</dd>
                <dd id="ElectraAggregationHead.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ElectraAggregationHead.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ElectraAggregationHead.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ElectraAggregationHead.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ElectraAggregationHead.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ElectraAggregationHead.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ElectraAggregationHead.state_dict" class="function">state_dict</dd>
                <dd id="ElectraAggregationHead.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ElectraAggregationHead.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ElectraAggregationHead.parameters" class="function">parameters</dd>
                <dd id="ElectraAggregationHead.named_parameters" class="function">named_parameters</dd>
                <dd id="ElectraAggregationHead.buffers" class="function">buffers</dd>
                <dd id="ElectraAggregationHead.named_buffers" class="function">named_buffers</dd>
                <dd id="ElectraAggregationHead.children" class="function">children</dd>
                <dd id="ElectraAggregationHead.named_children" class="function">named_children</dd>
                <dd id="ElectraAggregationHead.modules" class="function">modules</dd>
                <dd id="ElectraAggregationHead.named_modules" class="function">named_modules</dd>
                <dd id="ElectraAggregationHead.train" class="function">train</dd>
                <dd id="ElectraAggregationHead.eval" class="function">eval</dd>
                <dd id="ElectraAggregationHead.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ElectraAggregationHead.zero_grad" class="function">zero_grad</dd>
                <dd id="ElectraAggregationHead.share_memory" class="function">share_memory</dd>
                <dd id="ElectraAggregationHead.extra_repr" class="function">extra_repr</dd>
                <dd id="ElectraAggregationHead.compile" class="function">compile</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ElectraForAggregatePrediction">
                            <input id="ElectraForAggregatePrediction-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ElectraForAggregatePrediction</span><wbr>(<span class="base">transformers.models.electra.modeling_electra.ElectraPreTrainedModel</span>):

                <label class="view-source-button" for="ElectraForAggregatePrediction-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraForAggregatePrediction"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraForAggregatePrediction-1426"><a href="#ElectraForAggregatePrediction-1426"><span class="linenos">1426</span></a><span class="k">class</span> <span class="nc">ElectraForAggregatePrediction</span><span class="p">(</span><span class="n">ElectraPreTrainedModel</span><span class="p">):</span>
</span><span id="ElectraForAggregatePrediction-1427"><a href="#ElectraForAggregatePrediction-1427"><span class="linenos">1427</span></a>
</span><span id="ElectraForAggregatePrediction-1428"><a href="#ElectraForAggregatePrediction-1428"><span class="linenos">1428</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction-1429"><a href="#ElectraForAggregatePrediction-1429"><span class="linenos">1429</span></a><span class="sd">    An Electra model with aggregate prediction for sequence embeddings.</span>
</span><span id="ElectraForAggregatePrediction-1430"><a href="#ElectraForAggregatePrediction-1430"><span class="linenos">1430</span></a>
</span><span id="ElectraForAggregatePrediction-1431"><a href="#ElectraForAggregatePrediction-1431"><span class="linenos">1431</span></a><span class="sd">    This class extends the Electra model by adding a custom head for aggregate prediction.</span>
</span><span id="ElectraForAggregatePrediction-1432"><a href="#ElectraForAggregatePrediction-1432"><span class="linenos">1432</span></a><span class="sd">    It takes token embeddings, aggregates sequence embeddings, and makes predictions </span>
</span><span id="ElectraForAggregatePrediction-1433"><a href="#ElectraForAggregatePrediction-1433"><span class="linenos">1433</span></a><span class="sd">    for entire sequences or documents.</span>
</span><span id="ElectraForAggregatePrediction-1434"><a href="#ElectraForAggregatePrediction-1434"><span class="linenos">1434</span></a>
</span><span id="ElectraForAggregatePrediction-1435"><a href="#ElectraForAggregatePrediction-1435"><span class="linenos">1435</span></a><span class="sd">    Attributes</span>
</span><span id="ElectraForAggregatePrediction-1436"><a href="#ElectraForAggregatePrediction-1436"><span class="linenos">1436</span></a><span class="sd">    ----------</span>
</span><span id="ElectraForAggregatePrediction-1437"><a href="#ElectraForAggregatePrediction-1437"><span class="linenos">1437</span></a><span class="sd">    config : ElectraConfig</span>
</span><span id="ElectraForAggregatePrediction-1438"><a href="#ElectraForAggregatePrediction-1438"><span class="linenos">1438</span></a><span class="sd">        The configuration object for the Electra model.</span>
</span><span id="ElectraForAggregatePrediction-1439"><a href="#ElectraForAggregatePrediction-1439"><span class="linenos">1439</span></a><span class="sd">    num_labels : int</span>
</span><span id="ElectraForAggregatePrediction-1440"><a href="#ElectraForAggregatePrediction-1440"><span class="linenos">1440</span></a><span class="sd">        The number of labels for classification tasks.</span>
</span><span id="ElectraForAggregatePrediction-1441"><a href="#ElectraForAggregatePrediction-1441"><span class="linenos">1441</span></a><span class="sd">    electra : ElectraModel</span>
</span><span id="ElectraForAggregatePrediction-1442"><a href="#ElectraForAggregatePrediction-1442"><span class="linenos">1442</span></a><span class="sd">        The Electra encoder model for generating token embeddings.</span>
</span><span id="ElectraForAggregatePrediction-1443"><a href="#ElectraForAggregatePrediction-1443"><span class="linenos">1443</span></a><span class="sd">    head : ElectraAggregationHead</span>
</span><span id="ElectraForAggregatePrediction-1444"><a href="#ElectraForAggregatePrediction-1444"><span class="linenos">1444</span></a><span class="sd">        The custom head for making aggregate predictions with sequence embeddings.</span>
</span><span id="ElectraForAggregatePrediction-1445"><a href="#ElectraForAggregatePrediction-1445"><span class="linenos">1445</span></a>
</span><span id="ElectraForAggregatePrediction-1446"><a href="#ElectraForAggregatePrediction-1446"><span class="linenos">1446</span></a><span class="sd">    Methods</span>
</span><span id="ElectraForAggregatePrediction-1447"><a href="#ElectraForAggregatePrediction-1447"><span class="linenos">1447</span></a><span class="sd">    -------</span>
</span><span id="ElectraForAggregatePrediction-1448"><a href="#ElectraForAggregatePrediction-1448"><span class="linenos">1448</span></a><span class="sd">    forward(input_ids: List[List[Tensor]], attention_mask: List[List[Tensor]], labels: Optional[torch.Tensor] = None) -&gt; Any</span>
</span><span id="ElectraForAggregatePrediction-1449"><a href="#ElectraForAggregatePrediction-1449"><span class="linenos">1449</span></a><span class="sd">        Performs the forward pass, generating sequence embeddings and making predictions.</span>
</span><span id="ElectraForAggregatePrediction-1450"><a href="#ElectraForAggregatePrediction-1450"><span class="linenos">1450</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction-1451"><a href="#ElectraForAggregatePrediction-1451"><span class="linenos">1451</span></a>
</span><span id="ElectraForAggregatePrediction-1452"><a href="#ElectraForAggregatePrediction-1452"><span class="linenos">1452</span></a>    
</span><span id="ElectraForAggregatePrediction-1453"><a href="#ElectraForAggregatePrediction-1453"><span class="linenos">1453</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraForAggregatePrediction-1454"><a href="#ElectraForAggregatePrediction-1454"><span class="linenos">1454</span></a>
</span><span id="ElectraForAggregatePrediction-1455"><a href="#ElectraForAggregatePrediction-1455"><span class="linenos">1455</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction-1456"><a href="#ElectraForAggregatePrediction-1456"><span class="linenos">1456</span></a><span class="sd">        Initializes the ElectraForAggregatePrediction model.</span>
</span><span id="ElectraForAggregatePrediction-1457"><a href="#ElectraForAggregatePrediction-1457"><span class="linenos">1457</span></a>
</span><span id="ElectraForAggregatePrediction-1458"><a href="#ElectraForAggregatePrediction-1458"><span class="linenos">1458</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraForAggregatePrediction-1459"><a href="#ElectraForAggregatePrediction-1459"><span class="linenos">1459</span></a><span class="sd">        ----------</span>
</span><span id="ElectraForAggregatePrediction-1460"><a href="#ElectraForAggregatePrediction-1460"><span class="linenos">1460</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraForAggregatePrediction-1461"><a href="#ElectraForAggregatePrediction-1461"><span class="linenos">1461</span></a><span class="sd">            The configuration object for the Electra model.</span>
</span><span id="ElectraForAggregatePrediction-1462"><a href="#ElectraForAggregatePrediction-1462"><span class="linenos">1462</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction-1463"><a href="#ElectraForAggregatePrediction-1463"><span class="linenos">1463</span></a>
</span><span id="ElectraForAggregatePrediction-1464"><a href="#ElectraForAggregatePrediction-1464"><span class="linenos">1464</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1465"><a href="#ElectraForAggregatePrediction-1465"><span class="linenos">1465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="ElectraForAggregatePrediction-1466"><a href="#ElectraForAggregatePrediction-1466"><span class="linenos">1466</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
</span><span id="ElectraForAggregatePrediction-1467"><a href="#ElectraForAggregatePrediction-1467"><span class="linenos">1467</span></a>        <span class="c1"># the encoder for creating token embeddings</span>
</span><span id="ElectraForAggregatePrediction-1468"><a href="#ElectraForAggregatePrediction-1468"><span class="linenos">1468</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">electra</span> <span class="o">=</span> <span class="n">ElectraModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1469"><a href="#ElectraForAggregatePrediction-1469"><span class="linenos">1469</span></a>        <span class="c1"># the head for creating a single prediction for a batch of embeddings, in our case a batch of sequence embeddings</span>
</span><span id="ElectraForAggregatePrediction-1470"><a href="#ElectraForAggregatePrediction-1470"><span class="linenos">1470</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">ElectraAggregationHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1471"><a href="#ElectraForAggregatePrediction-1471"><span class="linenos">1471</span></a>
</span><span id="ElectraForAggregatePrediction-1472"><a href="#ElectraForAggregatePrediction-1472"><span class="linenos">1472</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>
</span><span id="ElectraForAggregatePrediction-1473"><a href="#ElectraForAggregatePrediction-1473"><span class="linenos">1473</span></a>
</span><span id="ElectraForAggregatePrediction-1474"><a href="#ElectraForAggregatePrediction-1474"><span class="linenos">1474</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span><span id="ElectraForAggregatePrediction-1475"><a href="#ElectraForAggregatePrediction-1475"><span class="linenos">1475</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="ElectraForAggregatePrediction-1476"><a href="#ElectraForAggregatePrediction-1476"><span class="linenos">1476</span></a>        <span class="n">input_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePrediction-1477"><a href="#ElectraForAggregatePrediction-1477"><span class="linenos">1477</span></a>        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePrediction-1478"><a href="#ElectraForAggregatePrediction-1478"><span class="linenos">1478</span></a>        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ElectraForAggregatePrediction-1479"><a href="#ElectraForAggregatePrediction-1479"><span class="linenos">1479</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1480"><a href="#ElectraForAggregatePrediction-1480"><span class="linenos">1480</span></a><span class="w">        </span>
</span><span id="ElectraForAggregatePrediction-1481"><a href="#ElectraForAggregatePrediction-1481"><span class="linenos">1481</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction-1482"><a href="#ElectraForAggregatePrediction-1482"><span class="linenos">1482</span></a><span class="sd">        Performs the forward pass of the Electra model with aggregate prediction.</span>
</span><span id="ElectraForAggregatePrediction-1483"><a href="#ElectraForAggregatePrediction-1483"><span class="linenos">1483</span></a>
</span><span id="ElectraForAggregatePrediction-1484"><a href="#ElectraForAggregatePrediction-1484"><span class="linenos">1484</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraForAggregatePrediction-1485"><a href="#ElectraForAggregatePrediction-1485"><span class="linenos">1485</span></a><span class="sd">        ----------</span>
</span><span id="ElectraForAggregatePrediction-1486"><a href="#ElectraForAggregatePrediction-1486"><span class="linenos">1486</span></a><span class="sd">        input_ids : List[List[Tensor]]</span>
</span><span id="ElectraForAggregatePrediction-1487"><a href="#ElectraForAggregatePrediction-1487"><span class="linenos">1487</span></a><span class="sd">            A batch of input token IDs.</span>
</span><span id="ElectraForAggregatePrediction-1488"><a href="#ElectraForAggregatePrediction-1488"><span class="linenos">1488</span></a><span class="sd">        attention_mask : List[List[Tensor]]</span>
</span><span id="ElectraForAggregatePrediction-1489"><a href="#ElectraForAggregatePrediction-1489"><span class="linenos">1489</span></a><span class="sd">            A batch of attention masks corresponding to the input IDs.</span>
</span><span id="ElectraForAggregatePrediction-1490"><a href="#ElectraForAggregatePrediction-1490"><span class="linenos">1490</span></a><span class="sd">        labels : Optional[torch.Tensor], optional</span>
</span><span id="ElectraForAggregatePrediction-1491"><a href="#ElectraForAggregatePrediction-1491"><span class="linenos">1491</span></a><span class="sd">            Ground truth labels for the input sequences (default is None).</span>
</span><span id="ElectraForAggregatePrediction-1492"><a href="#ElectraForAggregatePrediction-1492"><span class="linenos">1492</span></a>
</span><span id="ElectraForAggregatePrediction-1493"><a href="#ElectraForAggregatePrediction-1493"><span class="linenos">1493</span></a><span class="sd">        Returns</span>
</span><span id="ElectraForAggregatePrediction-1494"><a href="#ElectraForAggregatePrediction-1494"><span class="linenos">1494</span></a><span class="sd">        -------</span>
</span><span id="ElectraForAggregatePrediction-1495"><a href="#ElectraForAggregatePrediction-1495"><span class="linenos">1495</span></a><span class="sd">        Any</span>
</span><span id="ElectraForAggregatePrediction-1496"><a href="#ElectraForAggregatePrediction-1496"><span class="linenos">1496</span></a><span class="sd">            The loss (if labels are provided) and logits.</span>
</span><span id="ElectraForAggregatePrediction-1497"><a href="#ElectraForAggregatePrediction-1497"><span class="linenos">1497</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction-1498"><a href="#ElectraForAggregatePrediction-1498"><span class="linenos">1498</span></a>       
</span><span id="ElectraForAggregatePrediction-1499"><a href="#ElectraForAggregatePrediction-1499"><span class="linenos">1499</span></a>        <span class="n">input_id_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_input_ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_input_ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
</span><span id="ElectraForAggregatePrediction-1500"><a href="#ElectraForAggregatePrediction-1500"><span class="linenos">1500</span></a>        <span class="n">attention_mask_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_attention_mask</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_attention_mask</span> <span class="ow">in</span> <span class="n">attention_mask</span><span class="p">]</span>
</span><span id="ElectraForAggregatePrediction-1501"><a href="#ElectraForAggregatePrediction-1501"><span class="linenos">1501</span></a>        <span class="c1"># Store the original shapes</span>
</span><span id="ElectraForAggregatePrediction-1502"><a href="#ElectraForAggregatePrediction-1502"><span class="linenos">1502</span></a>        <span class="n">original_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_ids_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">input_ids_tensor</span> <span class="ow">in</span> <span class="n">input_id_tensors</span><span class="p">]</span>
</span><span id="ElectraForAggregatePrediction-1503"><a href="#ElectraForAggregatePrediction-1503"><span class="linenos">1503</span></a>
</span><span id="ElectraForAggregatePrediction-1504"><a href="#ElectraForAggregatePrediction-1504"><span class="linenos">1504</span></a>        <span class="c1"># Step 2: Concatenate the tensors along the first dimension</span>
</span><span id="ElectraForAggregatePrediction-1505"><a href="#ElectraForAggregatePrediction-1505"><span class="linenos">1505</span></a>        <span class="n">flattened_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_id_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1506"><a href="#ElectraForAggregatePrediction-1506"><span class="linenos">1506</span></a>        <span class="n">flattened_attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attention_mask_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1507"><a href="#ElectraForAggregatePrediction-1507"><span class="linenos">1507</span></a>
</span><span id="ElectraForAggregatePrediction-1508"><a href="#ElectraForAggregatePrediction-1508"><span class="linenos">1508</span></a>        <span class="n">discriminator_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">electra</span><span class="p">(</span>
</span><span id="ElectraForAggregatePrediction-1509"><a href="#ElectraForAggregatePrediction-1509"><span class="linenos">1509</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">flattened_input_ids</span><span class="p">,</span>
</span><span id="ElectraForAggregatePrediction-1510"><a href="#ElectraForAggregatePrediction-1510"><span class="linenos">1510</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">flattened_attention_mask</span><span class="p">,</span>
</span><span id="ElectraForAggregatePrediction-1511"><a href="#ElectraForAggregatePrediction-1511"><span class="linenos">1511</span></a>        <span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1512"><a href="#ElectraForAggregatePrediction-1512"><span class="linenos">1512</span></a>
</span><span id="ElectraForAggregatePrediction-1513"><a href="#ElectraForAggregatePrediction-1513"><span class="linenos">1513</span></a>        <span class="c1"># collect all token embeddings </span>
</span><span id="ElectraForAggregatePrediction-1514"><a href="#ElectraForAggregatePrediction-1514"><span class="linenos">1514</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">discriminator_hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ElectraForAggregatePrediction-1515"><a href="#ElectraForAggregatePrediction-1515"><span class="linenos">1515</span></a>        <span class="c1"># collect the sequence embeddings, only assuming the first token is a seq token</span>
</span><span id="ElectraForAggregatePrediction-1516"><a href="#ElectraForAggregatePrediction-1516"><span class="linenos">1516</span></a>        <span class="n">sequence_embeddings</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="ElectraForAggregatePrediction-1517"><a href="#ElectraForAggregatePrediction-1517"><span class="linenos">1517</span></a>        <span class="c1"># logits is the real valued prediction</span>
</span><span id="ElectraForAggregatePrediction-1518"><a href="#ElectraForAggregatePrediction-1518"><span class="linenos">1518</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1519"><a href="#ElectraForAggregatePrediction-1519"><span class="linenos">1519</span></a>
</span><span id="ElectraForAggregatePrediction-1520"><a href="#ElectraForAggregatePrediction-1520"><span class="linenos">1520</span></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ElectraForAggregatePrediction-1521"><a href="#ElectraForAggregatePrediction-1521"><span class="linenos">1521</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1522"><a href="#ElectraForAggregatePrediction-1522"><span class="linenos">1522</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1523"><a href="#ElectraForAggregatePrediction-1523"><span class="linenos">1523</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1524"><a href="#ElectraForAggregatePrediction-1524"><span class="linenos">1524</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;regression&quot;</span>
</span><span id="ElectraForAggregatePrediction-1525"><a href="#ElectraForAggregatePrediction-1525"><span class="linenos">1525</span></a>                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span> <span class="ow">or</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">):</span>
</span><span id="ElectraForAggregatePrediction-1526"><a href="#ElectraForAggregatePrediction-1526"><span class="linenos">1526</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;single_label_classification&quot;</span>
</span><span id="ElectraForAggregatePrediction-1527"><a href="#ElectraForAggregatePrediction-1527"><span class="linenos">1527</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1528"><a href="#ElectraForAggregatePrediction-1528"><span class="linenos">1528</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>
</span><span id="ElectraForAggregatePrediction-1529"><a href="#ElectraForAggregatePrediction-1529"><span class="linenos">1529</span></a>
</span><span id="ElectraForAggregatePrediction-1530"><a href="#ElectraForAggregatePrediction-1530"><span class="linenos">1530</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1531"><a href="#ElectraForAggregatePrediction-1531"><span class="linenos">1531</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePrediction-1532"><a href="#ElectraForAggregatePrediction-1532"><span class="linenos">1532</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1533"><a href="#ElectraForAggregatePrediction-1533"><span class="linenos">1533</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</span><span id="ElectraForAggregatePrediction-1534"><a href="#ElectraForAggregatePrediction-1534"><span class="linenos">1534</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1535"><a href="#ElectraForAggregatePrediction-1535"><span class="linenos">1535</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1536"><a href="#ElectraForAggregatePrediction-1536"><span class="linenos">1536</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;single_label_classification&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1537"><a href="#ElectraForAggregatePrediction-1537"><span class="linenos">1537</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePrediction-1538"><a href="#ElectraForAggregatePrediction-1538"><span class="linenos">1538</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ElectraForAggregatePrediction-1539"><a href="#ElectraForAggregatePrediction-1539"><span class="linenos">1539</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;multi_label_classification&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction-1540"><a href="#ElectraForAggregatePrediction-1540"><span class="linenos">1540</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePrediction-1541"><a href="#ElectraForAggregatePrediction-1541"><span class="linenos">1541</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction-1542"><a href="#ElectraForAggregatePrediction-1542"><span class="linenos">1542</span></a>
</span><span id="ElectraForAggregatePrediction-1543"><a href="#ElectraForAggregatePrediction-1543"><span class="linenos">1543</span></a>        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>An Electra model with aggregate prediction for sequence embeddings.</p>

<p>This class extends the Electra model by adding a custom head for aggregate prediction.
It takes token embeddings, aggregates sequence embeddings, and makes predictions 
for entire sequences or documents.</p>

<h2 id="attributes">Attributes</h2>

<p>config : ElectraConfig
    The configuration object for the Electra model.
num_labels : int
    The number of labels for classification tasks.
electra : ElectraModel
    The Electra encoder model for generating token embeddings.
head : ElectraAggregationHead
    The custom head for making aggregate predictions with sequence embeddings.</p>

<h2 id="methods">Methods</h2>

<p>forward(input_ids: List[List[Tensor]], attention_mask: List[List[Tensor]], labels: Optional[torch.Tensor] = None) -> Any
    Performs the forward pass, generating sequence embeddings and making predictions.</p>
</div>


                            <div id="ElectraForAggregatePrediction.__init__" class="classattr">
                                        <input id="ElectraForAggregatePrediction.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ElectraForAggregatePrediction</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ElectraForAggregatePrediction.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraForAggregatePrediction.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraForAggregatePrediction.__init__-1453"><a href="#ElectraForAggregatePrediction.__init__-1453"><span class="linenos">1453</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ElectraForAggregatePrediction.__init__-1454"><a href="#ElectraForAggregatePrediction.__init__-1454"><span class="linenos">1454</span></a>
</span><span id="ElectraForAggregatePrediction.__init__-1455"><a href="#ElectraForAggregatePrediction.__init__-1455"><span class="linenos">1455</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction.__init__-1456"><a href="#ElectraForAggregatePrediction.__init__-1456"><span class="linenos">1456</span></a><span class="sd">        Initializes the ElectraForAggregatePrediction model.</span>
</span><span id="ElectraForAggregatePrediction.__init__-1457"><a href="#ElectraForAggregatePrediction.__init__-1457"><span class="linenos">1457</span></a>
</span><span id="ElectraForAggregatePrediction.__init__-1458"><a href="#ElectraForAggregatePrediction.__init__-1458"><span class="linenos">1458</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraForAggregatePrediction.__init__-1459"><a href="#ElectraForAggregatePrediction.__init__-1459"><span class="linenos">1459</span></a><span class="sd">        ----------</span>
</span><span id="ElectraForAggregatePrediction.__init__-1460"><a href="#ElectraForAggregatePrediction.__init__-1460"><span class="linenos">1460</span></a><span class="sd">        config : ElectraConfig</span>
</span><span id="ElectraForAggregatePrediction.__init__-1461"><a href="#ElectraForAggregatePrediction.__init__-1461"><span class="linenos">1461</span></a><span class="sd">            The configuration object for the Electra model.</span>
</span><span id="ElectraForAggregatePrediction.__init__-1462"><a href="#ElectraForAggregatePrediction.__init__-1462"><span class="linenos">1462</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction.__init__-1463"><a href="#ElectraForAggregatePrediction.__init__-1463"><span class="linenos">1463</span></a>
</span><span id="ElectraForAggregatePrediction.__init__-1464"><a href="#ElectraForAggregatePrediction.__init__-1464"><span class="linenos">1464</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.__init__-1465"><a href="#ElectraForAggregatePrediction.__init__-1465"><span class="linenos">1465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="ElectraForAggregatePrediction.__init__-1466"><a href="#ElectraForAggregatePrediction.__init__-1466"><span class="linenos">1466</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
</span><span id="ElectraForAggregatePrediction.__init__-1467"><a href="#ElectraForAggregatePrediction.__init__-1467"><span class="linenos">1467</span></a>        <span class="c1"># the encoder for creating token embeddings</span>
</span><span id="ElectraForAggregatePrediction.__init__-1468"><a href="#ElectraForAggregatePrediction.__init__-1468"><span class="linenos">1468</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">electra</span> <span class="o">=</span> <span class="n">ElectraModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.__init__-1469"><a href="#ElectraForAggregatePrediction.__init__-1469"><span class="linenos">1469</span></a>        <span class="c1"># the head for creating a single prediction for a batch of embeddings, in our case a batch of sequence embeddings</span>
</span><span id="ElectraForAggregatePrediction.__init__-1470"><a href="#ElectraForAggregatePrediction.__init__-1470"><span class="linenos">1470</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">ElectraAggregationHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.__init__-1471"><a href="#ElectraForAggregatePrediction.__init__-1471"><span class="linenos">1471</span></a>
</span><span id="ElectraForAggregatePrediction.__init__-1472"><a href="#ElectraForAggregatePrediction.__init__-1472"><span class="linenos">1472</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the ElectraForAggregatePrediction model.</p>

<h2 id="parameters">Parameters</h2>

<p>config : ElectraConfig
    The configuration object for the Electra model.</p>
</div>


                            </div>
                            <div id="ElectraForAggregatePrediction.config" class="classattr">
                                <div class="attr variable">
            <span class="name">config</span>

        
    </div>
    <a class="headerlink" href="#ElectraForAggregatePrediction.config"></a>
    
    

                            </div>
                            <div id="ElectraForAggregatePrediction.num_labels" class="classattr">
                                <div class="attr variable">
            <span class="name">num_labels</span>

        
    </div>
    <a class="headerlink" href="#ElectraForAggregatePrediction.num_labels"></a>
    
    

                            </div>
                            <div id="ElectraForAggregatePrediction.electra" class="classattr">
                                <div class="attr variable">
            <span class="name">electra</span>

        
    </div>
    <a class="headerlink" href="#ElectraForAggregatePrediction.electra"></a>
    
    

                            </div>
                            <div id="ElectraForAggregatePrediction.head" class="classattr">
                                <div class="attr variable">
            <span class="name">head</span>

        
    </div>
    <a class="headerlink" href="#ElectraForAggregatePrediction.head"></a>
    
    

                            </div>
                            <div id="ElectraForAggregatePrediction.forward" class="classattr">
                                        <input id="ElectraForAggregatePrediction.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Any</span>:</span></span>

                <label class="view-source-button" for="ElectraForAggregatePrediction.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElectraForAggregatePrediction.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElectraForAggregatePrediction.forward-1474"><a href="#ElectraForAggregatePrediction.forward-1474"><span class="linenos">1474</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span><span id="ElectraForAggregatePrediction.forward-1475"><a href="#ElectraForAggregatePrediction.forward-1475"><span class="linenos">1475</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="ElectraForAggregatePrediction.forward-1476"><a href="#ElectraForAggregatePrediction.forward-1476"><span class="linenos">1476</span></a>        <span class="n">input_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePrediction.forward-1477"><a href="#ElectraForAggregatePrediction.forward-1477"><span class="linenos">1477</span></a>        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ElectraForAggregatePrediction.forward-1478"><a href="#ElectraForAggregatePrediction.forward-1478"><span class="linenos">1478</span></a>        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ElectraForAggregatePrediction.forward-1479"><a href="#ElectraForAggregatePrediction.forward-1479"><span class="linenos">1479</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1480"><a href="#ElectraForAggregatePrediction.forward-1480"><span class="linenos">1480</span></a><span class="w">        </span>
</span><span id="ElectraForAggregatePrediction.forward-1481"><a href="#ElectraForAggregatePrediction.forward-1481"><span class="linenos">1481</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction.forward-1482"><a href="#ElectraForAggregatePrediction.forward-1482"><span class="linenos">1482</span></a><span class="sd">        Performs the forward pass of the Electra model with aggregate prediction.</span>
</span><span id="ElectraForAggregatePrediction.forward-1483"><a href="#ElectraForAggregatePrediction.forward-1483"><span class="linenos">1483</span></a>
</span><span id="ElectraForAggregatePrediction.forward-1484"><a href="#ElectraForAggregatePrediction.forward-1484"><span class="linenos">1484</span></a><span class="sd">        Parameters</span>
</span><span id="ElectraForAggregatePrediction.forward-1485"><a href="#ElectraForAggregatePrediction.forward-1485"><span class="linenos">1485</span></a><span class="sd">        ----------</span>
</span><span id="ElectraForAggregatePrediction.forward-1486"><a href="#ElectraForAggregatePrediction.forward-1486"><span class="linenos">1486</span></a><span class="sd">        input_ids : List[List[Tensor]]</span>
</span><span id="ElectraForAggregatePrediction.forward-1487"><a href="#ElectraForAggregatePrediction.forward-1487"><span class="linenos">1487</span></a><span class="sd">            A batch of input token IDs.</span>
</span><span id="ElectraForAggregatePrediction.forward-1488"><a href="#ElectraForAggregatePrediction.forward-1488"><span class="linenos">1488</span></a><span class="sd">        attention_mask : List[List[Tensor]]</span>
</span><span id="ElectraForAggregatePrediction.forward-1489"><a href="#ElectraForAggregatePrediction.forward-1489"><span class="linenos">1489</span></a><span class="sd">            A batch of attention masks corresponding to the input IDs.</span>
</span><span id="ElectraForAggregatePrediction.forward-1490"><a href="#ElectraForAggregatePrediction.forward-1490"><span class="linenos">1490</span></a><span class="sd">        labels : Optional[torch.Tensor], optional</span>
</span><span id="ElectraForAggregatePrediction.forward-1491"><a href="#ElectraForAggregatePrediction.forward-1491"><span class="linenos">1491</span></a><span class="sd">            Ground truth labels for the input sequences (default is None).</span>
</span><span id="ElectraForAggregatePrediction.forward-1492"><a href="#ElectraForAggregatePrediction.forward-1492"><span class="linenos">1492</span></a>
</span><span id="ElectraForAggregatePrediction.forward-1493"><a href="#ElectraForAggregatePrediction.forward-1493"><span class="linenos">1493</span></a><span class="sd">        Returns</span>
</span><span id="ElectraForAggregatePrediction.forward-1494"><a href="#ElectraForAggregatePrediction.forward-1494"><span class="linenos">1494</span></a><span class="sd">        -------</span>
</span><span id="ElectraForAggregatePrediction.forward-1495"><a href="#ElectraForAggregatePrediction.forward-1495"><span class="linenos">1495</span></a><span class="sd">        Any</span>
</span><span id="ElectraForAggregatePrediction.forward-1496"><a href="#ElectraForAggregatePrediction.forward-1496"><span class="linenos">1496</span></a><span class="sd">            The loss (if labels are provided) and logits.</span>
</span><span id="ElectraForAggregatePrediction.forward-1497"><a href="#ElectraForAggregatePrediction.forward-1497"><span class="linenos">1497</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElectraForAggregatePrediction.forward-1498"><a href="#ElectraForAggregatePrediction.forward-1498"><span class="linenos">1498</span></a>       
</span><span id="ElectraForAggregatePrediction.forward-1499"><a href="#ElectraForAggregatePrediction.forward-1499"><span class="linenos">1499</span></a>        <span class="n">input_id_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_input_ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_input_ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
</span><span id="ElectraForAggregatePrediction.forward-1500"><a href="#ElectraForAggregatePrediction.forward-1500"><span class="linenos">1500</span></a>        <span class="n">attention_mask_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_attention_mask</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_attention_mask</span> <span class="ow">in</span> <span class="n">attention_mask</span><span class="p">]</span>
</span><span id="ElectraForAggregatePrediction.forward-1501"><a href="#ElectraForAggregatePrediction.forward-1501"><span class="linenos">1501</span></a>        <span class="c1"># Store the original shapes</span>
</span><span id="ElectraForAggregatePrediction.forward-1502"><a href="#ElectraForAggregatePrediction.forward-1502"><span class="linenos">1502</span></a>        <span class="n">original_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_ids_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">input_ids_tensor</span> <span class="ow">in</span> <span class="n">input_id_tensors</span><span class="p">]</span>
</span><span id="ElectraForAggregatePrediction.forward-1503"><a href="#ElectraForAggregatePrediction.forward-1503"><span class="linenos">1503</span></a>
</span><span id="ElectraForAggregatePrediction.forward-1504"><a href="#ElectraForAggregatePrediction.forward-1504"><span class="linenos">1504</span></a>        <span class="c1"># Step 2: Concatenate the tensors along the first dimension</span>
</span><span id="ElectraForAggregatePrediction.forward-1505"><a href="#ElectraForAggregatePrediction.forward-1505"><span class="linenos">1505</span></a>        <span class="n">flattened_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_id_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.forward-1506"><a href="#ElectraForAggregatePrediction.forward-1506"><span class="linenos">1506</span></a>        <span class="n">flattened_attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">attention_mask_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.forward-1507"><a href="#ElectraForAggregatePrediction.forward-1507"><span class="linenos">1507</span></a>
</span><span id="ElectraForAggregatePrediction.forward-1508"><a href="#ElectraForAggregatePrediction.forward-1508"><span class="linenos">1508</span></a>        <span class="n">discriminator_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">electra</span><span class="p">(</span>
</span><span id="ElectraForAggregatePrediction.forward-1509"><a href="#ElectraForAggregatePrediction.forward-1509"><span class="linenos">1509</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">flattened_input_ids</span><span class="p">,</span>
</span><span id="ElectraForAggregatePrediction.forward-1510"><a href="#ElectraForAggregatePrediction.forward-1510"><span class="linenos">1510</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">flattened_attention_mask</span><span class="p">,</span>
</span><span id="ElectraForAggregatePrediction.forward-1511"><a href="#ElectraForAggregatePrediction.forward-1511"><span class="linenos">1511</span></a>        <span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.forward-1512"><a href="#ElectraForAggregatePrediction.forward-1512"><span class="linenos">1512</span></a>
</span><span id="ElectraForAggregatePrediction.forward-1513"><a href="#ElectraForAggregatePrediction.forward-1513"><span class="linenos">1513</span></a>        <span class="c1"># collect all token embeddings </span>
</span><span id="ElectraForAggregatePrediction.forward-1514"><a href="#ElectraForAggregatePrediction.forward-1514"><span class="linenos">1514</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">discriminator_hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ElectraForAggregatePrediction.forward-1515"><a href="#ElectraForAggregatePrediction.forward-1515"><span class="linenos">1515</span></a>        <span class="c1"># collect the sequence embeddings, only assuming the first token is a seq token</span>
</span><span id="ElectraForAggregatePrediction.forward-1516"><a href="#ElectraForAggregatePrediction.forward-1516"><span class="linenos">1516</span></a>        <span class="n">sequence_embeddings</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="ElectraForAggregatePrediction.forward-1517"><a href="#ElectraForAggregatePrediction.forward-1517"><span class="linenos">1517</span></a>        <span class="c1"># logits is the real valued prediction</span>
</span><span id="ElectraForAggregatePrediction.forward-1518"><a href="#ElectraForAggregatePrediction.forward-1518"><span class="linenos">1518</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">sequence_embeddings</span><span class="p">,</span> <span class="n">original_shapes</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.forward-1519"><a href="#ElectraForAggregatePrediction.forward-1519"><span class="linenos">1519</span></a>
</span><span id="ElectraForAggregatePrediction.forward-1520"><a href="#ElectraForAggregatePrediction.forward-1520"><span class="linenos">1520</span></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ElectraForAggregatePrediction.forward-1521"><a href="#ElectraForAggregatePrediction.forward-1521"><span class="linenos">1521</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1522"><a href="#ElectraForAggregatePrediction.forward-1522"><span class="linenos">1522</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1523"><a href="#ElectraForAggregatePrediction.forward-1523"><span class="linenos">1523</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1524"><a href="#ElectraForAggregatePrediction.forward-1524"><span class="linenos">1524</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;regression&quot;</span>
</span><span id="ElectraForAggregatePrediction.forward-1525"><a href="#ElectraForAggregatePrediction.forward-1525"><span class="linenos">1525</span></a>                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span> <span class="ow">or</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">):</span>
</span><span id="ElectraForAggregatePrediction.forward-1526"><a href="#ElectraForAggregatePrediction.forward-1526"><span class="linenos">1526</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;single_label_classification&quot;</span>
</span><span id="ElectraForAggregatePrediction.forward-1527"><a href="#ElectraForAggregatePrediction.forward-1527"><span class="linenos">1527</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1528"><a href="#ElectraForAggregatePrediction.forward-1528"><span class="linenos">1528</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>
</span><span id="ElectraForAggregatePrediction.forward-1529"><a href="#ElectraForAggregatePrediction.forward-1529"><span class="linenos">1529</span></a>
</span><span id="ElectraForAggregatePrediction.forward-1530"><a href="#ElectraForAggregatePrediction.forward-1530"><span class="linenos">1530</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1531"><a href="#ElectraForAggregatePrediction.forward-1531"><span class="linenos">1531</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePrediction.forward-1532"><a href="#ElectraForAggregatePrediction.forward-1532"><span class="linenos">1532</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1533"><a href="#ElectraForAggregatePrediction.forward-1533"><span class="linenos">1533</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</span><span id="ElectraForAggregatePrediction.forward-1534"><a href="#ElectraForAggregatePrediction.forward-1534"><span class="linenos">1534</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1535"><a href="#ElectraForAggregatePrediction.forward-1535"><span class="linenos">1535</span></a>                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.forward-1536"><a href="#ElectraForAggregatePrediction.forward-1536"><span class="linenos">1536</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;single_label_classification&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1537"><a href="#ElectraForAggregatePrediction.forward-1537"><span class="linenos">1537</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePrediction.forward-1538"><a href="#ElectraForAggregatePrediction.forward-1538"><span class="linenos">1538</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ElectraForAggregatePrediction.forward-1539"><a href="#ElectraForAggregatePrediction.forward-1539"><span class="linenos">1539</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;multi_label_classification&quot;</span><span class="p">:</span>
</span><span id="ElectraForAggregatePrediction.forward-1540"><a href="#ElectraForAggregatePrediction.forward-1540"><span class="linenos">1540</span></a>                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="ElectraForAggregatePrediction.forward-1541"><a href="#ElectraForAggregatePrediction.forward-1541"><span class="linenos">1541</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="ElectraForAggregatePrediction.forward-1542"><a href="#ElectraForAggregatePrediction.forward-1542"><span class="linenos">1542</span></a>
</span><span id="ElectraForAggregatePrediction.forward-1543"><a href="#ElectraForAggregatePrediction.forward-1543"><span class="linenos">1543</span></a>        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Performs the forward pass of the Electra model with aggregate prediction.</p>

<h2 id="parameters">Parameters</h2>

<p>input_ids : List[List[Tensor]]
    A batch of input token IDs.
attention_mask : List[List[Tensor]]
    A batch of attention masks corresponding to the input IDs.
labels : Optional[torch.Tensor], optional
    Ground truth labels for the input sequences (default is None).</p>

<h2 id="returns">Returns</h2>

<p>Any
    The loss (if labels are provided) and logits.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>transformers.models.electra.modeling_electra.ElectraPreTrainedModel</dt>
                                <dd id="ElectraForAggregatePrediction.config_class" class="variable">config_class</dd>
                <dd id="ElectraForAggregatePrediction.load_tf_weights" class="function">load_tf_weights</dd>
                <dd id="ElectraForAggregatePrediction.base_model_prefix" class="variable">base_model_prefix</dd>
                <dd id="ElectraForAggregatePrediction.supports_gradient_checkpointing" class="variable">supports_gradient_checkpointing</dd>

            </div>
            <div><dt>transformers.modeling_utils.PreTrainedModel</dt>
                                <dd id="ElectraForAggregatePrediction.main_input_name" class="variable">main_input_name</dd>
                <dd id="ElectraForAggregatePrediction.model_tags" class="variable">model_tags</dd>
                <dd id="ElectraForAggregatePrediction.is_parallelizable" class="variable">is_parallelizable</dd>
                <dd id="ElectraForAggregatePrediction.dummy_inputs" class="variable">dummy_inputs</dd>
                <dd id="ElectraForAggregatePrediction.framework" class="variable">framework</dd>
                <dd id="ElectraForAggregatePrediction.name_or_path" class="variable">name_or_path</dd>
                <dd id="ElectraForAggregatePrediction.warnings_issued" class="variable">warnings_issued</dd>
                <dd id="ElectraForAggregatePrediction.generation_config" class="variable">generation_config</dd>
                <dd id="ElectraForAggregatePrediction.post_init" class="function">post_init</dd>
                <dd id="ElectraForAggregatePrediction.dequantize" class="function">dequantize</dd>
                <dd id="ElectraForAggregatePrediction.add_model_tags" class="function">add_model_tags</dd>
                <dd id="ElectraForAggregatePrediction.base_model" class="variable">base_model</dd>
                <dd id="ElectraForAggregatePrediction.can_generate" class="function">can_generate</dd>
                <dd id="ElectraForAggregatePrediction.enable_input_require_grads" class="function">enable_input_require_grads</dd>
                <dd id="ElectraForAggregatePrediction.disable_input_require_grads" class="function">disable_input_require_grads</dd>
                <dd id="ElectraForAggregatePrediction.get_input_embeddings" class="function">get_input_embeddings</dd>
                <dd id="ElectraForAggregatePrediction.set_input_embeddings" class="function">set_input_embeddings</dd>
                <dd id="ElectraForAggregatePrediction.get_output_embeddings" class="function">get_output_embeddings</dd>
                <dd id="ElectraForAggregatePrediction.tie_weights" class="function">tie_weights</dd>
                <dd id="ElectraForAggregatePrediction.resize_token_embeddings" class="function">resize_token_embeddings</dd>
                <dd id="ElectraForAggregatePrediction.resize_position_embeddings" class="function">resize_position_embeddings</dd>
                <dd id="ElectraForAggregatePrediction.get_position_embeddings" class="function">get_position_embeddings</dd>
                <dd id="ElectraForAggregatePrediction.init_weights" class="function">init_weights</dd>
                <dd id="ElectraForAggregatePrediction.prune_heads" class="function">prune_heads</dd>
                <dd id="ElectraForAggregatePrediction.gradient_checkpointing_enable" class="function">gradient_checkpointing_enable</dd>
                <dd id="ElectraForAggregatePrediction.gradient_checkpointing_disable" class="function">gradient_checkpointing_disable</dd>
                <dd id="ElectraForAggregatePrediction.is_gradient_checkpointing" class="variable">is_gradient_checkpointing</dd>
                <dd id="ElectraForAggregatePrediction.save_pretrained" class="function">save_pretrained</dd>
                <dd id="ElectraForAggregatePrediction.push_to_hub" class="function">push_to_hub</dd>
                <dd id="ElectraForAggregatePrediction.get_memory_footprint" class="function">get_memory_footprint</dd>
                <dd id="ElectraForAggregatePrediction.cuda" class="function">cuda</dd>
                <dd id="ElectraForAggregatePrediction.to" class="function">to</dd>
                <dd id="ElectraForAggregatePrediction.half" class="function">half</dd>
                <dd id="ElectraForAggregatePrediction.float" class="function">float</dd>
                <dd id="ElectraForAggregatePrediction.from_pretrained" class="function">from_pretrained</dd>
                <dd id="ElectraForAggregatePrediction.retrieve_modules_from_names" class="function">retrieve_modules_from_names</dd>
                <dd id="ElectraForAggregatePrediction.register_for_auto_class" class="function">register_for_auto_class</dd>
                <dd id="ElectraForAggregatePrediction.to_bettertransformer" class="function">to_bettertransformer</dd>
                <dd id="ElectraForAggregatePrediction.reverse_bettertransformer" class="function">reverse_bettertransformer</dd>
                <dd id="ElectraForAggregatePrediction.warn_if_padding_and_no_attention_mask" class="function">warn_if_padding_and_no_attention_mask</dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ElectraForAggregatePrediction.dump_patches" class="variable">dump_patches</dd>
                <dd id="ElectraForAggregatePrediction.training" class="variable">training</dd>
                <dd id="ElectraForAggregatePrediction.call_super_init" class="variable">call_super_init</dd>
                <dd id="ElectraForAggregatePrediction.register_buffer" class="function">register_buffer</dd>
                <dd id="ElectraForAggregatePrediction.register_parameter" class="function">register_parameter</dd>
                <dd id="ElectraForAggregatePrediction.add_module" class="function">add_module</dd>
                <dd id="ElectraForAggregatePrediction.register_module" class="function">register_module</dd>
                <dd id="ElectraForAggregatePrediction.get_submodule" class="function">get_submodule</dd>
                <dd id="ElectraForAggregatePrediction.get_parameter" class="function">get_parameter</dd>
                <dd id="ElectraForAggregatePrediction.get_buffer" class="function">get_buffer</dd>
                <dd id="ElectraForAggregatePrediction.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ElectraForAggregatePrediction.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ElectraForAggregatePrediction.apply" class="function">apply</dd>
                <dd id="ElectraForAggregatePrediction.ipu" class="function">ipu</dd>
                <dd id="ElectraForAggregatePrediction.xpu" class="function">xpu</dd>
                <dd id="ElectraForAggregatePrediction.cpu" class="function">cpu</dd>
                <dd id="ElectraForAggregatePrediction.type" class="function">type</dd>
                <dd id="ElectraForAggregatePrediction.double" class="function">double</dd>
                <dd id="ElectraForAggregatePrediction.bfloat16" class="function">bfloat16</dd>
                <dd id="ElectraForAggregatePrediction.to_empty" class="function">to_empty</dd>
                <dd id="ElectraForAggregatePrediction.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ElectraForAggregatePrediction.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ElectraForAggregatePrediction.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ElectraForAggregatePrediction.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ElectraForAggregatePrediction.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ElectraForAggregatePrediction.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ElectraForAggregatePrediction.state_dict" class="function">state_dict</dd>
                <dd id="ElectraForAggregatePrediction.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ElectraForAggregatePrediction.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ElectraForAggregatePrediction.parameters" class="function">parameters</dd>
                <dd id="ElectraForAggregatePrediction.named_parameters" class="function">named_parameters</dd>
                <dd id="ElectraForAggregatePrediction.buffers" class="function">buffers</dd>
                <dd id="ElectraForAggregatePrediction.named_buffers" class="function">named_buffers</dd>
                <dd id="ElectraForAggregatePrediction.children" class="function">children</dd>
                <dd id="ElectraForAggregatePrediction.named_children" class="function">named_children</dd>
                <dd id="ElectraForAggregatePrediction.modules" class="function">modules</dd>
                <dd id="ElectraForAggregatePrediction.named_modules" class="function">named_modules</dd>
                <dd id="ElectraForAggregatePrediction.train" class="function">train</dd>
                <dd id="ElectraForAggregatePrediction.eval" class="function">eval</dd>
                <dd id="ElectraForAggregatePrediction.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ElectraForAggregatePrediction.zero_grad" class="function">zero_grad</dd>
                <dd id="ElectraForAggregatePrediction.share_memory" class="function">share_memory</dd>
                <dd id="ElectraForAggregatePrediction.extra_repr" class="function">extra_repr</dd>
                <dd id="ElectraForAggregatePrediction.compile" class="function">compile</dd>

            </div>
            <div><dt>transformers.modeling_utils.ModuleUtilsMixin</dt>
                                <dd id="ElectraForAggregatePrediction.add_memory_hooks" class="function">add_memory_hooks</dd>
                <dd id="ElectraForAggregatePrediction.reset_memory_hooks_state" class="function">reset_memory_hooks_state</dd>
                <dd id="ElectraForAggregatePrediction.device" class="variable">device</dd>
                <dd id="ElectraForAggregatePrediction.dtype" class="variable">dtype</dd>
                <dd id="ElectraForAggregatePrediction.invert_attention_mask" class="function">invert_attention_mask</dd>
                <dd id="ElectraForAggregatePrediction.create_extended_attention_mask_for_decoder" class="function">create_extended_attention_mask_for_decoder</dd>
                <dd id="ElectraForAggregatePrediction.get_extended_attention_mask" class="function">get_extended_attention_mask</dd>
                <dd id="ElectraForAggregatePrediction.get_head_mask" class="function">get_head_mask</dd>
                <dd id="ElectraForAggregatePrediction.num_parameters" class="function">num_parameters</dd>
                <dd id="ElectraForAggregatePrediction.estimate_tokens" class="function">estimate_tokens</dd>
                <dd id="ElectraForAggregatePrediction.floating_point_ops" class="function">floating_point_ops</dd>

            </div>
            <div><dt>transformers.generation.utils.GenerationMixin</dt>
                                <dd id="ElectraForAggregatePrediction.prepare_inputs_for_generation" class="function">prepare_inputs_for_generation</dd>
                <dd id="ElectraForAggregatePrediction.compute_transition_scores" class="function">compute_transition_scores</dd>
                <dd id="ElectraForAggregatePrediction.generate" class="function">generate</dd>
                <dd id="ElectraForAggregatePrediction.heal_tokens" class="function">heal_tokens</dd>
                <dd id="ElectraForAggregatePrediction.contrastive_search" class="function">contrastive_search</dd>

            </div>
            <div><dt>transformers.integrations.peft.PeftAdapterMixin</dt>
                                <dd id="ElectraForAggregatePrediction.load_adapter" class="function">load_adapter</dd>
                <dd id="ElectraForAggregatePrediction.add_adapter" class="function">add_adapter</dd>
                <dd id="ElectraForAggregatePrediction.set_adapter" class="function">set_adapter</dd>
                <dd id="ElectraForAggregatePrediction.disable_adapters" class="function">disable_adapters</dd>
                <dd id="ElectraForAggregatePrediction.enable_adapters" class="function">enable_adapters</dd>
                <dd id="ElectraForAggregatePrediction.active_adapters" class="function">active_adapters</dd>
                <dd id="ElectraForAggregatePrediction.active_adapter" class="function">active_adapter</dd>
                <dd id="ElectraForAggregatePrediction.get_adapter_state_dict" class="function">get_adapter_state_dict</dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>